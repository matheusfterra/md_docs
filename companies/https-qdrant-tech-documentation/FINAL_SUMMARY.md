# Estrutura de Diretórios
```plaintext
├── FINAL_SUMMARY.md
├── http-qdrant-tech.md
├── https-code-search-qdrant-tech.md
├── https-demo-qdrant-tech.md
├── https-food-discovery-qdrant-tech.md
├── https-qdrant-tech-about-us.md
├── https-qdrant-tech-advanced-search.md
├── https-qdrant-tech-ai-agents-ai-agents.md
├── https-qdrant-tech-ai-agents.md
├── https-qdrant-tech-articles-agentic-rag.md
├── https-qdrant-tech-articles-batch-vector-search-with-qdrant.md
├── https-qdrant-tech-articles-binary-quantization-openai.md
├── https-qdrant-tech-articles-binary-quantization.md
├── https-qdrant-tech-articles-cross-encoder-integration-gsoc.md
├── https-qdrant-tech-articles-data-exploration.md
├── https-qdrant-tech-articles-data-privacy.md
├── https-qdrant-tech-articles-dedicated-vector-search.md
├── https-qdrant-tech-articles-detecting-coffee-anomalies.md
├── https-qdrant-tech-articles-dimension-reduction-qsoc.md
├── https-qdrant-tech-articles-discovery-search.md
├── https-qdrant-tech-articles-distance-based-exploration.md
├── https-qdrant-tech-articles-ecosystem.md
├── https-qdrant-tech-articles-fastembed.md
├── https-qdrant-tech-articles-filtrable-hnsw.md
├── https-qdrant-tech-articles-food-discovery-demo.md
├── https-qdrant-tech-articles-gridstore-key-value-storage.md
├── https-qdrant-tech-articles-hybrid-search.md
├── https-qdrant-tech-articles-immutable-data-structures.md
├── https-qdrant-tech-articles-indexing-optimization.md
├── https-qdrant-tech-articles-io-uring.md
├── https-qdrant-tech-articles-machine-learning.md
├── https-qdrant-tech-articles-memory-consumption.md
├── https-qdrant-tech-articles-modern-sparse-neural-retrieval.md
├── https-qdrant-tech-articles-multitenancy.md
├── https-qdrant-tech-articles-neural-search-tutorial.md
├── https-qdrant-tech-articles-practicle-examples.md
├── https-qdrant-tech-articles-product-quantization-clustering.md
├── https-qdrant-tech-articles-product-quantization-cutting-the-vector-into-pieces.md
├── https-qdrant-tech-articles-product-quantization-full-process.md
├── https-qdrant-tech-articles-product-quantization-how-does-product-quantization-work.md
├── https-qdrant-tech-articles-product-quantization-measuring-the-distance.md
├── https-qdrant-tech-articles-product-quantization-product-quantization-benchmarks.md
├── https-qdrant-tech-articles-product-quantization-product-quantization-vs-scalar-quantization.md
├── https-qdrant-tech-articles-product-quantization-using-qdrant-for-product-quantization.md
├── https-qdrant-tech-articles-product-quantization-what-is-product-quantization.md
├── https-qdrant-tech-articles-product-quantization.md
├── https-qdrant-tech-articles-qdrant-internals.md
├── https-qdrant-tech-articles-rag-and-genai.md
├── https-qdrant-tech-articles-rapid-rag-optimization-with-qdrant-and-quotient.md
├── https-qdrant-tech-articles-scalar-quantization-accessing-best-practices.md
├── https-qdrant-tech-articles-scalar-quantization-benchmarks.md
├── https-qdrant-tech-articles-scalar-quantization-oversampling-and-rescoring.md
├── https-qdrant-tech-articles-scalar-quantization-scalar-quantization.md
├── https-qdrant-tech-articles-scalar-quantization-theoretical-background.md
├── https-qdrant-tech-articles-scalar-quantization.md
├── https-qdrant-tech-articles-search-as-you-type.md
├── https-qdrant-tech-articles-search-feedback-loop.md
├── https-qdrant-tech-articles-semantic-cache-ai-data-retrieval.md
├── https-qdrant-tech-articles-serverless.md
├── https-qdrant-tech-articles-sparse-vectors.md
├── https-qdrant-tech-articles-storing-multiple-vectors-per-object-in-qdrant.md
├── https-qdrant-tech-articles-vector-search-filtering.md
├── https-qdrant-tech-articles-vector-search-manuals.md
├── https-qdrant-tech-articles-vector-search-resource-optimization.md
├── https-qdrant-tech-articles-vector-similarity-beyond-search.md
├── https-qdrant-tech-articles-web-ui-gsoc.md
├── https-qdrant-tech-articles-what-are-embeddings.md
├── https-qdrant-tech-articles-what-is-a-vector-database.md
├── https-qdrant-tech-articles-what-is-vector-quantization-1-initial-quantized-search.md
├── https-qdrant-tech-articles-what-is-vector-quantization-1-what-is-scalar-quantization.md
├── https-qdrant-tech-articles-what-is-vector-quantization-2-oversampling.md
├── https-qdrant-tech-articles-what-is-vector-quantization-2-what-is-binary-quantization.md
├── https-qdrant-tech-articles-what-is-vector-quantization-3-rescoring-with-original-vectors.md
├── https-qdrant-tech-articles-what-is-vector-quantization-3-what-is-product-quantization.md
├── https-qdrant-tech-articles-what-is-vector-quantization-4-reranking.md
├── https-qdrant-tech-articles-what-is-vector-quantization-distributing-resources-between-disk-memory.md
├── https-qdrant-tech-articles-what-is-vector-quantization-learn-more.md
├── https-qdrant-tech-articles-what-is-vector-quantization-performance-of-quantized-vs-non-quantized-data.md
├── https-qdrant-tech-articles-what-is-vector-quantization-rescoring-oversampling-and-reranking.md
├── https-qdrant-tech-articles-what-is-vector-quantization-speeding-up-rescoring-with-io-uring.md
├── https-qdrant-tech-articles-what-is-vector-quantization-switching-between-quantization-methods.md
├── https-qdrant-tech-articles-what-is-vector-quantization-wrapping-up.md
├── https-qdrant-tech-articles-what-is-vector-quantization.md
├── https-qdrant-tech-articles-why-rust.md
├── https-qdrant-tech-articles.md
├── https-qdrant-tech-benchmarks-are-we-biased.md
├── https-qdrant-tech-benchmarks-benchmarking-vector-databases.md
├── https-qdrant-tech-benchmarks-benchmarks-faq.md
├── https-qdrant-tech-benchmarks-filter-result-2023-02-03-json.md
├── https-qdrant-tech-benchmarks-filtered-results.md
├── https-qdrant-tech-benchmarks-filtered-search-benchmark.md
├── https-qdrant-tech-benchmarks-how-to-contribute.md
├── https-qdrant-tech-benchmarks-how-to-read-the-results.md
├── https-qdrant-tech-benchmarks-how-to-reproduce-the-benchmark.md
├── https-qdrant-tech-benchmarks-how-we-select-hardware.md
├── https-qdrant-tech-benchmarks-latency-vs-rps.md
├── https-qdrant-tech-benchmarks-observations.md
├── https-qdrant-tech-benchmarks-results-1-100-thread-2024-06-15-json.md
├── https-qdrant-tech-benchmarks-setup.md
├── https-qdrant-tech-benchmarks-single-node-benchmarks.md
├── https-qdrant-tech-benchmarks-single-node-speed-benchmark-2022.md
├── https-qdrant-tech-benchmarks-single-node-speed-benchmark.md
├── https-qdrant-tech-benchmarks-tested-datasets.md
├── https-qdrant-tech-benchmarks-what-about-closed-source-saas-platforms.md
├── https-qdrant-tech-benchmarks-what-do-we-measure.md
├── https-qdrant-tech-benchmarks-why-filtering-is-not-trivial.md
├── https-qdrant-tech-benchmarks-why-we-decided-to-test-with-the-python-client.md
├── https-qdrant-tech-benchmarks-why-you-are-not-comparing-with-faiss-or-annoy.md
├── https-qdrant-tech-benchmarks.md
├── https-qdrant-tech-blog-case-study-dailymotion.md
├── https-qdrant-tech-blog-case-study-deutsche-telekom.md
├── https-qdrant-tech-blog-case-study-hubspot.md
├── https-qdrant-tech-blog-case-study-kairoswealth.md
├── https-qdrant-tech-blog-case-study-kern.md
├── https-qdrant-tech-blog-case-study-mixpeek.md
├── https-qdrant-tech-blog-case-study-nyris.md
├── https-qdrant-tech-blog-case-study-qatech.md
├── https-qdrant-tech-blog-case-study-sprinklr.md
├── https-qdrant-tech-blog-case-study-visua.md
├── https-qdrant-tech-blog-case-study-voiceflow.md
├── https-qdrant-tech-blog-colpali-qdrant-optimization.md
├── https-qdrant-tech-blog-dust-and-qdrant.md
├── https-qdrant-tech-blog-enterprise-vector-search.md
├── https-qdrant-tech-blog-human-language-ai-models.md
├── https-qdrant-tech-blog-iris-agent-qdrant.md
├── https-qdrant-tech-blog-metadata-deasy-labs.md
├── https-qdrant-tech-blog-page-10.md
├── https-qdrant-tech-blog-page-2.md
├── https-qdrant-tech-blog-page-3.md
├── https-qdrant-tech-blog-page-4.md
├── https-qdrant-tech-blog-page-5.md
├── https-qdrant-tech-blog-page-6.md
├── https-qdrant-tech-blog-page-7.md
├── https-qdrant-tech-blog-page-8.md
├── https-qdrant-tech-blog-page-9.md
├── https-qdrant-tech-blog-qdrant-1-13-x.md
├── https-qdrant-tech-blog-qdrant-n8n-beyond-simple-similarity-search.md
├── https-qdrant-tech-blog-qdrant-soc2-type2-audit.md
├── https-qdrant-tech-blog-satellite-vector-broadcasting.md
├── https-qdrant-tech-blog-static-embeddings.md
├── https-qdrant-tech-blog-webinar-crewai-qdrant-obsidian.md
├── https-qdrant-tech-blog-webinar-vibe-coding-rag.md
├── https-qdrant-tech-blog.md
├── https-qdrant-tech-cloud.md
├── https-qdrant-tech-community.md
├── https-qdrant-tech-contact-us.md
├── https-qdrant-tech-customers.md
├── https-qdrant-tech-data-analysis-anomaly-detection.md
├── https-qdrant-tech-demo.md
├── https-qdrant-tech-documentation-advanced-tutorials-code-search.md
├── https-qdrant-tech-documentation-advanced-tutorials-collaborative-filtering.md
├── https-qdrant-tech-documentation-advanced-tutorials-pdf-retrieval-at-scale.md
├── https-qdrant-tech-documentation-advanced-tutorials.md
├── https-qdrant-tech-documentation-agentic-rag-crewai-zoom.md
├── https-qdrant-tech-documentation-beginner-tutorials-hybrid-search-fastembed.md
├── https-qdrant-tech-documentation-beginner-tutorials-neural-search.md
├── https-qdrant-tech-documentation-beginner-tutorials-retrieval-quality.md
├── https-qdrant-tech-documentation-beginner-tutorials-search-beginners.md
├── https-qdrant-tech-documentation-beginner-tutorials.md
├── https-qdrant-tech-documentation-cloud-authentication.md
├── https-qdrant-tech-documentation-cloud-backups.md
├── https-qdrant-tech-documentation-cloud-cluster-scaling.md
├── https-qdrant-tech-documentation-cloud-qdrant-cloud-setup-enterprise-single-sign-on-sso.md
├── https-qdrant-tech-documentation-concepts-collections.md
├── https-qdrant-tech-documentation-concepts-explore.md
├── https-qdrant-tech-documentation-concepts-filtering-full-text-match.md
├── https-qdrant-tech-documentation-concepts-filtering-geo-bounding-box.md
├── https-qdrant-tech-documentation-concepts-filtering-geo-radius.md
├── https-qdrant-tech-documentation-concepts-filtering-match.md
├── https-qdrant-tech-documentation-concepts-filtering-nested-key.md
├── https-qdrant-tech-documentation-concepts-filtering-range.md
├── https-qdrant-tech-documentation-concepts-filtering.md
├── https-qdrant-tech-documentation-concepts-hybrid-queries.md
├── https-qdrant-tech-documentation-concepts-indexing-filtrable-index.md
├── https-qdrant-tech-documentation-concepts-indexing-full-text-index.md
├── https-qdrant-tech-documentation-concepts-indexing-idf-modifier.md
├── https-qdrant-tech-documentation-concepts-indexing-indexing.md
├── https-qdrant-tech-documentation-concepts-indexing-on-disk-payload-index.md
├── https-qdrant-tech-documentation-concepts-indexing-parameterized-index.md
├── https-qdrant-tech-documentation-concepts-indexing-payload-index.md
├── https-qdrant-tech-documentation-concepts-indexing-principal-index.md
├── https-qdrant-tech-documentation-concepts-indexing-sparse-vector-index.md
├── https-qdrant-tech-documentation-concepts-indexing-tenant-index.md
├── https-qdrant-tech-documentation-concepts-indexing-vector-index.md
├── https-qdrant-tech-documentation-concepts-indexing.md
├── https-qdrant-tech-documentation-concepts-optimizer.md
├── https-qdrant-tech-documentation-concepts-payload-bool.md
├── https-qdrant-tech-documentation-concepts-payload-datetime.md
├── https-qdrant-tech-documentation-concepts-payload-float.md
├── https-qdrant-tech-documentation-concepts-payload-geo.md
├── https-qdrant-tech-documentation-concepts-payload-integer.md
├── https-qdrant-tech-documentation-concepts-payload-keyword.md
├── https-qdrant-tech-documentation-concepts-payload-uuid.md
├── https-qdrant-tech-documentation-concepts-payload.md
├── https-qdrant-tech-documentation-concepts-points.md
├── https-qdrant-tech-documentation-concepts-search-query-planning.md
├── https-qdrant-tech-documentation-concepts-search.md
├── https-qdrant-tech-documentation-concepts-snapshots.md
├── https-qdrant-tech-documentation-concepts-storage.md
├── https-qdrant-tech-documentation-concepts-vectors.md
├── https-qdrant-tech-documentation-concepts.md
├── https-qdrant-tech-documentation-database-tutorials-async-api.md
├── https-qdrant-tech-documentation-database-tutorials-automate-filtering-with-llms.md
├── https-qdrant-tech-documentation-database-tutorials-bulk-upload.md
├── https-qdrant-tech-documentation-database-tutorials-create-snapshot.md
├── https-qdrant-tech-documentation-database-tutorials-huggingface-datasets.md
├── https-qdrant-tech-documentation-database-tutorials-large-scale-search.md
├── https-qdrant-tech-documentation-database-tutorials.md
├── https-qdrant-tech-documentation-embeddings.md
├── https-qdrant-tech-documentation-faq-database-optimization.md
├── https-qdrant-tech-documentation-faq-qdrant-fundamentals.md
├── https-qdrant-tech-documentation-frameworks-autogen.md
├── https-qdrant-tech-documentation-frameworks-crewai.md
├── https-qdrant-tech-documentation-frameworks-langgraph.md
├── https-qdrant-tech-documentation-frameworks-swarm.md
├── https-qdrant-tech-documentation-frameworks.md
├── https-qdrant-tech-documentation-guides-administration.md
├── https-qdrant-tech-documentation-guides-capacity-planning.md
├── https-qdrant-tech-documentation-guides-common-errors.md
├── https-qdrant-tech-documentation-guides-configuration.md
├── https-qdrant-tech-documentation-guides-distributed-deployment.md
├── https-qdrant-tech-documentation-guides-installation.md
├── https-qdrant-tech-documentation-guides-monitoring.md
├── https-qdrant-tech-documentation-guides-multiple-partitions.md
├── https-qdrant-tech-documentation-guides-optimize.md
├── https-qdrant-tech-documentation-guides-quantization-accuracy-tuning.md
├── https-qdrant-tech-documentation-guides-quantization-binary-quantization-as-hamming-distance.md
├── https-qdrant-tech-documentation-guides-quantization-binary-quantization.md
├── https-qdrant-tech-documentation-guides-quantization-how-to-choose-the-right-quantization-method.md
├── https-qdrant-tech-documentation-guides-quantization-memory-and-speed-tuning.md
├── https-qdrant-tech-documentation-guides-quantization-product-quantization.md
├── https-qdrant-tech-documentation-guides-quantization-quantization-tips.md
├── https-qdrant-tech-documentation-guides-quantization-quantization.md
├── https-qdrant-tech-documentation-guides-quantization-scalar-quantization.md
├── https-qdrant-tech-documentation-guides-quantization-searching-with-quantization.md
├── https-qdrant-tech-documentation-guides-quantization-setting-up-binary-quantization.md
├── https-qdrant-tech-documentation-guides-quantization-setting-up-product-quantization.md
├── https-qdrant-tech-documentation-guides-quantization-setting-up-quantization-in-qdrant.md
├── https-qdrant-tech-documentation-guides-quantization-setting-up-scalar-quantization.md
├── https-qdrant-tech-documentation-guides-quantization.md
├── https-qdrant-tech-documentation-guides-running-with-gpu.md
├── https-qdrant-tech-documentation-guides-security.md
├── https-qdrant-tech-documentation-guides-usage-statistics.md
├── https-qdrant-tech-documentation-guides.md
├── https-qdrant-tech-documentation-hybrid-cloud.md
├── https-qdrant-tech-documentation-interfaces-api-reference.md
├── https-qdrant-tech-documentation-interfaces.md
├── https-qdrant-tech-documentation-overview-vector-search.md
├── https-qdrant-tech-documentation-overview.md
├── https-qdrant-tech-documentation-quantization-setting-up-quantization-in-qdrant.md
├── https-qdrant-tech-documentation-quick-start.md
├── https-qdrant-tech-documentation-quickstart-cloud.md
├── https-qdrant-tech-documentation-quickstart.md
├── https-qdrant-tech-documentation-search-query-planning.md
├── https-qdrant-tech-documentation-tutorials-multimodal-search-fastembed.md
├── https-qdrant-tech-documentation-tutorials.md
├── https-qdrant-tech-documentation-web-ui.md
├── https-qdrant-tech-documentation.md
├── https-qdrant-tech-enterprise-solutions.md
├── https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-articles-product-quantization-md.md
├── https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-articles-scalar-quantization-md.md
├── https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-articles-what-is-quantization-md.md
├── https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-documentation-concepts-indexing-md.md
├── https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-documentation-guides-quantization-md.md
├── https-qdrant-tech-guides-distributed-deployment.md
├── https-qdrant-tech-hybrid-cloud.md
├── https-qdrant-tech-legal-impressum.md
├── https-qdrant-tech-legal-privacy-policy.md
├── https-qdrant-tech-legal-terms-and-conditions.md
├── https-qdrant-tech-misc-qdrant-security-public-key-asc.md
├── https-qdrant-tech-partners.md
├── https-qdrant-tech-pricing.md
├── https-qdrant-tech-private-cloud.md
├── https-qdrant-tech-qdrant-for-startups-form.md
├── https-qdrant-tech-qdrant-for-startups.md
├── https-qdrant-tech-qdrant-vector-database.md
├── https-qdrant-tech-rag-rag-evaluation-guide.md
├── https-qdrant-tech-rag.md
├── https-qdrant-tech-recommendations.md
├── https-qdrant-tech-security-bug-bounty-program.md
├── https-qdrant-tech-solutions.md
├── https-qdrant-tech-stars.md
├── https-qdrant-tech-subscribe.md
├── https-qdrant-tech.md
├── https-try-qdrant-tech-5-minute-rag-hslang-en.md
├── https-try-qdrant-tech-agentic-rag-crewai-hslang-en.md
├── https-try-qdrant-tech-ai-agents-webinar-hslang-en.md
├── https-try-qdrant-tech-build-advanced-agents-with-llamaindex-and-qdrant-hslang-en.md
├── https-try-qdrant-tech-colpali-webinar-hslang-en.md
├── https-try-qdrant-tech-deepseek-hslang-en.md
├── https-try-qdrant-tech-deutsche-telekom-talk-hslang-en.md
├── https-try-qdrant-tech-events.md
├── https-try-qdrant-tech-llm-rag-hslang-en.md
└── https-try-qdrant-tech-mcp-agent-interoperability-hslang-en.md
```
                    ---
                    ## 📄 `FINAL_SUMMARY.md`
                    ```md
                    # Estrutura de Diretórios
```plaintext
├── http-qdrant-tech.md
├── https-code-search-qdrant-tech.md
├── https-demo-qdrant-tech.md
├── https-food-discovery-qdrant-tech.md
├── https-qdrant-tech-about-us.md
├── https-qdrant-tech-advanced-search.md
├── https-qdrant-tech-ai-agents-ai-agents.md
├── https-qdrant-tech-ai-agents.md
├── https-qdrant-tech-articles-agentic-rag.md
├── https-qdrant-tech-articles-batch-vector-search-with-qdrant.md
├── https-qdrant-tech-articles-binary-quantization-openai.md
├── https-qdrant-tech-articles-binary-quantization.md
├── https-qdrant-tech-articles-cross-encoder-integration-gsoc.md
├── https-qdrant-tech-articles-data-exploration.md
├── https-qdrant-tech-articles-data-privacy.md
├── https-qdrant-tech-articles-dedicated-vector-search.md
├── https-qdrant-tech-articles-detecting-coffee-anomalies.md
├── https-qdrant-tech-articles-dimension-reduction-qsoc.md
├── https-qdrant-tech-articles-discovery-search.md
├── https-qdrant-tech-articles-distance-based-exploration.md
├── https-qdrant-tech-articles-ecosystem.md
├── https-qdrant-tech-articles-fastembed.md
├── https-qdrant-tech-articles-filtrable-hnsw.md
├── https-qdrant-tech-articles-food-discovery-demo.md
├── https-qdrant-tech-articles-gridstore-key-value-storage.md
├── https-qdrant-tech-articles-hybrid-search.md
├── https-qdrant-tech-articles-immutable-data-structures.md
├── https-qdrant-tech-articles-indexing-optimization.md
├── https-qdrant-tech-articles-io-uring.md
├── https-qdrant-tech-articles-machine-learning.md
├── https-qdrant-tech-articles-memory-consumption.md
├── https-qdrant-tech-articles-modern-sparse-neural-retrieval.md
├── https-qdrant-tech-articles-multitenancy.md
├── https-qdrant-tech-articles-neural-search-tutorial.md
├── https-qdrant-tech-articles-practicle-examples.md
├── https-qdrant-tech-articles-product-quantization-clustering.md
├── https-qdrant-tech-articles-product-quantization-cutting-the-vector-into-pieces.md
├── https-qdrant-tech-articles-product-quantization-full-process.md
├── https-qdrant-tech-articles-product-quantization-how-does-product-quantization-work.md
├── https-qdrant-tech-articles-product-quantization-measuring-the-distance.md
├── https-qdrant-tech-articles-product-quantization-product-quantization-benchmarks.md
├── https-qdrant-tech-articles-product-quantization-product-quantization-vs-scalar-quantization.md
├── https-qdrant-tech-articles-product-quantization-using-qdrant-for-product-quantization.md
├── https-qdrant-tech-articles-product-quantization-what-is-product-quantization.md
├── https-qdrant-tech-articles-product-quantization.md
├── https-qdrant-tech-articles-qdrant-internals.md
├── https-qdrant-tech-articles-rag-and-genai.md
├── https-qdrant-tech-articles-rapid-rag-optimization-with-qdrant-and-quotient.md
├── https-qdrant-tech-articles-scalar-quantization-accessing-best-practices.md
├── https-qdrant-tech-articles-scalar-quantization-benchmarks.md
├── https-qdrant-tech-articles-scalar-quantization-oversampling-and-rescoring.md
├── https-qdrant-tech-articles-scalar-quantization-scalar-quantization.md
├── https-qdrant-tech-articles-scalar-quantization-theoretical-background.md
├── https-qdrant-tech-articles-scalar-quantization.md
├── https-qdrant-tech-articles-search-as-you-type.md
├── https-qdrant-tech-articles-search-feedback-loop.md
├── https-qdrant-tech-articles-semantic-cache-ai-data-retrieval.md
├── https-qdrant-tech-articles-serverless.md
├── https-qdrant-tech-articles-sparse-vectors.md
├── https-qdrant-tech-articles-storing-multiple-vectors-per-object-in-qdrant.md
├── https-qdrant-tech-articles-vector-search-filtering.md
├── https-qdrant-tech-articles-vector-search-manuals.md
├── https-qdrant-tech-articles-vector-search-resource-optimization.md
├── https-qdrant-tech-articles-vector-similarity-beyond-search.md
├── https-qdrant-tech-articles-web-ui-gsoc.md
├── https-qdrant-tech-articles-what-are-embeddings.md
├── https-qdrant-tech-articles-what-is-a-vector-database.md
├── https-qdrant-tech-articles-what-is-vector-quantization-1-initial-quantized-search.md
├── https-qdrant-tech-articles-what-is-vector-quantization-1-what-is-scalar-quantization.md
├── https-qdrant-tech-articles-what-is-vector-quantization-2-oversampling.md
├── https-qdrant-tech-articles-what-is-vector-quantization-2-what-is-binary-quantization.md
├── https-qdrant-tech-articles-what-is-vector-quantization-3-rescoring-with-original-vectors.md
├── https-qdrant-tech-articles-what-is-vector-quantization-3-what-is-product-quantization.md
├── https-qdrant-tech-articles-what-is-vector-quantization-4-reranking.md
├── https-qdrant-tech-articles-what-is-vector-quantization-distributing-resources-between-disk-memory.md
├── https-qdrant-tech-articles-what-is-vector-quantization-learn-more.md
├── https-qdrant-tech-articles-what-is-vector-quantization-performance-of-quantized-vs-non-quantized-data.md
├── https-qdrant-tech-articles-what-is-vector-quantization-rescoring-oversampling-and-reranking.md
├── https-qdrant-tech-articles-what-is-vector-quantization-speeding-up-rescoring-with-io-uring.md
├── https-qdrant-tech-articles-what-is-vector-quantization-switching-between-quantization-methods.md
├── https-qdrant-tech-articles-what-is-vector-quantization-wrapping-up.md
├── https-qdrant-tech-articles-what-is-vector-quantization.md
├── https-qdrant-tech-articles-why-rust.md
├── https-qdrant-tech-articles.md
├── https-qdrant-tech-benchmarks-are-we-biased.md
├── https-qdrant-tech-benchmarks-benchmarking-vector-databases.md
├── https-qdrant-tech-benchmarks-benchmarks-faq.md
├── https-qdrant-tech-benchmarks-filter-result-2023-02-03-json.md
├── https-qdrant-tech-benchmarks-filtered-results.md
├── https-qdrant-tech-benchmarks-filtered-search-benchmark.md
├── https-qdrant-tech-benchmarks-how-to-contribute.md
├── https-qdrant-tech-benchmarks-how-to-read-the-results.md
├── https-qdrant-tech-benchmarks-how-to-reproduce-the-benchmark.md
├── https-qdrant-tech-benchmarks-how-we-select-hardware.md
├── https-qdrant-tech-benchmarks-latency-vs-rps.md
├── https-qdrant-tech-benchmarks-observations.md
├── https-qdrant-tech-benchmarks-results-1-100-thread-2024-06-15-json.md
├── https-qdrant-tech-benchmarks-setup.md
├── https-qdrant-tech-benchmarks-single-node-benchmarks.md
├── https-qdrant-tech-benchmarks-single-node-speed-benchmark-2022.md
├── https-qdrant-tech-benchmarks-single-node-speed-benchmark.md
├── https-qdrant-tech-benchmarks-tested-datasets.md
├── https-qdrant-tech-benchmarks-what-about-closed-source-saas-platforms.md
├── https-qdrant-tech-benchmarks-what-do-we-measure.md
├── https-qdrant-tech-benchmarks-why-filtering-is-not-trivial.md
├── https-qdrant-tech-benchmarks-why-we-decided-to-test-with-the-python-client.md
├── https-qdrant-tech-benchmarks-why-you-are-not-comparing-with-faiss-or-annoy.md
├── https-qdrant-tech-benchmarks.md
├── https-qdrant-tech-blog-case-study-dailymotion.md
├── https-qdrant-tech-blog-case-study-deutsche-telekom.md
├── https-qdrant-tech-blog-case-study-hubspot.md
├── https-qdrant-tech-blog-case-study-kairoswealth.md
├── https-qdrant-tech-blog-case-study-kern.md
├── https-qdrant-tech-blog-case-study-mixpeek.md
├── https-qdrant-tech-blog-case-study-nyris.md
├── https-qdrant-tech-blog-case-study-qatech.md
├── https-qdrant-tech-blog-case-study-sprinklr.md
├── https-qdrant-tech-blog-case-study-visua.md
├── https-qdrant-tech-blog-case-study-voiceflow.md
├── https-qdrant-tech-blog-colpali-qdrant-optimization.md
├── https-qdrant-tech-blog-dust-and-qdrant.md
├── https-qdrant-tech-blog-enterprise-vector-search.md
├── https-qdrant-tech-blog-human-language-ai-models.md
├── https-qdrant-tech-blog-iris-agent-qdrant.md
├── https-qdrant-tech-blog-metadata-deasy-labs.md
├── https-qdrant-tech-blog-page-10.md
├── https-qdrant-tech-blog-page-2.md
├── https-qdrant-tech-blog-page-3.md
├── https-qdrant-tech-blog-page-4.md
├── https-qdrant-tech-blog-page-5.md
├── https-qdrant-tech-blog-page-6.md
├── https-qdrant-tech-blog-page-7.md
├── https-qdrant-tech-blog-page-8.md
├── https-qdrant-tech-blog-page-9.md
├── https-qdrant-tech-blog-qdrant-1-13-x.md
├── https-qdrant-tech-blog-qdrant-n8n-beyond-simple-similarity-search.md
├── https-qdrant-tech-blog-qdrant-soc2-type2-audit.md
├── https-qdrant-tech-blog-satellite-vector-broadcasting.md
├── https-qdrant-tech-blog-static-embeddings.md
├── https-qdrant-tech-blog-webinar-crewai-qdrant-obsidian.md
├── https-qdrant-tech-blog-webinar-vibe-coding-rag.md
├── https-qdrant-tech-blog.md
├── https-qdrant-tech-cloud.md
├── https-qdrant-tech-community.md
├── https-qdrant-tech-contact-us.md
├── https-qdrant-tech-customers.md
├── https-qdrant-tech-data-analysis-anomaly-detection.md
├── https-qdrant-tech-demo.md
├── https-qdrant-tech-documentation-advanced-tutorials-code-search.md
├── https-qdrant-tech-documentation-advanced-tutorials-collaborative-filtering.md
├── https-qdrant-tech-documentation-advanced-tutorials-pdf-retrieval-at-scale.md
├── https-qdrant-tech-documentation-advanced-tutorials.md
├── https-qdrant-tech-documentation-agentic-rag-crewai-zoom.md
├── https-qdrant-tech-documentation-beginner-tutorials-hybrid-search-fastembed.md
├── https-qdrant-tech-documentation-beginner-tutorials-neural-search.md
├── https-qdrant-tech-documentation-beginner-tutorials-retrieval-quality.md
├── https-qdrant-tech-documentation-beginner-tutorials-search-beginners.md
├── https-qdrant-tech-documentation-beginner-tutorials.md
├── https-qdrant-tech-documentation-cloud-authentication.md
├── https-qdrant-tech-documentation-cloud-backups.md
├── https-qdrant-tech-documentation-cloud-cluster-scaling.md
├── https-qdrant-tech-documentation-cloud-qdrant-cloud-setup-enterprise-single-sign-on-sso.md
├── https-qdrant-tech-documentation-concepts-collections.md
├── https-qdrant-tech-documentation-concepts-explore.md
├── https-qdrant-tech-documentation-concepts-filtering-full-text-match.md
├── https-qdrant-tech-documentation-concepts-filtering-geo-bounding-box.md
├── https-qdrant-tech-documentation-concepts-filtering-geo-radius.md
├── https-qdrant-tech-documentation-concepts-filtering-match.md
├── https-qdrant-tech-documentation-concepts-filtering-nested-key.md
├── https-qdrant-tech-documentation-concepts-filtering-range.md
├── https-qdrant-tech-documentation-concepts-filtering.md
├── https-qdrant-tech-documentation-concepts-hybrid-queries.md
├── https-qdrant-tech-documentation-concepts-indexing-filtrable-index.md
├── https-qdrant-tech-documentation-concepts-indexing-full-text-index.md
├── https-qdrant-tech-documentation-concepts-indexing-idf-modifier.md
├── https-qdrant-tech-documentation-concepts-indexing-indexing.md
├── https-qdrant-tech-documentation-concepts-indexing-on-disk-payload-index.md
├── https-qdrant-tech-documentation-concepts-indexing-parameterized-index.md
├── https-qdrant-tech-documentation-concepts-indexing-payload-index.md
├── https-qdrant-tech-documentation-concepts-indexing-principal-index.md
├── https-qdrant-tech-documentation-concepts-indexing-sparse-vector-index.md
├── https-qdrant-tech-documentation-concepts-indexing-tenant-index.md
├── https-qdrant-tech-documentation-concepts-indexing-vector-index.md
├── https-qdrant-tech-documentation-concepts-indexing.md
├── https-qdrant-tech-documentation-concepts-optimizer.md
├── https-qdrant-tech-documentation-concepts-payload-bool.md
├── https-qdrant-tech-documentation-concepts-payload-datetime.md
├── https-qdrant-tech-documentation-concepts-payload-float.md
├── https-qdrant-tech-documentation-concepts-payload-geo.md
├── https-qdrant-tech-documentation-concepts-payload-integer.md
├── https-qdrant-tech-documentation-concepts-payload-keyword.md
├── https-qdrant-tech-documentation-concepts-payload-uuid.md
├── https-qdrant-tech-documentation-concepts-payload.md
├── https-qdrant-tech-documentation-concepts-points.md
├── https-qdrant-tech-documentation-concepts-search-query-planning.md
├── https-qdrant-tech-documentation-concepts-search.md
├── https-qdrant-tech-documentation-concepts-snapshots.md
├── https-qdrant-tech-documentation-concepts-storage.md
├── https-qdrant-tech-documentation-concepts-vectors.md
├── https-qdrant-tech-documentation-concepts.md
├── https-qdrant-tech-documentation-database-tutorials-async-api.md
├── https-qdrant-tech-documentation-database-tutorials-automate-filtering-with-llms.md
├── https-qdrant-tech-documentation-database-tutorials-bulk-upload.md
├── https-qdrant-tech-documentation-database-tutorials-create-snapshot.md
├── https-qdrant-tech-documentation-database-tutorials-huggingface-datasets.md
├── https-qdrant-tech-documentation-database-tutorials-large-scale-search.md
├── https-qdrant-tech-documentation-database-tutorials.md
├── https-qdrant-tech-documentation-embeddings.md
├── https-qdrant-tech-documentation-faq-database-optimization.md
├── https-qdrant-tech-documentation-faq-qdrant-fundamentals.md
├── https-qdrant-tech-documentation-frameworks-autogen.md
├── https-qdrant-tech-documentation-frameworks-crewai.md
├── https-qdrant-tech-documentation-frameworks-langgraph.md
├── https-qdrant-tech-documentation-frameworks-swarm.md
├── https-qdrant-tech-documentation-frameworks.md
├── https-qdrant-tech-documentation-guides-administration.md
├── https-qdrant-tech-documentation-guides-capacity-planning.md
├── https-qdrant-tech-documentation-guides-common-errors.md
├── https-qdrant-tech-documentation-guides-configuration.md
├── https-qdrant-tech-documentation-guides-distributed-deployment.md
├── https-qdrant-tech-documentation-guides-installation.md
├── https-qdrant-tech-documentation-guides-monitoring.md
├── https-qdrant-tech-documentation-guides-multiple-partitions.md
├── https-qdrant-tech-documentation-guides-optimize.md
├── https-qdrant-tech-documentation-guides-quantization-accuracy-tuning.md
├── https-qdrant-tech-documentation-guides-quantization-binary-quantization-as-hamming-distance.md
├── https-qdrant-tech-documentation-guides-quantization-binary-quantization.md
├── https-qdrant-tech-documentation-guides-quantization-how-to-choose-the-right-quantization-method.md
├── https-qdrant-tech-documentation-guides-quantization-memory-and-speed-tuning.md
├── https-qdrant-tech-documentation-guides-quantization-product-quantization.md
├── https-qdrant-tech-documentation-guides-quantization-quantization-tips.md
├── https-qdrant-tech-documentation-guides-quantization-quantization.md
├── https-qdrant-tech-documentation-guides-quantization-scalar-quantization.md
├── https-qdrant-tech-documentation-guides-quantization-searching-with-quantization.md
├── https-qdrant-tech-documentation-guides-quantization-setting-up-binary-quantization.md
├── https-qdrant-tech-documentation-guides-quantization-setting-up-product-quantization.md
├── https-qdrant-tech-documentation-guides-quantization-setting-up-quantization-in-qdrant.md
├── https-qdrant-tech-documentation-guides-quantization-setting-up-scalar-quantization.md
├── https-qdrant-tech-documentation-guides-quantization.md
├── https-qdrant-tech-documentation-guides-running-with-gpu.md
├── https-qdrant-tech-documentation-guides-security.md
├── https-qdrant-tech-documentation-guides-usage-statistics.md
├── https-qdrant-tech-documentation-guides.md
├── https-qdrant-tech-documentation-hybrid-cloud.md
├── https-qdrant-tech-documentation-interfaces-api-reference.md
├── https-qdrant-tech-documentation-interfaces.md
├── https-qdrant-tech-documentation-overview-vector-search.md
├── https-qdrant-tech-documentation-overview.md
├── https-qdrant-tech-documentation-quantization-setting-up-quantization-in-qdrant.md
├── https-qdrant-tech-documentation-quick-start.md
├── https-qdrant-tech-documentation-quickstart-cloud.md
├── https-qdrant-tech-documentation-quickstart.md
├── https-qdrant-tech-documentation-search-query-planning.md
├── https-qdrant-tech-documentation-tutorials-multimodal-search-fastembed.md
├── https-qdrant-tech-documentation-tutorials.md
├── https-qdrant-tech-documentation-web-ui.md
├── https-qdrant-tech-documentation.md
├── https-qdrant-tech-enterprise-solutions.md
├── https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-articles-product-quantization-md.md
├── https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-articles-scalar-quantization-md.md
├── https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-articles-what-is-quantization-md.md
├── https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-documentation-concepts-indexing-md.md
├── https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-documentation-guides-quantization-md.md
├── https-qdrant-tech-guides-distributed-deployment.md
├── https-qdrant-tech-hybrid-cloud.md
├── https-qdrant-tech-legal-impressum.md
├── https-qdrant-tech-legal-privacy-policy.md
├── https-qdrant-tech-legal-terms-and-conditions.md
├── https-qdrant-tech-misc-qdrant-security-public-key-asc.md
├── https-qdrant-tech-partners.md
├── https-qdrant-tech-pricing.md
├── https-qdrant-tech-private-cloud.md
├── https-qdrant-tech-qdrant-for-startups-form.md
├── https-qdrant-tech-qdrant-for-startups.md
├── https-qdrant-tech-qdrant-vector-database.md
├── https-qdrant-tech-rag-rag-evaluation-guide.md
├── https-qdrant-tech-rag.md
├── https-qdrant-tech-recommendations.md
├── https-qdrant-tech-security-bug-bounty-program.md
├── https-qdrant-tech-solutions.md
├── https-qdrant-tech-stars.md
├── https-qdrant-tech-subscribe.md
├── https-qdrant-tech.md
├── https-try-qdrant-tech-5-minute-rag-hslang-en.md
├── https-try-qdrant-tech-agentic-rag-crewai-hslang-en.md
├── https-try-qdrant-tech-ai-agents-webinar-hslang-en.md
├── https-try-qdrant-tech-build-advanced-agents-with-llamaindex-and-qdrant-hslang-en.md
├── https-try-qdrant-tech-colpali-webinar-hslang-en.md
├── https-try-qdrant-tech-deepseek-hslang-en.md
├── https-try-qdrant-tech-deutsche-telekom-talk-hslang-en.md
├── https-try-qdrant-tech-events.md
├── https-try-qdrant-tech-llm-rag-hslang-en.md
└── https-try-qdrant-tech-mcp-agent-interoperability-hslang-en.md
```
                    ---
                    ## 📄 `http-qdrant-tech.md`
                    ```md
                    # http://qdrant.tech/
# High-Performance Vector Search at Scale
Powering the next generation of AI applications with advanced, open-source vector similarity search technology.
[Learn More](https://qdrant.tech/qdrant-vector-database/)
![Hero image: an astronaut looking at dark hole from the planet surface.](https://qdrant.tech/img/hero-home-illustration-x1.png)
Qdrant Powers Thousands of Top AI Solutions. [Customer Stories](https://qdrant.tech/customers/)
## AI Meets Advanced Vector Search
The leading open source vector database and similarity search engine designed to handle high-dimensional vectors for performance and massive-scale AI applications.
[All features](https://qdrant.tech/qdrant-vector-database/)
#### Cloud-Native Scalability & High-Availability
Enterprise-grade Managed Cloud. Vertical and horizontal scaling and zero-downtime upgrades.
[Qdrant Cloud](https://qdrant.tech/cloud/)
###### Ease of Use & Simple Deployment
Quick deployment in any environment with Docker and a lean API for easy integration, ideal for local testing.
[Quick Start Guide](https://qdrant.tech/documentation/quick-start/)
###### Cost Efficiency with Storage Options
Dramatically reduce memory usage with built-in compression options and offload data to disk.
[Quantization](https://qdrant.tech/articles/scalar-quantization/)
###### Rust-Powered Reliability & Performance
Purpose built in Rust for unmatched speed and reliability even when processing billions of vectors.
[Benchmarks](https://qdrant.tech/benchmarks/)
### Our Customers Words
[Customer Stories](https://qdrant.tech/customers/)
![Hubspot](https://qdrant.tech/img/brands/hubspot.svg)
“Qdrant powers our demanding recommendation and RAG applications. We chose it for its ease of deployment and high performance at scale, and have been consistently impressed with its results.”
![Srubin Sethu Madhavan](https://qdrant.tech/img/customers/srubin-sethu-madhavan.svg)
Srubin Sethu Madhavan
Technical Lead II at Hubspot
![Bayer](https://qdrant.tech/img/brands/bayer.svg)
“VectorStores are definitely here to stay, the objects in the world around us from image, sound, video and text become easily universal and searchable thanks to the embedding models. I personally recommend Qdrant. We have been using it for a while and couldn't be happier.“
![Hooman Sedghamiz](https://qdrant.tech/img/customers/hooman-sedghamiz.svg)
Hooman Sedghamiz
Director Al /ML, Bayer
![CB Insights](https://qdrant.tech/img/brands/cb-insights.svg)
“We looked at all the big options out there right now for vector databases, with our focus on ease of use, performance, pricing, and communication. **Qdrant came out on top in each category...** ultimately, it wasn't much of a contest.”
![Alex Webb](https://qdrant.tech/img/customers/alex-webb.svg)
Alex Webb
Director of Engineering, CB Insights
![Bosch](https://qdrant.tech/img/brands/bosch.svg)
“With Qdrant, we found the missing piece to develop our own provider independent multimodal generative AI platform on enterprise scale.”
![Jeremy T. & Daly Singh](https://qdrant.tech/img/customers/jeremy-t.png) ![Jeremy T. & Daly Singh](https://qdrant.tech/img/customers/daly-singh.png)
Jeremy T. & Daly Singh
Generative AI Expert & Product Owner, Bosch
![Cognizant](https://qdrant.tech/img/brands/cognizant.svg)
“We LOVE Qdrant! The exceptional engineering, strong business value, and outstanding team behind the product drove our choice. Thank you for your great contribution to the technology community!”
![Kyle Tobin](https://qdrant.tech/img/customers/kyle-tobin.png)
Kyle Tobin
Principal, Cognizant
See what our community is saying on our 
## Integrations
Qdrant integrates with all leading [embeddings](https://qdrant.tech/documentation/embeddings/) and [frameworks](https://qdrant.tech/documentation/frameworks/).
[See Integrations](https://qdrant.tech/documentation/frameworks/)
### Deploy Qdrant locally with Docker
Get started with our [Quick Start Guide](https://qdrant.tech/documentation/quick-start/), or our main 
`1 docker pull qdrant/qdrant  
2 docker run -p 6333:6333 qdrant/qdrant  
`
## Vectors in Action
Turn embeddings or neural network encoders into full-fledged applications for matching, searching, recommending, and more.
#### Advanced Search
Elevate your apps with advanced search capabilities. Qdrant excels in processing high-dimensional data, enabling nuanced similarity searches, and understanding semantics in depth. Qdrant also handles multimodal data with fast and accurate search algorithms.
[Learn More](https://qdrant.tech/advanced-search/)
#### Recommendation Systems
Create highly responsive and personalized recommendation systems with tailored suggestions. Qdrant’s Recommendation API offers great flexibility, featuring options such as best score recommendation strategy. This enables new scenarios of using multiple vectors in a single query to impact result relevancy.
[Learn More](https://qdrant.tech/recommendations/)
#### Retrieval Augmented Generation (RAG)
Enhance the quality of AI-generated content. Leverage Qdrant's efficient nearest neighbor search and payload filtering features for retrieval-augmented generation. You can then quickly access relevant vectors and integrate a vast array of data points.
[Learn More](https://qdrant.tech/rag/)
#### Data Analysis and Anomaly Detection
Transform your approach to Data Analysis and Anomaly Detection. Leverage vectors to quickly identify patterns and outliers in complex datasets. This ensures robust and real-time anomaly detection for critical applications.
[Learn More](https://qdrant.tech/data-analysis-anomaly-detection/)
#### AI Agents
Unlock the full potential of your AI agents with Qdrant’s powerful vector search and scalable infrastructure, allowing them to handle complex tasks, adapt in real time, and drive smarter, data-driven outcomes across any environment.
[Learn More](https://qdrant.tech/ai-agents/)
### Get started for free
Turn embeddings or neural network encoders into full-fledged applications for matching, searching, recommending, and more.
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
  * [Qdrant Vector Database](https://qdrant.tech/qdrant-vector-database/)
  * [Qdrant Cloud](https://qdrant.tech/cloud/)
  * [Qdrant Hybrid Cloud](https://qdrant.tech/hybrid-cloud/)
  * [Qdrant Enterprise Solutions](https://qdrant.tech/enterprise-solutions/)
Use Cases
  * [Advanced Search](https://qdrant.tech/advanced-search/)
  * [Recommendation Systems](https://qdrant.tech/recommendations/)
  * [Retrieval Augmented Generation](https://qdrant.tech/rag/)
  * [Data Analysis & Anomaly Detection](https://qdrant.tech/data-analysis-anomaly-detection/)
  * [AI Agents](https://qdrant.tech/ai-agents/)
Developers
  * [Documentation](https://qdrant.tech/documentation/)
  * [Community](https://qdrant.tech/community/)
Resources
  * [Blog](https://qdrant.tech/blog/)
  * [Benchmarks](https://qdrant.tech/benchmarks/)
  * [Articles](https://qdrant.tech/articles/)
  * [Events](https://try.qdrant.tech/events)
  * [Startup Program](https://qdrant.tech/qdrant-for-startups/)
  * [Demos](https://qdrant.tech/demo/)
  * [Bug Bounty](https://qdrant.tech/security/bug-bounty-program/)
Company
  * [About Us](https://qdrant.tech/about-us/)
  * [Customers](https://qdrant.tech/customers/)
  * [Partners](https://qdrant.tech/partners/)
  * [Contact Us](https://qdrant.tech/contact-us/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](http://qdrant.tech/legal/privacy-policy/)[I accept](http://qdrant.tech/)
                    ```

                    ---
                    ## 📄 `https-code-search-qdrant-tech.md`
                    ```md
                    # https://code-search.qdrant.tech/
Search
Try this:
cardinality of should requestgeo condition filterflush WAL
![Qdrant Landing](https://code-search.qdrant.tech/landing.gif)
### Qdrant Code Search Unleashing Semantic Power
Qdrant Code Explorer: Empowering Semantic Searching in Qdrant Repository with Advanced Code Analysis
                    ## 📄 `https-demo-qdrant-tech.md`
                    ```md
                    # https://demo.qdrant.tech/
# Startup Semantic search with Qdrant
This demo uses short descriptions of startups to perform a semantic search.
Neural
Text
Search
Try this:
Qdrant
Wooden furniture
Milk Company
![No results found.](https://demo.qdrant.tech/home.gif)
Enter a query to start searching.
                    ## 📄 `https-food-discovery-qdrant-tech.md`
                    ```md
                    # https://food-discovery.qdrant.tech/
[![Powered by Qdrant](https://food-discovery.qdrant.tech/powered_by_qdrant.svg)](https://qdrant.tech)
Semantic search
## Food Discovery
Here we will show your likes and dislikes
## Recommendation results
Select food items you like and dislike to improve your search results.
New recommendations algorithm
### Spinatisupp rõõsa koorega
## Spinatisupp rõõsa koorega
About Restaurant:
Name: Retrokohvik
Rating: 
Address: Kalda tee 1 C
Close
### 1196．セゾンファクトリー あら挽き胡麻ドレッシング
## 1196．セゾンファクトリー あら挽き胡麻ドレッシング
About Restaurant:
Name: Fukuya Hiroshima Ekimae
Rating: 
Address: 広島市南区松原町9-1 地下一階
Close
### ローストビーフのシーザーサラダS
瑞々しい野菜と当店自慢のローストビーフをのせ、シーザーサラダ仕立てにした一品です。
## ローストビーフのシーザーサラダS
瑞々しい野菜と当店自慢のローストビーフをのせ、シーザーサラダ仕立てにした一品です。
About Restaurant:
Name: Palam Sendai Kokubuncho
Rating: 
Address: This is a virtual venue
Close
### Iced Latte
12oz
## Iced Latte
12oz
About Restaurant:
Name: Coffee Island Αγίου Νικολάου
Rating: 
Address: Agiou Nikolaou 83 
Close
### Side: Nachos with Salsa & Nacho Cheese
Nachos with Salsa & Nacho Cheese
## Side: Nachos with Salsa & Nacho Cheese
Nachos with Salsa & Nacho Cheese
About Restaurant:
Name: Los Tacos Storo
Rating: 
Address: Vitaminveien 11
Close
### Zrinjevac
Umak od rajčice, Mozzarela Fior di Latte, sušena panceta, češnjak, masline
## Zrinjevac
Umak od rajčice, Mozzarela Fior di Latte, sušena panceta, češnjak, masline
About Restaurant:
Name: Pizzeria Park
Rating: 
Address: Martićeva 14D
Close
### Oreo Milkshake
## Oreo Milkshake
About Restaurant:
Name: Carl's Jr. Rødovre
Rating: 
Address: Rødovre Centrum 1M, st. 43
Close
### 34. Kuroi sake 🌶
Rūkyta lašiša, agurkas, svogūnų traškučiai, kremas, čili padažas, sezamų sėklos. 8 vnt.
## 34. Kuroi sake 🌶
Rūkyta lašiša, agurkas, svogūnų traškučiai, kremas, čili padažas, sezamų sėklos. 8 vnt.
About Restaurant:
Name: Sushi Express (Babilonas)
Rating: 
Address: Klaipedos g. 143A
Close
### 国産山椒うな重弁当
山椒のピリッとした辛さや爽やかな香りが、うなぎの美味しさをより引き立ててくれるので、脂がのっているのにさっぱりいただけます。
## 国産山椒うな重弁当
山椒のピリッとした辛さや爽やかな香りが、うなぎの美味しさをより引き立ててくれるので、脂がのっているのにさっぱりいただけます。
About Restaurant:
Name: Unagi Unaoto Akihabara
Address: This is a virtual venue
Close
### 【単品】ロッテリア クラシックビッグ オリジナル
クオーターパウンド（約113g）の100％ビーフパティを、レタス、トマト、スライスオニオン、ピクルス、特製ハニーマスタードソースなどとともに挟んだ、本格バーガー。 ※掲載画像はイメージです。 ※ソースや具材の増減量・追加や抜くことは承っておりません。
## 【単品】ロッテリア クラシックビッグ オリジナル
クオーターパウンド（約113g）の100％ビーフパティを、レタス、トマト、スライスオニオン、ピクルス、特製ハニーマスタードソースなどとともに挟んだ、本格バーガー。 ※掲載画像はイメージです。 ※ソースや具材の増減量・追加や抜くことは承っておりません。
About Restaurant:
Name: LOTTERIA Ginza Crystal Bldg
Rating: 
Address: 東京都中央区銀座4-2-12
Close
### Балийская лапша Ми Горенг
Яичная лапша с королевскими креветками, жареным тофу, снежным крабом, овощами и яичным блинчиком в остром соусе ми горенг, 400 гр
## Балийская лапша Ми Горенг
Яичная лапша с королевскими креветками, жареным тофу, снежным крабом, овощами и яичным блинчиком в остром соусе ми горенг, 400 гр
About Restaurant:
Name: BAO Noodles*Sushi*Bar TSUM
Rating: 
Address: проспект Бухар-Жырау, строение 53/8 ТЦ «ЦУМ»
Close
### シュガーバター
福井県産の国産玄蕎麦100%のガレットです。 発酵バターをたっぷり生地に塗り、砂糖をお好みの甘さで調整させて頂きます。 シンプルながらも毎日でも食べたくなるような一品です。
## シュガーバター
福井県産の国産玄蕎麦100%のガレットです。 発酵バターをたっぷり生地に塗り、砂糖をお好みの甘さで調整させて頂きます。 シンプルながらも毎日でも食べたくなるような一品です。
About Restaurant:
Name: Café et Galette Lilou
Address: 大阪市西区新町1丁目24-1 MIMARU大阪 心斎橋WEST 北側駐車スペース内のキッチンカー
Close
## What are you looking for?
CancelSearch
                    ## 📄 `https-qdrant-tech-about-us.md`
                    ```md
                    # https://qdrant.tech/about-us/
## Building the most efficient, scalable, high-performance vector database on the market
## Our story
#### A paradigm shift is underway in the field of data management and information retrieval.
Today, our world is increasingly dominated by complex, unstructured data like images, audio, video, and text. Traditional ways of retrieving data based on keyword matching are no longer sufficient. Vector databases are designed to handle complex high-dimensional data, unlocking the foundation for pivotal AI applications.
##### In 2021
We started Qdrant with the mission to build the most efficient, scalable, high-performance vector database on the market. Since then we have seen incredible user growth and support from our open-source community with thousands of users and millions of downloads.
###### Today Qdrant powers the most ambitious AI applications, from cutting-edge startups to large-scale enterprises.
## Leadership
André Zayarni
CEO & Co-Founder
Andrey Vasnetsov
CTO & Co-Founder
Fabrizio Schmidt
Product & Engineering
Bastian Hofmann
Enterprise Solutions
Dominik Alberts
Finance
David Myriel
Developer Relations
Manuel Meyer
Growth
## Our Investors
##### Want to build the technology for the next generation of AI applications with us?
Take a look at our open roles. We’re excited to hear from you.
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/about-us/)
                    ## 📄 `https-qdrant-tech-advanced-search.md`
                    ```md
                    # https://qdrant.tech/advanced-search/
# Advanced Search
Dive into next-gen search capabilities with Qdrant, offering a smarter way to deliver precise and tailored content to users, enhancing interaction accuracy and depth.
[Contact Us](https://qdrant.tech/contact-us/)
![Advanced search](https://qdrant.tech/img/vectors/vector-0.svg)
### Search with Qdrant
Qdrant enhances search, offering semantic, similarity, multimodal, and hybrid search capabilities for accurate, user-centric results, serving applications in different industries like e-commerce to healthcare.
![Similarity](https://qdrant.tech/icons/outline/similarity-blue.svg)
###### Semantic Search
Qdrant optimizes similarity search, identifying the closest database items to any query vector for applications like recommendation systems, RAG and image retrieval, enhancing accuracy and user experience.
[Learn More](https://qdrant.tech/documentation/concepts/search/)
![Search text](https://qdrant.tech/icons/outline/search-text-blue.svg)
###### Hybrid Search for Text
By combining dense vector embeddings with sparse vectors e.g. BM25, Qdrant powers semantic search to deliver context-aware results, transcending traditional keyword search by understanding the deeper meaning of data.
[Learn More](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)
![Selection](https://qdrant.tech/icons/outline/selection-blue.svg)
###### Multimodal Search
Qdrant's capability extends to multi-modal search, indexing and retrieving various data forms (text, images, audio) once vectorized, facilitating a comprehensive search experience.
[View Tutorial](https://qdrant.tech/documentation/tutorials/multimodal-search-fastembed/)
![Filter](https://qdrant.tech/icons/outline/filter-blue.svg)
###### Single Stage filtering That Works
Qdrant enhances search speeds and control and context understanding through filtering on any nested entry in our payload. Unique architecture allows Qdrant to avoid expensive pre-filtering and post-filtering stages, making search faster and accurate.
[Learn More](https://qdrant.tech/articles/filtrable-hnsw/)
## Learn how to get started with Qdrant for your search use case
![Startup Semantic Search](https://qdrant.tech/img/advanced-search-use-cases/startup-semantic-search.svg)
###### Startup Semantic Search Demo
The demo showcases semantic search for startup descriptions through SentenceTransformer and Qdrant, comparing neural search's accuracy with traditional searches for better content discovery.
[View Demo](https://demo.qdrant.tech/)
![Multimodal Semantic Search](https://qdrant.tech/img/advanced-search-use-cases/multimodal-semantic-search.svg)
###### Multimodal Semantic Search with FastEmbed
This tutorial shows you how to run a proper multimodal semantic search system with a few lines of code, without the need to annotate the data or train your networks.
[View Tutorial](https://qdrant.tech/documentation/tutorials/multimodal-search-fastembed/)
![Simple Neural Search](https://qdrant.tech/img/advanced-search-use-cases/simple-neural-search.svg)
###### Create a Simple Neural Search Service
This tutorial shows you how to build and deploy your own neural search service.
[View Tutorial](https://qdrant.tech/documentation/beginner-tutorials/neural-search/)
![Image Classification](https://qdrant.tech/img/advanced-search-use-cases/image-classification.svg)
###### Image Classification with Qdrant Vector Semantic Search
In this tutorial, you will learn how a semantic search engine for images can help diagnose different types of skin conditions.
![Semantic Search 101](https://qdrant.tech/img/advanced-search-use-cases/semantic-search-101.svg)
###### Semantic Search 101
Build a semantic search engine for science fiction books in 5 mins.
[View Tutorial](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)
![Create a Hybrid Search Service with FastEmbed](https://qdrant.tech/img/advanced-search-use-cases/hybrid-search-service-fastembed.svg)
###### Create a Hybrid Search Service with FastEmbed
This tutorial guides you through building and deploying your own hybrid search service using FastEmbed.
[View Tutorial](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/advanced-search/)
                    ## 📄 `https-qdrant-tech-ai-agents-ai-agents.md`
                    ```md
                    # https://qdrant.tech/ai-agents/#ai-agents
# AI Agents
Unlock the full potential of your AI agents with Qdrant’s powerful vector search and scalable infrastructure, allowing them to handle complex tasks, adapt in real time, and drive smarter, data-driven outcomes across any environment.
[Learn More](https://qdrant.tech/ai-agents/#ai-agents)
![AI agents chat](https://qdrant.tech/img/vectors/vector-4.svg)
![Dashboard cloud](https://qdrant.tech/img/ai-agents-dashboard-cloud.png)
### AI Agents with Qdrant
AI agents powered by Qdrant leverage advanced vector search to access and retrieve high-dimensional data in real-time, enabling intelligent, Agentic-RAG driven, multi-step decision-making across dynamic environments.
###### Multimodal Data Handling
Qdrant enables AI agents to process and retrieve high-dimensional vectors from diverse data types (text, images, audio), supporting more comprehensive decision-making in multimodal environments.
###### Adaptive Learning
Qdrant supports continuous learning by enabling efficient vector retrieval and updates, allowing agents to learn and evolve based on real-time interactions and new data points.
### Qdrant equips AI agents to adapt, learn, and collaborate efficiently.
![Precision](https://qdrant.tech/icons/outline/precision-blue.svg)
###### Contextual Precision
Qdrant’s hybrid search combines semantic vector search, lexical search, and metadata filtering, enabling AI Agents to retrieve highly relevant and contextually precise information. This enhances decision-making by allowing agents to leverage both meaning-based and keyword-based strategies, ensuring accuracy and relevance for complex queries in dynamic environments.
[Hybrid Search](https://qdrant.tech/articles/hybrid-search/)
![Multitenancy](https://qdrant.tech/icons/outline/multitenancy-blue.svg)
###### Multi-Agent Systems
Qdrant’s scalability and multitenancy ensures that multiple agents can collaborate in distributed systems, enabling seamless coordination and communication - key for Agentic RAG workflows.
[Multitenancy](https://qdrant.tech/articles/multitenancy/)
![Time](https://qdrant.tech/icons/outline/time-blue.svg)
###### Real Time Decision Making
Qdrant’s real-time, advanced vector search enables AI agents to act instantly on live data, which is crucial for time-sensitive, autonomous decision-making.
[HNSW](https://qdrant.tech/articles/filtrable-hnsw/)
![Server rack](https://qdrant.tech/icons/outline/server-rack-blue.svg)
###### Optimized CPU Performance for Embedding Processing
Qdrant’s architecture is optimized for high-throughput embedding processing, minimizing CPU load and preventing performance bottlenecks. This enables AI agents in Agentic RAG workflows to execute complex, multi-step tasks efficiently, ensuring smooth operation even at scale.
[Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/)
![Speedometer](https://qdrant.tech/icons/outline/speedometer-blue.svg)
###### Semantic Cache for Rapid Query Handling
Qdrant enhances AI agent efficiency with semantic caching, which preserves results of queries based on semantic equivalence rather than exact matches. This method reduces query processing times and system load by reusing previously computed answers, essential for high-throughput AI applications.
[Semantic Cache](https://qdrant.tech/articles/semantic-cache-ai-data-retrieval/)
#### Qdrant integrates with the leading AI Agent frameworks
[![LangGraph logo](https://qdrant.tech/img/integrations/integration-lang-graph.svg) LangGraph Framework for managing multi-LLM workflows with structured graphs for AI agents. ](https://qdrant.tech/documentation/frameworks/langgraph/)
[![Open AI logo](https://qdrant.tech/img/integrations/integration-open-ai.svg) Swarm Decentralized platform enabling collaboration among AI agents for task completion. ](https://qdrant.tech/documentation/frameworks/swarm/)
[![Crew AI logo](https://qdrant.tech/img/integrations/integration-crew-ai.svg) CrewAI Team-based AI agent collaboration system orchestrating multi-agent workflows efficiently. ](https://qdrant.tech/documentation/frameworks/crewai/)
[![AutoGen logo](https://qdrant.tech/img/integrations/integration-auto-gen.svg) AutoGen Automation tool for generating AI agent workflows and automating complex tasks. ](https://qdrant.tech/documentation/frameworks/autogen/)
![Training](https://qdrant.tech/icons/outline/training-purple.svg)
On-demand Webinar
### Building Agents with LlamaIndex & Qdrant
Ready to build more advanced AI agents? Watch this webinar to learn how to use LlamaIndex and Qdrant to create intelligent agents capable of handling complex, multi-modal queries in RAG-enabled systems.
![AI agents webinar](https://qdrant.tech/img/ai-agents-webinar.svg)
### Learn how to get started with Qdrant for your AI Agent use case
![Comparing AI agent frameworks](https://qdrant.tech/img/ai-agents-use-cases/comparing-ai-agent-frameworks.svg) ![Comparing AI agent frameworks](https://qdrant.tech/img/ai-agents-use-cases/comparing-ai-agent-frameworks.svg)
###### Comparing AI Agent Frameworks: LangGraph, CrewAI, Swarm, and AutoGen
This guide offers a comparison of key AI agent frameworks, highlighting their strengths and ideal use cases for developers.
[View Guide](https://qdrant.tech/articles/agentic-rag/)
![Open AI agents](https://qdrant.tech/img/ai-agents-use-cases/open-ai-agents.svg) ![Open AI agents](https://qdrant.tech/img/ai-agents-use-cases/open-ai-agents.svg)
###### Building OpenAI Swarm Agents with Qdrant
Learn how to build OpenAI Swarm agents using Qdrant for fast, scalable vector search and real-time actions.
[Read the Docs](https://qdrant.tech/documentation/frameworks/swarm/)
![AI scheduler](https://qdrant.tech/img/ai-agents-use-cases/ai-scheduler.svg) ![AI scheduler](https://qdrant.tech/img/ai-agents-use-cases/ai-scheduler.svg)
###### Building an AI Scheduler with Zoom, CrewAI, and Qdrant
Learn how to build an AI meeting scheduler with Zoom, LlamaIndex, and Qdrant, featuring a hands-on RAG recommendation engine code sample.
[View Tutorial](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)
![Logo](https://qdrant.tech/img/ai-agents-use-cases/customer-logo.svg)
##### QA.tech Case Study: AI Agents for Web Testing
QA.tech enhanced web app testing by deploying AI agents that mimic user interactions. To handle high-speed actions and make real-time decisions, they integrated Qdrant for scalable vector search, allowing for faster and more efficient data proc...
[Read Case Study](https://qdrant.tech/blog/case-study-qatech/)
![Preview](https://qdrant.tech/img/ai-agents-use-cases/case-study.png)
![Training](https://qdrant.tech/icons/outline/training-purple.svg)
On-demand Webinar
### Building AI Agents for personalized recommendations with Qdrant and n8n
Learn in this video how to build an AI-powered recommendation system using Qdrant and n8n. It demonstrates how an AI agent retrieves data from Qdrant's vector database and leverages a large language model (LLM) to generate personalized recommendations based on user inputs.
### Building AI agents?
Apply for the Qdrant for Startups program to access a 20% discount to Qdrant Cloud, our managed cloud service, perks from Hugging Face, LlamaIndex, and Airbyte, and much more.
[Apply Now](https://qdrant.tech/qdrant-for-startups/)
![](https://qdrant.tech/img/ai-agent.svg)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/ai-agents/)
                    ## 📄 `https-qdrant-tech-ai-agents.md`
                    ```md
                    # https://qdrant.tech/ai-agents/
                    ## 📄 `https-qdrant-tech-articles-agentic-rag.md`
                    ```md
                    # https://qdrant.tech/articles/agentic-rag/
### Learn
[Vector Search Manuals](https://qdrant.tech/articles/vector-search-manuals/)
[Qdrant Internals](https://qdrant.tech/articles/qdrant-internals/)
[Data Exploration](https://qdrant.tech/articles/data-exploration/)
[Machine Learning](https://qdrant.tech/articles/machine-learning/)
[RAG & GenAI](https://qdrant.tech/articles/rag-and-genai/)
[Practical Examples](https://qdrant.tech/articles/practicle-examples/)
[Ecosystem](https://qdrant.tech/articles/ecosystem/)
  * [Articles](https://qdrant.tech/articles/)
  * What is Agentic RAG? Building Agents with Qdrant
[](https://qdrant.tech/articles/rag-and-genai/)
# What is Agentic RAG? Building Agents with Qdrant
Kacper Łukawski
·
November 22, 2024
![What is Agentic RAG? Building Agents with Qdrant](https://qdrant.tech/articles_data/agentic-rag/preview/title.jpg)
Standard [Retrieval Augmented Generation](https://qdrant.tech/articles/what-is-rag-in-ai/) follows a predictable, linear path: receive a query, retrieve relevant documents, and generate a response. In many cases that might be enough to solve a particular problem. In the worst case scenario, your LLM will just decide to not answer the question, because the context does not provide enough information.
![Standard, linear RAG pipeline](https://qdrant.tech/articles_data/agentic-rag/linear-rag.png)
On the other hand, we have agents. These systems are given more freedom to act, and can take multiple non-linear steps to achieve a certain goal. There isn’t a single definition of what an agent is, but in general, it is an application that uses LLM and usually some tools to communicate with the outside world. LLMs are used as decision-makers which decide what action to take next. Actions can be anything, but they are usually well-defined and limited to a certain set of possibilities. One of these actions might be to query a vector database, like Qdrant, to retrieve relevant documents, if the context is not enough to make a decision. However, RAG is just a single tool in the agent’s arsenal.
![AI Agent](https://qdrant.tech/articles_data/agentic-rag/ai-agent.png)
## Agentic RAG: Combining RAG with Agents
Since the agent definition is vague, the concept of **Agentic RAG** is also not well-defined. In general, it refers to the combination of RAG with agents. This allows the agent to use external knowledge sources to make decisions, and primarily to decide when the external knowledge is needed. We can describe a system as Agentic RAG if it breaks the linear flow of a standard RAG system, and gives the agent the ability to take multiple steps to achieve a goal.
A simple router that chooses a path to follow is often described as the simplest form of an agent. Such a system has multiple paths with conditions describing when to take a certain path. In the context of Agentic RAG, the agent can decide to query a vector database if the context is not enough to answer, or skip the query if it’s enough, or when the question refers to common knowledge. Alternatively, there might be multiple collections storing different kinds of information, and the agent can decide which collection to query based on the context. The key factor is that the decision of choosing a path is made by the LLM, which is the core of the agent. A routing agent never comes back to the previous step, so it’s ultimately just a conditional decision-making system.
![Routing Agent](https://qdrant.tech/articles_data/agentic-rag/routing-agent.png)
However, routing is just the beginning. Agents can be much more complex, and extreme forms of agents can have complete freedom to act. In such cases, the agent is given a set of tools and can autonomously decide which ones to use, how to use them, and in which order. LLMs are asked to plan and execute actions, and the agent can take multiple steps to achieve a goal, including taking steps back if needed. Such a system does not have to follow a DAG structure (Directed Acyclic Graph), and can have loops that help to self-correct the decisions made in the past. An agentic RAG system built in that manner can have tools not only to query a vector database, but also to play with the query, summarize the results, or even generate new data to answer the question. Options are endless, but there are some common patterns that can be observed in the wild.
![Autonomous Agent](https://qdrant.tech/articles_data/agentic-rag/autonomous-agent.png)
### Solving Information Retrieval Problems with LLMs
Generally speaking, tools exposed in an agentic RAG system are used to solve information retrieval problems which are not new to the search community. LLMs have changed how we approach these problems, but the core of the problem remains the same. What kind of tools you can consider using in an agentic RAG? Here are some examples:
  * **Querying a vector database** - the most common tool used in agentic RAG systems. It allows the agent to retrieve relevant documents based on the query.
  * **Query expansion** - a tool that can be used to improve the query. It can be used to add synonyms, correct typos, or even to generate new queries based on the original one. ![Query expansion example](https://qdrant.tech/articles_data/agentic-rag/query-expansion.png)
  * **Extracting filters** - vector search alone is sometimes not enough. In many cases, you might want to narrow down the results based on specific parameters. This extraction process can automatically identify relevant conditions from the query. Otherwise, your users would have to manually define these search constraints. ![Extracting filters](https://qdrant.tech/articles_data/agentic-rag/extracting-filters.png)
  * **Quality judgement** - knowing the quality of the results for given query can be used to decide whether they are good enough to answer, or if the agent should take another step to improve them somehow. Alternatively it can also admit the failure to provide good response. ![Quality judgement](https://qdrant.tech/articles_data/agentic-rag/quality-judgement.png)
These are just some of the examples, but the list is not exhaustive. For example, your LLM could possibly play with Qdrant search parameters or choose different methods to query it. An example? If your users are searching using some specific keywords, you may prefer sparse vectors to dense vectors, as they are more efficient in such cases. In that case you have to arm your agent with tools to decide when to use sparse vectors and when to use dense vectors. Agent aware of the collection structure can make such decisions easily.
Each of these tools might be a separate agent on its own, and multi-agent systems are not uncommon. In such cases, agents can communicate with each other, and one agent can decide to use another agent to solve a particular problem. Pretty useful component of an agentic RAG is also a human in the loop, which can be used to correct the agent’s decisions, or steer it in the right direction.
## Where are Agents Used?
Agents are an interesting concept, but since they heavily rely on LLMs, they are not applicable to all problems. Using Large Language Models is expensive and tend to be slow, what in many cases, it’s not worth the cost. Standard RAG involves just a single call to the LLM, and the response is generated in a predictable way. Agents, on the other hand, can take multiple steps, and the latency experienced by the user adds up. In many cases, it’s not acceptable. Agentic RAG is probably not that widely applicable in ecommerce search, where the user expects a quick response, but might be fine for customer support, where the user is willing to wait a bit longer for a better answer.
## Which Framework is Best?
There are lots of frameworks available to build agents, and choosing the best one is not easy. It depends on your existing stack or the tools you are familiar with. Some of the most popular LLM libraries have already drifted towards the agent paradigm, and they are offering tools to build them. There are, however, some tools built primarily for agents development, so let’s focus on them.
### LangGraph
Developed by the LangChain team, LangGraph seems like a natural extension for those who already use LangChain for building their RAG systems, and would like to start with agentic RAG.
Surprisingly, LangGraph has nothing to do with Large Language Models on its own. It’s a framework for building graph-based applications in which each **node** is a step of the workflow. Each node takes an application **state** as an input, and produces a modified state as an output. The state is then passed to the next node, and so on. **Edges** between the nodes might be conditional what makes branching possible. Contrary to some DAG-based tool (i.e. Apache Airflow), LangGraph allows for loops in the graph, which makes it possible to implement cyclic workflows, so an agent can achieve self-reflection and self-correction. Theoretically, LangGraph can be used to build any kind of applications in a graph-based manner, not only LLM agents.
Some of the strengths of LangGraph include:
  * **Persistence** - the state of the workflow graph is stored as a checkpoint. That happens at each so-called super-step (which is a single sequential node of a graph). It enables replying certain steps of the workflow, fault-tolerance, and including human-in-the-loop interactions. This mechanism also acts as a **short-term memory** , accessible in a context of a particular workflow execution.
  * **Long-term memory** - LangGraph also has a concept of memories that are shared between different workflow runs. However, this mechanism has to explicitly handled by our nodes. **Qdrant with its semantic search capabilities is often used as a long-term memory layer**.
  * **Multi-agent support** - while there is no separate concept of multi-agent systems in LangGraph, it’s possible to create such an architecture by building a graph that includes multiple agents and some kind of supervisor that makes a decision which agent to use in a given situation. If a node might be anything, then it might be another agent as well.
Some other interesting features of LangGraph include the ability to visualize the graph, automate the retries of failed steps, and include human-in-the-loop interactions.
A minimal example of an agentic RAG could improve the user query, e.g. by fixing typos, expanding it with synonyms, or even generating a new query based on the original one. The agent could then retrieve documents from a vector database based on the improved query, and generate a response. The LangGraph app implementing this approach could look like this:
```
from typing import Sequence
from typing_extensions import TypedDict, Annotated
from langchain_core.messages import BaseMessage
from langgraph.constants import START, END
from langgraph.graph import add_messages, StateGraph
class AgentState(TypedDict):
    # The state of the agent includes at least the messages exchanged between the agent(s) 
    # and the user. It is, however, possible to include other information in the state, as 
    # it depends on the specific agent.
    messages: Annotated[Sequence[BaseMessage], add_messages]
def improve_query(state: AgentState):
    ...
def retrieve_documents(state: AgentState):
    ...
def generate_response(state: AgentState):
    ...
# Building a graph requires defining nodes and building the flow between them with edges.
builder = StateGraph(AgentState)
builder.add_node("improve_query", improve_query)
builder.add_node("retrieve_documents", retrieve_documents)
builder.add_node("generate_response", generate_response)
builder.add_edge(START, "improve_query")
builder.add_edge("improve_query", "retrieve_documents")
builder.add_edge("retrieve_documents", "generate_response")
builder.add_edge("generate_response", END)
# Compiling the graph performs some checks and prepares the graph for execution.
compiled_graph = builder.compile()
# Compiled graph might be invoked with the initial state to start.
compiled_graph.invoke({
    "messages": [
        ("user", "Why Qdrant is the best vector database out there?"),
    ]
})

```
Each node of the process is just a Python function that does certain operation. You can call an LLM of your choice inside of them, if you want to, but there is no assumption about the messages being created by any AI. **LangGraph rather acts as a runtime that launches these functions in a specific order, and passes the state between them**. While 
### CrewAI
CrewAI is another popular choice for building agents, including agentic RAG. It’s a high-level framework that assumes there are some LLM-based agents working together to achieve a common goal. That’s where the “crew” in CrewAI comes from. CrewAI is designed with multi-agent systems in mind. Contrary to LangGraph, the developer does not create a graph of processing, but defines agents and their roles within the crew.
Some of the key concepts of CrewAI include:
  * **Agent** - a unit that has a specific role and goal, controlled by an LLM. It can optionally use some external tools to communicate with the outside world, but generally steered by prompt we provide to the LLM.
  * **Process** - currently either sequential or hierarchical. It defines how the task will be executed by the agents. In a sequential process, agents are executed one after another, while in a hierarchical process, agent is selected by the manager agent, which is responsible for making decisions about which agent to use in a given situation.
  * **Roles and goals** - each agent has a certain role within the crew, and the goal it should aim to achieve. These are set when we define an agent and are used to make decisions about which agent to use in a given situation.
  * **Memory** - an extensive memory system consists of short-term memory, long-term memory, entity memory, and contextual memory that combines the other three. There is also user memory for preferences and personalization. **This is where Qdrant comes into play, as it might be used as a long-term memory layer.**
CrewAI provides a rich set of tools integrated into the framework. That may be a huge advantage for those who want to combine RAG with e.g. code execution, or image generation. The ecosystem is rich, however brining your own tools is not a big deal, as CrewAI is designed to be extensible.
A simple agentic RAG application implemented in CrewAI could look like this:
```
from crewai import Crew, Agent, Task
from crewai.memory.entity.entity_memory import EntityMemory
from crewai.memory.short_term.short_term_memory import ShortTermMemory
from crewai.memory.storage.rag_storage import RAGStorage
class QdrantStorage(RAGStorage):
    ...
response_generator_agent = Agent(
    role="Generate response based on the conversation",
    goal="Provide the best response, or admit when the response is not available.",
    backstory=(
        "I am a response generator agent. I generate "
        "responses based on the conversation."
    ),
    verbose=True,
)
query_reformulation_agent = Agent(
    role="Reformulate the query",
    goal="Rewrite the query to get better results. Fix typos, grammar, word choice, etc.",
    backstory=(
        "I am a query reformulation agent. I reformulate the " 
        "query to get better results."
    ),
    verbose=True,
)
task = Task(
    description="Let me know why Qdrant is the best vector database out there.",
    expected_output="3 bullet points",
    agent=response_generator_agent,
)
crew = Crew(
    agents=[response_generator_agent, query_reformulation_agent],
    tasks=[task],
    memory=True,
    entity_memory=EntityMemory(storage=QdrantStorage("entity")),
    short_term_memory=ShortTermMemory(storage=QdrantStorage("short-term")),
)
crew.kickoff()

```
_Disclaimer: QdrantStorage is not a part of the CrewAI framework, but it’s taken from the Qdrant documentation on[how to integrate Qdrant with CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)._
Although it’s not a technical advantage, CrewAI has a 
### AutoGen
AutoGen emphasizes multi-agent architectures as a fundamental design principle. The framework requires at least two agents in any system to really call an application agentic - typically an assistant and a user proxy exchange messages to achieve a common goal. Sequential chat with more than two agents is also supported, as well as group chat and nested chat for internal dialogue. However, AutoGen does not assume there is a structured state that is passed between the agents, and the chat conversation is the only way to communicate between them.
There are many interesting concepts in the framework, some of them even quite unique:
  * **Tools/functions** - external components that can be used by agents to communicate with the outside world. They are defined as Python callables, and can be used for any external interaction we want to allow the agent to do. Type annotations are used to define the input and output of the tools, and Pydantic models are supported for more complex type schema. AutoGen supports only OpenAI-compatible tool call API for the time being.
  * **Code executors** - built-in code executors include local command, Docker command, and Jupyter. An agent can write and launch code, so theoretically the agents can do anything that can be done in Python. None of the other frameworks made code generation and execution that prominent. Code execution being the first-class citizen in AutoGen is an interesting concept.
Each AutoGen agent uses at least one of the components: human-in-the-loop, code executor, tool executor, or LLM. A simple agentic RAG, based on the conversation of two agents which can retrieve documents from a vector database, or improve the query, could look like this:
```
from os import environ
from autogen import ConversableAgent
from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent
from qdrant_client import QdrantClient
client = QdrantClient(...)
response_generator_agent = ConversableAgent(
    name="response_generator_agent",
    system_message=(
        "You answer user questions based solely on the provided context. You ask to retrieve relevant documents for "
        "your query, or reformulate the query, if it is incorrect in some way."
    ),
    description="A response generator agent that can answer your queries.",
    llm_config={"config_list": [{"model": "gpt-4", "api_key": environ.get("OPENAI_API_KEY")}]},
    human_input_mode="NEVER",
)
user_proxy = RetrieveUserProxyAgent(
    name="retrieval_user",
    llm_config={"config_list": [{"model": "gpt-4", "api_key": environ.get("OPENAI_API_KEY")}]},
    human_input_mode="NEVER",
    retrieve_config={
        "task": "qa",
        "chunk_token_size": 2000,
        "vector_db": "qdrant",
        "db_config": {"client": client},
        "get_or_create": True,
        "overwrite": True,
    },
)
result = user_proxy.initiate_chat(
    response_generator_agent,
    message=user_proxy.message_generator,
    problem="Why Qdrant is the best vector database out there?",
    max_turns=10,
)

```
For those new to agent development, AutoGen offers AutoGen Studio, a low-code interface for prototyping agents. While not intended for production use, it significantly lowers the barrier to entry for experimenting with agent architectures.
![AutoGen Studio](https://qdrant.tech/articles_data/agentic-rag/autogen-studio.png)
It’s worth noting that AutoGen is currently undergoing significant updates, with version 0.4.x in development introducing substantial API changes compared to the stable 0.2.x release. While the framework currently has limited built-in persistence and state management capabilities, these features may evolve in future releases.
### OpenAI Swarm
Unliked the other frameworks described in this article, OpenAI Swarm is an educational project, and it’s not ready for production use. It’s worth mentioning, though, as it’s pretty lightweight and easy to get started with. OpenAI Swarm is an experimental framework for orchestrating multi-agent workflows that focuses on agent coordination through direct handoffs rather than complex orchestration patterns.
With that setup, **agents** are just exchanging messages in a chat, optionally calling some Python functions to communicate with external services, or handing off the conversation to another agent, if the other one seems to be more suitable to answer the question. Each agent has a certain role, defined by the instructions we have to define. We have to decide which LLM will a particular agent use, and a set of functions it can call. For example, **a retrieval agent could use a vector database to retrieve documents** , and return the results to the next agent. That means, there should be a function that performs the semantic search on its behalf, but the model will decide how the query should look like.
Here is how a similar agentic RAG application, implemented in OpenAI Swarm, could look like:
```
from swarm import Swarm, Agent
client = Swarm()
def retrieve_documents(query: str) -> list[str]:
    """
    Retrieve documents based on the query.
    """
    ...
def transfer_to_query_improve_agent():
    return query_improve_agent
query_improve_agent = Agent(
    name="Query Improve Agent",
    instructions=(
        "You are a search expert that takes user queries and improves them to get better results. You fix typos and "
        "extend queries with synonyms, if needed. You never ask the user for more information."
    ),
)
response_generation_agent = Agent(
    name="Response Generation Agent",
    instructions=(
        "You take the whole conversation and generate a final response based on the chat history. "
        "If you don't have enough information, you can retrieve the documents from the knowledge base or "
        "reformulate the query by transferring to other agent. You never ask the user for more information. "
        "You have to always be the last participant of each conversation."
    ),
    functions=[retrieve_documents, transfer_to_query_improve_agent],
)
response = client.run(
    agent=response_generation_agent,
    messages=[
        {
            "role": "user",
            "content": "Why Qdrant is the best vector database out there?"
        }
    ],
)

```
Even though we don’t explicitly define the graph of processing, the agents can still decide to hand off the processing to a different agent. There is no concept of a state, so everything relies on the messages exchanged between different components.
OpenAI Swarm does not focus on integration with external tools, and **if you would like to integrate semantic search with Qdrant, you would have to implement it fully yourself**. Obviously, the library is tightly coupled with OpenAI models, and while using some other ones is possible, it requires some additional work like setting up proxy that will adjust the interface to OpenAI API.
### The winner?
Choosing the best framework for your agentic RAG system depends on your existing stack, team expertise, and the specific requirements of your project. All the described tools are strong contenders, and they are developed at rapid pace. It’s worth keeping an eye on all of them, as they are likely to evolve and improve over time. Eventually, you should be able to build the same processes with any of them, but some of them may be more suitable in a specific ecosystem of the tools you want your agent to interact with.
There are, however, some important factors to consider when choosing a framework for your agentic RAG system:
  * **Human-in-the-loop** - even though we aim to build autonomous agents, it’s often important to include the feedback from the human, so our agents cannot perform malicious actions.
  * **Observability** - how easy it is to debug the system, and how easy it is to understand what’s happening inside. Especially important, since we are dealing with lots of LLM prompts.
Still, choosing the right toolkit depends on the state of your project, and the specific requirements you have. If you want to integrate your agent with number of external tools, CrewAI might be the best choice, as the set of out-of-the-box integrations is the biggest. However, LangGraph integrates well with LangChain, so if you are familiar with that ecosystem, it may suit you better.
All the frameworks have different approaches to building agents, so it’s worth experimenting with all of them to see which one fits your needs the best. LangGraph and CrewAI are more mature and have more features, while AutoGen and OpenAI Swarm are more lightweight and more experimental. However, **none of the existing frameworks solves all the mentioned Information Retrieval problems** , so you still have to build your own tools to fill the gaps.
## Building Agentic RAG with Qdrant
No matter which framework you choose, Qdrant is a great tool to build agentic RAG systems. Please check out [our integrations](https://qdrant.tech/documentation/frameworks/) to choose the best one for your use case and preferences. The easiest way to start using Qdrant is to use our managed service, 
### Further Reading
See how Qdrant integrates with:
  * [Autogen](https://qdrant.tech/documentation/frameworks/autogen/)
  * [CrewAI](https://qdrant.tech/documentation/frameworks/crewai/)
  * [LangGraph](https://qdrant.tech/documentation/frameworks/langgraph/)
  * [Swarm](https://qdrant.tech/documentation/frameworks/swarm/)
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/agentic-rag.md) this page on GitHub, or 
On this page:
  * [Agentic RAG: Combining RAG with Agents](https://qdrant.tech/articles/agentic-rag/#agentic-rag-combining-rag-with-agents)
    * [Solving Information Retrieval Problems with LLMs](https://qdrant.tech/articles/agentic-rag/#solving-information-retrieval-problems-with-llms)
  * [Where are Agents Used?](https://qdrant.tech/articles/agentic-rag/#where-are-agents-used)
  * [Which Framework is Best?](https://qdrant.tech/articles/agentic-rag/#which-framework-is-best)
    * [LangGraph](https://qdrant.tech/articles/agentic-rag/#langgraph)
    * [CrewAI](https://qdrant.tech/articles/agentic-rag/#crewai)
    * [AutoGen](https://qdrant.tech/articles/agentic-rag/#autogen)
    * [OpenAI Swarm](https://qdrant.tech/articles/agentic-rag/#openai-swarm)
    * [The winner?](https://qdrant.tech/articles/agentic-rag/#the-winner)
  * [Building Agentic RAG with Qdrant](https://qdrant.tech/articles/agentic-rag/#building-agentic-rag-with-qdrant)
    * [Further Reading](https://qdrant.tech/articles/agentic-rag/#further-reading)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/agentic-rag/)
                    ## 📄 `https-qdrant-tech-articles-batch-vector-search-with-qdrant.md`
                    ```md
                    # https://qdrant.tech/articles/batch-vector-search-with-qdrant/
  * [Articles](https://qdrant.tech/articles/)
  * Mastering Batch Search for Vector Optimization
[](https://qdrant.tech/articles/vector-search-manuals/)
# Mastering Batch Search for Vector Optimization
Kacper Łukawski
·
September 26, 2022
![Mastering Batch Search for Vector Optimization](https://qdrant.tech/articles_data/batch-vector-search-with-qdrant/preview/title.jpg)
# How to Optimize Vector Search Using Batch Search in Qdrant 0.10.0
The latest release of Qdrant 0.10.0 has introduced a lot of functionalities that simplify some common tasks. Those new possibilities come with some slightly modified interfaces of the client library. One of the recently introduced features is the possibility to query the collection with [multiple vectors](https://qdrant.tech/blog/storing-multiple-vectors-per-object-in-qdrant/) at once — a batch search mechanism.
There are a lot of scenarios in which you may need to perform multiple non-related tasks at the same time. Previously, you only could send several requests to Qdrant API on your own. But multiple parallel requests may cause significant network overhead and slow down the process, especially in case of poor connection speed.
Now, thanks to the new batch search, you don’t need to worry about that. Qdrant will handle multiple search requests in just one API call and will perform those requests in the most optimal way.
## An example of using batch search to optimize vector search
We’ve used the official Python client to show how the batch search might be integrated with your application. Since there have been some changes in the interfaces of Qdrant 0.10.0, we’ll go step by step.
### Step 1: Creating the collection
The first step is to create a collection with a specified configuration — at least vector size and the distance function used to measure the similarity between vectors.
```
from qdrant_client import QdrantClient
from qdrant_client.conversions.common_types import VectorParams
client = QdrantClient("localhost", 6333)
if not client.collection_exists('test_collection'):
    client.create_collection(
        collection_name="test_collection",
        vectors_config=VectorParams(size=4, distance=Distance.EUCLID),
)

```
## Step 2: Loading the vectors
With the collection created, we can put some vectors into it. We’re going to have just a few examples.
```
vectors = [
    [.1, .0, .0, .0],
    [.0, .1, .0, .0],
    [.0, .0, .1, .0],
    [.0, .0, .0, .1],
    [.1, .0, .1, .0],
    [.0, .1, .0, .1],
    [.1, .1, .0, .0],
    [.0, .0, .1, .1],
    [.1, .1, .1, .1],
]
client.upload_collection(
    collection_name="test_collection",
    vectors=vectors,
)

```
## Step 3: Batch search in a single request
Now we’re ready to start looking for similar vectors, as our collection has some entries. Let’s say we want to find the distance between the selected vector and the most similar database entry and at the same time find the two most similar objects for a different vector query. Up till 0.9, we would need to call the API twice. Now, we can send both requests together:
```
results = client.search_batch(
    collection_name="test_collection",
    requests=[
        SearchRequest(
            vector=[0., 0., 2., 0.],
            limit=1,
        ),
        SearchRequest(
            vector=[0., 0., 0., 0.01],
            with_vector=True,
            limit=2,
        )
    ]
)
# Out: [
#   [ScoredPoint(id=2, version=0, score=1.9, 
#                payload=None, vector=None)],
#   [ScoredPoint(id=3, version=0, score=0.09, 
#                payload=None, vector=[0.0, 0.0, 0.0, 0.1]),
#    ScoredPoint(id=1, version=0, score=0.10049876, 
#                payload=None, vector=[0.0, 0.1, 0.0, 0.0])]
# ]

```
Each instance of the SearchRequest class may provide its own search parameters, including vector query but also some additional filters. The response will be a list of individual results for each request. In case any of the requests is malformed, there will be an exception thrown, so either all of them pass or none of them.
And that’s it! You no longer have to handle the multiple requests on your own. Qdrant will do it under the hood.
## Batch Search Benchmarks
The batch search is fairly easy to be integrated into your application, but if you prefer to see some numbers before deciding to switch, then it’s worth comparing four different options:
  1. Querying the database sequentially.
  2. Using many threads/processes with individual requests.
  3. Utilizing the batch search of Qdrant in a single request.
  4. Combining parallel processing and batch search.
In order to do that, we’ll create a richer collection of points, with vectors from the  _glove-25-angular_ dataset, quite a common choice for ANN comparison. If you’re interested in seeing some more details of how we benchmarked Qdrant, let’s take a 
## The results
We launched the benchmark 5 times on 10000 test vectors and averaged the results. Presented numbers are the mean values of all the attempts:
  1. Sequential search: 225.9 seconds
  2. Batch search: 208.0 seconds
  3. Multiprocessing search (8 processes): 194.2 seconds
  4. Multiprocessing batch search (8 processes, batch size 10): 148.9 seconds
The results you may achieve on a specific setup may vary depending on the hardware, however, at the first glance, it seems that batch searching may save you quite a lot of time.
Additional improvements could be achieved in the case of distributed deployment, as Qdrant won’t need to make extensive inter-cluster requests. Moreover, if your requests share the same filtering condition, the query optimizer would be able to reuse it among batch requests.
## Summary
Batch search allows packing different queries into a single API call and retrieving the results in a single response. If you ever struggled with sending several consecutive queries into Qdrant, then you can easily switch to the new batch search method and simplify your application code. As shown in the benchmarks, that may almost effortlessly speed up your interactions with Qdrant even by over 30%, even not considering the spare network overhead and possible reuse of filters!
Ready to unlock the potential of batch search and optimize your vector search with Qdrant 0.10.0? Contact us today to learn how we can revolutionize your search capabilities!
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/batch-vector-search-with-qdrant.md) this page on GitHub, or 
On this page:
  * [An example of using batch search to optimize vector search](https://qdrant.tech/articles/batch-vector-search-with-qdrant/#an-example-of-using-batch-search-to-optimize-vector-search)
    * [Step 1: Creating the collection](https://qdrant.tech/articles/batch-vector-search-with-qdrant/#step-1-creating-the-collection)
  * [Step 2: Loading the vectors](https://qdrant.tech/articles/batch-vector-search-with-qdrant/#step-2-loading-the-vectors)
  * [Step 3: Batch search in a single request](https://qdrant.tech/articles/batch-vector-search-with-qdrant/#step-3-batch-search-in-a-single-request)
  * [Batch Search Benchmarks](https://qdrant.tech/articles/batch-vector-search-with-qdrant/#batch-search-benchmarks)
  * [The results](https://qdrant.tech/articles/batch-vector-search-with-qdrant/#the-results)
  * [Summary](https://qdrant.tech/articles/batch-vector-search-with-qdrant/#summary)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/batch-vector-search-with-qdrant/)
                    ## 📄 `https-qdrant-tech-articles-binary-quantization-openai.md`
                    ```md
                    # https://qdrant.tech/articles/binary-quantization-openai/
  * [Articles](https://qdrant.tech/articles/)
  * Optimizing OpenAI Embeddings: Enhance Efficiency with Qdrant's Binary Quantization
[](https://qdrant.tech/articles/practicle-examples/)
# Optimizing OpenAI Embeddings: Enhance Efficiency with Qdrant's Binary Quantization
Nirant Kasliwal
·
February 21, 2024
![Optimizing OpenAI Embeddings: Enhance Efficiency with Qdrant's Binary Quantization](https://qdrant.tech/articles_data/binary-quantization-openai/preview/title.jpg)
OpenAI Ada-003 embeddings are a powerful tool for natural language processing (NLP). However, the size of the embeddings are a challenge, especially with real-time search and retrieval. In this article, we explore how you can use Qdrant’s Binary Quantization to enhance the performance and efficiency of OpenAI embeddings.
In this post, we discuss:
  * The significance of OpenAI embeddings and real-world challenges.
  * Qdrant’s Binary Quantization, and how it can improve the performance of OpenAI embeddings
  * Results of an experiment that highlights improvements in search efficiency and accuracy
  * Implications of these findings for real-world applications
  * Best practices for leveraging Binary Quantization to enhance OpenAI embeddings
If you’re new to Binary Quantization, consider reading our article which walks you through the concept and [how to use it with Qdrant](https://qdrant.tech/articles/binary-quantization/)
You can also try out these techniques as described in 
## New OpenAI embeddings: performance and changes
As the technology of embedding models has advanced, demand has grown. Users are looking more for powerful and efficient text-embedding models. OpenAI’s Ada-003 embeddings offer state-of-the-art performance on a wide range of NLP tasks, including those noted in 
These models include multilingual support in over 100 languages. The transition from text-embedding-ada-002 to text-embedding-3-large has led to a significant jump in performance scores (from 31.4% to 54.9% on MIRACL).
#### Matryoshka representation learning
The new OpenAI models have been trained with a novel approach called “
Here, we show how the accuracy of binary quantization is quite good across different dimensions – for both the models.
## Enhanced performance and efficiency with binary quantization
By reducing storage needs, you can scale applications with lower costs. This addresses a critical challenge posed by the original embedding sizes. Binary Quantization also speeds the search process. It simplifies the complex distance calculations between vectors into more manageable bitwise operations, which supports potentially real-time searches across vast datasets.
The accompanying graph illustrates the promising accuracy levels achievable with binary quantization across different model sizes, showcasing its practicality without severely compromising on performance. This dual advantage of storage reduction and accelerated search capabilities underscores the transformative potential of Binary Quantization in deploying OpenAI embeddings more effectively across various real-world applications.
![](https://qdrant.tech/blog/openai/Accuracy_Models.png)
The efficiency gains from Binary Quantization are as follows:
  * Reduced storage footprint: It helps with large-scale datasets. It also saves on memory, and scales up to 30x at the same cost.
  * Enhanced speed of data retrieval: Smaller data sizes generally leads to faster searches.
  * Accelerated search process: It is based on simplified distance calculations between vectors to bitwise operations. This enables real-time querying even in extensive databases.
### Experiment setup: OpenAI embeddings in focus
To identify Binary Quantization’s impact on search efficiency and accuracy, we designed our experiment on OpenAI text-embedding models. These models, which capture nuanced linguistic features and semantic relationships, are the backbone of our analysis. We then delve deep into the potential enhancements offered by Qdrant’s Binary Quantization feature.
This approach not only leverages the high-caliber OpenAI embeddings but also provides a broad basis for evaluating the search mechanism under scrutiny.
#### Dataset
The research employs 100K random samples from the 
#### Parameters: oversampling, rescoring, and search limits
For each record, we run a parameter sweep over the number of oversampling, rescoring, and search limits. We can then understand the impact of these parameters on search accuracy and efficiency. Our experiment was designed to assess the impact of Binary Quantization under various conditions, based on the following parameters:
  * **Oversampling** : By oversampling, we can limit the loss of information inherent in quantization. This also helps to preserve the semantic richness of your OpenAI embeddings. We experimented with different oversampling factors, and identified the impact on the accuracy and efficiency of search. Spoiler: higher oversampling factors tend to improve the accuracy of searches. However, they usually require more computational resources.
  * **Rescoring** : Rescoring refines the first results of an initial binary search. This process leverages the original high-dimensional vectors to refine the search results, **always** improving accuracy. We toggled rescoring on and off to measure effectiveness, when combined with Binary Quantization. We also measured the impact on search performance.
  * **Search Limits** : We specify the number of results from the search process. We experimented with various search limits to measure their impact the accuracy and efficiency. We explored the trade-offs between search depth and performance. The results provide insight for applications with different precision and speed requirements.
Through this detailed setup, our experiment sought to shed light on the nuanced interplay between Binary Quantization and the high-quality embeddings produced by OpenAI’s models. By meticulously adjusting and observing the outcomes under different conditions, we aimed to uncover actionable insights that could empower users to harness the full potential of Qdrant in combination with OpenAI’s embeddings, regardless of their specific application needs.
### Results: binary quantization’s impact on OpenAI embeddings
To analyze the impact of rescoring (`True` or `False`), we compared results across different model configurations and search limits. Rescoring sets up a more precise search, based on results from an initial query.
#### Rescoring
![Graph that measures the impact of rescoring](https://qdrant.tech/blog/openai/Rescoring_Impact.png)
Here are some key observations, which analyzes the impact of rescoring (`True` or `False`):
  1. **Significantly Improved Accuracy** :
     * Across all models and dimension configurations, enabling rescoring (`True`) consistently results in higher accuracy scores compared to when rescoring is disabled (`False`).
     * The improvement in accuracy is true across various search limits (10, 20, 50, 100).
  2. **Model and Dimension Specific Observations** :
     * For the `text-embedding-3-large` model with 3072 dimensions, rescoring boosts the accuracy from an average of about 76-77% without rescoring to 97-99% with rescoring, depending on the search limit and oversampling rate.
     * The accuracy improvement with increased oversampling is more pronounced when rescoring is enabled, indicating a better utilization of the additional binary codes in refining search results.
     * With the `text-embedding-3-small` model at 512 dimensions, accuracy increases from around 53-55% without rescoring to 71-91% with rescoring, highlighting the significant impact of rescoring, especially at lower dimensions.
In contrast, for lower dimension models (such as text-embedding-3-small with 512 dimensions), the incremental accuracy gains from increased oversampling levels are less significant, even with rescoring enabled. This suggests a diminishing return on accuracy improvement with higher oversampling in lower dimension spaces.
  1. **Influence of Search Limit** :
     * The performance gain from rescoring seems to be relatively stable across different search limits, suggesting that rescoring consistently enhances accuracy regardless of the number of top results considered.
In summary, enabling rescoring dramatically improves search accuracy across all tested configurations. It is crucial feature for applications where precision is paramount. The consistent performance boost provided by rescoring underscores its value in refining search results, particularly when working with complex, high-dimensional data like OpenAI embeddings. This enhancement is critical for applications that demand high accuracy, such as semantic search, content discovery, and recommendation systems, where the quality of search results directly impacts user experience and satisfaction.
### Dataset combinations
For those exploring the integration of text embedding models with Qdrant, it’s crucial to consider various model configurations for optimal performance. The dataset combinations defined above illustrate different configurations to test against Qdrant. These combinations vary by two primary attributes:
  1. **Model Name** : Signifying the specific text embedding model variant, such as “text-embedding-3-large” or “text-embedding-3-small”. This distinction correlates with the model’s capacity, with “large” models offering more detailed embeddings at the cost of increased computational resources.
  2. **Dimensions** : This refers to the size of the vector embeddings produced by the model. Options range from 512 to 3072 dimensions. Higher dimensions could lead to more precise embeddings but might also increase the search time and memory usage in Qdrant.
Optimizing these parameters is a balancing act between search accuracy and resource efficiency. Testing across these combinations allows users to identify the configuration that best meets their specific needs, considering the trade-offs between computational resources and the quality of search results.
```
dataset_combinations = [
    {
        "model_name": "text-embedding-3-large",
        "dimensions": 3072,
    },
    {
        "model_name": "text-embedding-3-large",
        "dimensions": 1024,
    },
    {
        "model_name": "text-embedding-3-large",
        "dimensions": 1536,
    },
    {
        "model_name": "text-embedding-3-small",
        "dimensions": 512,
    },
    {
        "model_name": "text-embedding-3-small",
        "dimensions": 1024,
    },
    {
        "model_name": "text-embedding-3-small",
        "dimensions": 1536,
    },
]

```
#### Exploring dataset combinations and their impacts on model performance
The code snippet iterates through predefined dataset and model combinations. For each combination, characterized by the model name and its dimensions, the corresponding experiment’s results are loaded. These results, which are stored in JSON format, include performance metrics like accuracy under different configurations: with and without oversampling, and with and without a rescore step.
Following the extraction of these metrics, the code computes the average accuracy across different settings, excluding extreme cases of very low limits (specifically, limits of 1 and 5). This computation groups the results by oversampling, rescore presence, and limit, before calculating the mean accuracy for each subgroup.
After gathering and processing this data, the average accuracies are organized into a pivot table. This table is indexed by the limit (the number of top results considered), and columns are formed based on combinations of oversampling and rescoring.
```
import pandas as pd
for combination in dataset_combinations:
    model_name = combination["model_name"]
    dimensions = combination["dimensions"]
    print(f"Model: {model_name}, dimensions: {dimensions}")
    results = pd.read_json(f"../results/results-{model_name}-{dimensions}.json", lines=True)
    average_accuracy = results[results["limit"] != 1]
    average_accuracy = average_accuracy[average_accuracy["limit"] != 5]
    average_accuracy = average_accuracy.groupby(["oversampling", "rescore", "limit"])[
        "accuracy"
    ].mean()
    average_accuracy = average_accuracy.reset_index()
    acc = average_accuracy.pivot(
        index="limit", columns=["oversampling", "rescore"], values="accuracy"
    )
    print(acc)

```
Here is a selected slice of these results, with `rescore=True`:
Method | Dimensionality | Test Dataset | Recall | Oversampling  
---|---|---|---|---  
OpenAI text-embedding-3-large (highest MTEB score from the table) | 3072 | 0.9966 | 3x  
OpenAI text-embedding-3-small | 1536 | 0.9847 | 3x  
OpenAI text-embedding-3-large | 1536 | 0.9826 | 3x  
#### Impact of oversampling
You can use oversampling in machine learning to counteract imbalances in datasets. It works well when one class significantly outnumbers others. This imbalance can skew the performance of models, which favors the majority class at the expense of others. By creating additional samples from the minority classes, oversampling helps equalize the representation of classes in the training dataset, thus enabling more fair and accurate modeling of real-world scenarios.
The screenshot showcases the effect of oversampling on model performance metrics. While the actual metrics aren’t shown, we expect to see improvements in measures such as precision, recall, or F1-score. These improvements illustrate the effectiveness of oversampling in creating a more balanced dataset. It allows the model to learn a better representation of all classes, not just the dominant one.
Without an explicit code snippet or output, we focus on the role of oversampling in model fairness and performance. Through graphical representation, you can set up before-and-after comparisons. These comparisons illustrate the contribution to machine learning projects.
![Measuring the impact of oversampling](https://qdrant.tech/blog/openai/Oversampling_Impact.png)
### Leveraging binary quantization: best practices
We recommend the following best practices for leveraging Binary Quantization to enhance OpenAI embeddings:
  1. Embedding Model: Use the text-embedding-3-large from MTEB. It is most accurate among those tested.
  2. Dimensions: Use the highest dimension available for the model, to maximize accuracy. The results are true for English and other languages.
  3. Oversampling: Use an oversampling factor of 3 for the best balance between accuracy and efficiency. This factor is suitable for a wide range of applications.
  4. Rescoring: Enable rescoring to improve the accuracy of search results.
  5. RAM: Store the full vectors and payload on disk. Limit what you load from memory to the binary quantization index. This helps reduce the memory footprint and improve the overall efficiency of the system. The incremental latency from the disk read is negligible compared to the latency savings from the binary scoring in Qdrant, which uses SIMD instructions where possible.
## What’s next?
Binary quantization is exceptional if you need to work with large volumes of data under high recall expectations. You can try this feature either by spinning up a 
The article gives examples of data sets and configuration you can use to get going. Our documentation covers [adding large datasets to Qdrant](https://qdrant.tech/documentation/tutorials/bulk-upload/) to your Qdrant instance as well as [more quantization methods](https://qdrant.tech/documentation/guides/quantization/).
Want to discuss these findings and learn more about Binary Quantization? 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/binary-quantization-openai.md) this page on GitHub, or 
On this page:
  * [New OpenAI embeddings: performance and changes](https://qdrant.tech/articles/binary-quantization-openai/#new-openai-embeddings-performance-and-changes)
  * [Enhanced performance and efficiency with binary quantization](https://qdrant.tech/articles/binary-quantization-openai/#enhanced-performance-and-efficiency-with-binary-quantization)
    * [Experiment setup: OpenAI embeddings in focus](https://qdrant.tech/articles/binary-quantization-openai/#experiment-setup-openai-embeddings-in-focus)
    * [Results: binary quantization’s impact on OpenAI embeddings](https://qdrant.tech/articles/binary-quantization-openai/#results-binary-quantizations-impact-on-openai-embeddings)
    * [Dataset combinations](https://qdrant.tech/articles/binary-quantization-openai/#dataset-combinations)
    * [Leveraging binary quantization: best practices](https://qdrant.tech/articles/binary-quantization-openai/#leveraging-binary-quantization-best-practices)
  * [What’s next?](https://qdrant.tech/articles/binary-quantization-openai/#whats-next)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/binary-quantization-openai/)
                    ## 📄 `https-qdrant-tech-articles-binary-quantization.md`
                    ```md
                    # https://qdrant.tech/articles/binary-quantization/
  * [Articles](https://qdrant.tech/articles/)
  * Binary Quantization - Vector Search, 40x Faster
[](https://qdrant.tech/articles/qdrant-internals/)
# Binary Quantization - Vector Search, 40x Faster
Nirant Kasliwal
·
September 18, 2023
![Binary Quantization - Vector Search, 40x Faster ](https://qdrant.tech/articles_data/binary-quantization/preview/title.jpg)
# Optimizing High-Dimensional Vectors with Binary Quantization
Qdrant is built to handle typical scaling challenges: high throughput, low latency and efficient indexing. **Binary quantization (BQ)** is our latest attempt to give our customers the edge they need to scale efficiently. This feature is particularly excellent for collections with large vector lengths and a large number of points.
Our results are dramatic: Using BQ will reduce your memory consumption and improve retrieval speeds by up to 40x.
As is the case with other quantization methods, these benefits come at the cost of recall degradation. However, our implementation lets you balance the tradeoff between speed and recall accuracy at time of search, rather than time of index creation.
The rest of this article will cover:
  1. The importance of binary quantization
  2. Basic implementation using our Python client
  3. Benchmark analysis and usage recommendations
## What is Binary Quantization?
Binary quantization (BQ) converts any vector embedding of floating point numbers into a vector of binary or boolean values. This feature is an extension of our past work on [scalar quantization](https://qdrant.tech/articles/scalar-quantization/) where we convert `float32` to `uint8` and then leverage a specific SIMD CPU instruction to perform fast vector comparison.
![What is binary quantization](https://qdrant.tech/articles_data/binary-quantization/bq-2.png)
**This binarization function is how we convert a range to binary values. All numbers greater than zero are marked as 1. If it’s zero or less, they become 0.**
The benefit of reducing the vector embeddings to binary values is that boolean operations are very fast and need significantly less CPU instructions. In exchange for reducing our 32 bit embeddings to 1 bit embeddings we can see up to a 40x retrieval speed up gain!
One of the reasons vector search still works with such a high compression rate is that these large vectors are over-parameterized for retrieval. This is because they are designed for ranking, clustering, and similar use cases, which typically need more information encoded in the vector.
For example, The 1536 dimension OpenAI embedding is worse than Open Source counterparts of 384 dimension at retrieval and ranking. Specifically, it scores 49.25 on the same `bge-small` scores 51.82. This 2.57 points difference adds up quite soon.
Our implementation of quantization achieves a good balance between full, large vectors at ranking time and binary vectors at search and retrieval time. It also has the ability for you to adjust this balance depending on your use case.
## Faster search and retrieval
Unlike product quantization, binary quantization does not rely on reducing the search space for each probe. Instead, we build a binary index that helps us achieve large increases in search speed.
![Speed by quantization method](https://qdrant.tech/articles_data/binary-quantization/bq-3.png)
HNSW is the approximate nearest neighbor search. This means our accuracy improves up to a point of diminishing returns, as we check the index for more similar candidates. In the context of binary quantization, this is referred to as the **oversampling rate**.
For example, if `oversampling=2.0` and the `limit=100`, then 200 vectors will first be selected using a quantized index. For those 200 vectors, the full 32 bit vector will be used with their HNSW index to a much more accurate 100 item result set. As opposed to doing a full HNSW search, we oversample a preliminary search and then only do the full search on this much smaller set of vectors.
## Improved storage efficiency
The following diagram shows the binarization function, whereby we reduce 32 bits storage to 1 bit information.
Text embeddings can be over 1024 elements of floating point 32 bit numbers. For example, remember that OpenAI embeddings are 1536 element vectors. This means each vector is 6kB for just storing the vector.
![Improved storage efficiency](https://qdrant.tech/articles_data/binary-quantization/bq-4.png)
In addition to storing the vector, we also need to maintain an index for faster search and retrieval. Qdrant’s formula to estimate overall memory consumption is:
`memory_size = 1.5 * number_of_vectors * vector_dimension * 4 bytes`
For 100K OpenAI Embedding (`ada-002`) vectors we would need 900 Megabytes of RAM and disk space. This consumption can start to add up rapidly as you create multiple collections or add more items to the database.
**With binary quantization, those same 100K OpenAI vectors only require 128 MB of RAM.** We benchmarked this result using methods similar to those covered in our [Scalar Quantization memory estimation](https://qdrant.tech/articles/scalar-quantization/#benchmarks).
This reduction in RAM usage is achieved through the compression that happens in the binary conversion. HNSW and quantized vectors will live in RAM for quick access, while original vectors can be offloaded to disk only. For searching, quantized HNSW will provide oversampled candidates, then they will be re-evaluated using their disk-stored original vectors to refine the final results. All of this happens under the hood without any additional intervention on your part.
### When should you not use BQ?
Since this method exploits the over-parameterization of embedding, you can expect poorer results for small embeddings i.e. less than 1024 dimensions. With the smaller number of elements, there is not enough information maintained in the binary vector to achieve good results.
You will still get faster boolean operations and reduced RAM usage, but the accuracy degradation might be too high.
## Sample implementation
Now that we have introduced you to binary quantization, let’s try our a basic implementation. In this example, we will be using OpenAI and Cohere with Qdrant.
#### Create a collection with Binary Quantization enabled
Here is what you should do at indexing time when you create the collection:
  1. We store all the “full” vectors on disk.
  2. Then we set the binary embeddings to be in RAM.
By default, both the full vectors and BQ get stored in RAM. We move the full vectors to disk because this saves us memory and allows us to store more vectors in RAM. By doing this, we explicitly move the binary vectors to memory by setting `always_ram=True`.
```
from qdrant_client import QdrantClient
#collect to our Qdrant Server
client = QdrantClient(
    url="http://localhost:6333",
    prefer_grpc=True,
)
#Create the collection to hold our embeddings
# on_disk=True and the quantization_config are the areas to focus on
collection_name = "binary-quantization"
if not client.collection_exists(collection_name):
    client.create_collection(
        collection_name=f"{collection_name}",
        vectors_config=models.VectorParams(
            size=1536,
            distance=models.Distance.DOT,
            on_disk=True,
        ),
        optimizers_config=models.OptimizersConfigDiff(
            default_segment_number=5,
            indexing_threshold=0,
        ),
        quantization_config=models.BinaryQuantization(
            binary=models.BinaryQuantizationConfig(always_ram=True),
        ),
    )

```
#### What is happening in the OptimizerConfig?
We’re setting `indexing_threshold` to 0 i.e. disabling the indexing to zero. This allows faster uploads of vectors and payloads. We will turn it back on down below, once all the data is loaded
#### Next, we upload our vectors to this and then enable indexing:
```
batch_size = 10000
client.upload_collection(
    collection_name=collection_name,
    ids=range(len(dataset)),
    vectors=dataset["openai"],
    payload=[
        {"text": x} for x in dataset["text"]
    ],
    parallel=10, # based on the machine
)

```
Enable indexing again:
```
client.update_collection(
    collection_name=f"{collection_name}",
    optimizer_config=models.OptimizersConfigDiff(
        indexing_threshold=20000
    )
)

```
#### Configure the search parameters:
When setting search parameters, we specify that we want to use `oversampling` and `rescore`. Here is an example snippet:
```
client.search(
    collection_name="{collection_name}",
    query_vector=[0.2, 0.1, 0.9, 0.7, ...],
    search_params=models.SearchParams(
        quantization=models.QuantizationSearchParams(
            ignore=False,
            rescore=True,
            oversampling=2.0,
        )
    )
)

```
After Qdrant pulls the oversampled vectors set, the full vectors which will be, say 1536 dimensions for OpenAI will then be pulled up from disk. Qdrant computes the nearest neighbor with the query vector and returns the accurate, rescored order. This method produces much more accurate results. We enabled this by setting `rescore=True`.
These two parameters are how you are going to balance speed versus accuracy. The larger the size of your oversample, the more items you need to read from disk and the more elements you have to search with the relatively slower full vector index. On the other hand, doing this will produce more accurate results.
If you have lower accuracy requirements you can even try doing a small oversample without rescoring. Or maybe, for your data set combined with your accuracy versus speed requirements you can just search the binary index and no rescoring, i.e. leaving those two parameters out of the search query.
## Benchmark results
We retrieved some early results on the relationship between limit and oversampling using the the DBPedia OpenAI 1M vector dataset. We ran all these experiments on a Qdrant instance where 100K vectors were indexed and used 100 random queries.
We varied the 3 parameters that will affect query time and accuracy: limit, rescore and oversampling. We offer these as an initial exploration of this new feature. You are highly encouraged to reproduce these experiments with your data sets.
> Aside: Since this is a new innovation in vector databases, we are keen to hear feedback and results. 
**Oversampling:** In the figure below, we illustrate the relationship between recall and number of candidates:
![Correct vs candidates](https://qdrant.tech/articles_data/binary-quantization/bq-5.png)
We see that “correct” results i.e. recall increases as the number of potential “candidates” increase (limit x oversampling). To highlight the impact of changing the `limit`, different limit values are broken apart into different curves. For example, we see that the lowest recall for limit 50 is around 94 correct, with 100 candidates. This also implies we used an oversampling of 2.0
As oversampling increases, we see a general improvement in results – but that does not hold in every case.
**Rescore:** As expected, rescoring increases the time it takes to return a query. We also repeated the experiment with oversampling except this time we looked at how rescore impacted result accuracy.
![Relationship between limit and rescore on correct](https://qdrant.tech/articles_data/binary-quantization/bq-7.png)
**Limit:** We experiment with limits from Top 1 to Top 50 and we are able to get to 100% recall at limit 50, with rescore=True, in an index with 100K vectors.
## Recommendations
Quantization gives you the option to make tradeoffs against other parameters: Dimension count/embedding size Throughput and Latency requirements Recall requirements
If you’re working with OpenAI or Cohere embeddings, we recommend the following oversampling settings:
Method | Dimensionality | Test Dataset | Recall | Oversampling  
---|---|---|---|---  
OpenAI text-embedding-3-large | 3072 | 0.9966 | 3x  
OpenAI text-embedding-3-small | 1536 | 0.9847 | 3x  
OpenAI text-embedding-3-large | 1536 | 0.9826 | 3x  
OpenAI text-embedding-ada-002 | 1536 | 0.98 | 4x  
Gemini | 768 | No Open Data | 0.9563 | 3x  
Mistral Embed | 768 | No Open Data | 0.9445 | 3x  
If you determine that binary quantization is appropriate for your datasets and queries then we suggest the following:
  * Binary Quantization with always_ram=True
  * Vectors stored on disk
  * Oversampling=2.0 (or more)
  * Rescore=True
## What’s next?
Binary quantization is exceptional if you need to work with large volumes of data under high recall expectations. You can try this feature either by spinning up a 
The article gives examples of data sets and configuration you can use to get going. Our documentation covers [adding large datasets to Qdrant](https://qdrant.tech/documentation/tutorials/bulk-upload/) to your Qdrant instance as well as [more quantization methods](https://qdrant.tech/documentation/guides/quantization/).
If you have any feedback, drop us a note on Twitter or LinkedIn to tell us about your results. 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/binary-quantization.md) this page on GitHub, or 
On this page:
  * [What is Binary Quantization?](https://qdrant.tech/articles/binary-quantization/#what-is-binary-quantization)
  * [Faster search and retrieval](https://qdrant.tech/articles/binary-quantization/#faster-search-and-retrieval)
  * [Improved storage efficiency](https://qdrant.tech/articles/binary-quantization/#improved-storage-efficiency)
    * [When should you not use BQ?](https://qdrant.tech/articles/binary-quantization/#when-should-you-not-use-bq)
  * [Sample implementation](https://qdrant.tech/articles/binary-quantization/#sample-implementation)
  * [Benchmark results](https://qdrant.tech/articles/binary-quantization/#benchmark-results)
  * [Recommendations](https://qdrant.tech/articles/binary-quantization/#recommendations)
  * [What’s next?](https://qdrant.tech/articles/binary-quantization/#whats-next)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/binary-quantization/)
                    ## 📄 `https-qdrant-tech-articles-cross-encoder-integration-gsoc.md`
                    ```md
                    # https://qdrant.tech/articles/cross-encoder-integration-gsoc/
  * [Articles](https://qdrant.tech/articles/)
  * Qdrant Summer of Code 2024 - ONNX Cross Encoders in Python
[](https://qdrant.tech/articles/machine-learning/)
# Qdrant Summer of Code 2024 - ONNX Cross Encoders in Python
Huong (Celine) Hoang
·
October 14, 2024
![Qdrant Summer of Code 2024 - ONNX Cross Encoders in Python](https://qdrant.tech/articles_data/cross-encoder-integration-gsoc/preview/title.jpg)
## Introduction
Hi everyone! I’m Huong (Celine) Hoang, and I’m thrilled to share my experience working at Qdrant this summer as part of their Summer of Code 2024 program. During my internship, I worked on integrating cross-encoders into the FastEmbed library for re-ranking tasks. This enhancement widened the capabilities of the Qdrant ecosystem, enabling developers to build more context-aware search applications, such as question-answering systems, using Qdrant’s suite of libraries.
This project was both technically challenging and rewarding, pushing me to grow my skills in handling large-scale ONNX (Open Neural Network Exchange) model integrations, tokenization, and more. Let me take you through the journey, the lessons learned, and where things are headed next.
## Project Overview
Qdrant is well known for its vector search capabilities, but my task was to go one step further — introducing cross-encoders for re-ranking. Traditionally, the FastEmbed library would generate embeddings, but cross-encoders don’t do that. Instead, they provide a list of scores based on how well a query matches a list of documents. This kind of re-ranking is critical when you want to refine search results and bring the most relevant answers to the top.
The project revolved around creating a new input-output scheme: text data to scores. For this, I designed a family of classes to support ONNX models. Some of the key models I worked with included Xenova/ms-marco-MiniLM-L-6-v2, Xenova/ms-marco-MiniLM-L-12-v2, and BAAI/bge-reranker, all designed for re-ranking tasks.
An important point to mention is that FastEmbed is a minimalistic library: it doesn’t have heavy dependencies like PyTorch or TensorFlow, and as a result, it is lightweight, occupying far less storage space.
Below is a diagram that represents the overall workflow for this project, detailing the key steps from user interaction to the final output validation:
![Search workflow with reranking](https://qdrant.tech/articles_data/cross-encoder-integration-gsoc/rerank-workflow.png)
Search workflow with reranking
## Technical Challenges
### 1. Building a New Input-Output Scheme
FastEmbed already had support for embeddings, but re-ranking with cross-encoders meant building a completely new family of classes. These models accept a query and a set of documents, then return a list of relevance scores. For that, I created the base classes like `TextCrossEncoderBase` and `OnnxCrossEncoder`, taking inspiration from existing text embedding models.
One thing I had to ensure was that the new class hierarchy was user-friendly. Users should be able to work with cross-encoders without needing to know the complexities of the underlying models. For instance, they should be able to just write:
```
from fastembed.rerank.cross_encoder import TextCrossEncoder
encoder = TextCrossEncoder(model_name="Xenova/ms-marco-MiniLM-L-6-v2")
scores = encoder.rerank(query, documents)

```
Meanwhile, behind the scenes, we manage all the model loading, tokenization, and scoring.
### 2. Handling Tokenization for Cross-Encoders
Cross-encoders require careful tokenization because they need to distinguish between the query and the documents. This is done using token type IDs, which help the model differentiate between the two. To implement this, I configured the tokenizer to handle pairs of inputs—concatenating the query with each document and assigning token types accordingly.
Efficient tokenization is critical to ensure the performance of the models, and I optimized it specifically for ONNX models.
### 3. Model Loading and Integration
One of the most rewarding parts of the project was integrating the ONNX models into the FastEmbed library. ONNX models need to be loaded into a runtime environment that efficiently manages the computations.
While PyTorch is a common framework for these types of tasks, FastEmbed exclusively supports ONNX models, making it both lightweight and efficient. I focused on extensive testing to ensure that the ONNX models performed equivalently to their PyTorch counterparts, ensuring users could trust the results.
I added support for batching as well, allowing users to re-rank large sets of documents without compromising speed.
### 4. Debugging and Code Reviews
During the project, I encountered a number of challenges, including issues with model configurations, tokenizers, and test cases. With the help of my mentor, George Panchuk, I was able to resolve these issues and improve my understanding of best practices, particularly around code readability, maintainability, and style.
One notable lesson was the importance of keeping the code organized and maintainable, with a strong focus on readability. This included properly structuring modules and ensuring the entire codebase followed a clear, consistent style.
### 5. Testing and Validation
To ensure the accuracy and performance of the models, I conducted extensive testing. I compared the output of ONNX models with their PyTorch counterparts, ensuring the conversion to ONNX was correct. A key part of this process was rigorous testing to verify the outputs and identify potential issues, such as incorrect conversions or bugs in our implementation.
For instance, a test to validate the model’s output was structured as follows:
```
def test_rerank():
    is_ci = os.getenv("CI")
    for model_desc in TextCrossEncoder.list_supported_models():
        if not is_ci and model_desc["size_in_GB"] > 1:
            continue
        model_name = model_desc["model"]
        model = TextCrossEncoder(model_name=model_name)
        query = "What is the capital of France?"
        documents = ["Paris is the capital of France.", "Berlin is the capital of Germany."]
        scores = np.array(model.rerank(query, documents))
        canonical_scores = CANONICAL_SCORE_VALUES[model_name]
        assert np.allclose(
            scores, canonical_scores, atol=1e-3
        ), f"Model: {model_name}, Scores: {scores}, Expected: {canonical_scores}"

```
The `CANONICAL_SCORE_VALUES` were retrieved directly from the result of applying the original PyTorch models to the same input
## Outcomes and Future Improvements
By the end of my project, I successfully added cross-encoders to the FastEmbed library, allowing users to re-rank search results based on relevance scores. This enhancement opens up new possibilities for applications that rely on contextual ranking, such as search engines and recommendation systems. This functionality will be available as of FastEmbed `0.4.0`.
Some areas for future improvements include:
  * Expanding Model Support: We could add more cross-encoder models, especially from the sentence transformers library, to give users more options.
  * Parallelization: Optimizing batch processing to handle even larger datasets could further improve performance.
  * Custom Tokenization: For models with non-standard tokenization, like BAAI/bge-reranker, more specific tokenizer configurations could be added.
## Overall Experience and Wrapping Up
Looking back, this internship has been an incredibly valuable experience. I’ve grown not only as a developer but also as someone who can take on complex projects and see them through from start to finish. The Qdrant team has been so supportive, especially during the debugging and review stages. I’ve learned so much about model integration, ONNX, and how to build tools that are user-friendly and scalable.
One key takeaway for me is the importance of understanding the user experience. It’s not just about getting the models to work but making sure they are easy to use and integrate into real-world applications. This experience has solidified my passion for building solutions that truly make an impact, and I’m excited to continue working on projects like this in the future.
Thank you for taking the time to read about my journey with Qdrant and the FastEmbed library. I’m excited to see how this work will continue to improve search experiences for users!
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/cross-encoder-integration-gsoc.md) this page on GitHub, or 
On this page:
  * [Introduction](https://qdrant.tech/articles/cross-encoder-integration-gsoc/#introduction)
  * [Project Overview](https://qdrant.tech/articles/cross-encoder-integration-gsoc/#project-overview)
  * [Technical Challenges](https://qdrant.tech/articles/cross-encoder-integration-gsoc/#technical-challenges)
    * [1. Building a New Input-Output Scheme](https://qdrant.tech/articles/cross-encoder-integration-gsoc/#1-building-a-new-input-output-scheme)
    * [2. Handling Tokenization for Cross-Encoders](https://qdrant.tech/articles/cross-encoder-integration-gsoc/#2-handling-tokenization-for-cross-encoders)
    * [3. Model Loading and Integration](https://qdrant.tech/articles/cross-encoder-integration-gsoc/#3-model-loading-and-integration)
    * [4. Debugging and Code Reviews](https://qdrant.tech/articles/cross-encoder-integration-gsoc/#4-debugging-and-code-reviews)
    * [5. Testing and Validation](https://qdrant.tech/articles/cross-encoder-integration-gsoc/#5-testing-and-validation)
  * [Outcomes and Future Improvements](https://qdrant.tech/articles/cross-encoder-integration-gsoc/#outcomes-and-future-improvements)
  * [Overall Experience and Wrapping Up](https://qdrant.tech/articles/cross-encoder-integration-gsoc/#overall-experience-and-wrapping-up)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/cross-encoder-integration-gsoc/)
                    ## 📄 `https-qdrant-tech-articles-data-exploration.md`
                    ```md
                    # https://qdrant.tech/articles/data-exploration/
  * [Articles](https://qdrant.tech/articles/)
  * Data Exploration
#### Data Exploration
Learn how you can leverage vector similarity beyond just search. Reveal hidden patterns and insights in your data, provide recommendations, and navigate data space.
[![Preview](https://qdrant.tech/articles_data/distance-based-exploration/preview/preview.jpg) Distance-based data exploration Explore your data under a new angle with Qdrant's tools for dimensionality reduction, clusterization, and visualization. Andrey Vasnetsov March 11, 2025 ](https://qdrant.tech/articles/distance-based-exploration/)[![Preview](https://qdrant.tech/articles_data/discovery-search/preview/preview.jpg) Discovery needs context Discovery Search, an innovative way to constrain the vector space in which a search is performed, relying only on vectors. Luis Cossío January 31, 2024 ](https://qdrant.tech/articles/discovery-search/)[![Preview](https://qdrant.tech/articles_data/vector-similarity-beyond-search/preview/preview.jpg) Vector Similarity: Going Beyond Full-Text Search | Qdrant Discover how vector similarity expands data exploration beyond full-text search. Explore diversity sampling and more for enhanced data discovery! Luis Cossío August 08, 2023 ](https://qdrant.tech/articles/vector-similarity-beyond-search/)[![Preview](https://qdrant.tech/articles_data/dataset-quality/preview/preview.jpg) Finding errors in datasets with Similarity Search Improving quality of text-and-images datasets on the online furniture marketplace example. George Panchuk July 18, 2022 ](https://qdrant.tech/articles/dataset-quality/)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/data-exploration/)
                    ## 📄 `https-qdrant-tech-articles-data-privacy.md`
                    ```md
                    # https://qdrant.tech/articles/data-privacy/
  * [Articles](https://qdrant.tech/articles/)
  * Data Privacy with Qdrant: Implementing Role-Based Access Control (RBAC)
# Data Privacy with Qdrant: Implementing Role-Based Access Control (RBAC)
Qdrant Team
·
June 18, 2024
![ Data Privacy with Qdrant: Implementing Role-Based Access Control \(RBAC\)](https://qdrant.tech/articles_data/data-privacy/preview/title.jpg)
Data stored in vector databases is often proprietary to the enterprise and may include sensitive information like customer records, legal contracts, electronic health records (EHR), financial data, and intellectual property. Moreover, strong security measures become critical to safeguarding this data. If the data stored in a vector database is not secured, it may open a vulnerability known as “
Strict compliance regulations govern data stored in vector databases across various industries. For instance, healthcare must comply with HIPAA, which dictates how protected health information (PHI) is stored, transmitted, and secured. Similarly, the financial services industry follows PCI DSS to safeguard sensitive financial data. These regulations require developers to ensure data storage and transmission comply with industry-specific legal frameworks across different regions. **As a result, features that enable data privacy, security and sovereignty are deciding factors when choosing the right vector database.**
This article explores various strategies to ensure the security of your critical data while leveraging the benefits of vector search. Implementing some of these security approaches can help you build privacy-enhanced similarity search algorithms and integrate them into your AI applications. Additionally, you will learn how to build a fully data-sovereign architecture, allowing you to retain control over your data and comply with relevant data laws and regulations.
> To skip right to the code implementation, [click here](https://qdrant.tech/articles/data-privacy/#jwt-on-qdrant).
## Vector Database Security: An Overview
Vector databases are often unsecured by default to facilitate rapid prototyping and experimentation. This approach allows developers to quickly ingest data, build vector representations, and test similarity search algorithms without initial security concerns. However, in production environments, unsecured databases pose significant data breach risks.
For production use, robust security systems are essential. Authentication, particularly using static API keys, is a common approach to control access and prevent unauthorized modifications. Yet, simple API authentication is insufficient for enterprise data, which requires granular control.
The primary challenge with static API keys is their all-or-nothing access, inadequate for role-based data segregation in enterprise applications. Additionally, a compromised key could grant attackers full access to manipulate or steal data. To strengthen the security of the vector database, developers typically need the following:
  1. **Encryption** : This ensures that sensitive data is scrambled as it travels between the application and the vector database. This safeguards against Man-in-the-Middle (
  2. **Role-Based Access Control** : As mentioned before, traditional static API keys grant all-or-nothing access, which is a significant security risk in enterprise environments. RBAC offers a more granular approach by defining user roles and assigning specific data access permissions based on those roles. For example, an analyst might have read-only access to specific datasets, while an administrator might have full CRUD (Create, Read, Update, Delete) permissions across the database.
  3. **Deployment Flexibility** : Data residency regulations like GDPR (General Data Protection Regulation) and industry-specific compliance requirements dictate where data can be stored, processed, and accessed. Developers would need to choose a database solution which offers deployment options that comply with these regulations. This might include on-premise deployments within a company’s private cloud or geographically distributed cloud deployments that adhere to data residency laws.
## How Qdrant Handles Data Privacy and Security
One of the cornerstones of our design choices at Qdrant has been the focus on security features. We have built in a range of features keeping the enterprise user in mind, which allow building of granular access control on a fully data sovereign architecture.
A Qdrant instance is unsecured by default. However, when you are ready to deploy in production, Qdrant offers a range of security features that allow you to control access to your data, protect it from breaches, and adhere to regulatory requirements. Using Qdrant, you can build granular access control, segregate roles and privileges, and create a fully data sovereign architecture.
### API Keys and TLS Encryption
For simpler use cases, Qdrant offers API key-based authentication. This includes both regular API keys and read-only API keys. Regular API keys grant full access to read, write, and delete operations, while read-only keys restrict access to data retrieval operations only, preventing write actions.
On Qdrant Cloud, you can create API keys using the [here](https://qdrant.tech/documentation/cloud/authentication/).
![web-ui](https://qdrant.tech/articles_data/data-privacy/web-ui.png)
For on-premise or local deployments, you’ll need to configure API key authentication. This involves specifying a key in either the Qdrant configuration file or as an environment variable. This ensures that all requests to the server must include a valid API key sent in the header.
When using the simple API key-based authentication, you should also turn on TLS encryption. Otherwise, you are exposing the connection to sniffing and MitM attacks. To secure your connection using TLS, you would need to create a certificate and private key, and then [enable TLS](https://qdrant.tech/documentation/guides/security/#tls) in the configuration.
API authentication, coupled with TLS encryption, offers a first layer of security for your Qdrant instance. However, to enable more granular access control, the recommended approach is to leverage JSON Web Tokens (JWTs).
### JWT on Qdrant
JSON Web Tokens (JWTs) are a compact, URL-safe, and stateless means of representing _claims_ to be transferred between two parties. These claims are encoded as a JSON object and are cryptographically signed.
JWT is composed of three parts: a header, a payload, and a signature, which are concatenated with dots (.) to form a single string. The header contains the type of token and algorithm being used. The payload contains the claims (explained in detail later). The signature is a cryptographic hash and ensures the token’s integrity.
In Qdrant, JWT forms the foundation through which powerful access controls can be built. Let’s understand how.
JWT is enabled on the Qdrant instance by specifying the API key and turning on the **jwt_rbac** feature in the configuration (alternatively, they can be set as environment variables). For any subsequent request, the API key is used to encode or decode the token.
The way JWT works is that just the API key is enough to generate the token, and doesn’t require any communication with the Qdrant instance or server. There are several libraries that help generate tokens by encoding a payload, such as 
We will look at the payload structure shortly, but here’s how you can generate a token using PyJWT.
```
import jwt
import datetime
# Define your API key and other payload data
api_key = "your_api_key"
payload = { ...
}
token = jwt.encode(payload, api_key, algorithm="HS256")
print(token)

```
Once you have generated the token, you should include it in the subsequent requests. You can do so by providing it as a bearer token in the Authorization header, or in the API Key header of your requests.
Below is an example of how to do so using QdrantClient in Python:
```
from qdrant_client import QdrantClient
qdrant_client = QdrantClient(
    "http://localhost:6333",
    api_key="<JWT>", # the token goes here
)
# Example search vector
search_vector = [0.1, 0.2, 0.3, 0.4]
# Example similarity search request
response = qdrant_client.search(
    collection_name="demo_collection",
    query_vector=search_vector,
    limit=5  # Number of results to retrieve
)

```
For convenience, we have added a JWT generation tool in the Qdrant Web UI, which is present under the 🔑 tab. For your local deployments, you will find it at 
### Payload Configuration
There are several different options (claims) you can use in the JWT payload that help control access and functionality. Let’s look at them one by one.
**exp** : This claim is the expiration time of the token, and is a unix timestamp in seconds. After the expiration time, the token will be invalid.
**value_exists** : This claim validates the token against a specific key-value stored in a collection. By using this claim, you can revoke access by simply changing a value without having to invalidate the API key.
**access** : This claim defines the access level of the token. The access level can be global read (r) or manage (m). It can also be specific to a collection, or even a subset of a collection, using read (r) and read-write (rw).
Let’s look at a few example JWT payload configurations.
**Scenario 1: 1-hour expiry time, and read-only access to a collection**
```
{
  "exp": 1690995200,  // Set to 1 hour from the current time (Unix timestamp)
"access": [
    {
      "collection": "demo_collection",
      "access": "r"  // Read-only access
}
  ]
}

```
**Scenario 2: 1-hour expiry time, and access to user with a specific role**
Suppose you have a ‘users’ collection and have defined specific roles for each user, such as ‘developer’, ‘manager’, ‘admin’, ‘analyst’, and ‘revoked’. In such a scenario, you can use a combination of **exp** and **value_exists**.
```
{
  "exp":  1690995200, 
  "value_exists": {
    "collection": "users",
    "matches": [
      { "key": "username", "value": "john" },
      { "key": "role", "value": "developer" }
    ],
  },
}

```
Now, if you ever want to revoke access for a user, simply change the value of their role. All future requests will be invalid using a token payload of the above type.
**Scenario 3: 1-hour expiry time, and read-write access to a subset of a collection**
You can even specify access levels specific to subsets of a collection. This can be especially useful when you are leveraging [multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/), and want to segregate access.
```
{
  "exp": 1690995200,
  "access": [
    {
      "collection": "demo_collection",
      "access": "r",
      "payload": {
        "user_id": "user_123456"
      }
    }
  ]
}

```
By combining the claims, you can fully customize the access level that a user or a role has within the vector store.
### Creating Role-Based Access Control (RBAC) Using JWT
As we saw above, JWT claims create powerful levers through which you can create granular access control on Qdrant. Let’s bring it all together and understand how it helps you create Role-Based Access Control (RBAC).
In a typical enterprise application, you will have a segregation of users based on their roles and permissions. These could be:
  1. **Admin or Owner:** with full access, and can generate API keys.
  2. **Editor:** with read-write access levels to specific collections.
  3. **Viewer:** with read-only access to specific collections.
  4. **Data Scientist or Analyst:** with read-only access to specific collections.
  5. **Developer:** with read-write access to development- or testing-specific collections, but limited access to production data.
  6. **Guest:** with limited read-only access to publicly available collections.
In addition, you can create access levels within sections of a collection. In a multi-tenant application, where you have used payload-based partitioning, you can create read-only access for specific user roles for a subset of the collection that belongs to that user.
Your application requirements will eventually help you decide the roles and access levels you should create. For example, in an application managing customer data, you could create additional roles such as:
**Customer Support Representative** : read-write access to customer service-related data but no access to billing information.
**Billing Department** : read-only access to billing data and read-write access to payment records.
**Marketing Analyst** : read-only access to anonymized customer data for analytics.
Each role can be assigned a JWT with claims that specify expiration times, read/write permissions for collections, and validating conditions.
In such an application, an example JWT payload for a customer support representative role could be:
```
{
  "exp": 1690995200,
  "access": [
    {
      "collection": "customer_data",
      "access": "rw",
      "payload": {
        "department": "support"
      }
    }
  ],
  "value_exists": {
    "collection": "departments",
    "matches": [
      { "key": "department", "value": "support" }
    ]
  }
}

```
As you can see, by implementing RBAC, you can ensure proper segregation of roles and their privileges, and avoid privacy loopholes in your application.
## Qdrant Hybrid Cloud and Data Sovereignty
Data governance varies by country, especially for global organizations dealing with different regulations on data privacy, security, and access. This often necessitates deploying infrastructure within specific geographical boundaries.
To address these needs, the vector database you choose should support deployment and scaling within your controlled infrastructure. [Qdrant Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/) offers this flexibility, along with features like sharding, replicas, JWT authentication, and monitoring.
Qdrant Hybrid Cloud integrates Kubernetes clusters from various environments—cloud, on-premises, or edge—into a unified managed service. This allows organizations to manage Qdrant databases through the Qdrant Cloud UI while keeping the databases within their infrastructure.
With JWT and RBAC, Qdrant Hybrid Cloud provides a secure, private, and sovereign vector store. Enterprises can scale their AI applications geographically, comply with local laws, and maintain strict data control.
## Conclusion
Vector similarity is increasingly becoming the backbone of AI applications that leverage unstructured data. By transforming data into vectors – their numerical representations – organizations can build powerful applications that harness semantic search, ranging from better recommendation systems to algorithms that help with personalization, or powerful customer support chatbots.
However, to fully leverage the power of AI in production, organizations need to choose a vector database that offers strong privacy and security features, while also helping them adhere to local laws and regulations.
Qdrant provides exceptional efficiency and performance, along with the capability to implement granular access control to data, Role-Based Access Control (RBAC), and the ability to build a fully data-sovereign architecture.
Interested in mastering vector search security and deployment strategies? 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/data-privacy.md) this page on GitHub, or 
On this page:
  * [Vector Database Security: An Overview](https://qdrant.tech/articles/data-privacy/#vector-database-security-an-overview)
  * [How Qdrant Handles Data Privacy and Security](https://qdrant.tech/articles/data-privacy/#how-qdrant-handles-data-privacy-and-security)
    * [API Keys and TLS Encryption](https://qdrant.tech/articles/data-privacy/#api-keys-and-tls-encryption)
    * [JWT on Qdrant](https://qdrant.tech/articles/data-privacy/#jwt-on-qdrant)
    * [Payload Configuration](https://qdrant.tech/articles/data-privacy/#payload-configuration)
    * [Creating Role-Based Access Control (RBAC) Using JWT](https://qdrant.tech/articles/data-privacy/#creating-role-based-access-control-rbac-using-jwt)
  * [Qdrant Hybrid Cloud and Data Sovereignty](https://qdrant.tech/articles/data-privacy/#qdrant-hybrid-cloud-and-data-sovereignty)
  * [Conclusion](https://qdrant.tech/articles/data-privacy/#conclusion)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/data-privacy/)
                    ## 📄 `https-qdrant-tech-articles-dedicated-vector-search.md`
                    ```md
                    # https://qdrant.tech/articles/dedicated-vector-search/
  * [Articles](https://qdrant.tech/articles/)
  * Built for Vector Search
# Built for Vector Search
Evgeniya Sukhodolskaya & Andrey Vasnetsov
·
February 17, 2025
![Built for Vector Search](https://qdrant.tech/articles_data/dedicated-vector-search/preview/title.jpg)
Any problem with even a bit of complexity requires a specialized solution. You can use a Swiss Army knife to open a bottle or poke a hole in a cardboard box, but you will need an axe to chop wood — the same goes for software.
In this article, we will describe the unique challenges vector search poses and why a dedicated solution is the best way to tackle them.
## Vectors
![vectors](https://qdrant.tech/articles_data/dedicated-vector-search/image1.jpg)
Let’s look at the central concept of vector databases — [**vectors**](https://qdrant.tech/documentation/concepts/vectors/).
Vectors (also known as embeddings) are high-dimensional representations of various data points — texts, images, videos, etc. Many state-of-the-art (SOTA) embedding models generate representations of over 1,500 dimensions. When it comes to state-of-the-art PDF retrieval, the representations can reach [**over 100,000 dimensions per page**](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/).
This brings us to the first challenge of vector search — vectors are heavy.
### Vectors are Heavy
To put this in perspective, consider one million records stored in a relational database. It’s a relatively small amount of data for modern databases, which a free tier of many cloud providers could easily handle.
Now, generate a 1536-dimensional embedding with OpenAI’s `text-embedding-ada-002` model from each record, and you are looking at around **6GB of storage**. As a result, vector search workloads, especially if not optimized, will quickly dominate the main use cases of a non-vector database.
Having vectors as a part of a main database is a potential issue for another reason — vectors are always a transformation of other data.
### Vectors are a Transformation
Vectors are obtained from some other source-of-truth data. They can be restored if lost with the same embedding model previously used. At the same time, even small changes in that model can shift the geometry of the vector space, so if you update or change the embedding model, you need to update and reindex all the data to maintain accurate vector comparisons.
If coupled with the main database, this update process can lead to significant complications and even unavailability of the whole system.
Decouple vector workloads even if you plan to use a general-purpose database for vectors.
However, vectors have positive properties as well. One of the most important is that vectors are fixed-size.
### Vectors are Fixed-Size
Embedding models are designed to produce vectors of a fixed size. We have to use it to our advantage.
For fast search, vectors need to be instantly accessible. Whether in [**RAM or disk**](https://qdrant.tech/documentation/concepts/storage/), vectors should be stored in a format that allows quick access and comparison. This is essential, as vector comparison is a very hot operation in vector search workloads. It is often performed thousands of times per search query, so even a small overhead can lead to a significant slowdown.
For dedicated storage, vectors’ fixed size comes as a blessing. Knowing how much space one data point needs, we don’t have to deal with the usual overhead of locating data — the location of elements in storage is straightforward to calculate.
Everything becomes far less intuitive if vectors are stored together with other data types, for example, texts or JSONs. The size of a single data point is not fixed anymore, so accessing it becomes non-trivial, especially if data is added, updated, and deleted over time.
![Fixed size columns VS Variable length table](https://qdrant.tech/articles_data/dedicated-vector-search/dedicated_storage.png)
Fixed size columns VS Variable length table
**Storing vectors together with other types of data, we lose all the benefits of their characteristics** ; however, we fully “enjoy” their drawbacks, polluting the storage with an extremely heavy transformation of data already existing in that storage.
## Vector Search
![vector-search](https://qdrant.tech/articles_data/dedicated-vector-search/image2.jpg)
Unlike traditional databases that serve as data stores, **vector databases are more like search engines**. They are designed to be **scalable** , always **available** , and capable of delivering high-speed search results even under heavy loads. Just as Google or Bing can handle billions of queries at once, vector databases are designed for scenarios where rapid, high-throughput, low-latency retrieval is a must.
![Database Compass](https://qdrant.tech/articles_data/dedicated-vector-search/compass.png)
Database Compass
### Pick Any Two
Distributed systems are perfect for scalability — horizontal scaling in these systems allows you to add more machines as needed. In the world of distributed systems, one well-known principle — the **CAP theorem** — illustrates that you cannot have it all. The theorem states that a distributed system can guarantee only two out of three properties: **Consistency** , **Availability** , and **Partition Tolerance**.
As network partitions are inevitable in any real-world distributed system, all modern distributed databases are designed with partition tolerance in mind, forcing a trade-off between **consistency** (providing the most up-to-date data) and **availability** (remaining responsive).
**CP systems** are still available to clients under normal operation — they prioritize data correctness over availability during failures.  
**AP systems** deliver quick responses by relaxing immediate consistency guarantees but eventually converge to a correct state.
There are two main design philosophies for databases in this context:
### ACID: Prioritizing Consistency
The ACID model ensures that every transaction (a group of operations treated as a single unit, such as transferring money between accounts) is executed fully or not at all (reverted), leaving the database in a valid state. When a system is distributed, achieving ACID properties requires complex coordination between nodes. Each node must communicate and agree on the state of a transaction, which can **limit system availability** — if a node is uncertain about the state of another, it may refuse to process a transaction until consistency is assured. This coordination also makes **scaling more challenging**.
Financial institutions use ACID-compliant databases when dealing with money transfers, where even a momentary discrepancy in an account balance is unacceptable.
### BASE: Prioritizing Availability
On the other hand, the BASE model favors high availability and partition tolerance. BASE systems distribute data and workload across multiple nodes, enabling them to respond to read and write requests immediately. They operate under the principle of **eventual consistency** — although data may be temporarily out-of-date, the system will converge on a consistent state given time.
Social media platforms, streaming services, and search engines all benefit from the BASE approach. For these applications, having immediate responsiveness is more critical than strict consistency.
### BASEd Vector Search
Considering the specifics of vector search — its nature demanding availability & scalability — it should be served on BASE-oriented architecture. This choice is made due to the need for horizontal scaling, high availability, low latency, and high throughput. For example, having BASE-focused architecture allows us to [**easily manage resharding**](https://qdrant.tech/documentation/cloud/cluster-scaling/#resharding).
A strictly consistent transactional approach also loses its attractiveness when we remember that vectors are heavy transformations of data at our disposal — what’s the point in limiting data protection mechanisms if we can always restore vectorized data through a transformation?
## Vector Index
![vector-index](https://qdrant.tech/articles_data/dedicated-vector-search/image3.jpg)
[**Vector search**](https://qdrant.tech/documentation/concepts/search/) relies on high-dimensional vector mathematics, making it computationally heavy at scale. A brute-force similarity search would require comparing a query against every vector in the database. In a database with 100 million 1536-dimensional vectors, performing 100 million comparisons per one query is unfeasible for production scenarios. Instead of a brute-force approach, vector databases have specialized approximate nearest neighbour (ANN) indexes that balance search precision and speed. These indexes require carefully designed architectures to make their maintenance in production feasible.
![HNSW Index](https://qdrant.tech/articles_data/dedicated-vector-search/hnsw.png)
HNSW Index
One of the most popular vector indexes is **HNSW (Hierarchical Navigable Small World)** , which we picked for its capability to provide simultaneously high search speed and accuracy. High performance came with a cost — implementing it in production is untrivial due to several challenges, so to make it shine all the system’s architecture has to be structured around it, serving the capricious index.
### Index Complexity
[**HNSW**](https://qdrant.tech/documentation/concepts/indexing/) is structured as a multi-layered graph. With a new data point inserted, the algorithm must compare it to existing nodes across several layers to index it. As the number of vectors grows, these comparisons will noticeably slow down the construction process, making updates increasingly time-consuming. The indexing operation can quickly become the bottleneck in the system, slowing down search requests.
Building an HNSW monolith means limiting the scalability of your solution — its size has to be capped, as its construction time scales **non-linearly** with the number of elements. To keep the construction process feasible and ensure it doesn’t affect the search time, we came up with a layered architecture that breaks down all data management into small units called **segments**.
![Storage structure](https://qdrant.tech/articles_data/dedicated-vector-search/segments.png)
Storage structure
Each segment isolates a subset of vectorized corpora and supports all collection-level operations on it, from searching to indexing, for example segments build their own index on the subset of data available to them. For users working on a collection level, the specifics of segmentation are unnoticeable. The search results they get span the whole collection, as sub-results are gathered from segments and then merged & deduplicated.
By balancing between size and number of segments, we can ensure the right balance between search speed and indexing time, making the system flexible for different workloads.
### Immutability
With index maintenance divided between segments, Qdrant can ensure high performance even during heavy load, and additional optimizations secure that further. These optimizations come from an idea that working with immutable structures introduces plenty of benefits: the possibility of using internally fixed sized lists (so no dynamic updates), ordering stored data accordingly to access patterns (so no unpredictable random accesses). With this in mind, to optimize search speed and memory management further, we use a strategy that combines and manages [**mutable and immutable segments**](https://qdrant.tech/articles/immutable-data-structures/).
**Mutable Segments** | These are used for quickly ingesting new data and handling changes (updates) to existing data.  
---|---  
**Immutable Segments** | Once a mutable segment reaches a certain size, an optimization process converts it into an immutable segment, constructing an HNSW index – you could [**read about these optimizers here**](https://qdrant.tech/documentation/concepts/optimizer/#optimizer) in detail. This immutability trick allowed us, for example, to ensure effective [**tenant isolation**](https://qdrant.tech/documentation/concepts/indexing/#tenant-index).  
Immutable segments are an implementation detail transparent for users — they can delete vectors at any time, while additions and updates are applied to a mutable segment instead. This combination of mutability and immutability allows search and indexing to smoothly run simultaneously, even under heavy loads. This approach minimizes the performance impact of indexing time and allows on-the-fly configuration changes on a collection level (such as enabling or disabling data quantization) without downtimes.
### Filterable Index
Vector search wasn’t historically designed for filtering — imposing strict constraints on results. It’s inherently fuzzy; every document is, to some extent, both similar and dissimilar to any query — there’s no binary “ _fits/doesn’t fit_ ” segregation. As a result, vector search algorithms weren’t originally built with filtering in mind.
At the same time, filtering is unavoidable in many vector search applications, such as [**e-commerce search/recommendations**](https://qdrant.tech/recommendations/). Searching for a Christmas present, you might want to filter out everything over 100 euros while still benefiting from the vector search’s semantic nature.
In many vector search solutions, filtering is approached in two ways: **pre-filtering** (computes a binary mask for all vectors fitting the condition before running HNSW search) or **post-filtering** (running HNSW as usual and then filtering the results).
❌ | **Pre-filtering** | Has the linear complexity of computing the vector mask and becomes a bottleneck for large datasets.  
---|---|---  
❌ | **Post-filtering** | The problem with **post-filtering** is tied to vector search “ _everything fits and doesn’t at the same time_ ” nature: imagine a low-cardinality filter that leaves only a few matching elements in the database. If none of them are similar enough to the query to appear in the top-X retrieved results, they’ll all be filtered out.  
Qdrant [**took filtering in vector search further**](https://qdrant.tech/articles/vector-search-filtering/), recognizing the limitations of pre-filtering & post-filtering strategies. We developed an adaptation of HNSW — [**filterable HNSW**](https://qdrant.tech/articles/filtrable-hnsw/) — that also enables **in-place filtering** during graph traversal. To make this possible, we condition HNSW index construction on possible filtering conditions reflected by [**payload indexes**](https://qdrant.tech/documentation/concepts/indexing/#payload-index) (inverted indexes built on vectors’ [**metadata**](https://qdrant.tech/documentation/concepts/payload/)).
**Qdrant was designed with a vector index being a central component of the system.** That made it possible to organize optimizers, payload indexes and other components around the vector index, unlocking the possibility of building a filterable HNSW.
![Filterable Vector Index](https://qdrant.tech/articles_data/dedicated-vector-search/filterable-vector-index.png)
Filterable Vector Index
In general, optimizing vector search requires a custom, finely tuned approach to data and index management that secures high performance even as data grows and changes dynamically. This specialized architecture is the key reason why **dedicated vector databases will always outperform general-purpose databases in production settings**.
## Vector Search Beyond RAG
![Vector Search is not Text Search Extension](https://qdrant.tech/articles_data/dedicated-vector-search/venn-diagram.png)
Vector Search is not Text Search Extension
Many discussions about the purpose of vector databases focus on Retrieval-Augmented Generation (RAG) — or its more advanced variant, agentic RAG — where vector databases are used as a knowledge source to retrieve context for large language models (LLMs). This is a legitimate use case, however, the hype wave of RAG solutions has overshadowed the broader potential of vector search, which goes [**beyond augmenting generative AI**](https://qdrant.tech/articles/vector-similarity-beyond-search/).
### Discovery
The strength of vector search lies in its ability to facilitate [**discovery**](https://qdrant.tech/articles/discovery-search/). Vector search allows you to refine your choices as you search rather than starting with a fixed query. Say, [**you’re ordering food not knowing exactly what you want**](https://qdrant.tech/articles/food-discovery-demo/) — just that it should contain meat & not a burger, or that it should be meat with cheese & not tacos. Instead of searching for a specific dish, vector search helps you navigate options based on similarity and dissimilarity, guiding you toward something that matches your taste without requiring you to define it upfront.
### Recommendations
Vector search is perfect for [**recommendations**](https://qdrant.tech/documentation/concepts/explore/#recommendation-api). Imagine browsing for a new book or movie. Instead of searching for an exact match, you might look for stories that capture a certain mood or theme but differ in key aspects from what you already know. For example, you may 
### Big Unstructured Data Analysis
Vector search nature makes it also ideal for 
### Fundamentally Different
**Vector search beyond RAG isn’t just another feature — it’s a fundamental shift in how we interact with data**. Dedicated solutions integrate these capabilities natively and are designed from the ground up to handle high-dimensional math and (dis-)similarity-based retrieval. In contrast, databases with vector extensions are built around a different data paradigm, making it impossible to efficiently support advanced vector search capabilities.
Even if you want to retrofit these capabilities, it’s not just a matter of adding a new feature — it’s a structural problem. Supporting advanced vector search requires **dedicated interfaces** that enable flexible usage of vector search from multi-stage filtering to dynamic exploration of high-dimensional spaces.
When the underlying architecture wasn’t initially designed for this kind of interaction, integrating interfaces is a **software engineering team nightmare**. You end up breaking existing assumptions, forcing inefficient workarounds, and often introducing backwards-compatibility problems. It’s why attempts to patch vector search onto traditional databases won’t match the efficiency of purpose-built systems.
## Making Vector Search State-of-the-Art
![vector-search-state-of-the-art](https://qdrant.tech/articles_data/dedicated-vector-search/image4.jpg)
Now, let’s shift focus to another key advantage of dedicated solutions — their ability to keep up with state-of-the-art solutions in the field.
[**Vector databases**](https://qdrant.tech/qdrant-vector-database/) are purpose-built for vector retrieval, and as a result, they offer cutting-edge features that are often critical for AI businesses relying on vector search. Vector database engineers invest significant time and effort into researching and implementing the most optimal ways to perform vector search. Many of these innovations come naturally to vector-native architectures, while general-purpose databases with added vector capabilities may struggle to adapt and replicate these benefits efficiently.
Consider some of the advanced features implemented in Qdrant:
  * [**GPU-Accelerated Indexing**](https://qdrant.tech/blog/qdrant-1.13.x/#gpu-accelerated-indexing)  
By offloading index construction tasks to the GPU, Qdrant can significantly speed up the process of data indexing while keeping costs low. This becomes especially valuable when working with large datasets in hot data scenarios.
GPU acceleration in Qdrant is a custom solution developed by an enthusiast from our core team. It’s vendor-free and natively supports all Qdrant’s unique architectural features, from FIlterable HNSW to multivectors.
  * [**Multivectors**](https://qdrant.tech/documentation/concepts/vectors/?q=multivectors#multivectors)  
Some modern embedding models produce an entire matrix (a list of vectors) as output rather than a single vector. Qdrant supports multivectors natively.
This feature is critical when using state-of-the-art retrieval models such as [**ColBERT**](https://qdrant.tech/documentation/fastembed/fastembed-colbert/), ColPali, or ColQwen. For instance, ColPali and ColQwen produce multivector outputs, and supporting them natively is crucial for [**state-of-the-art (SOTA) PDF-retrieval**](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/).
In addition to that, we continuously look for improvements in:
**Memory Efficiency & Compression** | Techniques such as [**quantization**](https://qdrant.tech/articles/dedicated-vector-search/documentation/guides/quantization/) and [**HNSW compression**](https://qdrant.tech/blog/qdrant-1.13.x/#hnsw-graph-compression) to reduce storage requirements  
---|---  
**Retrieval Algorithms** | Support for the latest retrieval algorithms, including [**sparse neural retrieval**](https://qdrant.tech/articles/modern-sparse-neural-retrieval/), [**hybrid search**](https://qdrant.tech/documentation/concepts/hybrid-queries/) methods, and [**re-rankers**](https://qdrant.tech/documentation/fastembed/fastembed-rerankers/).  
**Vector Data Analysis & Visualization** | Tools like the [**distance matrix API**](https://qdrant.tech/blog/qdrant-1.12.x/#distance-matrix-api-for-data-insights) provide insights into vectorized data, and a [**Web UI**](https://qdrant.tech/blog/qdrant-1.11.x/#web-ui-search-quality-tool) allows for intuitive exploration of data.  
**Search Speed & Scalability** | Includes optimizations for [**multi-tenant environments**](https://qdrant.tech/articles/multitenancy/) to ensure efficient and scalable search.  
**These advancements are not just incremental improvements — they define the difference between a system optimized for vector search and one that accommodates it.**
Staying at the cutting edge of vector search is not just about performance — it’s also about keeping pace with an evolving AI landscape.
## Summing up
![conclusion-vector-search](https://qdrant.tech/articles_data/dedicated-vector-search/image5.jpg)
When it comes to vector search, there’s a clear distinction between using a dedicated vector search solution and extending a database to support vector operations.
**For small-scale applications or prototypes handling up to a million data points, a non-optimized architecture might suffice.** However, as the volume of vectors grows, an unoptimized solution will quickly become a bottleneck — slowing down search operations and limiting scalability. Dedicated vector search solutions are engineered from the ground up to handle massive amounts of high-dimensional data efficiently.
State-of-the-art (SOTA) vector search evolves rapidly. If you plan to build on the latest advances, using a vector extension will eventually hold you back. Dedicated vector search solutions integrate these features natively, ensuring that you benefit from continuous innovations without compromising performance.
The power of vector search extends into areas such as big data analysis, recommendation systems, and discovery-based applications, and to support these vector search capabilities, a dedicated solution is needed.
### When to Choose a Dedicated Database over an Extension:
  * **High-Volume, Real-Time Search** : Ideal for applications with many simultaneous users who require fast, continuous access to search results—think search engines, e-commerce recommendations, social media, or media streaming services.
  * **Dynamic, Unstructured Data** : Perfect for scenarios where data is continuously evolving and where the goal is to discover insights from data patterns.
  * **Innovative Applications** : If you’re looking to implement advanced use cases such as recommendation engines, hybrid search solutions, or exploratory data analysis where traditional exact or token-based searches hold short.
Investing in a dedicated vector search engine will deliver the performance and flexibility necessary for success if your application relies on vector search at scale, keeps up with trends, or requires more than just a simple small-scale similarity search.
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/dedicated-vector-search.md) this page on GitHub, or 
On this page:
  * [Vectors](https://qdrant.tech/articles/dedicated-vector-search/#vectors)
    * [Vectors are Heavy](https://qdrant.tech/articles/dedicated-vector-search/#vectors-are-heavy)
    * [Vectors are a Transformation](https://qdrant.tech/articles/dedicated-vector-search/#vectors-are-a-transformation)
    * [Vectors are Fixed-Size](https://qdrant.tech/articles/dedicated-vector-search/#vectors-are-fixed-size)
  * [Vector Search](https://qdrant.tech/articles/dedicated-vector-search/#vector-search)
    * [Pick Any Two](https://qdrant.tech/articles/dedicated-vector-search/#pick-any-two)
    * [ACID: Prioritizing Consistency](https://qdrant.tech/articles/dedicated-vector-search/#acid-prioritizing-consistency)
    * [BASE: Prioritizing Availability](https://qdrant.tech/articles/dedicated-vector-search/#base-prioritizing-availability)
    * [BASEd Vector Search](https://qdrant.tech/articles/dedicated-vector-search/#based-vector-search)
  * [Vector Index](https://qdrant.tech/articles/dedicated-vector-search/#vector-index)
    * [Index Complexity](https://qdrant.tech/articles/dedicated-vector-search/#index-complexity)
    * [Immutability](https://qdrant.tech/articles/dedicated-vector-search/#immutability)
    * [Filterable Index](https://qdrant.tech/articles/dedicated-vector-search/#filterable-index)
  * [Vector Search Beyond RAG](https://qdrant.tech/articles/dedicated-vector-search/#vector-search-beyond-rag)
    * [Discovery](https://qdrant.tech/articles/dedicated-vector-search/#discovery)
    * [Recommendations](https://qdrant.tech/articles/dedicated-vector-search/#recommendations)
    * [Big Unstructured Data Analysis](https://qdrant.tech/articles/dedicated-vector-search/#big-unstructured-data-analysis)
    * [Fundamentally Different](https://qdrant.tech/articles/dedicated-vector-search/#fundamentally-different)
  * [Making Vector Search State-of-the-Art](https://qdrant.tech/articles/dedicated-vector-search/#making-vector-search-state-of-the-art)
  * [Summing up](https://qdrant.tech/articles/dedicated-vector-search/#summing-up)
    * [When to Choose a Dedicated Database over an Extension:](https://qdrant.tech/articles/dedicated-vector-search/#when-to-choose-a-dedicated-database-over-an-extension)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/dedicated-vector-search/)
                    ## 📄 `https-qdrant-tech-articles-detecting-coffee-anomalies.md`
                    ```md
                    # https://qdrant.tech/articles/detecting-coffee-anomalies/
  * [Articles](https://qdrant.tech/articles/)
  * Metric Learning for Anomaly Detection
# Metric Learning for Anomaly Detection
Yusuf Sarıgöz
·
May 04, 2022
![Metric Learning for Anomaly Detection](https://qdrant.tech/articles_data/detecting-coffee-anomalies/preview/title.jpg)
Anomaly detection is a thirsting yet challenging task that has numerous use cases across various industries. The complexity results mainly from the fact that the task is data-scarce by definition.
Similarly, anomalies are, again by definition, subject to frequent change, and they may take unexpected forms. For that reason, supervised classification-based approaches are:
  * Data-hungry - requiring quite a number of labeled data;
  * Expensive - data labeling is an expensive task itself;
  * Time-consuming - you would try to obtain what is necessarily scarce;
  * Hard to maintain - you would need to re-train the model repeatedly in response to changes in the data distribution.
These are not desirable features if you want to put your model into production in a rapidly-changing environment. And, despite all the mentioned difficulties, they do not necessarily offer superior performance compared to the alternatives. In this post, we will detail the lessons learned from such a use case.
## Coffee Beans
**30 thousand** images of coffee beans with various defects - wet, broken, chipped, or bug-infested samples. This data is used to train a classifier that evaluates crop quality and highlights possible problems.
![Anomalies in coffee](https://qdrant.tech/articles_data/detecting-coffee-anomalies/detection.gif)
Anomalies in coffee
We should note that anomalies are very diverse, so the enumeration of all possible anomalies is a challenging task on it’s own. In the course of work, new types of defects appear, and shooting conditions change. Thus, a one-time labeled dataset becomes insufficient.
Let’s find out how metric learning might help to address this challenge.
## Metric Learning Approach
In this approach, we aimed to encode images in an n-dimensional vector space and then use learned similarities to label images during the inference.
The simplest way to do this is KNN classification. The algorithm retrieves K-nearest neighbors to a given query vector and assigns a label based on the majority vote.
In production environment kNN classifier could be easily replaced with 
![Production deployment](https://qdrant.tech/articles_data/detecting-coffee-anomalies/anomalies_detection.png)
Production deployment
This approach has the following advantages:
  * We can benefit from unlabeled data, considering labeling is time-consuming and expensive.
  * The relevant metric, e.g., precision or recall, can be tuned according to changing requirements during the inference without re-training.
  * Queries labeled with a high score can be added to the KNN classifier on the fly as new data points.
To apply metric learning, we need to have a neural encoder, a model capable of transforming an image into a vector.
Training such an encoder from scratch may require a significant amount of data we might not have. Therefore, we will divide the training into two steps:
  * The first step is to train the autoencoder, with which we will prepare a model capable of representing the target domain.
  * The second step is finetuning. Its purpose is to train the model to distinguish the required types of anomalies.
![Model training architecture](https://qdrant.tech/articles_data/detecting-coffee-anomalies/anomaly_detection_training.png)
Model training architecture
### Step 1 - Autoencoder for Unlabeled Data
First, we pretrained a Resnet18-like model in a vanilla autoencoder architecture by leaving the labels aside. Autoencoder is a model architecture composed of an encoder and a decoder, with the latter trying to recreate the original input from the low-dimensional bottleneck output of the former.
There is no intuitive evaluation metric to indicate the performance in this setup, but we can evaluate the success by examining the recreated samples visually.
![Example of image reconstruction with Autoencoder](https://qdrant.tech/articles_data/detecting-coffee-anomalies/image_reconstruction.png)
Example of image reconstruction with Autoencoder
Then we encoded a subset of the data into 128-dimensional vectors by using the encoder, and created a KNN classifier on top of these embeddings and associated labels.
Although the results are promising, we can do even better by finetuning with metric learning.
### Step 2 - Finetuning with Metric Learning
We started by selecting 200 labeled samples randomly without replacement.
In this step, The model was composed of the encoder part of the autoencoder with a randomly initialized projection layer stacked on top of it. We applied transfer learning from the frozen encoder and trained only the projection layer with Triplet Loss and an online batch-all triplet mining strategy.
Unfortunately, the model overfitted quickly in this attempt. In the next experiment, we used an online batch-hard strategy with a trick to prevent vector space from collapsing. We will describe our approach in the further articles.
This time it converged smoothly, and our evaluation metrics also improved considerably to match the supervised classification approach.
![Metrics for the autoencoder model with KNN classifier](https://qdrant.tech/articles_data/detecting-coffee-anomalies/ae_report_knn.png)
Metrics for the autoencoder model with KNN classifier
![Metrics for the finetuned model with KNN classifier](https://qdrant.tech/articles_data/detecting-coffee-anomalies/ft_report_knn.png)
Metrics for the finetuned model with KNN classifier
We repeated this experiment with 500 and 2000 samples, but it showed only a slight improvement. Thus we decided to stick to 200 samples - see below for why.
## Supervised Classification Approach
We also wanted to compare our results with the metrics of a traditional supervised classification model. For this purpose, a Resnet50 model was finetuned with ~30k labeled images, made available for training. Surprisingly, the F1 score was around ~0.86.
Please note that we used only 200 labeled samples in the metric learning approach instead of ~30k in the supervised classification approach. These numbers indicate a huge saving with no considerable compromise in the performance.
## Conclusion
We obtained results comparable to those of the supervised classification method by using **only 0.66%** of the labeled data with metric learning. This approach is time-saving and resource-efficient, and that may be improved further. Possible next steps might be:
  * Collect more unlabeled data and pretrain a larger autoencoder.
  * Obtain high-quality labels for a small number of images instead of tens of thousands for finetuning.
  * Use hyperparameter optimization and possibly gradual unfreezing in the finetuning step.
  * Use 
We are actively looking into these, and we will continue to publish our findings in this challenge and other use cases of metric learning.
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/detecting-coffee-anomalies.md) this page on GitHub, or 
On this page:
  * [Coffee Beans](https://qdrant.tech/articles/detecting-coffee-anomalies/#coffee-beans)
  * [Metric Learning Approach](https://qdrant.tech/articles/detecting-coffee-anomalies/#metric-learning-approach)
    * [Step 1 - Autoencoder for Unlabeled Data](https://qdrant.tech/articles/detecting-coffee-anomalies/#step-1---autoencoder-for-unlabeled-data)
    * [Step 2 - Finetuning with Metric Learning](https://qdrant.tech/articles/detecting-coffee-anomalies/#step-2---finetuning-with-metric-learning)
  * [Supervised Classification Approach](https://qdrant.tech/articles/detecting-coffee-anomalies/#supervised-classification-approach)
  * [Conclusion](https://qdrant.tech/articles/detecting-coffee-anomalies/#conclusion)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/detecting-coffee-anomalies/)
                    ## 📄 `https-qdrant-tech-articles-dimension-reduction-qsoc.md`
                    ```md
                    # https://qdrant.tech/articles/dimension-reduction-qsoc/
  * [Articles](https://qdrant.tech/articles/)
  * Qdrant Summer of Code 2024 - WASM based Dimension Reduction
[](https://qdrant.tech/articles/ecosystem/)
# Qdrant Summer of Code 2024 - WASM based Dimension Reduction
Jishan Bhattacharya
·
August 31, 2024
![Qdrant Summer of Code 2024 - WASM based Dimension Reduction](https://qdrant.tech/articles_data/dimension-reduction-qsoc/preview/title.jpg)
## Introduction
Hello, everyone! I’m Jishan Bhattacharya, and I had the incredible opportunity to intern at Qdrant this summer as part of the Qdrant Summer of Code 2024. Under the mentorship of 
## Project Overview
Qdrant is a robust vector database and search engine designed to store vector data and perform tasks like similarity search and clustering. One of its standout features is the ability to visualize high-dimensional vectors in a 2D space. However, the existing implementation faced performance bottlenecks, especially when scaling to large datasets. My mission was to tackle this challenge by leveraging a WASM-based solution for dimensionality reduction in the visualization process.
## Learnings & Challenges
Our weapon of choice was Rust, paired with WASM, and we employed the t-SNE algorithm for dimensionality reduction. For those unfamiliar, t-SNE (t-Distributed Stochastic Neighbor Embedding) is a technique that helps visualize high-dimensional data by projecting it into two or three dimensions. It operates in two main steps:
  1. **Computing Pairwise Similarity:** This step involves calculating the similarity between each pair of data points in the original high-dimensional space.
  2. **Iterative Optimization:** The second step is iterative, where the embedding is refined using gradient descent. Here, the similarity matrix from the first step plays a crucial role.
At the outset, Andrey tasked me with rewriting the existing JavaScript implementation of t-SNE in Rust, introducing multi-threading along the way. Setting up WASM with Vite for multi-threaded execution was no small feat, but the effort paid off. The resulting Rust implementation outperformed the single-threaded JavaScript version, although it still struggled with large datasets.
Next came the challenge of optimizing the algorithm further. A key aspect of t-SNE’s first step is finding the nearest neighbors for each data point, which requires an efficient data structure. I opted for a 
To illustrate, imagine dividing a 2D space into quadrants, each containing multiple points. Every quadrant is again subdivided into four quadrants. This is done until every point belongs to a single cell.
![Calculating the resultant force on red point using Barnes-Hut approximation](https://qdrant.tech/articles_data/dimension-reduction-qsoc/barnes_hut.png)
Barnes-Hut Approximation
We then calculate the center of mass for each cell represented by a blue circle as shown in the figure. Now let’s say we want to find all the forces, represented by dotted lines, on the red point. Barnes Hut’s approximation states that for points that are sufficiently distant, instead of computing the force for each individual point, we use the center of mass as a proxy, significantly reducing the computational load. This is represented by the blue dotted line in the figure.
These optimizations made a remarkable difference — Barnes-Hut t-SNE was eight times faster than the exact t-SNE for 10,000 vectors.
![Image of visualizing 10,000 vectors using exact t-SNE which took 884.728s](https://qdrant.tech/articles_data/dimension-reduction-qsoc/rust_rewrite.jpg)
Exact t-SNE - Total time: 884.728s
![Image of visualizing 10,000 vectors using Barnes-Hut t-SNE which took 110.728s](https://qdrant.tech/articles_data/dimension-reduction-qsoc/rust_bhtsne.jpg)
Barnes-Hut t-SNE - Total time: 104.191s
Despite these improvements, the first step of the algorithm was still a bottleneck, leading to noticeable delays and blank screens. I experimented with approximate nearest neighbor algorithms, but the performance gains were minimal. After consulting with my mentor, we decided to compute the nearest neighbors on the server side, passing the distance matrix directly to the visualization process instead of the raw vectors.
While waiting for the distance-matrix API to be ready, I explored further optimizations. I observed that the worker thread sent results to the main thread for rendering at specific intervals, causing unnecessary delays due to serialization and deserialization.
![Image showing serialization and deserialization overhead due to message passing between threads](https://qdrant.tech/articles_data/dimension-reduction-qsoc/channels.png)
Serialization and Deserialization Overhead
To address this, I implemented a `SharedArrayBuffer`, allowing the main thread to access changes made by the worker thread instantly. This change led to noticeable improvements.
Additionally, the previous architecture resulted in choppy animations due to the fixed intervals at which the worker thread sent results.
![Image showing the previous architecture of the frontend with fixed intervals for sending results](https://qdrant.tech/articles_data/dimension-reduction-qsoc/prev_arch.png)
Previous architecture with fixed intervals
I introduced a “rendering-on-demand” approach, where the main thread would signal the worker thread when it was ready to render the next result. This created smoother, more responsive animations.
![Image showing the current architecture of the frontend with rendering-on-demand approach](https://qdrant.tech/articles_data/dimension-reduction-qsoc/curr_arch.png)
Current architecture with rendering-on-demand
With these optimizations in place, the final step was wrapping up the project by creating a Node.js 
## Areas for Improvement
While reflecting on this transformative journey, there are still areas that offer room for improvement and future enhancements:
  1. **Payload Parsing:** When requesting a large number of vectors, parsing the payload on the main thread can make the user interface unresponsive. Implementing a faster parser could mitigate this issue.
  2. **Direct Data Requests:** Allowing the worker thread to request data directly could eliminate the initial transfer of data from the main thread, speeding up the overall process.
  3. **Chart Library Optimization:** Profiling revealed that nearly 80% of the time was spent on the Chart.js update function. Switching to a WebGL-accelerated chart library could dramatically improve performance, especially for large datasets.
![Image showing profiling results with 80% time spent on Chart.js update function](https://qdrant.tech/articles_data/dimension-reduction-qsoc/profiling.png)
Profiling Result
## Conclusion
Participating in the Qdrant Summer of Code 2024 was a deeply rewarding experience. I had the chance to push the boundaries of my coding skills while exploring new technologies like Rust and WebAssembly. I’m incredibly grateful for the guidance and support from my mentor and the entire Qdrant team, who made this journey both educational and enjoyable.
This experience has not only honed my technical skills but also ignited a deeper passion for optimizing performance in real-world applications. I’m excited to apply the knowledge and skills I’ve gained to future projects and to see how Qdrant’s enhanced vector visualization feature will benefit users worldwide.
This experience has not only honed my technical skills but also ignited a deeper passion for optimizing performance in real-world applications. I’m excited to apply the knowledge and skills I’ve gained to future projects and to see how Qdrant’s enhanced vector visualization feature will benefit users worldwide.
Thank you for joining me on this coding adventure. I hope you found something valuable in my journey, and I look forward to sharing more exciting projects with you in the future. Happy coding!
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/dimension-reduction-qsoc.md) this page on GitHub, or 
On this page:
  * [Introduction](https://qdrant.tech/articles/dimension-reduction-qsoc/#introduction)
  * [Project Overview](https://qdrant.tech/articles/dimension-reduction-qsoc/#project-overview)
  * [Learnings & Challenges](https://qdrant.tech/articles/dimension-reduction-qsoc/#learnings--challenges)
  * [Areas for Improvement](https://qdrant.tech/articles/dimension-reduction-qsoc/#areas-for-improvement)
  * [Conclusion](https://qdrant.tech/articles/dimension-reduction-qsoc/#conclusion)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/dimension-reduction-qsoc/)
                    ## 📄 `https-qdrant-tech-articles-discovery-search.md`
                    ```md
                    # https://qdrant.tech/articles/discovery-search/
  * [Articles](https://qdrant.tech/articles/)
  * Discovery needs context
[](https://qdrant.tech/articles/data-exploration/)
# Discovery needs context
Luis Cossío
·
January 31, 2024
![Discovery needs context](https://qdrant.tech/articles_data/discovery-search/preview/title.jpg)
# Discovery needs context
When Christopher Columbus and his crew sailed to cross the Atlantic Ocean, they were not looking for the Americas. They were looking for a new route to India because they were convinced that the Earth was round. They didn’t know anything about a new continent, but since they were going west, they stumbled upon it.
They couldn’t reach their _target_ , because the geography didn’t let them, but once they realized it wasn’t India, they claimed it a new “discovery” for their crown. If we consider that sailors need water to sail, then we can establish a _context_ which is positive in the water, and negative on land. Once the sailor’s search was stopped by the land, they could not go any further, and a new route was found. Let’s keep these concepts of _target_ and _context_ in mind as we explore the new functionality of Qdrant: **Discovery search**.
## What is discovery search?
In version 1.7, Qdrant [released](https://qdrant.tech/articles/qdrant-1.7.x/) this novel API that lets you constrain the space in which a search is performed, relying only on pure vectors. This is a powerful tool that lets you explore the vector space in a more controlled way. It can be used to find points that are not necessarily closest to the target, but are still relevant to the search.
You can already select which points are available to the search by using payload filters. This by itself is very versatile because it allows us to craft complex filters that show only the points that satisfy their criteria deterministically. However, the payload associated with each point is arbitrary and cannot tell us anything about their position in the vector space. In other words, filtering out irrelevant points can be seen as creating a _mask_ rather than a hyperplane –cutting in between the positive and negative vectors– in the space.
## Understanding context
This is where a **vector _context_** can help. We define _context_ as a list of pairs. Each pair is made up of a positive and a negative vector. With a context, we can define hyperplanes within the vector space, which always prefer the positive over the negative vectors. This effectively partitions the space where the search is performed. After the space is partitioned, we then need a _target_ to return the points that are more similar to it.
![Discovery search visualization](https://qdrant.tech/articles_data/discovery-search/discovery-search.png)
While positive and negative vectors might suggest the use of the [recommendation interface](https://qdrant.tech/documentation/concepts/explore/#recommendation-api), in the case of _context_ they require to be paired up in a positive-negative fashion. This is inspired from the machine-learning concept of 
![Triplet loss](https://qdrant.tech/articles_data/discovery-search/triplet-loss.png)
[**Discovery search**](https://qdrant.tech/articles/discovery-search/#discovery-search), then, is made up of two main inputs:
  * **target** : the main point of interest
  * **context** : the pairs of positive and negative points we just defined.
However, it is not the only way to use it. Alternatively, you can **only** provide a context, which invokes a [**Context Search**](https://qdrant.tech/articles/discovery-search/#context-search). This is useful when you want to explore the space defined by the context, but don’t have a specific target in mind. But hold your horses, we’ll get to that [later ↪](https://qdrant.tech/articles/discovery-search/#context-search).
## Real-world discovery search applications
Let’s talk about the first case: context with a target.
To understand why this is useful, let’s take a look at a real-world example: using a multimodal encoder like **and** images. CLIP is a neural network that can embed both images and text into the same vector space. This means that you can search for images using either a text query or an image query. For this example, we’ll reuse our [food recommendations demo](https://food-discovery.qdrant.tech/) by typing “burger” in the text input:
![Burger text input in food demo](https://qdrant.tech/articles_data/discovery-search/search-for-burger.png)
This is basically nearest neighbor search, and while technically we have only images of burgers, one of them is a logo representation of a burger. We’re looking for actual burgers, though. Let’s try to exclude images like that by adding it as a negative example:
![Try to exclude burger drawing](https://qdrant.tech/articles_data/discovery-search/try-to-exclude-non-burger.png)
Wait a second, what has just happened? These pictures have **nothing** to do with burgers, and still, they appear on the first results. Is the demo broken?
Turns out, multimodal encoders 
![Mental model of CLIP embeddings](https://qdrant.tech/articles_data/discovery-search/clip-mental-model.png)
This is where discovery excels because it allows us to constrain the space considering the same mode (images) while using a target from the other mode (text).
![Cross-modal search with discovery](https://qdrant.tech/articles_data/discovery-search/clip-discovery.png)
Discovery search also lets us keep giving feedback to the search engine in the shape of more context pairs, so we can keep refining our search until we find what we are looking for.
Another intuitive example: imagine you’re looking for a fish pizza, but pizza names can be confusing, so you can just type “pizza”, and prefer a fish over meat. Discovery search will let you use these inputs to suggest a fish pizza… even if it’s not called fish pizza!
![Simple discovery example](https://qdrant.tech/articles_data/discovery-search/discovery-example-with-images.png)
## Context search
Now, the second case: only providing context.
Ever been caught in the same recommendations on your favorite music streaming service? This may be caused by getting stuck in a similarity bubble. As user input gets more complex, diversity becomes scarce, and it becomes harder to force the system to recommend something different.
![Context vs recommendation search](https://qdrant.tech/articles_data/discovery-search/context-vs-recommendation.png)
**Context search** solves this by de-focusing the search around a single point. Instead, it selects points randomly from within a zone in the vector space. This search is the most influenced by _triplet loss_ , as the score can be thought of as _“how much a point is closer to a negative than a positive vector?”_. If it is closer to the positive one, then its score will be zero, same as any other point within the same zone. But if it is on the negative side, it will be assigned a more and more negative score the further it gets.
![Context search visualization](https://qdrant.tech/articles_data/discovery-search/context-search.png)
Creating complex tastes in a high-dimensional space becomes easier since you can just add more context pairs to the search. This way, you should be able to constrain the space enough so you select points from a per-search “category” created just from the context in the input.
![A more complex context search](https://qdrant.tech/articles_data/discovery-search/complex-context-search.png)
This way you can give refreshing recommendations, while still being in control by providing positive and negative feedback, or even by trying out different permutations of pairs.
## Key takeaways:
  * Discovery search is a powerful tool for controlled exploration in vector spaces. Context, consisting of positive and negative vectors constrain the search space, while a target guides the search.
  * Real-world applications include multimodal search, diverse recommendations, and context-driven exploration.
  * Ready to learn more about the math behind it and how to use it? Check out the [documentation](https://qdrant.tech/documentation/concepts/explore/#discovery-api)
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/discovery-search.md) this page on GitHub, or 
On this page:
  * [What is discovery search?](https://qdrant.tech/articles/discovery-search/#what-is-discovery-search)
  * [Understanding context](https://qdrant.tech/articles/discovery-search/#understanding-context)
  * [Real-world discovery search applications](https://qdrant.tech/articles/discovery-search/#real-world-discovery-search-applications)
  * [Context search](https://qdrant.tech/articles/discovery-search/#context-search)
  * [Key takeaways:](https://qdrant.tech/articles/discovery-search/#key-takeaways)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/discovery-search/)
                    ## 📄 `https-qdrant-tech-articles-distance-based-exploration.md`
                    ```md
                    # https://qdrant.tech/articles/distance-based-exploration/
  * [Articles](https://qdrant.tech/articles/)
  * Distance-based data exploration
# Distance-based data exploration
Andrey Vasnetsov
·
March 11, 2025
![Distance-based data exploration](https://qdrant.tech/articles_data/distance-based-exploration/preview/title.jpg)
## Hidden Structure
When working with large collections of documents, images, or other arrays of unstructured data, it often becomes useful to understand the big picture. Examining data points individually is not always the best way to grasp the structure of the data.
![Data visualization](https://qdrant.tech/articles_data/distance-based-exploration/no-context-data.png)
Datapoints without context, pretty much useless
As numbers in a table obtain meaning when plotted on a graph, visualising distances (similar/dissimilar) between unstructured data items can reveal hidden structures and patterns.
![Data visualization](https://qdrant.tech/articles_data/distance-based-exploration/data-on-chart.png)
Vizualized chart, very intuitive
There are many tools to investigate data similarity, and Qdrant’s [1.12 release](https://qdrant.tech/blog/qdrant-1.12.x/) made it much easier to start this investigation. With the new [Distance Matrix API](https://qdrant.tech/documentation/concepts/explore/#distance-matrix), Qdrant handles the most computationally expensive part of the process—calculating the distances between data points.
In many implementations, the distance matrix calculation was part of the clustering or visualization processes, requiring either brute-force computation or building a temporary index. With Qdrant, however, the data is already indexed, and the distance matrix can be computed relatively cheaply.
In this article, we will explore several methods for data exploration using the Distance Matrix API.
## Dimensionality Reduction
Initially, we might want to visualize an entire dataset, or at least a large portion of it, at a glance. However, high-dimensional data cannot be directly visualized. We must apply dimensionality reduction techniques to convert data into a lower-dimensional representation while preserving important data properties.
In this article, we will use 
Here is a **very** simplified but intuitive explanation of UMAP:
  1. _Randomly generate points in 2D space_ : Assign a random 2D point to each high-dimensional point.
  2. _Compute distance matrix for high-dimensional points_ : Calculate distances between all pairs of points.
  3. _Compute distance matrix for 2D points_ : Perform similarly to step 2.
  4. _Match both distance matrices_ : Adjust 2D points to minimize differences.
![UMAP](https://qdrant.tech/articles_data/distance-based-exploration/umap.png)
Canonical example of UMAP results, 
UMAP preserves the relative distances between high-dimensional points; the actual coordinates are not essential. If we already have the distance matrix, step 2 can be skipped entirely.
Let’s use Qdrant to calculate the distance matrix and apply UMAP. We will use one of the default datasets perfect for experimenting in Qdrant–
Use this command to download and import the dataset into Qdrant:
```
PUT /collections/midlib/snapshots/recover
{
  "location": "http://snapshots.qdrant.io/midlib.snapshot"
}

```
We also need to prepare our python enviroment:
```
pip install umap-learn seaborn matplotlib qdrant-client

```
Import the necessary libraries:
```
# Used to talk to Qdrant
from qdrant_client import QdrantClient
# Package with original UMAP implementation
from umap import UMAP
# Python implementation for sparse matrices
from scipy.sparse import csr_matrix
# For vizualization
import seaborn as sns

```
Establish connection to Qdrant:
```
client = QdrantClient("http://localhost:6333")

```
After this is done, we can compute the distance matrix:
```
# Request distances matrix from Qdrant
# `_offsets` suffix defines a format of the output matrix.
result = client.search_matrix_offsets(
  collection_name="midlib",
  sample=1000, # Select a subset of the data, as the whole dataset might be too large
  limit=20, # For performance reasons, limit the number of closest neighbors to consider
)
# Convert distances matrix to python-native format 
matrix = csr_matrix(
    (result.scores, (result.offsets_row, result.offsets_col))
)
# Make the matrix symmetric, as UMAP expects it.
# Distance matrix is always symmetric, but qdrant only computes half of it.
matrix = matrix + matrix.T

```
Now we can apply UMAP to the distance matrix:
```
umap = UMAP(
    metric="precomputed", # We provide ready-made distance matrix
    n_components=2, # output dimension
    n_neighbors=20, # Same as the limit in the search_matrix_offsets
)
vectors_2d = umap.fit_transform(matrix)

```
That’s all that is needed to get the 2d representation of the data.
![UMAP on Midlib](https://qdrant.tech/articles_data/distance-based-exploration/umap-midlib.png)
UMAP applied to Midlib dataset
Interactive version of this plot is available in [Qdrant Web UI ](https://qdrant.tech/documentation/web-ui/)!
UMAP isn’t the only algorithm compatible with our distance matrix API. For example, `scikit-learn` also offers:
## Clustering
Another approach to data structure understanding is clustering–grouping similar items.
_Note that there’s no universally best clustering criterion or algorithm._
![Clustering](https://qdrant.tech/articles_data/distance-based-exploration/clustering.png)
Clustering example, 
Many clustering algorithms accept precomputed distance matrix as input, so we can use the same distance matrix we calculated before.
Let’s consider a simple example of clustering the Midlib dataset with **KMeans algorithm**.
From `fit()` method of KMeans algorithm prefers as an input:
> `X : {array-like, sparse matrix} of shape (n_samples, n_features)`:  
> Training instances to cluster. It must be noted that the data will be converted to C ordering, which will cause a memory copy if the given data is not C-contiguous. If a sparse matrix is passed, a copy will be made if it’s not in CSR format.
So we can re-use `matrix` from the previous example:
```
from sklearn.cluster import KMeans
# Initialize KMeans with 10 clusters
kmeans = KMeans(n_clusters=10)
# Generate index of the cluster each sample belongs to
cluster_labels = kmeans.fit_predict(matrix)

```
With this simple code, we have clustered the data into 10 clusters, while the main CPU-intensive part of the process was done by Qdrant.
![Clustering on Midlib](https://qdrant.tech/articles_data/distance-based-exploration/clustering-midlib.png)
Clustering applied to Midlib dataset
How to plot this chart
```
sns.scatterplot(
    # Coordinates obtained from UMAP
    x=vectors_2d[:, 0], y=vectors_2d[:, 1],
    # Color datapoints by cluster
    hue=cluster_labels,
    palette=sns.color_palette("pastel", 10),
    legend="full",
)

```
## Graphs
Clustering and dimensionality reduction both aim to provide a more transparent overview of the data. However, they share a common characteristic - they require a training step before the results can be visualized.
This also implies that introducing new data points necessitates re-running the training step, which may be computationally expensive.
Graphs offer an alternative approach to data exploration, enabling direct, interactive visualization of relationships between data points. In a graph representation, each data point is a node, and similarities between data points are represented as edges connecting the nodes.
Such a graph can be rendered in real-time using 
Adding new data points to the graph is as straightforward as inserting new nodes and edges without the need to re-run any training steps.
In practice, rendering a graph for an entire dataset at once may be computationally expensive and overwhelming for the user. Therefore, let’s explore a few strategies to address this issue.
### Expanding from a single node
This is the simplest approach, where we start with a single node and expand the graph by adding the most similar nodes to the graph.
![Graph](https://qdrant.tech/articles_data/distance-based-exploration/graph.gif)
Graph representation of the data
An interactive version of this plot is available in [Qdrant Web UI ](https://qdrant.tech/documentation/web-ui/)!
### Sampling from a collection
Expanding a single node works well if you want to explore neighbors of a single point, but what if you want to explore the whole dataset? If your dataset is small enough, you can render relations for all the data points at once. But it is a rare case in practice.
Instead, we can sample a subset of the data and render the graph for this subset. This way, we can get a good overview of the data without overwhelming the user with too much information.
Let’s try to do so in [Qdrant’s Graph Exploration Tool](https://qdrant.tech/blog/qdrant-1.11.x/#web-ui-graph-exploration-tool):
```
{
  "limit": 5, # node neighbors to consider
  "sample": 100 # nodes
}

```
![Graph](https://qdrant.tech/articles_data/distance-based-exploration/graph-sampled.png)
Graph representation of the data ([Qdrant’s Graph Exploration Tool](https://qdrant.tech/blog/qdrant-1.11.x/#web-ui-graph-exploration-tool))
This graph captures some high-level structure of the data, but as you might have noticed, it is quite noisy. This is because the differences in similarities are relatively small, and they might be overwhelmed by the stretches and compressions of the force-directed layout algorithm.
To make the graph more readable, let’s concentrate on the most important similarities and build a so called 
```
{
  "limit": 5,
  "sample": 100,
  "tree": true
}

```
![Graph](https://qdrant.tech/articles_data/distance-based-exploration/spanning-tree.png)
Spanning tree of the graph ([Qdrant’s Graph Exploration Tool](https://qdrant.tech/blog/qdrant-1.11.x/#web-ui-graph-exploration-tool))
This algorithm will only keep the most important edges and remove the rest while keeping the graph connected. By doing so, we can reveal clusters of the data and the most important relations between them.
In some sense, this is similar to hierarchical clustering, but with the ability to interactively explore the data. Another analogy might be a dynamically constructed mind map.
## Conclusion
Vector similarity goes beyond looking up the nearest neighbors–it provides a powerful tool for data exploration. Many algorithms can construct human-readable data representations, and Qdrant makes using them easy.
Several data exploration instruments are available in the Qdrant Web UI ([Visualization and Graph Exploration Tools](https://qdrant.tech/articles/web-ui-gsoc/)), and for more advanced use cases, you could directly utilise our distance matrix API.
Try it with your data and see what hidden structures you can reveal!
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/distance-based-exploration.md) this page on GitHub, or 
On this page:
  * [Hidden Structure](https://qdrant.tech/articles/distance-based-exploration/#hidden-structure)
  * [Dimensionality Reduction](https://qdrant.tech/articles/distance-based-exploration/#dimensionality-reduction)
  * [Clustering](https://qdrant.tech/articles/distance-based-exploration/#clustering)
  * [Graphs](https://qdrant.tech/articles/distance-based-exploration/#graphs)
    * [Expanding from a single node](https://qdrant.tech/articles/distance-based-exploration/#expanding-from-a-single-node)
    * [Sampling from a collection](https://qdrant.tech/articles/distance-based-exploration/#sampling-from-a-collection)
  * [Conclusion](https://qdrant.tech/articles/distance-based-exploration/#conclusion)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/distance-based-exploration/)
                    ## 📄 `https-qdrant-tech-articles-ecosystem.md`
                    ```md
                    # https://qdrant.tech/articles/ecosystem/
  * [Articles](https://qdrant.tech/articles/)
  * Ecosystem
#### Ecosystem
Tools, libraries and integrations around Qdrant vector search engine.
[![Preview](https://qdrant.tech/articles_data/dimension-reduction-qsoc/preview/preview.jpg) Qdrant Summer of Code 2024 - WASM based Dimension Reduction My journey as a Qdrant Summer of Code 2024 participant working on enhancing vector visualization using WebAssembly (WASM) based dimension reduction. Jishan Bhattacharya August 31, 2024 ](https://qdrant.tech/articles/dimension-reduction-qsoc/)[![Preview](https://qdrant.tech/articles_data/fastembed/preview/preview.jpg) FastEmbed: Qdrant's Efficient Python Library for Embedding Generation Learn how to accurately and efficiently create text embeddings with FastEmbed. Nirant Kasliwal October 18, 2023 ](https://qdrant.tech/articles/fastembed/)[![Preview](https://qdrant.tech/articles_data/web-ui-gsoc/preview/preview.jpg) Google Summer of Code 2023 - Web UI for Visualization and Exploration My journey as a Google Summer of Code 2023 student working on the "Web UI for Visualization and Exploration" project for Qdrant. Kartik Gupta August 28, 2023 ](https://qdrant.tech/articles/web-ui-gsoc/)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/ecosystem/)
                    ## 📄 `https-qdrant-tech-articles-fastembed.md`
                    ```md
                    # https://qdrant.tech/articles/fastembed/
  * [Articles](https://qdrant.tech/articles/)
  * FastEmbed: Qdrant's Efficient Python Library for Embedding Generation
# FastEmbed: Qdrant's Efficient Python Library for Embedding Generation
Nirant Kasliwal
·
October 18, 2023
![FastEmbed: Qdrant's Efficient Python Library for Embedding Generation](https://qdrant.tech/articles_data/fastembed/preview/title.jpg)
Data Science and Machine Learning practitioners often find themselves navigating through a labyrinth of models, libraries, and frameworks. Which model to choose, what embedding size, and how to approach tokenizing, are just some questions you are faced with when starting your work. We understood how many data scientists wanted an easier and more intuitive means to do their embedding work. This is why we built FastEmbed, a Python library engineered for speed, efficiency, and usability. We have created easy to use default workflows, handling the 80% use cases in NLP embedding.
## Current State of Affairs for Generating Embeddings
Usually you make embedding by utilizing PyTorch or TensorFlow models under the hood. However, using these libraries comes at a cost in terms of ease of use and computational speed. This is at least in part because these are built for both: model inference and improvement e.g. via fine-tuning.
To tackle these problems we built a small library focused on the task of quickly and efficiently creating text embeddings. We also decided to start with only a small sample of best in class transformer models. By keeping it small and focused on a particular use case, we could make our library focused without all the extraneous dependencies. We ship with limited models, quantize the model weights and seamlessly integrate them with the ONNX Runtime. FastEmbed strikes a balance between inference time, resource utilization and performance (recall/accuracy).
## Quick Embedding Text Document Example
Here is an example of how simple we have made embedding text documents:
```
documents: List[str] = [
    "Hello, World!",
    "fastembed is supported by and maintained by Qdrant."
] 
embedding_model = DefaultEmbedding() 
embeddings: List[np.ndarray] = list(embedding_model.embed(documents))

```
These 3 lines of code do a lot of heavy lifting for you: They download the quantized model, load it using ONNXRuntime, and then run a batched embedding creation of your documents.
### Code Walkthrough
Let’s delve into a more advanced example code snippet line-by-line:
```
from fastembed.embedding import DefaultEmbedding

```
Here, we import the FlagEmbedding class from FastEmbed and alias it as Embedding. This is the core class responsible for generating embeddings based on your chosen text model. This is also the class which you can import directly as DefaultEmbedding which is 
```
documents: List[str] = [
    "passage: Hello, World!",
    "query: How is the World?",
    "passage: This is an example passage.",
    "fastembed is supported by and maintained by Qdrant."
]

```
In this list called documents, we define four text strings that we want to convert into embeddings.
Note the use of prefixes “passage” and “query” to differentiate the types of embeddings to be generated. This is inherited from the cross-encoder implementation of the BAAI/bge series of models themselves. This is particularly useful for retrieval and we strongly recommend using this as well.
The use of text prefixes like “query” and “passage” isn’t merely syntactic sugar; it informs the algorithm on how to treat the text for embedding generation. A “query” prefix often triggers the model to generate embeddings that are optimized for similarity comparisons, while “passage” embeddings are fine-tuned for contextual understanding. If you omit the prefix, the default behavior is applied, although specifying it is recommended for more nuanced results.
Next, we initialize the Embedding model with the default model: 
```
embedding_model = DefaultEmbedding()

```
The default model and several other models have a context window of a maximum of 512 tokens. This maximum limit comes from the embedding model training and design itself. If you’d like to embed sequences larger than that, we’d recommend using some pooling strategy to get a single vector out of the sequence. For example, you can use the mean of the embeddings of different chunks of a document. This is also what the 
This model strikes a balance between speed and accuracy, ideal for real-world applications.
```
embeddings: List[np.ndarray] = list(embedding_model.embed(documents))

```
Finally, we call the `embed()` method on our embedding_model object, passing in the documents list. The method returns a Python generator, so we convert it to a list to get all the embeddings. These embeddings are NumPy arrays, optimized for fast mathematical operations.
The `embed()` method returns a list of NumPy arrays, each corresponding to the embedding of a document in your original documents list. The dimensions of these arrays are determined by the model you chose e.g. for “BAAI/bge-small-en-v1.5” it’s a 384-dimensional vector.
You can easily parse these NumPy arrays for any downstream application—be it clustering, similarity comparison, or feeding them into a machine learning model for further analysis.
## 3 Key Features of FastEmbed
FastEmbed is built for inference speed, without sacrificing (too much) performance:
  1. 50% faster than PyTorch Transformers
  2. Better performance than Sentence Transformers and OpenAI Ada-002
  3. Cosine similarity of quantized and original model vectors is 0.92
We use `BAAI/bge-small-en-v1.5` as our DefaultEmbedding, hence we’ve chosen that for comparison:
![](https://qdrant.tech/articles_data/fastembed/throughput.png)
## Under the Hood of FastEmbed
**Quantized Models** : We quantize the models for CPU (and Mac Metal) – giving you the best buck for your compute model. Our default model is so small, you can run this in AWS Lambda if you’d like!
Shout out to Huggingface’s 
**Reduced Installation Time** :
FastEmbed sets itself apart by maintaining a low minimum RAM/Disk usage.
It’s designed to be agile and fast, useful for businesses looking to integrate text embedding for production usage. For FastEmbed, the list of dependencies is refreshingly brief:
>   * onnx: Version ^1.11 – We’ll try to drop this also in the future if we can!
>   * onnxruntime: Version ^1.15
>   * tqdm: Version ^4.65 – used only at Download
>   * requests: Version ^2.31 – used only at Download
>   * tokenizers: Version ^0.13
> 
This minimized list serves two purposes. First, it significantly reduces the installation time, allowing for quicker deployments. Second, it limits the amount of disk space required, making it a viable option even for environments with storage limitations.
Notably absent from the dependency list are bulky libraries like PyTorch, and there’s no requirement for CUDA drivers. This is intentional. FastEmbed is engineered to deliver optimal performance right on your CPU, eliminating the need for specialized hardware or complex setups.
**ONNXRuntime** : The ONNXRuntime gives us the ability to support multiple providers. The quantization we do is limited for CPU (Intel), but we intend to support GPU versions of the same in the future as well. This allows for greater customization and optimization, further aligning with your specific performance and computational requirements.
## Current Models
We’ve started with a small set of supported models:
All the models we support are 
If you’re using FastEmbed and you’ve got ideas or need certain features, feel free to let us know. Just drop an issue on our GitHub page. That’s where we look first when we’re deciding what to work on next. Here’s where you can do it: 
When it comes to FastEmbed’s DefaultEmbedding model, we’re committed to supporting the best Open Source models.
If anything changes, you’ll see a new version number pop up, like going from 0.0.6 to 0.1. So, it’s a good idea to lock in the FastEmbed version you’re using to avoid surprises.
## Using FastEmbed with Qdrant
Qdrant is a Vector Store, offering comprehensive, efficient, and scalable [enterprise solutions](https://qdrant.tech/enterprise-solutions/) for modern machine learning and AI applications. Whether you are dealing with billions of data points, require a low latency performant [vector database solution](https://qdrant.tech/qdrant-vector-database/), or specialized quantization methods – [Qdrant is engineered](https://qdrant.tech/documentation/overview/) to meet those demands head-on.
The fusion of FastEmbed with Qdrant’s vector store capabilities enables a transparent workflow for seamless embedding generation, storage, and retrieval. This simplifies the API design — while still giving you the flexibility to make significant changes e.g. you can use FastEmbed to make your own embedding other than the DefaultEmbedding and use that with Qdrant.
Below is a detailed guide on how to get started with FastEmbed in conjunction with Qdrant.
### Step 1: Installation
Before diving into the code, the initial step involves installing the Qdrant Client along with the FastEmbed library. This can be done using pip:
```
pip install qdrant-client[fastembed]

```
For those using zsh as their shell, you might encounter syntax issues. In such cases, wrap the package name in quotes:
```
pip install 'qdrant-client[fastembed]'

```
### Step 2: Initializing the Qdrant Client
After successful installation, the next step involves initializing the Qdrant Client. This can be done either in-memory or by specifying a database path:
```
from qdrant_client import QdrantClient
# Initialize the client
client = QdrantClient(":memory:")  # or QdrantClient(path="path/to/db")

```
### Step 3: Preparing Documents, Metadata, and IDs
Once the client is initialized, prepare the text documents you wish to embed, along with any associated metadata and unique IDs:
```
docs = [
    "Qdrant has Langchain integrations",
    "Qdrant also has Llama Index integrations"
]
metadata = [
    {"source": "Langchain-docs"},
    {"source": "LlamaIndex-docs"},
]
ids = [42, 2]

```
Note that the add method we’ll use is overloaded: If you skip the ids, we’ll generate those for you. metadata is obviously optional. So, you can simply use this too:
```
docs = [
    "Qdrant has Langchain integrations",
    "Qdrant also has Llama Index integrations"
]

```
### Step 4: Adding Documents to a Collection
With your documents, metadata, and IDs ready, you can proceed to add these to a specified collection within Qdrant using the add method:
```
client.add(
    collection_name="demo_collection",
    documents=docs,
    metadata=metadata,
    ids=ids
)

```
Inside this function, Qdrant Client uses FastEmbed to make the text embedding, generate ids if they’re missing, and then add them to the index with metadata. This uses the DefaultEmbedding model: 
![INDEX TIME: Sequence Diagram for Qdrant and FastEmbed](https://qdrant.tech/articles_data/fastembed/generate-embeddings-from-docs.png)
### Step 5: Performing Queries
Finally, you can perform queries on your stored documents. Qdrant offers a robust querying capability, and the query results can be easily retrieved as follows:
```
search_result = client.query(
    collection_name="demo_collection",
    query_text="This is a query document"
)
print(search_result)

```
Behind the scenes, we first convert the query_text to the embedding and use that to query the vector index.
![QUERY TIME: Sequence Diagram for Qdrant and FastEmbed integration](https://qdrant.tech/articles_data/fastembed/generate-embeddings-query.png)
By following these steps, you effectively utilize the combined capabilities of FastEmbed and Qdrant, thereby streamlining your embedding generation and retrieval tasks.
Qdrant is designed to handle large-scale datasets with billions of data points. Its architecture employs techniques like [binary quantization](https://qdrant.tech/articles/binary-quantization/) and [scalar quantization](https://qdrant.tech/articles/scalar-quantization/) for efficient storage and retrieval. When you inject FastEmbed’s CPU-first design and lightweight nature into this equation, you end up with a system that can scale seamlessly while maintaining low latency.
## Summary
If you’re curious about how FastEmbed and Qdrant can make your search tasks a breeze, why not take it for a spin? You get a real feel for what it can do. Here are two easy ways to get started:
  1. **Cloud** : Get started with a free plan on the 
  2. **Docker Container** : If you’re the DIY type, you can set everything up on your own machine. Here’s a quick guide to help you out: [Quick Start with Docker](https://qdrant.tech/documentation/quick-start/?utm_source=qdrant&utm_medium=website&utm_campaign=fastembed&utm_content=article).
So, go ahead, take it for a test drive. We’re excited to hear what you think!
Lastly, If you find FastEmbed useful and want to keep up with what we’re doing, giving our GitHub repo a star would mean a lot to us. Here’s the link to 
If you ever have questions about FastEmbed, please ask them on the Qdrant Discord: 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/fastembed.md) this page on GitHub, or 
On this page:
  * [Current State of Affairs for Generating Embeddings](https://qdrant.tech/articles/fastembed/#current-state-of-affairs-for-generating-embeddings)
  * [Quick Embedding Text Document Example](https://qdrant.tech/articles/fastembed/#quick-embedding-text-document-example)
    * [Code Walkthrough](https://qdrant.tech/articles/fastembed/#code-walkthrough)
  * [3 Key Features of FastEmbed](https://qdrant.tech/articles/fastembed/#3-key-features-of-fastembed)
  * [Under the Hood of FastEmbed](https://qdrant.tech/articles/fastembed/#under-the-hood-of-fastembed)
  * [Current Models](https://qdrant.tech/articles/fastembed/#current-models)
  * [Using FastEmbed with Qdrant](https://qdrant.tech/articles/fastembed/#using-fastembed-with-qdrant)
    * [Step 1: Installation](https://qdrant.tech/articles/fastembed/#step-1-installation)
    * [Step 2: Initializing the Qdrant Client](https://qdrant.tech/articles/fastembed/#step-2-initializing-the-qdrant-client)
    * [Step 3: Preparing Documents, Metadata, and IDs](https://qdrant.tech/articles/fastembed/#step-3-preparing-documents-metadata-and-ids)
    * [Step 4: Adding Documents to a Collection](https://qdrant.tech/articles/fastembed/#step-4-adding-documents-to-a-collection)
    * [Step 5: Performing Queries](https://qdrant.tech/articles/fastembed/#step-5-performing-queries)
  * [Summary](https://qdrant.tech/articles/fastembed/#summary)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/fastembed/)
                    ## 📄 `https-qdrant-tech-articles-filtrable-hnsw.md`
                    ```md
                    # https://qdrant.tech/articles/filtrable-hnsw/
  * [Articles](https://qdrant.tech/articles/)
  * Filtrable HNSW
# Filtrable HNSW
Andrei Vasnetsov
·
November 24, 2019
![Filtrable HNSW](https://qdrant.tech/articles_data/filtrable-hnsw/preview/title.jpg)
If you need to find some similar objects in vector space, provided e.g. by embeddings or matching NN, you can choose among a variety of libraries: Annoy, FAISS or NMSLib. All of them will give you a fast approximate neighbors search within almost any space.
But what if you need to introduce some constraints in your search? For example, you want search only for products in some category or select the most similar customer of a particular brand. I did not find any simple solutions for this. There are several discussions like 
Let’s see if we could somehow modify any of ANN algorithms to be able to apply constrains during the search itself.
Annoy builds tree index over random projections. Tree index implies that we will meet same problem that appears in relational databases: if field indexes were built independently, then it is possible to use only one of them at a time. Since nobody solved this problem before, it seems that there is no easy approach.
There is another algorithm which shows top results on the 
The m and always contains the nearest considered points.
![NSW](https://qdrant.tech/articles_data/filtrable-hnsw/NSW.png)
### How can we modify it?
What if we simply apply the filter criteria to the nodes of this graph and use in the greedy search only those that meet these criteria? It turns out that even with this naive modification algorithm can cover some use cases.
One such case is if your criteria do not correlate with vector semantics. For example, you use a vector search for clothing names and want to filter out some sizes. In this case, the nodes will be uniformly filtered out from the entire cluster structure. Therefore, the theoretical conclusions obtained in the 
> Percolation is related to the robustness of the graph (called also network). Given a random graph of n nodes and an average degree ⟨k⟩ . Next we remove randomly a fraction 1−p of nodes and leave only a fraction p. There exists a critical percolation threshold pc=1⟨k⟩ below which the network becomes fragmented while above pc a giant connected component exists.
This statement also confirmed by experiments:
![Dependency of connectivity to the number of edges](https://qdrant.tech/articles_data/filtrable-hnsw/exp_connectivity_glove_m0.png)
Dependency of connectivity to the number of edges
![Dependency of connectivity to the number of point \(no dependency\).](https://qdrant.tech/articles_data/filtrable-hnsw/exp_connectivity_glove_num_elements.png)
Dependency of connectivity to the number of point (no dependency).
There is a clear threshold when the search begins to fail. This threshold is due to the decomposition of the graph into small connected components. The graphs also show that this threshold can be shifted by increasing the m parameter of the algorithm, which is responsible for the degree of nodes.
Let’s consider some other filtering conditions we might want to apply in the search:
  * Categorical filtering
    * Select only points in a specific category
    * Select points which belong to a specific subset of categories
    * Select points with a specific set of labels
  * Numerical range
  * Selection within some geographical region
In the first case, we can guarantee that the HNSW graph will be connected simply by creating additional edges inside each category separately, using the same graph construction algorithm, and then combining them into the original graph. In this case, the total number of edges will increase by no more than 2 times, regardless of the number of categories.
Second case is a little harder. A connection may be lost between two categories if they lie in different clusters.
![category clusters](https://qdrant.tech/articles_data/filtrable-hnsw/hnsw_graph_category.png)
The idea here is to build same navigation graph but not between nodes, but between categories. Distance between two categories might be defined as distance between category entry points (or, for precision, as the average distance between a random sample). Now we can estimate expected graph connectivity by number of excluded categories, not nodes. It still does not guarantee that two random categories will be connected, but allows us to switch to multiple searches in each category if connectivity threshold passed. In some cases, multiple searches can be even faster if you take advantage of parallel processing.
![Dependency of connectivity to the random categories included in search](https://qdrant.tech/articles_data/filtrable-hnsw/exp_random_groups.png)
Dependency of connectivity to the random categories included in search
Third case might be resolved in a same way it is resolved in classical databases. Depending on labeled subsets size ration we can go for one of the following scenarios:
  * if at least one subset is small: perform search over the label containing smallest subset and then filter points consequently.
  * if large subsets give large intersection: perform regular search with constraints expecting that intersection size fits connectivity threshold.
  * if large subsets give small intersection: perform linear search over intersection expecting that it is small enough to fit a time frame.
Numerical range case can be reduces to the previous one if we split numerical range into a buckets containing equal amount of points. Next we also connect neighboring buckets to achieve graph connectivity. We still need to filter some results which presence in border buckets but do not fulfill actual constraints, but their amount might be regulated by the size of buckets.
Geographical case is a lot like a numerical one. Usual geographical search involves 
![Geohash example](https://qdrant.tech/articles_data/filtrable-hnsw/geohash.png)
We can use this identifiers as categories and additionally make connections between neighboring geohashes. It will ensure that any selected geographical region will also contain connected HNSW graph.
## Conclusion
It is possible to enchant HNSW algorithm so that it will support filtering points in a first search phase. Filtering can be carried out on the basis of belonging to categories, which in turn is generalized to such popular cases as numerical ranges and geo.
Experiments were carried by modification 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/filtrable-hnsw.md) this page on GitHub, or 
On this page:
  *     * [How can we modify it?](https://qdrant.tech/articles/filtrable-hnsw/#how-can-we-modify-it)
  * [Conclusion](https://qdrant.tech/articles/filtrable-hnsw/#conclusion)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/filtrable-hnsw/)
                    ## 📄 `https-qdrant-tech-articles-food-discovery-demo.md`
                    ```md
                    # https://qdrant.tech/articles/food-discovery-demo/
  * [Articles](https://qdrant.tech/articles/)
  * Food Discovery Demo
# Food Discovery Demo
Kacper Łukawski
·
September 05, 2023
![Food Discovery Demo](https://qdrant.tech/articles_data/food-discovery-demo/preview/title.jpg)
Not every search journey begins with a specific destination in mind. Sometimes, you just want to explore and see what’s out there and what you might like. This is especially true when it comes to food. You might be craving something sweet, but you don’t know what. You might be also looking for a new dish to try, and you just want to see the options available. In these cases, it’s impossible to express your needs in a textual query, as the thing you are looking for is not yet defined. Qdrant’s semantic search for images is useful when you have a hard time expressing your tastes in words.
## General architecture
We are happy to announce a refreshed version of our [Food Discovery Demo](https://food-discovery.qdrant.tech/). This time available as an open source project, so you can easily deploy it on your own and play with it. If you prefer to dive into the source code directly, then feel free to check out the 
In general, our application consists of three parts: a [Qdrant](https://qdrant.tech/) instance. The architecture diagram below shows how these components interact with each other:
![Archtecture diagram](https://qdrant.tech/articles_data/food-discovery-demo/architecture-diagram.png)
## Why did we use a CLIP model?
CLIP is a neural network that can be used to encode both images and texts into vectors. And more importantly, both images and texts are vectorized into the same latent space, so we can compare them directly. This lets you perform semantic search on images using text queries and the other way around. For example, if you search for “flat bread with toppings”, you will get images of pizza. Or if you search for “pizza”, you will get images of some flat bread with toppings, even if they were not labeled as “pizza”. This is because CLIP embeddings capture the semantics of the images and texts and can find the similarities between them no matter the wording.
![CLIP model](https://qdrant.tech/articles_data/food-discovery-demo/clip-model.png)
CLIP is available in many different ways. We used the pretrained `clip-ViT-B-32` model available in the 
## The dataset
The demo is based on the 
```
{
    "cafe": {
        "address": "VGX7+6R2 Vecchia Napoli, Valletta",
        "categories": ["italian", "pasta", "pizza", "burgers", "mediterranean"],
        "location": {"lat": 35.8980154, "lon": 14.5145106},
        "menu_id": "610936a4ee8ea7a56f4a372a",
        "name": "Vecchia Napoli Is-Suq Tal-Belt",
        "rating": 9,
        "slug": "vecchia-napoli-skyparks-suq-tal-belt"
    },
    "description": "Tomato sauce, mozzarella fior di latte, crispy guanciale, Pecorino Romano cheese and a hint of chilli",
    "image": "https://wolt-menu-images-cdn.wolt.com/menu-images/610936a4ee8ea7a56f4a372a/005dfeb2-e734-11ec-b667-ced7a78a5abd_l_amatriciana_pizza_joel_gueller1.jpeg",
    "name": "L'Amatriciana"
}

```
Processing this amount of records takes some time, so we precomputed the CLIP embeddings, stored them in a Qdrant collection and exported the collection as a snapshot. You may 
## Different search modes
The FastAPI backend 
### Cold start
Recommendation systems struggle with a cold start problem. When a new user joins the system, there is no data about their preferences, so it’s hard to recommend anything. The same applies to our demo. When you open it, you will see a random selection of dishes, and it changes every time you refresh the page. Internally, the demo 
![Random points selection](https://qdrant.tech/articles_data/food-discovery-demo/random-results.png)
That procedure should result in returning diverse results, so we have a higher chance of showing something interesting to the user.
### Textual search
Since the demo suffers from the cold start problem, we implemented a textual search mode that is useful to start exploring the data. You can type in any text query by clicking a search icon in the top right corner. The demo will use the CLIP model to encode the query into a vector and then search for the nearest neighbors in the vector space.
![Random points selection](https://qdrant.tech/articles_data/food-discovery-demo/textual-search.png)
This is implemented as [Search groups](https://qdrant.tech/documentation/concepts/search/#search-groups) is a mechanism similar to `GROUP BY` clause in SQL, and it’s useful when you want to get a specific number of result per group (in our case just one).
```
import settings
# Encode query into a vector, model is an instance of
# sentence_transformers.SentenceTransformer that loaded CLIP model
query_vector = model.encode(query).tolist()
# Search for nearest neighbors, client is an instance of 
# qdrant_client.QdrantClient that has to be initialized before
response = client.search_groups(
    settings.QDRANT_COLLECTION,
    query_vector=query_vector,
    group_by=settings.GROUP_BY_FIELD,
    limit=search_query.limit,
)

```
### Exploring the results
The main feature of the demo is the ability to explore the space of the dishes. You can click on any of them to see more details, but first of all you can like or dislike it, and the demo will update the search results accordingly.
![Recommendation results](https://qdrant.tech/articles_data/food-discovery-demo/recommendation-results.png)
#### Negative feedback only
Qdrant [Recommendation API](https://qdrant.tech/documentation/concepts/search/#recommendation-api) needs at least one positive example to work. However, in our demo we want to be able to provide only negative examples. This is because we want to be able to say “I don’t like this dish” without having to like anything first. To achieve this, we use a trick. We negate the vectors of the disliked dishes and use their mean as a query. This way, the disliked dishes will be pushed away from the search results. **This works because the cosine distance is based on the angle between two vectors, and the angle between a vector and its negation is 180 degrees.**
![CLIP model](https://qdrant.tech/articles_data/food-discovery-demo/negated-vector.png)
Food Discovery Demo [Scroll API](https://qdrant.tech/documentation/concepts/points/#scroll-points) to find disliked items, and then calculate a negated mean of all their vectors. That allows using the [Search Groups API](https://qdrant.tech/documentation/concepts/search/#search-groups) to find the nearest neighbors of the negated mean vector.
```
import numpy as np
# Retrieve the disliked points based on their ids
disliked_points, _ = client.scroll(
    settings.QDRANT_COLLECTION,
    scroll_filter=models.Filter(
        must=[
            models.HasIdCondition(has_id=search_query.negative),
        ]
    ),
    with_vectors=True,
)
# Calculate a mean vector of disliked points
disliked_vectors = np.array([point.vector for point in disliked_points])
mean_vector = np.mean(disliked_vectors, axis=0)
negated_vector = -mean_vector
# Search for nearest neighbors of the negated mean vector
response = client.search_groups(
    settings.QDRANT_COLLECTION,
    query_vector=negated_vector.tolist(),
    group_by=settings.GROUP_BY_FIELD,
    limit=search_query.limit,
)

```
#### Positive and negative feedback
Since the [Recommendation API](https://qdrant.tech/documentation/concepts/search/#recommendation-api) requires at least one positive example, we can use it only when the user has liked at least one dish. We could theoretically use the same trick as above and negate the disliked dishes, but it would be a bit weird, as Qdrant has that feature already built-in, and we can call it just once to do the job. It’s always better to perform the search server-side. Thus, in this case 
```
response = client.recommend_groups(
    settings.QDRANT_COLLECTION,
    positive=search_query.positive,
    negative=search_query.negative,
    group_by=settings.GROUP_BY_FIELD,
    limit=search_query.limit,
)

```
From the user perspective nothing changes comparing to the previous case.
### Location-based search
Last but not least, location plays an important role in the food discovery process. You are definitely looking for something you can find nearby, not on the other side of the globe. Therefore, your current location can be toggled as a filtering condition. You can enable it by clicking on “Find near me” icon in the top right. This way you can find the best pizza in your neighborhood, not in the whole world. Qdrant [geo radius filter](https://qdrant.tech/documentation/concepts/filtering/#geo-radius) is a perfect choice for this. It lets you filter the results by distance from a given point.
```
from qdrant_client import models
# Create a geo radius filter
query_filter = models.Filter(
    must=[
        models.FieldCondition(
            key="cafe.location",
            geo_radius=models.GeoRadius(
                center=models.GeoPoint(
                    lon=location.longitude,
                    lat=location.latitude,
                ),
                radius=location.radius_km * 1000,
            ),
        )
    ]
)

```
Such a filter needs [a payload index](https://qdrant.tech/documentation/concepts/indexing/#payload-index) to work efficiently, and it was created on a collection we used to create the snapshot. When you import it into your instance, the index will be already there.
## Using the demo
The Food Discovery Demo [is available online](https://food-discovery.qdrant.tech/), but if you prefer to run it locally, you can do it with Docker. The 
```
git clone git@github.com:qdrant/demo-food-discovery.git
cd demo-food-discovery
# Create .env file based on .env.example
docker-compose up -d

```
The demo will be available at `http://localhost:8001`, but you won’t be able to search anything until you [import the snapshot into your Qdrant instance](https://qdrant.tech/documentation/concepts/snapshots/#recover-via-api). If you don’t want to bother with hosting a local one, you can use the 
## Fork and reuse
Our demo is completely open-source. Feel free to fork it, update with your own dataset or adapt the application to your use case. Whether you’re looking to understand the mechanics of semantic search or to have a foundation to build a larger project, this demo can serve as a starting point. Check out the 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/food-discovery-demo.md) this page on GitHub, or 
On this page:
  * [General architecture](https://qdrant.tech/articles/food-discovery-demo/#general-architecture)
  * [Why did we use a CLIP model?](https://qdrant.tech/articles/food-discovery-demo/#why-did-we-use-a-clip-model)
  * [The dataset](https://qdrant.tech/articles/food-discovery-demo/#the-dataset)
  * [Different search modes](https://qdrant.tech/articles/food-discovery-demo/#different-search-modes)
    * [Cold start](https://qdrant.tech/articles/food-discovery-demo/#cold-start)
    * [Textual search](https://qdrant.tech/articles/food-discovery-demo/#textual-search)
    * [Exploring the results](https://qdrant.tech/articles/food-discovery-demo/#exploring-the-results)
    * [Location-based search](https://qdrant.tech/articles/food-discovery-demo/#location-based-search)
  * [Using the demo](https://qdrant.tech/articles/food-discovery-demo/#using-the-demo)
  * [Fork and reuse](https://qdrant.tech/articles/food-discovery-demo/#fork-and-reuse)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/food-discovery-demo/)
                    ## 📄 `https-qdrant-tech-articles-gridstore-key-value-storage.md`
                    ```md
                    # https://qdrant.tech/articles/gridstore-key-value-storage/
  * [Articles](https://qdrant.tech/articles/)
  * Introducing Gridstore: Qdrant's Custom Key-Value Store
# Introducing Gridstore: Qdrant's Custom Key-Value Store
Luis Cossio, Arnaud Gourlay & David Myriel
·
February 05, 2025
![Introducing Gridstore: Qdrant's Custom Key-Value Store](https://qdrant.tech/articles_data/gridstore-key-value-storage/preview/title.jpg)
## Why We Built Our Own Storage Engine
Databases need a place to store and retrieve data. That’s what Qdrant’s 
When we started building Qdrant, we needed to pick something ready for the task. So we chose 
![RocksDB](https://qdrant.tech/articles_data/gridstore-key-value-storage/rocksdb.jpg)
It is mature, reliable, and well-documented.
Over time, we ran into issues. Its architecture required compaction (uses 
While there are already some good options written in Rust that we could leverage, we needed something custom. Nothing out there fit our needs in the way we wanted. We didn’t require generic keys. We wanted full control over when and which data was written and flushed. Our system already has crash recovery mechanisms built-in. Online compaction isn’t a priority, we already have optimizers for that. Debugging misconfigurations was not a great use of our time.
So we built our own storage. As of [**Qdrant Version 1.13**](https://qdrant.tech/blog/qdrant-1.13.x/), we are using Gridstore for **payload and sparse vector storages**.
![Gridstore](https://qdrant.tech/articles_data/gridstore-key-value-storage/gridstore.png)
Simple, efficient, and designed just for Qdrant.
#### In this article, you’ll learn about:
  * **How Gridstore works** – a deep dive into its architecture and mechanics.
  * **Why we built it this way** – the key design decisions that shaped it.
  * **Rigorous testing** – how we ensured the new storage is production-ready.
  * **Performance benchmarks** – official metrics that demonstrate its efficiency.
**Our first challenge?** Figuring out the best way to handle sequential keys and variable-sized data.
## Gridstore Architecture: Three Main Components
![gridstore](https://qdrant.tech/articles_data/gridstore-key-value-storage/gridstore-2.png)
Gridstore’s architecture is built around three key components that enable fast lookups and efficient space management:
Component | Description  
---|---  
The Data Layer | Stores values in fixed-sized blocks and retrieves them using a pointer-based lookup system.  
The Mask Layer | Uses a bitmask to track which blocks are in use and which are available.  
The Gaps Layer | Manages block availability at a higher level, allowing for quick space allocation.  
### 1. The Data Layer for Fast Retrieval
At the core of Gridstore is **The Data Layer** , which is designed to store and retrieve values quickly based on their keys. This layer allows us to do efficient reads and lets us store variable-sized data. The main two components of this layer are **The Tracker** and **The Data Grid**.
Since internal IDs are always sequential integers (0, 1, 2, 3, 4, …), the tracker is an array of pointers, where each pointer tells the system exactly where a value starts and how long it is.
![The Data Layer](https://qdrant.tech/articles_data/gridstore-key-value-storage/data-layer.png)
The Data Layer uses an array of pointers to quickly retrieve data.
This makes lookups incredibly fast. For example, finding key 3 is just a matter of jumping to the third position in the tracker, and following the pointer to find the value in the data grid.
However, because values are of variable size, the data itself is stored separately in a grid of fixed-sized blocks, which are grouped into larger page files. The fixed size of each block is usually 128 bytes. When inserting a value, Gridstore allocates one or more consecutive blocks to store it, ensuring that each block only holds data from a single value.
### 2. The Mask Layer Reuses Space
**The Mask Layer** helps Gridstore handle updates and deletions without the need for expensive data compaction. Instead of maintaining complex metadata for each block, Gridstore tracks usage with a bitmask, where each bit represents a block, with 1 for used, 0 for free.
![The Mask Layer](https://qdrant.tech/articles_data/gridstore-key-value-storage/mask-layer.png)
The bitmask efficiently tracks block usage.
This makes it easy to determine where new values can be written. When a value is removed, it gets soft-deleted at its pointer, and the corresponding blocks in the bitmask are marked as available. Similarly, when updating a value, the new version is written elsewhere, and the old blocks are freed at the bitmask.
This approach ensures that Gridstore doesn’t waste space. As the storage grows, however, scanning for available blocks in the entire bitmask can become computationally expensive.
### 3. The Gaps Layer for Effective Updates
To further optimize update handling, Gridstore introduces **The Gaps Layer** , which provides a higher-level view of block availability.
Instead of scanning the entire bitmask, Gridstore splits the bitmask into regions and keeps track of the largest contiguous free space within each region, known as **The Region Gap**. By also storing the leading and trailing gaps of each region, the system can efficiently combine multiple regions when needed for storing large values.
![The Gaps Layer](https://qdrant.tech/articles_data/gridstore-key-value-storage/architecture.png)
The complete architecture of Gridstore
This layered approach allows Gridstore to locate available space quickly, scaling down the work required for scans while keeping memory overhead minimal. With this system, finding storage space for new values requires scanning only a tiny fraction of the total metadata, making updates and insertions highly efficient, even in large segments.
Given the default configuration, the gaps layer is scoped out in a millionth fraction of the actual storage size. This means that for each 1GB of data, the gaps layer only requires scanning 6KB of metadata. With this mechanism, the other operations can be executed in virtually constant-time complexity.
## Gridstore in Production: Maintaining Data Integrity
![gridstore](https://qdrant.tech/articles_data/gridstore-key-value-storage/gridstore-1.png)
Gridstore’s architecture introduces multiple interdependent structures that must remain in sync to ensure data integrity:
  * **The Data Layer** holds the data and associates each key with its location in storage, including page ID, block offset, and the size of its value.
  * **The Mask Layer** keeps track of which blocks are occupied and which are free.
  * **The Gaps Layer** provides an indexed view of free blocks for efficient space allocation.
Every time a new value is inserted or an existing value is updated, all these components need to be modified in a coordinated way.
### When Things Break in Real Life
Real-world systems don’t operate in a vacuum. Failures happen: software bugs cause unexpected crashes, memory exhaustion forces processes to terminate, disks fail to persist data reliably, and power losses can interrupt operations at any moment.
_The critical question is: what happens if a failure occurs while updating these structures?_
If one component is updated but another isn’t, the entire system could become inconsistent. Worse, if an operation is only partially written to disk, it could lead to orphaned data, unusable space, or even data corruption.
### Stability Through Idempotency: Recovering With WAL
To guard against these risks, Qdrant relies on a [**Write-Ahead Log (WAL)**](https://qdrant.tech/documentation/concepts/storage/). Before committing an operation, Qdrant ensures that it is at least recorded in the WAL. If a crash happens before all updates are flushed, the system can safely replay operations from the log.
This recovery mechanism introduces another essential property: 
The storage system must be designed so that reapplying the same operation after a failure leads to the same final state as if the operation had been applied just once.
### The Grand Solution: Lazy Updates
To achieve this, **Gridstore completes updates lazily** , prioritizing the most critical part of the write: the data itself.
👉 Instead of immediately updating all metadata structures, it writes the new value first while keeping lightweight pending changes in a buffer.  
---  
👉 The system only finalizes these updates when explicitly requested, ensuring that a crash never results in marking data as deleted before the update has been safely persisted.  
👉 In the worst-case scenario, Gridstore may need to write the same data twice, leading to a minor space overhead, but it will never corrupt the storage by overwriting valid data.  
## How We Tested the Final Product
![gridstore](https://qdrant.tech/articles_data/gridstore-key-value-storage/gridstore-3.png)
### First… Model Testing
Gridstore can be tested efficiently using model testing, which compares its behavior to a simple in-memory hash map. Since Gridstore should function like a persisted hash map, this method quickly detects inconsistencies.
The process is straightforward:
  1. Initialize a Gridstore instance and an empty hash map.
  2. Run random operations (put, delete, update) on both.
  3. Verify that results match after each operation.
  4. Compare all keys and values to ensure consistency.
This approach provides high test coverage, exposing issues like incorrect persistence or faulty deletions. Running large-scale model tests ensures Gridstore remains reliable in real-world use.
Here is a naive way to generate operations in Rust.
```
enum Operation{Put(PointOffset,Payload),Delete(PointOffset),Update(PointOffset,Payload),}implOperation{fn random(rng: &mutimplRng,max_point_offset: u32)Self{letpoint_offset=rng.random_range(0..=max_point_offset);letoperation=rng.gen_range(0..3);matchoperation{0=>{letsize_factor=rng.random_range(1..10);letpayload=random_payload(rng,size_factor);Operation::Put(point_offset,payload)}1=>Operation::Delete(point_offset),2=>{letsize_factor=rng.random_range(1..10);letpayload=random_payload(rng,size_factor);Operation::Update(point_offset,payload)}_=>unreachable!(),}}}
```
Model testing is a high-value way to catch bugs, especially when your system mimics a well-defined component like a hash map. If your component behaves the same as another one, using model testing brings a lot of value for a bit of effort.
We could have tested against RocksDB, but simplicity matters more. A simple hash map lets us run massive test sequences quickly, exposing issues faster.
For even sharper debugging, Property-Based Testing adds automated test generation and shrinking. It pinpoints failures with minimalized test cases, making bug hunting faster and more effective.
### Crash Testing: Can Gridstore Handle the Pressure?
Designing for crash resilience is one thing, and proving it works under stress is another. To push Qdrant’s data integrity to the limit, we built 
Crasher runs a loop that continuously writes data, then randomly crashes Qdrant. On each restart, Qdrant replays its [**Write-Ahead Log (WAL)**](https://qdrant.tech/documentation/concepts/storage/), and we verify if data integrity holds. Possible anomalies include:
  * Missing data (points, vectors, or payloads)
  * Corrupt payload values
This aggressive yet simple approach has uncovered real-world issues when run for extended periods. While we also use chaos testing for distributed setups, Crasher excels at fast, repeatable failure testing in a local environment.
## Testing Gridstore Performance: Benchmarks
![gridstore](https://qdrant.tech/articles_data/gridstore-key-value-storage/gridstore-4.png)
To measure the impact of our new storage engine, we used 
Workload Type | Operation Distribution  
---|---  
Read-heavy | 95% reads  
Insert-heavy | 80% inserts  
Update-heavy | 50% updates  
#### The results speak for themselves:
Average latency for all kinds of workloads is lower across the board, particularly for inserts.
![image.png](https://qdrant.tech/articles_data/gridstore-key-value-storage/1.png)
This shows a clear boost in performance. As we can see, the investment in Gridstore is paying off.
### End-to-End Benchmarking
Now, let’s test the impact on a real Qdrant instance. So far, we’ve only integrated Gridstore for [**payloads**](https://qdrant.tech/documentation/concepts/payload/) and [**sparse vectors**](https://qdrant.tech/documentation/concepts/vectors/#sparse-vectors), but even this partial switch should show noticeable improvements.
For benchmarking, we used our in-house 
```
bfb -n 2000000 --max-id 1000000 \
    --sparse-vectors 0.02 \
    --set-payload \
    --on-disk-payload \
    --dim 1 \
    --sparse-dim 5000 \
    --bool-payloads \
    --keywords 100 \
    --float-payloads true \
    --int-payloads 100000 \
    --text-payloads \
    --text-payload-length 512 \
    --skip-field-indices \
    --jsonl-updates ./rps.jsonl

```
This benchmark upserts 1 million points twice. Each point has:
  * A medium to large payload
  * A tiny dense vector (dense vectors use a different storage type)
  * A sparse vector
* * *
#### Additional configuration:
  1. The test we conducted updated payload data separately in another request.
  2. There were no payload indices, which ensured we measured pure ingestion speed.
  3. Finally, we gathered request latency metrics for analysis.
* * *
We ran this against Qdrant 1.12.6, toggling between the old and new storage backends.
### Final Result
Data ingestion is **twice as fast and with a smoother throughput** — a massive win! 😍
![image.png](https://qdrant.tech/articles_data/gridstore-key-value-storage/2.png)
We optimized for speed, and it paid off—but what about storage size?
  * Gridstore: 2333MB
  * RocksDB: 2319MB
Strictly speaking, RocksDB is slightly smaller, but the difference is negligible compared to the 2x faster ingestion and more stable throughput. A small trade-off for a big performance gain!
## Trying Out Gridstore
Gridstore represents a significant advancement in how Qdrant manages its **key-value storage** needs. It offers great performance and streamlined updates tailored specifically for our use case. We have managed to achieve faster, more reliable data ingestion while maintaining data integrity, even under heavy workloads and unexpected failures. It is already used as a storage backend for on-disk payloads and sparse vectors.
👉 It’s important to note that Gridstore remains tightly integrated with Qdrant and, as such, has not been released as a standalone crate.
Its API is still evolving, and we are focused on refining it within our ecosystem to ensure maximum stability and performance. That said, we recognize the value this innovation could bring to the wider Rust community. In the future, once the API stabilizes and we decouple it enough from Qdrant, we will consider publishing it as a contribution to the community ❤️.
For now, Gridstore continues to drive improvements in Qdrant, demonstrating the benefits of a custom-tailored storage engine designed with modern demands in mind. Stay tuned for further updates and potential community releases as we keep pushing the boundaries of performance and reliability.
![Gridstore](https://qdrant.tech/articles_data/gridstore-key-value-storage/gridstore.png)
Simple, efficient, and designed just for Qdrant.
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/gridstore-key-value-storage.md) this page on GitHub, or 
On this page:
  * [Why We Built Our Own Storage Engine](https://qdrant.tech/articles/gridstore-key-value-storage/#why-we-built-our-own-storage-engine)
  * [Gridstore Architecture: Three Main Components](https://qdrant.tech/articles/gridstore-key-value-storage/#gridstore-architecture-three-main-components)
    * [1. The Data Layer for Fast Retrieval](https://qdrant.tech/articles/gridstore-key-value-storage/#1-the-data-layer-for-fast-retrieval)
    * [2. The Mask Layer Reuses Space](https://qdrant.tech/articles/gridstore-key-value-storage/#2-the-mask-layer-reuses-space)
    * [3. The Gaps Layer for Effective Updates](https://qdrant.tech/articles/gridstore-key-value-storage/#3-the-gaps-layer-for-effective-updates)
  * [Gridstore in Production: Maintaining Data Integrity](https://qdrant.tech/articles/gridstore-key-value-storage/#gridstore-in-production-maintaining-data-integrity)
    * [When Things Break in Real Life](https://qdrant.tech/articles/gridstore-key-value-storage/#when-things-break-in-real-life)
    * [Stability Through Idempotency: Recovering With WAL](https://qdrant.tech/articles/gridstore-key-value-storage/#stability-through-idempotency-recovering-with-wal)
    * [The Grand Solution: Lazy Updates](https://qdrant.tech/articles/gridstore-key-value-storage/#the-grand-solution-lazy-updates)
  * [How We Tested the Final Product](https://qdrant.tech/articles/gridstore-key-value-storage/#how-we-tested-the-final-product)
    * [First… Model Testing](https://qdrant.tech/articles/gridstore-key-value-storage/#first-model-testing)
    * [Crash Testing: Can Gridstore Handle the Pressure?](https://qdrant.tech/articles/gridstore-key-value-storage/#crash-testing-can-gridstore-handle-the-pressure)
  * [Testing Gridstore Performance: Benchmarks](https://qdrant.tech/articles/gridstore-key-value-storage/#testing-gridstore-performance-benchmarks)
    * [End-to-End Benchmarking](https://qdrant.tech/articles/gridstore-key-value-storage/#end-to-end-benchmarking)
    * [Final Result](https://qdrant.tech/articles/gridstore-key-value-storage/#final-result)
  * [Trying Out Gridstore](https://qdrant.tech/articles/gridstore-key-value-storage/#trying-out-gridstore)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/gridstore-key-value-storage/)
                    ## 📄 `https-qdrant-tech-articles-hybrid-search.md`
                    ```md
                    # https://qdrant.tech/articles/hybrid-search/
  * [Articles](https://qdrant.tech/articles/)
  * Hybrid Search Revamped - Building with Qdrant's Query API
# Hybrid Search Revamped - Building with Qdrant's Query API
Kacper Łukawski
·
July 25, 2024
![Hybrid Search Revamped - Building with Qdrant's Query API](https://qdrant.tech/articles_data/hybrid-search/preview/title.jpg)
It’s been over a year since we published the original article on how to build a hybrid search system with Qdrant. The idea was straightforward: combine the results from different search methods to improve retrieval quality. Back in 2023, you still needed to use an additional service to bring lexical search capabilities and combine all the intermediate results. Things have changed since then. Once we introduced support for sparse vectors, [the additional search service became obsolete](https://qdrant.tech/articles/sparse-vectors/), but you were still required to combine the results from different methods on your end.
**Qdrant 1.10 introduces a new Query API that lets you build a search system by combining different search methods to improve retrieval quality**. Everything is now done on the server side, and you can focus on building the best search experience for your users. In this article, we will show you how to utilize the new [Query API](https://qdrant.tech/documentation/concepts/search/#query-api) to build a hybrid search system.
## Introducing the new Query API
At Qdrant, we believe that vector search capabilities go well beyond a simple search for nearest neighbors. That’s why we provided separate methods for different search use cases, such as `search`, `recommend`, or `discover`. With the latest release, we are happy to introduce the new Query API, which combines all of these methods into a single endpoint and also supports creating nested multistage queries that can be used to build complex search pipelines.
If you are an existing Qdrant user, you probably have a running search mechanism that you want to improve, whether sparse or dense. Doing any changes should be preceded by a proper evaluation of its effectiveness.
## How effective is your search system?
None of the experiments makes sense if you don’t measure the quality. How else would you compare which method works better for your use case? The most common way of doing that is by using the standard metrics, such as `precision@k`, `MRR`, or `NDCG`. There are existing libraries, such as 
```
from ranx import Qrels, Run, evaluate
# Qrels, or query relevance judgments, keep the ground truth data
qrels_dict = { "q_1": { "d_12": 5, "d_25": 3 },
               "q_2": { "d_11": 6, "d_22": 1 } }
# Runs are built from the search results
run_dict = { "q_1": { "d_12": 0.9, "d_23": 0.8, "d_25": 0.7,
                      "d_36": 0.6, "d_32": 0.5, "d_35": 0.4  },
             "q_2": { "d_12": 0.9, "d_11": 0.8, "d_25": 0.7,
                      "d_36": 0.6, "d_22": 0.5, "d_35": 0.4  } }
# We need to create both objects, and then we can evaluate the run against the qrels
qrels = Qrels(qrels_dict)
run = Run(run_dict)
# Calculating the NDCG@5 metric is as simple as that
evaluate(qrels, run, "ndcg@5")

```
## Available embedding options with Query API
Support for multiple vectors per point is nothing new in Qdrant, but introducing the Query API makes it even more powerful. The 1.10 release supports the multivectors, allowing you to treat embedding lists as a single entity. There are many possible ways of utilizing this feature, and the most prominent one is the support for late interaction models, such as [ColBERT](https://qdrant.tech/documentation/fastembed/fastembed-colbert/). Instead of having a single embedding for each document or query, this family of models creates a separate one for each token of text. In the search process, the final score is calculated based on the interaction between the tokens of the query and the document. Contrary to cross-encoders, document embedding might be precomputed and stored in the database, which makes the search process much faster. If you are curious about the details, please check out 
![Late interaction](https://qdrant.tech/articles_data/hybrid-search/late-interaction.png)
Besides multivectors, you can use regular dense and sparse vectors, and experiment with smaller data types to reduce memory use. Named vectors can help you store different dimensionalities of the embeddings, which is useful if you use multiple models to represent your data, or want to utilize the Matryoshka embeddings.
![Multiple vectors per point](https://qdrant.tech/articles_data/hybrid-search/multiple-vectors.png)
There is no single way of building a hybrid search. The process of designing it is an exploratory exercise, where you need to test various setups and measure their effectiveness. Building a proper search experience is a complex task, and it’s better to keep it data-driven, not just rely on the intuition.
## Fusion vs reranking
We can, distinguish two main approaches to building a hybrid search system: fusion and reranking. The former is about combining the results from different search methods, based solely on the scores returned by each method. That usually involves some normalization, as the scores returned by different methods might be in different ranges. After that, there is a formula that takes the relevancy measures and calculates the final score that we use later on to reorder the documents. Qdrant has built-in support for the Reciprocal Rank Fusion method, which is the de facto standard in the field.
![Fusion](https://qdrant.tech/articles_data/hybrid-search/fusion.png)
Reranking, on the other hand, is about taking the results from different search methods and reordering them based on some additional processing using the content of the documents, not just the scores. This processing may rely on an additional neural model, such as a cross-encoder which would be inefficient enough to be used on the whole dataset. These methods are practically applicable only when used on a smaller subset of candidates returned by the faster search methods. Late interaction models, such as ColBERT, are way more efficient in this case, as they can be used to rerank the candidates without the need to access all the documents in the collection.
![Reranking](https://qdrant.tech/articles_data/hybrid-search/reranking.png)
### Why not a linear combination?
It’s often proposed to use full-text and vector search scores to form a linear combination formula to rerank the results. So it goes like this:
`final_score = 0.7 * vector_score + 0.3 * full_text_score`
However, we didn’t even consider such a setup. Why? Those scores don’t make the problem linearly separable. We used the BM25 score along with cosine vector similarity to use both of them as points coordinates in 2-dimensional space. The chart shows how those points are distributed:
![A distribution of both Qdrant and BM25 scores mapped into 2D space.](https://qdrant.tech/articles_data/hybrid-search/linear-combination.png)
_A distribution of both Qdrant and BM25 scores mapped into 2D space. It clearly shows relevant and non-relevant objects are not linearly separable in that space, so using a linear combination of both scores won’t give us a proper hybrid search._
Both relevant and non-relevant items are mixed. **None of the linear formulas would be able to distinguish between them.** Thus, that’s not the way to solve it.
## Building a hybrid search system in Qdrant
Ultimately, **any search mechanism might also be a reranking mechanism**. You can prefetch results with sparse vectors and then rerank them with the dense ones, or the other way around. Or, if you have Matryoshka embeddings, you can start with oversampling the candidates with the dense vectors of the lowest dimensionality and then gradually reduce the number of candidates by reranking them with the higher-dimensional embeddings. Nothing stops you from combining both fusion and reranking.
Let’s go a step further and build a hybrid search mechanism that combines the results from the Matryoshka embeddings, dense vectors, and sparse vectors and then reranks them with the late interaction model. In the meantime, we will introduce additional reranking and fusion steps.
![Complex search pipeline](https://qdrant.tech/articles_data/hybrid-search/complex-search-pipeline.png)
Our search pipeline consists of two branches, each of them responsible for retrieving a subset of documents that we eventually want to rerank with the late interaction model. Let’s connect to Qdrant first and then build the search pipeline.
```
from qdrant_client import QdrantClient, models
client = QdrantClient("http://localhost:6333")

```
All the steps utilizing Matryoshka embeddings might be specified in the Query API as a nested structure:
```
# The first branch of our search pipeline retrieves 25 documents
# using the Matryoshka embeddings with multistep retrieval.
matryoshka_prefetch = models.Prefetch(
    prefetch=[
        models.Prefetch(
            prefetch=[
                # The first prefetch operation retrieves 100 documents
                # using the Matryoshka embeddings with the lowest
                # dimensionality of 64.
                models.Prefetch(
                    query=[0.456, -0.789, ..., 0.239],
                    using="matryoshka-64dim",
                    limit=100,
                ),
            ],
            # Then, the retrieved documents are re-ranked using the
            # Matryoshka embeddings with the dimensionality of 128.
            query=[0.456, -0.789, ..., -0.789],
            using="matryoshka-128dim",
            limit=50,
        )
    ],
    # Finally, the results are re-ranked using the Matryoshka
    # embeddings with the dimensionality of 256.
    query=[0.456, -0.789, ..., 0.123],
    using="matryoshka-256dim",
    limit=25,
)

```
Similarly, we can build the second branch of our search pipeline, which retrieves the documents using the dense and sparse vectors and performs the fusion of them using the Reciprocal Rank Fusion method:
```
# The second branch of our search pipeline also retrieves 25 documents,
# but uses the dense and sparse vectors, with their results combined
# using the Reciprocal Rank Fusion.
sparse_dense_rrf_prefetch = models.Prefetch(
    prefetch=[
        models.Prefetch(
            prefetch=[
                # The first prefetch operation retrieves 100 documents
                # using dense vectors using integer data type. Retrieval
                # is faster, but quality is lower.
                models.Prefetch(
                    query=[7, 63, ..., 92],
                    using="dense-uint8",
                    limit=100,
                )
            ],
            # Integer-based embeddings are then re-ranked using the
            # float-based embeddings. Here we just want to retrieve
            # 25 documents.
            query=[-1.234, 0.762, ..., 1.532],
            using="dense",
            limit=25,
        ),
        # Here we just add another 25 documents using the sparse
        # vectors only.
        models.Prefetch(
            query=models.SparseVector(
                indices=[125, 9325, 58214],
                values=[-0.164, 0.229, 0.731],
            ),
            using="sparse",
            limit=25,
        ),
    ],
    # RRF is activated below, so there is no need to specify the
    # query vector here, as fusion is done on the scores of the
    # retrieved documents.
    query=models.FusionQuery(
        fusion=models.Fusion.RRF,
    ),
)

```
The second branch could have already been called hybrid, as it combines the results from the dense and sparse vectors with fusion. However, nothing stops us from building even more complex search pipelines.
Here is how the target call to the Query API would look like in Python:
```
client.query_points(
    "my-collection",
    prefetch=[
        matryoshka_prefetch,
        sparse_dense_rrf_prefetch,
    ],
    # Finally rerank the results with the late interaction model. It only 
    # considers the documents retrieved by all the prefetch operations above. 
    # Return 10 final results.
    query=[
        [1.928, -0.654, ..., 0.213],
        [-1.197, 0.583, ..., 1.901],
        ...,
        [0.112, -1.473, ..., 1.786],
    ],
    using="late-interaction",
    with_payload=False,
    limit=10,
)

```
The options are endless, the new Query API gives you the flexibility to experiment with different setups. **You rarely need to build such a complex search pipeline** , but it’s good to know that you can do that if needed.
The example above is a simplified version of the search pipeline using **multi-vector representations, such as late interaction models**. Practically, these methods are computationally expensive, and there are some considerations to take into account when building a real-world system. The paragraph below will give you some hints on how to use these methods efficiently.
## Lessons learned: multi-vector representations
Many of you have already started building hybrid search systems and reached out to us with questions and feedback. We’ve seen many different approaches, however one recurring idea was to utilize **multi-vector representations with ColBERT-style models as a reranking step** , after retrieving candidates with single-vector dense and/or sparse methods. This reflects the latest trends in the field, as single-vector methods are still the most efficient, but multivectors capture the nuances of the text better.
![Reranking with late interaction models](https://qdrant.tech/articles_data/hybrid-search/late-interaction-reranking.png)
Assuming you never use late interaction models for retrieval alone, but only for reranking, this setup comes with a hidden cost. By default, each configured dense vector of the collection will have a corresponding HNSW graph created. Even, if it is a multi-vector.
```
from qdrant_client import QdrantClient, models
client = QdrantClient(...)
client.create_collection(
    collection_name="my-collection",
    vectors_config={
        "dense": models.VectorParams(...),
        "late-interaction": models.VectorParams(
            size=128,
            distance=models.Distance.COSINE,
            multivector_config=models.MultiVectorConfig(
                comparator=models.MultiVectorComparator.MAX_SIM
            ),
        )
    },
    sparse_vectors_config={
        "sparse": models.SparseVectorParams(...)
    },
)

```
Reranking will never use the created graph, as all the candidates are already retrieved. Multi-vector ranking will only be applied to the candidates retrieved by the previous steps, so no search operation is needed. HNSW becomes redundant while still the indexing process has to be performed, and in that case, it will be quite heavy. ColBERT-like models create hundreds of embeddings for each document, so the overhead is significant. **To avoid it, you can disable the HNSW graph creation for this kind of model** :
```
client.create_collection(
    collection_name="my-collection",
    vectors_config={
        "dense": models.VectorParams(...),
        "late-interaction": models.VectorParams(
            size=128,
            distance=models.Distance.COSINE,
            multivector_config=models.MultiVectorConfig(
                comparator=models.MultiVectorComparator.MAX_SIM
            ),
            hnsw_config=models.HnswConfigDiff(
                m=0,  # Disable HNSW graph creation
            ),
        )
    },
    sparse_vectors_config={
        "sparse": models.SparseVectorParams(...)
    },
)

```
You won’t notice any difference in the search performance, but the use of resources will be significantly lower when you upload the embeddings to the collection.
## Some anecdotal observations
Neither of the algorithms performs best in all cases. In some cases, keyword-based search will be the winner and vice-versa. The following table shows some interesting examples we could find in the 
Query | BM25 Search | Vector Search  
---|---|---  
cybersport desk | desk ❌ | gaming desk ✅  
plates for icecream | "eat" plates on wood wall décor ❌ | alicyn 8.5 '' melamine dessert plate ✅  
kitchen table with a thick board | craft kitchen acacia wood cutting board ❌ | industrial solid wood dining table ✅  
wooden bedside table | 30 '' bedside table lamp ❌ | portable bedside end table ✅  
Also examples where keyword-based search did better:
Query | BM25 Search | Vector Search  
---|---|---  
computer chair | vibrant computer task chair ✅ | office chair ❌  
64.2 inch console table | cervantez 64.2 '' console table ✅ | 69.5 '' console table ❌  
## Try the New Query API in Qdrant 1.10
The new Query API introduced in Qdrant 1.10 is a game-changer for building hybrid search systems. You don’t need any additional services to combine the results from different search methods, and you can even create more complex pipelines and serve them directly from Qdrant.
Our webinar on _Building the Ultimate Hybrid Search_ takes you through the process of building a hybrid search system with Qdrant Query API. If you missed it, you can 
If you have any questions or need help with building your hybrid search system, don’t hesitate to reach out to us on 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/hybrid-search.md) this page on GitHub, or 
On this page:
  * [Introducing the new Query API](https://qdrant.tech/articles/hybrid-search/#introducing-the-new-query-api)
  * [How effective is your search system?](https://qdrant.tech/articles/hybrid-search/#how-effective-is-your-search-system)
  * [Available embedding options with Query API](https://qdrant.tech/articles/hybrid-search/#available-embedding-options-with-query-api)
  * [Fusion vs reranking](https://qdrant.tech/articles/hybrid-search/#fusion-vs-reranking)
    * [Why not a linear combination?](https://qdrant.tech/articles/hybrid-search/#why-not-a-linear-combination)
  * [Building a hybrid search system in Qdrant](https://qdrant.tech/articles/hybrid-search/#building-a-hybrid-search-system-in-qdrant)
  * [Lessons learned: multi-vector representations](https://qdrant.tech/articles/hybrid-search/#lessons-learned-multi-vector-representations)
  * [Some anecdotal observations](https://qdrant.tech/articles/hybrid-search/#some-anecdotal-observations)
  * [Try the New Query API in Qdrant 1.10](https://qdrant.tech/articles/hybrid-search/#try-the-new-query-api-in-qdrant-110)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/hybrid-search/)
                    ## 📄 `https-qdrant-tech-articles-immutable-data-structures.md`
                    ```md
                    # https://qdrant.tech/articles/immutable-data-structures/
  * [Articles](https://qdrant.tech/articles/)
  * Qdrant Internals: Immutable Data Structures
# Qdrant Internals: Immutable Data Structures
Andrey Vasnetsov
·
August 20, 2024
![Qdrant Internals: Immutable Data Structures](https://qdrant.tech/articles_data/immutable-data-structures/preview/title.jpg)
## Data Structures 101
Those who took programming courses might remember that there is no such thing as a universal data structure. Some structures are good at accessing elements by index (like arrays), while others shine in terms of insertion efficiency (like linked lists).
![Hardware-optimized data structure](https://qdrant.tech/articles_data/immutable-data-structures/hardware-optimized.png)
Hardware-optimized data structure
However, when we move from theoretical data structures to real-world systems, and particularly in performance-critical areas such as [vector search](https://qdrant.tech/use-cases/), things become more complex. 
> From the perspective of hardware efficiency, the ideal data structure is a contiguous array of bytes that can be read sequentially in a single thread. This scenario allows hardware optimizations like prefetching, caching, and branch prediction to operate at their best.
However, real-world use cases require more complex structures to perform various operations like insertion, deletion, and search. These requirements increase complexity and introduce performance trade-offs.
### Mutability
One of the most significant challenges when working with data structures is ensuring **mutability — the ability to change the data structure after it’s created** , particularly with fast update operations.
Let’s consider a simple example: we want to iterate over items in sorted order. Without a mutability requirement, we can use a simple array and sort it once. This is very close to our ideal scenario. We can even put the structure on disk - which is trivial for an array.
However, if we need to insert an item into this array, **things get more complicated**. Inserting into a sorted array requires shifting all elements after the insertion point, which leads to linear time complexity for each insertion, which is not acceptable for many applications.
To handle such cases, more complex structures like 
Here’s a benchmark that illustrates the difference between iterating over a plain array and a BTreeSet in Rust:
```
usestd::collections::BTreeSet;userand::Rng;fn main(){// Benchmark plain vector VS btree in a task of iteration over all elements
letmutrand=rand::thread_rng();letvector: Vec<_>=(0..1000000).map(|_|rand.gen::<u64>()).collect();letbtree: BTreeSet<_>=vector.iter().copied().collect();{letmutsum=0;forelinvector{sum+=el;}}// Elapsed: 850.924µs
{letmutsum=0;forelinbtree{sum+=el;}}// Elapsed: 5.213025ms, ~6x slower
}
```
[Vector databases](https://qdrant.tech/), like Qdrant, have to deal with a large variety of data structures. If we could make them immutable, it would significantly improve performance and optimize memory usage.
## How Does Immutability Help?
A large part of the immutable advantage comes from the fact that we know the exact data we need to put into the structure even before we start building it. The simplest example is a sorted array: we would know exactly how many elements we have to put into the array so we can allocate the exact amount of memory once.
More complex data structures might require additional statistics to be collected before the structure is built. A Qdrant-related example of this is [Scalar Quantization](https://qdrant.tech/articles/scalar-quantization/#conversion-to-integers): in order to select proper quantization levels, we have to know the distribution of the data.
![Scalar Quantization Quantile](https://qdrant.tech/articles_data/immutable-data-structures/quantization-quantile.png)
Scalar Quantization Quantile
Computing this distribution requires knowing all the data in advance, but once we have it, applying scalar quantization is a simple operation.
Let’s take a look at a non-exhaustive list of data structures and potential improvements we can get from making them immutable:
Function | Mutable Data Structure | Immutable Alternative | Potential improvements  
---|---|---|---  
Read by index | Array | Fixed chunk of memory | Allocate exact amount of memory  
Vector Storage | Array or Arrays | Memory-mapped file | Offload data to disk  
Read sorted ranges | B-Tree | Sorted Array | Store all data close, avoid cache misses  
Read by key | Hash Map | Hash Map with Perfect Hashing | Avoid hash collisions  
Get documents by keyword | Inverted Index | Inverted Index with Sorted  
and BitPacked Postings | Less memory usage, faster search  
Vector Search | HNSW graph | HNSW graph with  
payload-aware connections | Better precision with filters  
Tenant Isolation | Vector Storage | Defragmented Vector Storage | Faster access to on-disk data  
For more info on payload-aware connections in HNSW, read our [previous article](https://qdrant.tech/articles/filtrable-hnsw/).
This time around, we will focus on the latest additions to Qdrant:
  * **the immutable hash map with perfect hashing**
  * **defragmented vector storage**.
### Perfect Hashing
A hash table is one of the most commonly used data structures implemented in almost every programming language, including Rust. It provides fast access to elements by key, with an average time complexity of O(1) for read and write operations.
There is, however, the assumption that should be satisfied for the hash table to work efficiently: _hash collisions should not cause too much overhead_. In a hash table, each key is mapped to a “bucket,” a slot where the value is stored. When different keys map to the same bucket, a collision occurs.
In regular mutable hash tables, minimization of collisions is achieved by:
  * making the number of buckets bigger so the probability of collision is lower
  * using a linked list or a tree to store multiple elements with the same hash
However, these strategies have overheads, which become more significant if we consider using high-latency storage like disk.
Indeed, every read operation from disk is several orders of magnitude slower than reading from RAM, so we want to know the correct location of the data from the first attempt.
In order to achieve this, we can use a so-called minimal perfect hash function (MPHF). This special type of hash function is constructed specifically for a given set of keys, and it guarantees no collisions while using minimal amount of buckets.
In Qdrant, we decided to use _fingerprint-based minimal perfect hash function_ implemented in the 
Volume | `ph::Function` | `std::hash::Hash` | `HashMap::get`  
---|---|---|---  
1000 | 60ns | ~20ns | 34ns  
100k | 90ns | ~20ns | 220ns  
10M | 238ns | ~20ns | 500ns  
Even thought the absolute time for hashing is higher, the time for the whole operation is lower, because PHF guarantees no collisions. The difference is even more significant when we consider disk read time, which might up to several milliseconds (10^6 ns).
PHF RAM size scales linearly for `ph::Function`: 3.46 kB for 10k elements, 119MB for 350M elements. The construction time required to build the hash function is surprisingly low, and we only need to do it once:
Volume |  `ph::Function` (construct) | PHF size | Size of int64 keys (for reference)  
---|---|---|---  
1M | 52ms | 0.34Mb | 7.62Mb  
100M | 7.4s | 33.7Mb | 762.9Mb  
The usage of PHF in Qdrant lets us minimize the latency of cold reads, which is especially important for large-scale multi-tenant systems. With PHF, it is enough to read a single page from a disk to get the exact location of the data.
### Defragmentation
When you read data from a disk, you almost never read a single byte. Instead, you read a page, which is a fixed-size chunk of data. On many systems, the page size is 4KB, which means that every read operation will read 4KB of data, even if you only need a single byte.
Vector search, on the other hand, requires reading a lot of small vectors, which might create a large overhead. It is especially noticeable if we use binary quantization, where the size of even large OpenAI 1536d vectors is compressed down to **192 bytes**.
![Overhead when reading a single vector](https://qdrant.tech/articles_data/immutable-data-structures/page-vector.png)
Overhead when reading single vector
That means if the vectors we access during the search are randomly scattered across the disk, we will have to read 4KB for each vector, which is 20 times more than the actual data size.
There is, however, a simple way to avoid this overhead: **defragmentation**. If we knew some additional information about the data, we could combine all relevant vectors into a single page.
![Defragmentation](https://qdrant.tech/articles_data/immutable-data-structures/defragmentation.png)
Defragmentation
This additional information is available to Qdrant via the [payload index](https://qdrant.tech/documentation/concepts/indexing/#payload-index).
By specifying the payload index, which is going to be used for filtering most of the time, we can put all vectors with the same payload together. This way, reading a single page will also read nearby vectors, which will be used in the search.
This approach is especially efficient for [multi-tenant systems](https://qdrant.tech/documentation/guides/multiple-partitions/), where only a small subset of vectors is actively used for search. The capacity of such a deployment is typically defined by the size of the hot subset, which is much smaller than the total number of vectors.
> Grouping relevant vectors together allows us to optimize the size of the hot subset by avoiding caching of irrelevant data. The following benchmark data compares RPS for defragmented and non-defragmented storage:
% of hot subset | Tenant Size (vectors) | RPS, Non-defragmented | RPS, Defragmented  
---|---|---|---  
2.5% | 50k | 1.5 | 304  
12.5% | 50k | 0.47 | 279  
25% | 50k | 0.4 | 63  
50% | 50k | 0.3 | 8  
2.5% | 5k | 56 | 490  
12.5% | 5k | 5.8 | 488  
25% | 5k | 3.3 | 490  
50% | 5k | 3.1 | 480  
75% | 5k | 2.9 | 130  
100% | 5k | 2.7 | 95  
**Dataset size:** 2M 768d vectors (~6Gb Raw data), binary quantization, 650Mb of RAM limit. All benchmarks are made with minimal RAM allocation to demonstrate disk cache efficiency.
As you can see, the biggest impact is on the small tenant size, where defragmentation allows us to achieve **100x more RPS**. Of course, the real-world impact of defragmentation depends on the specific workload and the size of the hot subset, but enabling this feature can significantly improve the performance of Qdrant.
Please find more details on how to enable defragmentation in the [indexing documentation](https://qdrant.tech/documentation/concepts/indexing/#tenant-index).
## Updating Immutable Data Structures
One may wonder how Qdrant allows updating collection data if everything is immutable. Indeed, [Qdrant API](https://api.qdrant.tech) allows the change of any vector or payload at any time, so from the user’s perspective, the whole collection is mutable at any time.
As it usually happens with every decent magic trick, the secret is disappointingly simple: not all data in Qdrant is immutable. In Qdrant, storage is divided into segments, which might be either mutable or immutable. New data is always written to the mutable segment, which is later converted to the immutable one by the optimization process.
![Optimization process](https://qdrant.tech/articles_data/immutable-data-structures/optimization.png)
Optimization process
If we need to update the data in the immutable or currenly optimized segment, instead of changing the data in place, we perform a copy-on-write operation, move the data to the mutable segment, and update it there.
Data in the original segment is marked as deleted, and later vacuumed by the optimization process.
## Downsides and How to Compensate
While immutable data structures are great for read-heavy operations, they come with trade-offs:
  * **Higher update costs:** Immutable structures are less efficient for updates. The amortized time complexity might be the same as mutable structures, but the constant factor is higher.
  * **Rebuilding overhead:** In some cases, we may need to rebuild indices or structures for the same data more than once.
  * **Read-heavy workloads:** Immutability assumes a search-heavy workload, which is typical for search engines but not for all applications.
In Qdrant, we mitigate these downsides by allowing the user to adapt the system to their specific workload. For example, changing the default size of the segment might help to reduce the overhead of rebuilding indices.
In extreme cases, multi-segment storage can act as a single segment, falling back to the mutable data structure when needed.
## Conclusion
Immutable data structures, while tricky to implement correctly, offer significant performance gains, especially for read-heavy systems like search engines. They allow us to take full advantage of hardware optimizations, reduce memory overhead, and improve cache performance.
In Qdrant, the combination of techniques like perfect hashing and defragmentation brings further benefits, making our vector search operations faster and more efficient. While there are trade-offs, the flexibility of Qdrant’s architecture — including segment-based storage — allows us to balance the best of both worlds.
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/immutable-data-structures.md) this page on GitHub, or 
On this page:
  * [Data Structures 101](https://qdrant.tech/articles/immutable-data-structures/#data-structures-101)
    * [Mutability](https://qdrant.tech/articles/immutable-data-structures/#mutability)
  * [How Does Immutability Help?](https://qdrant.tech/articles/immutable-data-structures/#how-does-immutability-help)
    * [Perfect Hashing](https://qdrant.tech/articles/immutable-data-structures/#perfect-hashing)
    * [Defragmentation](https://qdrant.tech/articles/immutable-data-structures/#defragmentation)
  * [Updating Immutable Data Structures](https://qdrant.tech/articles/immutable-data-structures/#updating-immutable-data-structures)
  * [Downsides and How to Compensate](https://qdrant.tech/articles/immutable-data-structures/#downsides-and-how-to-compensate)
  * [Conclusion](https://qdrant.tech/articles/immutable-data-structures/#conclusion)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/immutable-data-structures/)
                    ## 📄 `https-qdrant-tech-articles-indexing-optimization.md`
                    ```md
                    # https://qdrant.tech/articles/indexing-optimization/
  * [Articles](https://qdrant.tech/articles/)
  * Optimizing Memory for Bulk Uploads
# Optimizing Memory for Bulk Uploads
Sabrina Aquino
·
February 13, 2025
![Optimizing Memory for Bulk Uploads](https://qdrant.tech/articles_data/indexing-optimization/preview/title.jpg)
# Optimizing Memory Consumption During Bulk Uploads
Efficient memory management is a constant challenge when you’re dealing with **large-scale vector data**. In high-volume ingestion scenarios, even seemingly minor configuration choices can significantly impact stability and performance.
Let’s take a look at the best practices and recommendations to help you optimize memory usage during bulk uploads in Qdrant. We’ll cover scenarios with both **dense** and **sparse** vectors, helping your deployments remain performant even under high load and avoiding out-of-memory errors.
## Indexing for dense vs. sparse vectors
**Dense vectors**
Qdrant employs an **HNSW-based index** for fast similarity search on dense vectors. By default, HNSW is built or updated once the number of **unindexed** vectors in a segment exceeds a set `indexing_threshold`. Although it delivers excellent query speed, building or updating the HNSW graph can be **resource-intensive** if it occurs frequently or across many small segments.
**Sparse vectors**
Sparse vectors use an **inverted index**. This index is updated at the **time of upsertion** , meaning you cannot disable or postpone it for sparse vectors. In most cases, its overhead is smaller than that of building an HNSW graph, but you should still be aware that each upsert triggers a sparse index update.
Sparse vectors are always indexed on upsert, regardless of the threshold.
## Bulk upload configuration for dense vectors
When performing high-volume vector ingestion, you have **two primary options** for handling indexing overhead. You should choose one depending on your specific workload and memory constraints:
  * **Disable HNSW indexing**
To reduce memory and CPU pressure during bulk ingestion, you can **disable HNSW indexing entirely** by setting `"m": 0`. For dense vectors, the `m` parameter defines how many edges each node in the HNSW graph can have. This way, no dense vector index will be built, preventing unnecessary CPU usage during ingestion.
**Figure 1:** A description of three key HNSW parameters.
![](https://qdrant.tech/articles_data/indexing-optimization/hnsw-parameters.png)
```
PATCH /collections/your_collection
{
  "hnsw_config": {
    "m": 0
  }
}

```
**After ingestion is complete** , you can **re-enable HNSW** by setting `m` back to a production value (commonly 16 or 32). Remember that search won’t use HNSW until the index is built, so search performance may be slower during this period.
  * **Disabling optimizations completely**
The `indexing_threshold` tells Qdrant how many unindexed dense vectors can accumulate in a segment before building the HNSW graph. Setting `"indexing_threshold"=0` defers indexing entirely, keeping **ingestion speed at maximum**. However, this means uploaded vectors are not moved to disk while uploading, which can lead to **high RAM usage**.
```
PATCH /collections/your_collection
{
  "optimizer_config": {
    "indexing_threshold": 0
  }
}

```
Warning: If your dataset is large, this can lead to excessive memory usage. Ensure your system has sufficient RAM or consider using "m"=0 instead.
After bulk ingestion, set `indexing_threshold` to a positive value to ensure vectors are indexed and searchable via HNSW. **Vectors will not be searchable via HNSW until indexing is performed.**
Small thresholds (e.g., 100) mean more frequent indexing, which can still be costly if many segments exist. Larger thresholds (e.g., 10000) delay indexing to batch more vectors at once, potentially using more RAM at the moment of index build, but fewer builds overall.
Between these two approaches, we generally recommend disabling HNSW (`"m"=0`) during bulk ingestion to keep memory usage predictable. Using `indexing_threshold=0` can be an alternative, but only if your system has enough memory to accommodate the unindexed vectors in RAM.
## On-Disk storage in Qdrant
By default, Qdrant keeps **vectors** , **payload data** , and **indexes** in memory to ensure low-latency queries. However, in large-scale or memory-constrained scenarios, you can configure some or all of them to be stored on-disk. This helps reduce RAM usage at the cost of potential increases in query latency, particularly for cold reads.
**When to use on-disk** :
  * You have **very large** or **rarely used** payload data or indexes, and freeing up RAM is worth potential I/O overhead.
  * Your dataset doesn’t fit comfortably in available memory.
  * You want to reduce memory pressure.
  * You can tolerate slower queries if it ensures the system remains stable under heavy loads.
## Memmap storage and segmentation
Qdrant uses **memory-mapped files** (segments) to store data on-disk. Rather than loading all vectors into RAM, Qdrant maps each segment into its address space, paging data in and out on demand. This helps keep the active RAM footprint lower, because data can be paged out if memory pressure is high. But each segment still incurs overhead (metadata, page table entries, etc.).
During **high-volume ingestion** , you can accumulate dozens of small segments. Qdrant’s **optimizer** can later merge these into fewer, larger segments, reducing per-segment overhead and lowering total memory usage.
When you create a collection with `"on_disk": true`, Qdrant will store newly inserted vectors in memmap storage from the start. For example:
```
PATCH /collections/your_collection
{
    "vectors": {
      "on_disk": true
    }
}

```
This approach immediately places all incoming vectors on disk, which can be very efficient in case of bulk ingestion.
However, **vector data and indexes are stored separately** , so enabling `on_disk` for vectors does not automatically store their indexes on disk. To fully optimize memory usage, you may need to configure **both vector storage and index storage** independently.
For dense vectors, you can enable on-disk storage for both the **vector data** and the **HNSW index** :
```
PATCH /collections/your_collection
{
    "vectors": {
        "on_disk": true
    },
    "hnsw_config": {
        "on_disk": true
    }
}

```
For sparse vectors, you need to enable `on_disk` for both the vector data and the sparse index separately:
```
PATCH /collections/your_collection
{
    "sparse_vectors": {
        "text": {
            "on_disk": true,
            "index": {
                "on_disk": true
            }
        }
    }
}

```
## **Best practices for high-volume vector ingestion**
Bulk ingestion can lead to high memory consumption and even out-of-memory (OOM) errors. **If you’re experiencing out-of-memory errors with your current setup** , scaling up temporarily (increasing available RAM) will provide a buffer while you adjust Qdrant’s configuration for more a efficient data ingestion.
The key here is to control indexing overhead. Let’s walk through the best practices for high-volume vector ingestion in a constrained-memory environment.
### 1. Store vector data on disk immediately
The most effective way to reduce memory usage is to store vector data on disk right from the start using `on_disk: true`. This prevents RAM from being overloaded with raw vectors before optimization kicks in.
```
PATCH /collections/your_collection
{
  "vectors": {
    "on_disk": true
  }
}

```
Previously, vector data had to be held in RAM until optimizers could move it to disk, which caused significant memory pressure. Now, by writing vectors to disk directly, memory overhead is significantly reduced, making bulk ingestion much more efficient.
### 2. Disable HNSW for dense vectors (`m=0`)
During an **initial bulk load** , you can **disable** dense indexing by setting `"m": 0.` This ensures Qdrant won’t build an HNSW graph for incoming vectors, avoiding unnecessary memory and CPU usage.
```
PATCH /collections/your_collection
{
  "hnsw_config": {
    "m": 0
  },
  "optimizer_config": {
    "indexing_threshold": 10000
  }
}

```
If your collection already contains a large number of vectors, changing these parameters will trigger a full index reconstruction, potentially causing slight performance degradation.
### 3. Let the optimizer run **after** bulk uploads
Qdrant’s optimizers continuously restructure data to improve search efficiency. However, during a bulk upload, this can lead to excessive data movement and overhead as segments are constantly reorganized while new data is still arriving.
To avoid this, **upload all data first** , then allow the optimizer to process everything in one go. This minimizes redundant operations and ensures a more efficient segment structure.
### **4. Wait for indexation to clear up memory**
Before performing additional operations, **allow Qdrant to finish any ongoing indexing**. Large indexing jobs can keep memory usage high until they fully complete.
Monitor Qdrant logs or metrics to confirm when indexing finishes—once that happens, memory consumption should drop as intermediate data structures are freed.
### 5. Re-enable HNSW post-ingestion
After the ingestion phase is over and memory usage has stabilized, re-enable HNSW for dense vectors by setting `m` back to a production value (commonly `16` or `32`):
```
PATCH /collections/your_collection
{
  "hnsw_config": {
    "m": 16
  }
}

```
If you're planning to use quantization, it’s best to enable it before re-enabling indexing, to avoid running additional optimizations later. Ideally, you can set both indexing and quantization in the same update call for efficiency.
### 5. Enable quantization
If you had planned to store all dense vectors on disk, be aware that searches can slow down drastically due to frequent disk I/O while memory pressure is high. A more balanced approach is **scalar quantization** : compress vectors (e.g., to `int8`) so they fit in RAM without occupying as much space as full floating-point values.
```
PATCH /collections/your_collection
{
  "quantization_config": {
    "scalar": {
      "type": "int8",
      "always_ram": true
    }
  }
}

```
Quantized vectors remain **in-memory** yet consume less space, preserving much of the performance advantage of RAM-based search. Learn more about [vector quantization](https://qdrant.tech/articles/what-is-vector-quantization/).
### Conclusion
High-volume vector ingestion can place significant memory demands on Qdrant, especially if dense vectors are indexed in real time. By following these tips, you can substantially reduce the risk of out-of-memory errors and maintain stable performance in a memory-limited environment.
As always, monitor your system’s behavior. Review logs, watch metrics, and keep an eye on memory usage. Each workload is different, so it’s wise to fine-tune Qdrant’s parameters according to your hardware and data scale.
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/indexing-optimization.md) this page on GitHub, or 
On this page:
  * [Indexing for dense vs. sparse vectors](https://qdrant.tech/articles/indexing-optimization/#indexing-for-dense-vs-sparse-vectors)
  * [Bulk upload configuration for dense vectors](https://qdrant.tech/articles/indexing-optimization/#bulk-upload-configuration-for-dense-vectors)
  * [On-Disk storage in Qdrant](https://qdrant.tech/articles/indexing-optimization/#on-disk-storage-in-qdrant)
  * [Memmap storage and segmentation](https://qdrant.tech/articles/indexing-optimization/#memmap-storage-and-segmentation)
  * [**Best practices for high-volume vector ingestion**](https://qdrant.tech/articles/indexing-optimization/#best-practices-for-high-volume-vector-ingestion)
    * [1. Store vector data on disk immediately](https://qdrant.tech/articles/indexing-optimization/#1-store-vector-data-on-disk-immediately)
    * [2. Disable HNSW for dense vectors (`m=0`)](https://qdrant.tech/articles/indexing-optimization/#2-disable-hnsw-for-dense-vectors-m0)
    * [3. Let the optimizer run **after** bulk uploads](https://qdrant.tech/articles/indexing-optimization/#3-let-the-optimizer-run-after-bulk-uploads)
    * [**4. Wait for indexation to clear up memory**](https://qdrant.tech/articles/indexing-optimization/#4-wait-for-indexation-to-clear-up-memory)
    * [5. Re-enable HNSW post-ingestion](https://qdrant.tech/articles/indexing-optimization/#5-re-enable-hnsw-post-ingestion)
    * [5. Enable quantization](https://qdrant.tech/articles/indexing-optimization/#5-enable-quantization)
    * [Conclusion](https://qdrant.tech/articles/indexing-optimization/#conclusion)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/indexing-optimization/)
                    ## 📄 `https-qdrant-tech-articles-io-uring.md`
                    ```md
                    # https://qdrant.tech/articles/io_uring/
  * [Articles](https://qdrant.tech/articles/)
  * Qdrant under the hood: io_uring
# Qdrant under the hood: io_uring
Andre Bogus
·
June 21, 2023
![Qdrant under the hood: io_uring](https://qdrant.tech/articles_data/io_uring/preview/title.jpg)
With Qdrant _async uring_ storage backend on Linux-based systems. Since its introduction, io_uring has been known to improve async throughput wherever the OS syscall overhead gets too high, which tends to occur in situations where software becomes _IO bound_ (that is, mostly waiting on disk).
## Input+Output
Around the mid-90s, the internet took off. The first servers used a process- per-request setup, which was good for serving hundreds if not thousands of concurrent request. The POSIX Input + Output (IO) was modeled in a strictly synchronous way. The overhead of starting a new process for each request made this model unsustainable. So servers started forgoing process separation, opting for the thread-per-request model. But even that ran into limitations.
I distinctly remember when someone asked the question whether a server could serve 10k concurrent connections, which at the time exhausted the memory of most systems (because every thread had to have its own stack and some other metadata, which quickly filled up available memory). As a result, the synchronous IO was replaced by asynchronous IO during the 2.5 kernel update, either via `select` or `epoll` (the latter being Linux-only, but a small bit more efficient, so most servers of the time used it).
However, even this crude form of asynchronous IO carries the overhead of at least one system call per operation. Each system call incurs a context switch, and while this operation is itself not that slow, the switch disturbs the caches. Today’s CPUs are much faster than memory, but if their caches start to miss data, the memory accesses required led to longer and longer wait times for the CPU.
### Memory-mapped IO
Another way of dealing with file IO (which unlike network IO doesn’t have a hard time requirement) is to map parts of files into memory - the system fakes having that chunk of the file in memory, so when you read from a location there, the kernel interrupts your process to load the needed data from disk, and resumes your process once done, whereas writing to the memory will also notify the kernel. Also the kernel can prefetch data while the program is running, thus reducing the likelyhood of interrupts.
Thus there is still some overhead, but (especially in asynchronous applications) it’s far less than with `epoll`. The reason this API is rarely used in web servers is that these usually have a large variety of files to access, unlike a database, which can map its own backing store into memory once.
### Combating the Poll-ution
There were multiple experiments to improve matters, some even going so far as moving a HTTP server into the kernel, which of course brought its own share of problems. Others like Intel added their own APIs that ignored the kernel and worked directly on the hardware.
Finally, Jens Axboe took matters into his own hands and proposed a ring buffer based interface called _io_uring_. The buffers are not directly for data, but for operations. User processes can setup a Submission Queue (SQ) and a Completion Queue (CQ), both of which are shared between the process and the kernel, so there’s no copying overhead.
![io_uring diagram](https://qdrant.tech/articles_data/io_uring/io-uring.png)
Apart from avoiding copying overhead, the queue-based architecture lends itself to multithreading as item insertion/extraction can be made lockless, and once the queues are set up, there is no further syscall that would stop any user thread.
Servers that use this can easily get to over 100k concurrent requests. Today Linux allows asynchronous IO via io_uring for network, disk and accessing other ports, e.g. for printing or recording video.
## And what about Qdrant?
Qdrant can store everything in memory, but not all data sets may fit, which can require storing on disk. Before io_uring, Qdrant used mmap to do its IO. This led to some modest overhead in case of disk latency. The kernel may stop a user thread trying to access a mapped region, which incurs some context switching overhead plus the wait time until the disk IO is finished. Ultimately, this works very well with the asynchronous nature of Qdrant’s core.
One of the great optimizations Qdrant offers is quantization (either [scalar](https://qdrant.tech/articles/scalar-quantization/) or [product](https://qdrant.tech/articles/product-quantization/)-based). However unless the collection resides fully in memory, this optimization method generates significant disk IO, so it is a prime candidate for possible improvements.
If you run Qdrant on Linux, you can enable io_uring with the following in your configuration:
```
# within the storage configstorage:# enable the async scorer which uses io_uringasync_scorer:true
```
You can return to the mmap based backend by either deleting the `async_scorer` entry or setting the value to `false`.
## Benchmarks
To run the benchmark, use a test instance of Qdrant. If necessary spin up a docker container and load a snapshot of the collection you want to benchmark with. You can copy and edit our [benchmark script](https://qdrant.tech/articles_data/io_uring/rescore-benchmark.sh) to run the benchmark. Run the script with and without enabling `storage.async_scorer` and once. You can measure IO usage with `iostat` from another console.
For our benchmark, we chose the laion dataset picking 5 million 768d entries. We enabled scalar quantization + HNSW with m=16 and ef_construct=512. We do the quantization in RAM, HNSW in RAM but keep the original vectors on disk (which was a network drive rented from Hetzner for the benchmark).
If you want to reproduce the benchmarks, you can get snapshots containing the datasets:
Running the benchmark, we get the following IOPS, CPU loads and wall clock times:
oversampling | parallel | ~max IOPS | CPU% (of 4 cores) | time (s) (avg of 3)  
---|---|---|---|---  
io_uring | 1 | 4 | 4000 | 200 | 12  
mmap | 1 | 4 | 2000 | 93 | 43  
io_uring | 1 | 8 | 4000 | 200 | 12  
mmap | 1 | 8 | 2000 | 90 | 43  
io_uring | 4 | 8 | 7000 | 100 | 30  
mmap | 4 | 8 | 2300 | 50 | 145  
Note that in this case, the IO operations have relatively high latency due to using a network disk. Thus, the kernel takes more time to fulfil the mmap requests, and application threads need to wait, which is reflected in the CPU percentage. On the other hand, with the io_uring backend, the application threads can better use available cores for the rescore operation without any IO-induced delays.
Oversampling is a new feature to improve accuracy at the cost of some performance. It allows setting a factor, which is multiplied with the `limit` while doing the search. The results are then re-scored using the original vector and only then the top results up to the limit are selected.
## Discussion
Looking back, disk IO used to be very serialized; re-positioning read-write heads on moving platter was a slow and messy business. So the system overhead didn’t matter as much, but nowadays with SSDs that can often even parallelize operations while offering near-perfect random access, the overhead starts to become quite visible. While memory-mapped IO gives us a fair deal in terms of ease of use and performance, we can improve on the latter in exchange for some modest complexity increase.
io_uring is still quite young, having only been introduced in 2019 with kernel 5.1, so some administrators will be wary of introducing it. Of course, as with performance, the right answer is usually “it depends”, so please review your personal risk profile and act accordingly.
## Best Practices
If your on-disk collection’s query performance is of sufficiently high priority to you, enable the io_uring-based async_scorer to greatly reduce operating system overhead from disk IO. On the other hand, if your collections are in memory only, activating it will be ineffective. Also note that many queries are not IO bound, so the overhead may or may not become measurable in your workload. Finally, on-device disks typically carry lower latency than network drives, which may also affect mmap overhead.
Therefore before you roll out io_uring, perform the above or a similar benchmark with both mmap and io_uring and measure both wall time and IOps). Benchmarks are always highly use-case dependent, so your mileage may vary. Still, doing that benchmark once is a small price for the possible performance wins. Also please 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/io_uring.md) this page on GitHub, or 
On this page:
  * [Input+Output](https://qdrant.tech/articles/io_uring/#inputoutput)
    * [Memory-mapped IO](https://qdrant.tech/articles/io_uring/#memory-mapped-io)
    * [Combating the Poll-ution](https://qdrant.tech/articles/io_uring/#combating-the-poll-ution)
  * [And what about Qdrant?](https://qdrant.tech/articles/io_uring/#and-what-about-qdrant)
  * [Benchmarks](https://qdrant.tech/articles/io_uring/#benchmarks)
  * [Discussion](https://qdrant.tech/articles/io_uring/#discussion)
  * [Best Practices](https://qdrant.tech/articles/io_uring/#best-practices)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/io_uring/)
                    ## 📄 `https-qdrant-tech-articles-machine-learning.md`
                    ```md
                    # https://qdrant.tech/articles/machine-learning/
  * [Articles](https://qdrant.tech/articles/)
  * Machine Learning
#### Machine Learning
Explore Machine Learning principles and practices which make modern semantic similarity search possible. Apply Qdrant and vector search capabilities to your ML projects.
[![Preview](https://qdrant.tech/articles_data/search-feedback-loop/preview/preview.jpg) Relevance Feedback in Informational Retrieval Relerance feedback: from ancient history to LLMs. Why relevance feedback techniques are good on paper but not popular in neural search, and what we can do about it. Evgeniya Sukhodolskaya March 27, 2025 ](https://qdrant.tech/articles/search-feedback-loop/)[![Preview](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/preview/preview.jpg) Modern Sparse Neural Retrieval: From Theory to Practice A comprehensive guide to modern sparse neural retrievers: COIL, TILDEv2, SPLADE, and more. Find out how they work and learn how to use them effectively. Evgeniya Sukhodolskaya October 23, 2024 ](https://qdrant.tech/articles/modern-sparse-neural-retrieval/)[![Preview](https://qdrant.tech/articles_data/cross-encoder-integration-gsoc/preview/preview.jpg) Qdrant Summer of Code 2024 - ONNX Cross Encoders in Python A summary of my work and experience at Qdrant Summer of Code 2024. Huong (Celine) Hoang October 14, 2024 ](https://qdrant.tech/articles/cross-encoder-integration-gsoc/)[![Preview](https://qdrant.tech/articles_data/late-interaction-models/preview/preview.jpg) Any* Embedding Model Can Become a Late Interaction Model... If You Give It a Chance! We recently discovered that embedding models can become late interaction models & can perform surprisingly well in some scenarios. See what we learned here. Kacper Łukawski August 14, 2024 ](https://qdrant.tech/articles/late-interaction-models/)[![Preview](https://qdrant.tech/articles_data/bm42/preview/preview.jpg) BM42: New Baseline for Hybrid Search Introducing BM42 - a new sparse embedding approach, which combines the benefits of exact keyword search with the intelligence of transformers. Andrey Vasnetsov July 01, 2024 ](https://qdrant.tech/articles/bm42/)[![Preview](https://qdrant.tech/articles_data/embedding-recycling/preview/preview.jpg) Layer Recycling and Fine-tuning Efficiency Learn when and how to use layer recycling to achieve different performance targets. Yusuf Sarıgöz August 23, 2022 ](https://qdrant.tech/articles/embedding-recycler/)[![Preview](https://qdrant.tech/articles_data/cars-recognition/preview/preview.jpg) Fine Tuning Similar Cars Search Learn how to train a similarity model that can retrieve similar car images in novel categories. Yusuf Sarıgöz June 28, 2022 ](https://qdrant.tech/articles/cars-recognition/)[![Preview](https://qdrant.tech/articles_data/detecting-coffee-anomalies/preview/preview.jpg) Metric Learning for Anomaly Detection Practical use of metric learning for anomaly detection. A way to match the results of a classification-based approach with only ~0.6% of the labeled data. Yusuf Sarıgöz May 04, 2022 ](https://qdrant.tech/articles/detecting-coffee-anomalies/)[![Preview](https://qdrant.tech/articles_data/triplet-loss/preview/preview.jpg) Triplet Loss - Advanced Intro What are the advantages of Triplet Loss over Contrastive loss and how to efficiently implement it? Yusuf Sarıgöz March 24, 2022 ](https://qdrant.tech/articles/triplet-loss/)[![Preview](https://qdrant.tech/articles_data/metric-learning-tips/preview/preview.jpg) Metric Learning Tips & Tricks Practical recommendations on how to train a matching model and serve it in production. Even with no labeled data. Andrei Vasnetsov May 15, 2021 ](https://qdrant.tech/articles/metric-learning-tips/)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/machine-learning/)
                    ## 📄 `https-qdrant-tech-articles-memory-consumption.md`
                    ```md
                    # https://qdrant.tech/articles/memory-consumption/
  * [Articles](https://qdrant.tech/articles/)
  * Minimal RAM you need to serve a million vectors
# Minimal RAM you need to serve a million vectors
Andrei Vasnetsov
·
December 07, 2022
![Minimal RAM you need to serve a million vectors](https://qdrant.tech/articles_data/memory-consumption/preview/title.jpg)
When it comes to measuring the memory consumption of our processes, we often rely on tools such as `htop` to give us an indication of how much RAM is being used. However, this method can be misleading and doesn’t always accurately reflect the true memory usage of a process.
There are many different ways in which `htop` may not be a reliable indicator of memory usage. For instance, a process may allocate memory in advance but not use it, or it may not free deallocated memory, leading to overstated memory consumption. A process may be forked, which means that it will have a separate memory space, but it will share the same code and data with the parent process. This means that the memory consumption of the child process will be counted twice. Additionally, a process may utilize disk cache, which is also accounted as resident memory in the `htop` measurements.
As a result, even if `htop` shows that a process is using 10GB of memory, it doesn’t necessarily mean that the process actually requires 10GB of RAM to operate efficiently. In this article, we will explore how to properly measure RAM usage and optimize [Qdrant](https://qdrant.tech/) for optimal memory consumption.
## How to measure actual RAM requirements
We need to know memory consumption in order to estimate how much RAM is required to run the program. So in order to determine that, we can conduct a simple experiment. Let’s limit the allowed memory of the process and observe at which point it stops functioning. In this way we can determine the minimum amount of RAM the program needs to operate.
One way to do this is by conducting a grid search, but a more efficient method is to use binary search to quickly find the minimum required amount of RAM. We can use docker to limit the memory usage of the process.
Before running each benchmark, it is important to clear the page cache with the following command:
```
sudo bash -c 'sync; echo 1 > /proc/sys/vm/drop_caches'

```
This ensures that the process doesn’t utilize any data from previous runs, providing more accurate and consistent results.
We can use the following command to run Qdrant with a memory limit of 1GB:
```
docker run -it --rm \
\
=host \
"$(pwd)/data/storage:/qdrant/storage" \

```
## Let’s run some benchmarks
Let’s run some benchmarks to see how much RAM Qdrant needs to serve 1 million vectors.
We can use the `glove-100-angular` and scripts from the 
```
# Upload vectors
python run.py --engines qdrant-all-in-ram --datasets glove-100-angular

```
After uploading vectors, we will repeat the same experiment with different RAM limits to see how they affect the memory consumption and search speed.
```
# Search vectors
python run.py --engines qdrant-all-in-ram --datasets glove-100-angular --skip-upload

```
### All in Memory
In the first experiment, we tested how well our system performs when all vectors are stored in memory. We tried using different amounts of memory, ranging from 1512mb to 1024mb, and measured the number of requests per second (rps) that our system was able to handle.
Memory | Requests/s  
---|---  
1512mb | 774.38  
1256mb | 760.63  
1200mb | 794.72  
1152mb | out of memory  
1024mb | out of memory  
We found that 1152MB memory limit resulted in our system running out of memory, but using 1512mb, 1256mb, and 1200mb of memory resulted in our system being able to handle around 780 RPS. This suggests that about 1.2GB of memory is needed to serve around 1 million vectors, and there is no speed degradation when limiting memory usage above 1.2GB.
### Vectors stored using MMAP
Let’s go a bit further! In the second experiment, we tested how well our system performs when **vectors are stored using the memory-mapped file** (mmap). Create collection with:
```
PUT /collections/benchmark
{
  "vectors": {
    ...
    "on_disk": true
  }
}

```
This configuration tells Qdrant to use mmap for vectors if the segment size is greater than 20000Kb (which is approximately 40K 128d-vectors).
Now the out-of-memory happens when we allow using **600mb** RAM only
Experiments details
Memory | Requests/s  
---|---  
1200mb | 759.94  
1100mb | 687.00  
1000mb | 10  
— use a bit faster disk —
Memory | Requests/s  
---|---  
1000mb | 25 rps  
750mb | 5 rps  
625mb | 2.5 rps  
600mb | out of memory  
At this point we have to switch from network-mounted storage to a faster disk, as the network-based storage is too slow to handle the amount of sequential reads that our system needs to serve the queries.
But let’s first see how much RAM we need to serve 1 million vectors and then we will discuss the speed optimization as well.
### Vectors and HNSW graph stored using MMAP
In the third experiment, we tested how well our system performs when vectors and [HNSW](https://qdrant.tech/articles/filtrable-hnsw/) graph are stored using the memory-mapped files. Create collection with:
```
PUT /collections/benchmark 
{
  "vectors": {
    ...
    "on_disk": true
  },
  "hnsw_config": {
    "on_disk": true
  },
  ...
}

```
With this configuration we are able to serve 1 million vectors with **only 135mb of RAM**!
Experiments details
Memory | Requests/s  
---|---  
600mb | 5 rps  
300mb | 0.9 rps / 1.1 sec per query  
150mb | 0.4 rps / 2.5 sec per query  
135mb | 0.33 rps / 3 sec per query  
125mb | out of memory  
At this point the importance of the disk speed becomes critical. We can serve the search requests with 135mb of RAM, but the speed of the requests makes it impossible to use the system in production.
Let’s see how we can improve the speed.
## How to speed up the search
To measure the impact of disk parameters on search speed, we used the `fio` tool to test the speed of different types of disks.
```
# Install fio
sudo apt-get install fio
# Run fio to check the random reads speed
fio --randrepeat=1 \
=libaio \
=1 \
=1 \
=fiotest \
=testfio \
=4k \
=64 \
=8G \
=randread

```
Initially, we tested on a network-mounted disk, but its performance was too slow, with a read IOPS of 6366 and a bandwidth of 24.9 MiB/s:
```
read: IOPS=6366, BW=24.9MiB/s (26.1MB/s)(8192MiB/329424msec)

```
To improve performance, we switched to a local disk, which showed much faster results, with a read IOPS of 63.2k and a bandwidth of 247 MiB/s:
```
read: IOPS=63.2k, BW=247MiB/s (259MB/s)(8192MiB/33207msec)

```
That gave us a significant speed boost, but we wanted to see if we could improve performance even further. To do that, we switched to a machine with a local SSD, which showed even better results, with a read IOPS of 183k and a bandwidth of 716 MiB/s:
```
read: IOPS=183k, BW=716MiB/s (751MB/s)(8192MiB/11438msec)

```
Let’s see how these results translate into search speed:
Memory | RPS with IOPS=63.2k | RPS with IOPS=183k  
---|---|---  
600mb | 5 | 50  
300mb | 0.9 | 13  
200mb | 0.5 | 8  
150mb | 0.4 | 7  
As you can see, the speed of the disk has a significant impact on the search speed. With a local SSD, we were able to increase the search speed by 10x!
With the production-grade disk, the search speed could be even higher. Some configurations of the SSDs can reach 1M IOPS and more.
Which might be an interesting option to serve large datasets with low search latency in Qdrant.
## Conclusion
In this article, we showed that Qdrant has flexibility in terms of RAM usage and can be used to serve large datasets. It provides configurable trade-offs between RAM usage and search speed. If you’re interested to learn more about Qdrant, [book a demo today](https://qdrant.tech/contact-us/)!
We are eager to learn more about how you use Qdrant in your projects, what challenges you face, and how we can help you solve them. Please feel free to join our 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/memory-consumption.md) this page on GitHub, or 
On this page:
  * [How to measure actual RAM requirements](https://qdrant.tech/articles/memory-consumption/#how-to-measure-actual-ram-requirements)
  * [Let’s run some benchmarks](https://qdrant.tech/articles/memory-consumption/#lets-run-some-benchmarks)
    * [All in Memory](https://qdrant.tech/articles/memory-consumption/#all-in-memory)
    * [Vectors stored using MMAP](https://qdrant.tech/articles/memory-consumption/#vectors-stored-using-mmap)
    * [Vectors and HNSW graph stored using MMAP](https://qdrant.tech/articles/memory-consumption/#vectors-and-hnsw-graph-stored-using-mmap)
  * [How to speed up the search](https://qdrant.tech/articles/memory-consumption/#how-to-speed-up-the-search)
  * [Conclusion](https://qdrant.tech/articles/memory-consumption/#conclusion)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/memory-consumption/)
                    ## 📄 `https-qdrant-tech-articles-modern-sparse-neural-retrieval.md`
                    ```md
                    # https://qdrant.tech/articles/modern-sparse-neural-retrieval/
  * [Articles](https://qdrant.tech/articles/)
  * Modern Sparse Neural Retrieval: From Theory to Practice
# Modern Sparse Neural Retrieval: From Theory to Practice
Evgeniya Sukhodolskaya
·
October 23, 2024
![Modern Sparse Neural Retrieval: From Theory to Practice](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/preview/title.jpg)
Finding enough time to study all the modern solutions while keeping your production running is rarely feasible. Dense retrievers, hybrid retrievers, late interaction… How do they work, and where do they fit best? If only we could compare retrievers as easily as products on Amazon!
We explored the most popular modern sparse neural retrieval models and broke them down for you. By the end of this article, you’ll have a clear understanding of the current landscape in sparse neural retrieval and how to navigate through complex, math-heavy research papers with sky-high NDCG scores without getting overwhelmed.
[The first part](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#sparse-neural-retrieval-evolution) of this article is theoretical, comparing different approaches used in modern sparse neural retrieval.  
[The second part](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#splade-in-qdrant) is more practical, showing how the best model in modern sparse neural retrieval, `SPLADE++`, can be used in Qdrant and recommendations on when to choose sparse neural retrieval for your solutions.
## Sparse Neural Retrieval: As If Keyword-Based Retrievers Understood Meaning
**Keyword-based (lexical) retrievers** like BM25 provide a good explainability. If a document matches a query, it’s easy to understand why: query terms are present in the document, and if these are rare terms, they are more important for retrieval.
![Keyword-based \(Lexical\) Retrieval](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/LexicalRetrievers.png)
With their mechanism of exact term matching, they are super fast at retrieval. A simple **inverted index** , which maps back from a term to a list of documents where this term occurs, saves time on checking millions of documents.
![Inverted Index](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/InvertedIndex.png)
Lexical retrievers are still a strong baseline in retrieval tasks. However, by design, they’re unable to bridge **vocabulary** and **semantic mismatch** gaps. Imagine searching for a “ _tasty cheese_ ” in an online store and not having a chance to get “ _Gouda_ ” or “ _Brie_ ” in your shopping basket.
**Dense retrievers** , based on machine learning models which encode documents and queries in dense vector representations, are capable of breaching this gap and finding you “ _a piece of Gouda_ ”.
![Dense Retrieval](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/DenseRetrievers.png)
However, explainability here suffers: why is this query representation close to this document representation? Why, searching for “ _cheese_ ”, we’re also offered “ _mouse traps_ ”? What does each number in this vector representation mean? Which one of them is capturing the cheesiness?
Without a solid understanding, balancing result quality and resource consumption becomes challenging. Since, hypothetically, any document could match a query, relying on an inverted index with exact matching isn’t feasible. This doesn’t mean dense retrievers are inherently slower. However, lexical retrieval has been around long enough to inspire several effective architectural choices, which are often worth reusing.
Sooner or later, there should have been somebody who would say, “ _Wait, but what if I want something timeproof like BM25 but with semantic understanding?_ ”
## Sparse Neural Retrieval Evolution
Imagine searching for a “ _flabbergasting murder_ ” story. ” _Flabbergasting_ ” is a rarely used word, so a keyword-based retriever, for example, BM25, will assign huge importance to it. Consequently, there is a high chance that a text unrelated to any crimes but mentioning something “ _flabbergasting_ ” will pop up in the top results.
What if we could instead of relying on term frequency in a document as a proxy of term’s importance as it happens in BM25, directly predict a term’s importance? The goal is for rare but non-impactful terms to be assigned a much smaller weight than important terms with the same frequency, while both would be equally treated in the BM25 scenario.
How can we determine if one term is more important than another? Word impact is related to its meaning, and its meaning can be derived from its context (words which surround this particular word). That’s how dense contextual embedding models come into the picture.
All the sparse retrievers are based on the idea of taking a model which produces contextual dense vector representations for terms and teaching it to produce sparse ones. Very often, 
### The Pioneer Of Sparse Neural Retrieval
![Deep Contextualized Term Weighting \(DeepCT\)](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/DeepCT.png) The authors of one of the first sparse retrievers, the 
When documents are uploaded into a database, the importance of words in a document is predicted by a trained linear regression model and stored in the inverted index in the same way as term frequencies in BM25 retrievers. Then, the retrieval process is identical to the BM25 one.
_**Why is DeepCT not a perfect solution?**_ To train linear regression, the authors needed to provide the true value (**ground truth**) of each word’s importance so the model could “see” what the right answer should be. This score is hard to define in a way that it truly expresses the query-document relevancy. Which score should have the most relevant word to a query when this word is taken from a five-page document? The second relevant? The third?
### Sparse Neural Retrieval on Relevance Objective
![DeepImpact](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/DeepImpact.png) It’s much easier to define whether a document as a whole is relevant or irrelevant to a query. That’s why the 
_**Why is DeepImpact not a perfect solution?**_ When converting texts into dense vector representations, the BERT model does not work on a word level. Sometimes, it breaks the words into parts. For example, the word “ _vector_ ” will be processed by BERT as one piece, but for some words that, for example, BERT hasn’t seen before, it is going to cut the word in pieces 
The DeepImpact model (like the DeepCT model) takes the first piece BERT produces for a word and discards the rest. However, what can one find searching for “ _Q_ ” instead of “ _Qdrant_ ”?
### Know Thine Tokenization
![Term Independent Likelihood MoDEl v2 \(TILDE v2\)](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/TILDEv2.png) To solve the problems of DeepImpact’s architecture, the 
_**Why is TILDEv2 not a perfect solution?**_ A single scalar importance score value might not be enough to capture all distinct meanings of a word. **Homonyms** (pizza, cocktail, flower, and female name “ _Margherita_ ”) are one of the troublemakers in information retrieval.
### Sparse Neural Retriever Which Understood Homonyms
![COntextualized Inverted List \(COIL\)](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/COIL.png)
If one value for the term importance score is insufficient, we could describe the term’s importance in a vector form! Authors of the 
For each vector representing a query token, COIL finds the closest match (using the maximum dot product) vector of the same token in a document. So, for example, if we are searching for “ _Revolut bank <finance institution>_” and a document in a database has the sentence “ _Vivid bank <finance institution> was moved to the bank of Amstel <river>_”, out of two “banks”, the first one will have a bigger value of a dot product with a “ _bank_ ” in the query, and it will count towards the final score. The final relevancy score of a document is a sum of scores of query terms matched.
_**Why is COIL not a perfect solution?**_ This way of defining the importance score captures deeper semantics; more meaning comes with more values used to describe it. However, storing 32-dimensional vectors for every term is far more expensive, and an inverted index does not work as-is with this architecture.
### Back to the Roots
![Universal COntextualized Inverted List \(UniCOIL\)](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/UNICOIL.png)   
It optimizes resources consumption but the deep semantics understanding tied to COIL architecture is again lost.
## Did we Solve the Vocabulary Mismatch Yet?
With the retrieval based on the exact matching, however sophisticated the methods to predict term importance are, we can’t match relevant documents which have no query terms in them. If you’re searching for “ _pizza_ ” in a book of recipes, you won’t find “ _Margherita_ ”.
A way to solve this problem is through the so-called **document expansion**. Let’s append words which could be in a potential query searching for this document. So, the “ _Margherita_ ” document becomes “ _Margherita pizza_ ”. Now, exact matching on “ _pizza_ ” will work!
![Document Expansion](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/DocumentExpansion.png)
There are two types of document expansion that are used in sparse neural retrieval: **external** (one model is responsible for expansion, another one for retrieval) and **internal** (all is done by a single model).
### External Document Expansion
External document expansion uses a **generative model** (Mistral 7B, Chat-GPT, and Claude are all generative models, generating words based on the input text) to compose additions to documents before converting them to sparse representations and applying exact matching methods.
#### External Document Expansion with docT5query
![External Document Expansion with docT5query](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/docT5queryDocumentExpansion.png)
The problem with docT5query expansion is a very long inference time, as with any generative model: it can generate only one token per run, and it spends a fair share of resources on it.
#### External Document Expansion with Term Independent Likelihood MODel (TILDE)
![External Document Expansion with Term Independent Likelihood MODel \(TILDE\)](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/TILDEDocumentExpansion.png)
Instead of predicting queries, TILDE predicts the most likely terms to see next after reading a passage’s text (**query likelihood paradigm**). TILDE takes the probability distribution of all tokens in a BERT vocabulary based on the document’s text and appends top-k of them to the document without repetitions.
_**Problems of external document expansion:**_ External document expansion might not be feasible in many production scenarios where there’s not enough time or compute to expand each and every document you want to store in a database and then additionally do all the calculations needed for retrievers. To solve this problem, a generation of models was developed which do everything in one go, expanding documents “internally”.
### Internal Document Expansion
Let’s assume we don’t care about the context of query terms, so we can treat them as independent words that we combine in random order to get the result. Then, for each contextualized term in a document, we are free to pre-compute how this term affects every word in our vocabulary.
For each document, a vector of the vocabulary length is created. To fill this vector in, for each word in the vocabulary, it is checked if the influence of any document term on it is big enough to consider it. Otherwise, the vocabulary word’s score in a document vector will be zero. For example, by pre-computing vectors for the document “ _pizza Margherita_ ” on a vocabulary of 50,000 most used English words, for this small document of two words, we will get a 50,000-dimensional vector of zeros, where non-zero values will be for a “ _pizza_ ”, “ _pizzeria_ ”, “ _flower_ ”, “ _woman_ ”, “ _girl_ ”, “ _Margherita_ ”, “ _cocktail_ ” and “ _pizzaiolo_ ”.
### Sparse Neural Retriever with Internal Document Expansion
![Sparse Transformer Matching \(SPARTA\)](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/SPARTA.png)
The authors of the 
_**Why is SPARTA not a perfect solution?**_ Trained on the MS MARCO dataset, many sparse neural retrievers, including SPARTA, show good results on MS MARCO test data, but when it comes to generalisation (working with other data), they 
### State-of-the-Art of Modern Sparse Neural Retrieval
![Sparse Lexical and Expansion Model Plus Plus, \(SPLADE++\)](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/SPLADE++.png) The authors of the 
  * The SPARTA model is not sparse enough by construction, so authors of the SPLADE family of models introduced explicit **sparsity regularisation** , preventing the model from producing too many non-zero values.
  * The SPARTA model mostly uses the BERT model as-is, without any additional neural network to capture the specifity of Information Retrieval problem, so SPLADE models introduce a trainable neural network on top of BERT with a specific architecture choice to make it perfectly fit the task.
  * SPLADE family of models, finally, uses **knowledge distillation** , which is learning from a bigger (and therefore much slower, not-so-fit for production tasks) model how to predict good representations.
One of the last versions of the SPLADE family of models is   
SPLADE++, opposed to SPARTA model, expands not only documents but also queries at inference time. We’ll demonstrate this in the next section.
## SPLADE++ in Qdrant
In Qdrant, you can use [FastEmbed](https://qdrant.tech/documentation/fastembed/).
#### Setup
Install `FastEmbed`.
```
pip install fastembed

```
Import sparse text embedding models supported in FastEmbed.
```
from fastembed import SparseTextEmbedding

```
You can list all sparse text embedding models currently supported.
```
SparseTextEmbedding.list_supported_models()

```
Output with a list of supported models
```
[{'model': 'prithivida/Splade_PP_en_v1',
  'vocab_size': 30522,
  'description': 'Independent Implementation of SPLADE++ Model for English',
  'size_in_GB': 0.532,
  'sources': {'hf': 'Qdrant/SPLADE_PP_en_v1'},
  'model_file': 'model.onnx'},
 {'model': 'prithvida/Splade_PP_en_v1',
  'vocab_size': 30522,
  'description': 'Independent Implementation of SPLADE++ Model for English',
  'size_in_GB': 0.532,
  'sources': {'hf': 'Qdrant/SPLADE_PP_en_v1'},
  'model_file': 'model.onnx'},
 {'model': 'Qdrant/bm42-all-minilm-l6-v2-attentions',
  'vocab_size': 30522,
  'description': 'Light sparse embedding model, which assigns an importance score to each token in the text',
  'size_in_GB': 0.09,
  'sources': {'hf': 'Qdrant/all_miniLM_L6_v2_with_attentions'},
  'model_file': 'model.onnx',
  'additional_files': ['stopwords.txt'],
  'requires_idf': True},
 {'model': 'Qdrant/bm25',
  'description': 'BM25 as sparse embeddings meant to be used with Qdrant',
  'size_in_GB': 0.01,
  'sources': {'hf': 'Qdrant/bm25'},
  'model_file': 'mock.file',
  'additional_files': ['arabic.txt',
   'azerbaijani.txt',
   'basque.txt',
   'bengali.txt',
   'catalan.txt',
   'chinese.txt',
   'danish.txt',
   'dutch.txt',
   'english.txt',
   'finnish.txt',
   'french.txt',
   'german.txt',
   'greek.txt',
   'hebrew.txt',
   'hinglish.txt',
   'hungarian.txt',
   'indonesian.txt',
   'italian.txt',
   'kazakh.txt',
   'nepali.txt',
   'norwegian.txt',
   'portuguese.txt',
   'romanian.txt',
   'russian.txt',
   'slovene.txt',
   'spanish.txt',
   'swedish.txt',
   'tajik.txt',
   'turkish.txt'],
  'requires_idf': True}]

```
Load SPLADE++.
```
sparse_model_name = "prithivida/Splade_PP_en_v1"
sparse_model = SparseTextEmbedding(model_name=sparse_model_name)

```
The model files will be fetched and downloaded, with progress showing.
#### Embed data
We will use a toy movie description dataset.
Movie description dataset
```
descriptions = ["In 1431, Jeanne d'Arc is placed on trial on charges of heresy. The ecclesiastical jurists attempt to force Jeanne to recant her claims of holy visions.",
 "A film projectionist longs to be a detective, and puts his meagre skills to work when he is framed by a rival for stealing his girlfriend's father's pocketwatch.",
 "A group of high-end professional thieves start to feel the heat from the LAPD when they unknowingly leave a clue at their latest heist.",
 "A petty thief with an utter resemblance to a samurai warlord is hired as the lord's double. When the warlord later dies the thief is forced to take up arms in his place.",
 "A young boy named Kubo must locate a magical suit of armour worn by his late father in order to defeat a vengeful spirit from the past.",
 "A biopic detailing the 2 decades that Punjabi Sikh revolutionary Udham Singh spent planning the assassination of the man responsible for the Jallianwala Bagh massacre.",
 "When a machine that allows therapists to enter their patients' dreams is stolen, all hell breaks loose. Only a young female therapist, Paprika, can stop it.",
 "An ordinary word processor has the worst night of his life after he agrees to visit a girl in Soho whom he met that evening at a coffee shop.",
 "A story that revolves around drug abuse in the affluent north Indian State of Punjab and how the youth there have succumbed to it en-masse resulting in a socio-economic decline.",
 "A world-weary political journalist picks up the story of a woman's search for her son, who was taken away from her decades ago after she became pregnant and was forced to live in a convent.",
 "Concurrent theatrical ending of the TV series Neon Genesis Evangelion (1995).",
 "During World War II, a rebellious U.S. Army Major is assigned a dozen convicted murderers to train and lead them into a mass assassination mission of German officers.",
 "The toys are mistakenly delivered to a day-care center instead of the attic right before Andy leaves for college, and it's up to Woody to convince the other toys that they weren't abandoned and to return home.",
 "A soldier fighting aliens gets to relive the same day over and over again, the day restarting every time he dies.",
 "After two male musicians witness a mob hit, they flee the state in an all-female band disguised as women, but further complications set in.",
 "Exiled into the dangerous forest by her wicked stepmother, a princess is rescued by seven dwarf miners who make her part of their household.",
 "A renegade reporter trailing a young runaway heiress for a big story joins her on a bus heading from Florida to New York, and they end up stuck with each other when the bus leaves them behind at one of the stops.",
 "Story of 40-man Turkish task force who must defend a relay station.",
 "Spinal Tap, one of England's loudest bands, is chronicled by film director Marty DiBergi on what proves to be a fateful tour.",
 "Oskar, an overlooked and bullied boy, finds love and revenge through Eli, a beautiful but peculiar girl."]

```
Embed movie descriptions with SPLADE++.
```
sparse_descriptions = list(sparse_model.embed(descriptions))

```
You can check how a sparse vector generated by SPLADE++ looks in Qdrant.
```
sparse_descriptions[0]

```
It is stored as **indices** of BERT tokens, weights of which are non-zero, and **values** of these weights.
```
SparseEmbedding(
  values=array([1.57449973, 0.90787691, ..., 1.21796167, 1.1321187]),
  indices=array([ 1040,  2001, ..., 28667, 29137])
)

```
#### Upload Embeddings to Qdrant
Install `qdrant-client`
```
pip install qdrant-client

```
Qdrant Client has a simple in-memory mode that allows you to experiment locally on small data volumes. Alternatively, you could use for experiments [a free tier cluster](https://qdrant.tech/documentation/cloud/create-cluster/#create-a-cluster) in Qdrant Cloud.
```
from qdrant_client import QdrantClient, models
qdrant_client = QdrantClient(":memory:") # Qdrant is running from RAM.

```
Now, let’s create a [collection](https://qdrant.tech/documentation/concepts/collections/) in which could upload our sparse SPLADE++ embeddings.  
For that, we will use the [sparse vectors](https://qdrant.tech/documentation/concepts/vectors/#sparse-vectors) representation supported in Qdrant.
```
qdrant_client.create_collection(
    collection_name="movies",
    vectors_config={},
    sparse_vectors_config={
        "film_description": models.SparseVectorParams(),
    },
)

```
To make this collection human-readable, let’s save movie metadata (name, description and movie’s length) together with an embeddings.
Movie metadata
```
metadata = [{"movie_name": "The Passion of Joan of Arc", "movie_watch_time_min": 114, "movie_description": "In 1431, Jeanne d'Arc is placed on trial on charges of heresy. The ecclesiastical jurists attempt to force Jeanne to recant her claims of holy visions."},
{"movie_name": "Sherlock Jr.", "movie_watch_time_min": 45, "movie_description": "A film projectionist longs to be a detective, and puts his meagre skills to work when he is framed by a rival for stealing his girlfriend's father's pocketwatch."},
{"movie_name": "Heat", "movie_watch_time_min": 170, "movie_description": "A group of high-end professional thieves start to feel the heat from the LAPD when they unknowingly leave a clue at their latest heist."},
{"movie_name": "Kagemusha", "movie_watch_time_min": 162, "movie_description": "A petty thief with an utter resemblance to a samurai warlord is hired as the lord's double. When the warlord later dies the thief is forced to take up arms in his place."},
{"movie_name": "Kubo and the Two Strings", "movie_watch_time_min": 101, "movie_description": "A young boy named Kubo must locate a magical suit of armour worn by his late father in order to defeat a vengeful spirit from the past."},
{"movie_name": "Sardar Udham", "movie_watch_time_min": 164, "movie_description": "A biopic detailing the 2 decades that Punjabi Sikh revolutionary Udham Singh spent planning the assassination of the man responsible for the Jallianwala Bagh massacre."},
{"movie_name": "Paprika", "movie_watch_time_min": 90, "movie_description": "When a machine that allows therapists to enter their patients' dreams is stolen, all hell breaks loose. Only a young female therapist, Paprika, can stop it."},
{"movie_name": "After Hours", "movie_watch_time_min": 97, "movie_description": "An ordinary word processor has the worst night of his life after he agrees to visit a girl in Soho whom he met that evening at a coffee shop."},
{"movie_name": "Udta Punjab", "movie_watch_time_min": 148, "movie_description": "A story that revolves around drug abuse in the affluent north Indian State of Punjab and how the youth there have succumbed to it en-masse resulting in a socio-economic decline."},
{"movie_name": "Philomena", "movie_watch_time_min": 98, "movie_description": "A world-weary political journalist picks up the story of a woman's search for her son, who was taken away from her decades ago after she became pregnant and was forced to live in a convent."},
{"movie_name": "Neon Genesis Evangelion: The End of Evangelion", "movie_watch_time_min": 87, "movie_description": "Concurrent theatrical ending of the TV series Neon Genesis Evangelion (1995)."},
{"movie_name": "The Dirty Dozen", "movie_watch_time_min": 150, "movie_description": "During World War II, a rebellious U.S. Army Major is assigned a dozen convicted murderers to train and lead them into a mass assassination mission of German officers."},
{"movie_name": "Toy Story 3", "movie_watch_time_min": 103, "movie_description": "The toys are mistakenly delivered to a day-care center instead of the attic right before Andy leaves for college, and it's up to Woody to convince the other toys that they weren't abandoned and to return home."},
{"movie_name": "Edge of Tomorrow", "movie_watch_time_min": 113, "movie_description": "A soldier fighting aliens gets to relive the same day over and over again, the day restarting every time he dies."},
{"movie_name": "Some Like It Hot", "movie_watch_time_min": 121, "movie_description": "After two male musicians witness a mob hit, they flee the state in an all-female band disguised as women, but further complications set in."},
{"movie_name": "Snow White and the Seven Dwarfs", "movie_watch_time_min": 83, "movie_description": "Exiled into the dangerous forest by her wicked stepmother, a princess is rescued by seven dwarf miners who make her part of their household."},
{"movie_name": "It Happened One Night", "movie_watch_time_min": 105, "movie_description": "A renegade reporter trailing a young runaway heiress for a big story joins her on a bus heading from Florida to New York, and they end up stuck with each other when the bus leaves them behind at one of the stops."},
{"movie_name": "Nefes: Vatan Sagolsun", "movie_watch_time_min": 128, "movie_description": "Story of 40-man Turkish task force who must defend a relay station."},
{"movie_name": "This Is Spinal Tap", "movie_watch_time_min": 82, "movie_description": "Spinal Tap, one of England's loudest bands, is chronicled by film director Marty DiBergi on what proves to be a fateful tour."},
{"movie_name": "Let the Right One In", "movie_watch_time_min": 114, "movie_description": "Oskar, an overlooked and bullied boy, finds love and revenge through Eli, a beautiful but peculiar girl."}]

```
Upload embedded descriptions with movie metadata into the collection.
```
qdrant_client.upsert(
    collection_name="movies",
    points=[
        models.PointStruct(
            id=idx,
            payload=metadata[idx],
            vector={
                "film_description": models.SparseVector(
                    indices=vector.indices,
                    values=vector.values
                )
            },
        )
        for idx, vector in enumerate(sparse_descriptions)
    ],
)

```
#### Querying
Let’s query our collection!
```
query_embedding = list(sparse_model.embed("A movie about music"))[0]
response = qdrant_client.query_points(
    collection_name="movies",
    query=models.SparseVector(indices=query_embedding.indices, values=query_embedding.values),
    using="film_description",
    limit=1,
    with_vectors=True,
    with_payload=True
)
print(response)

```
Output looks like this:
```
points=[ScoredPoint(
  id=18, 
  version=0, 
  score=9.6779785, 
  payload={
    'movie_name': 'This Is Spinal Tap', 
    'movie_watch_time_min': 82, 
    'movie_description': "Spinal Tap, one of England's loudest bands, 
    is chronicled by film director Marty DiBergi on what proves to be a fateful tour."
  }, 
  vector={
    'film_description': SparseVector(
      indices=[1010, 2001, ..., 25316, 25517], 
      values=[0.49717945, 0.19760133, ..., 1.2124698, 0.58689135])
  }, 
  shard_key=None, 
  order_value=None
)]

```
As you can see, there are no overlapping words in the query and a description of a found movie, even though the answer fits the query, and yet we’re working with **exact matching**.  
This is possible due to the **internal expansion** of the query and the document that SPLADE++ does.
#### Internal Expansion by SPLADE++
Let’s check how did SPLADE++ expand the query and the document we got as an answer.  
For that, we will need to use the HuggingFace library called **indices** of words in a vocabulary SPLADE++ uses.
Firstly we will need to install this library.
```
pip install tokenizers

```
Then, let’s write a function which will decode SPLADE++ sparse embeddings and return words SPLADE++ uses for encoding the input.  
We would like to return them in the descending order based on the weight (**impact score**), SPLADE++ assigned them.
```
from tokenizers import Tokenizer
tokenizer = Tokenizer.from_pretrained('Qdrant/SPLADE_PP_en_v1')
def get_tokens_and_weights(sparse_embedding, tokenizer):
    token_weight_dict = {}
    for i in range(len(sparse_embedding.indices)):
        token = tokenizer.decode([sparse_embedding.indices[i]])
        weight = sparse_embedding.values[i]
        token_weight_dict[token] = weight
    # Sort the dictionary by weights
    token_weight_dict = dict(sorted(token_weight_dict.items(), key=lambda item: item[1], reverse=True))
    return token_weight_dict

```
Firstly, we apply our function to the query.
```
query_embedding = list(sparse_model.embed("A movie about music"))[0]
print(get_tokens_and_weights(query_embedding, tokenizer))

```
That’s how SPLADE++ expanded the query:
```
{
    "music": 2.764289617538452,
    "movie": 2.674748420715332,
    "film": 2.3489091396331787,
    "musical": 2.276120901107788,
    "about": 2.124547004699707,
    "movies": 1.3825485706329346,
    "song": 1.2893378734588623,
    "genre": 0.9066758751869202,
    "songs": 0.8926399946212769,
    "a": 0.8900706768035889,
    "musicians": 0.5638002157211304,
    "sound": 0.49310919642448425,
    "musician": 0.46415239572525024,
    "drama": 0.462990403175354,
    "tv": 0.4398191571235657,
    "book": 0.38950803875923157,
    "documentary": 0.3758136034011841,
    "hollywood": 0.29099565744400024,
    "story": 0.2697228491306305,
    "nature": 0.25306591391563416,
    "concerning": 0.205053448677063,
    "game": 0.1546829640865326,
    "rock": 0.11775632947683334,
    "definition": 0.08842901140451431,
    "love": 0.08636035025119781,
    "soundtrack": 0.06807517260313034,
    "religion": 0.053535860031843185,
    "filmed": 0.025964470580220222,
    "sounds": 0.0004048719711136073
}

```
Then, we apply our function to the answer.
```
query_embedding = list(sparse_model.embed("A movie about music"))[0]
response = qdrant_client.query_points(
    collection_name="movies",
    query=models.SparseVector(indices=query_embedding.indices, values=query_embedding.values),
    using="film_description",
    limit=1,
    with_vectors=True,
    with_payload=True
)
print(get_tokens_and_weights(response.points[0].vector['film_description'], tokenizer))

```
And that’s how SPLADE++ expanded the answer.
```
{'spinal': 2.6548674, 'tap': 2.534881, 'marty': 2.223297, '##berg': 2.0402722, 
'##ful': 2.0030282, 'fate': 1.935915, 'loud': 1.8381964, 'spine': 1.7507898, 
'di': 1.6161551, 'bands': 1.5897619, 'band': 1.589473, 'uk': 1.5385966, 'tour': 1.4758654, 
'chronicle': 1.4577943, 'director': 1.4423795, 'england': 1.4301306, '##est': 1.3025658, 
'taps': 1.2124698, 'film': 1.1069428, '##berger': 1.1044296, 'tapping': 1.0424755, 'best': 1.0327196, 
'louder': 0.9229055, 'music': 0.9056678, 'directors': 0.8887502, 'movie': 0.870712, 'directing': 0.8396196, 
'sound': 0.83609974, 'genre': 0.803052, 'dave': 0.80212915, 'wrote': 0.7849579, 'hottest': 0.7594193, 'filmed': 0.750105, 
'english': 0.72807616, 'who': 0.69502294, 'tours': 0.6833075, 'club': 0.6375339, 'vertebrae': 0.58689135, 'chronicles': 0.57296354, 
'dance': 0.57278687, 'song': 0.50987065, ',': 0.49717945, 'british': 0.4971719, 'writer': 0.495709, 'directed': 0.4875775, 
'cork': 0.475757, '##i': 0.47122696, '##band': 0.46837863, 'most': 0.44112885, '##liest': 0.44084555, 'destiny': 0.4264851, 
'prove': 0.41789067, 'is': 0.40306947, 'famous': 0.40230379, 'hop': 0.3897451, 'noise': 0.38770816, '##iest': 0.3737782, 
'comedy': 0.36903998, 'sport': 0.35883865, 'quiet': 0.3552795, 'detail': 0.3397654, 'fastest': 0.30345848, 'filmmaker': 0.3013101, 
'festival': 0.28146765, '##st': 0.28040633, 'tram': 0.27373192, 'well': 0.2599603, 'documentary': 0.24368097, 'beat': 0.22953634, 
'direction': 0.22925079, 'hardest': 0.22293334, 'strongest': 0.2018861, 'was': 0.19760133, 'oldest': 0.19532987, 
'byron': 0.19360808, 'worst': 0.18397793, 'touring': 0.17598206, 'rock': 0.17319143, 'clubs': 0.16090117, 
'popular': 0.15969758, 'toured': 0.15917331, 'trick': 0.1530599, 'celebrity': 0.14458777, 'musical': 0.13888633, 
'filming': 0.1363699, 'culture': 0.13616633, 'groups': 0.1340591, 'ski': 0.13049376, 'venue': 0.12992987, 
'style': 0.12853126, 'history': 0.12696269, 'massage': 0.11969914, 'theatre': 0.11673525, 'sounds': 0.108338095, 
'visit': 0.10516077, 'editing': 0.078659914, 'death': 0.066746496, 'massachusetts': 0.055702563, 'stuart': 0.0447934, 
'romantic': 0.041140396, 'pamela': 0.03561337, 'what': 0.016409796, 'smallest': 0.010815808, 'orchestra': 0.0020691194}

```
Due to the expansion both the query and the document overlap in “ _music_ ”, “ _film_ ”, “ _sounds_ ”, and others, so **exact matching** works.
## Key Takeaways: When to Choose Sparse Neural Models for Retrieval
Sparse Neural Retrieval makes sense:
  * In areas where keyword matching is crucial but BM25 is insufficient for initial retrieval, semantic matching (e.g., synonyms, homonyms) adds significant value. This is especially true in fields such as medicine, academia, law, and e-commerce, where brand names and serial numbers play a critical role. Dense retrievers tend to return many false positives, while sparse neural retrieval helps narrow down these false positives.
  * Sparse neural retrieval can be a valuable option for scaling, especially when working with large datasets. It leverages exact matching using an inverted index, which can be fast depending on the nature of your data.
  * If you’re using traditional retrieval systems, sparse neural retrieval is compatible with them and helps bridge the semantic gap.
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/modern-sparse-neural-retrieval.md) this page on GitHub, or 
On this page:
  * [Sparse Neural Retrieval: As If Keyword-Based Retrievers Understood Meaning](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#sparse-neural-retrieval-as-if-keyword-based-retrievers-understood-meaning)
  * [Sparse Neural Retrieval Evolution](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#sparse-neural-retrieval-evolution)
    * [The Pioneer Of Sparse Neural Retrieval](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#the-pioneer-of-sparse-neural-retrieval)
    * [Sparse Neural Retrieval on Relevance Objective](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#sparse-neural-retrieval-on-relevance-objective)
    * [Know Thine Tokenization](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#know-thine-tokenization)
    * [Sparse Neural Retriever Which Understood Homonyms](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#sparse-neural-retriever-which-understood-homonyms)
    * [Back to the Roots](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#back-to-the-roots)
  * [Did we Solve the Vocabulary Mismatch Yet?](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#did-we-solve-the-vocabulary-mismatch-yet)
    * [External Document Expansion](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#external-document-expansion)
    * [Internal Document Expansion](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#internal-document-expansion)
    * [Sparse Neural Retriever with Internal Document Expansion](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#sparse-neural-retriever-with-internal-document-expansion)
    * [State-of-the-Art of Modern Sparse Neural Retrieval](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#state-of-the-art-of-modern-sparse-neural-retrieval)
  * [SPLADE++ in Qdrant](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#splade-in-qdrant)
  * [Key Takeaways: When to Choose Sparse Neural Models for Retrieval](https://qdrant.tech/articles/modern-sparse-neural-retrieval/#key-takeaways-when-to-choose-sparse-neural-models-for-retrieval)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/modern-sparse-neural-retrieval/)
                    ## 📄 `https-qdrant-tech-articles-multitenancy.md`
                    ```md
                    # https://qdrant.tech/articles/multitenancy/
  * [Articles](https://qdrant.tech/articles/)
  * How to Implement Multitenancy and Custom Sharding in Qdrant
# How to Implement Multitenancy and Custom Sharding in Qdrant
David Myriel
·
February 06, 2024
![How to Implement Multitenancy and Custom Sharding in Qdrant](https://qdrant.tech/articles_data/multitenancy/preview/title.jpg)
# Scaling Your Machine Learning Setup: The Power of Multitenancy and Custom Sharding in Qdrant
We are seeing the topics of [multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/) and [distributed deployment](https://qdrant.tech/documentation/guides/distributed_deployment/#sharding) pop-up daily on our 
Whether you are building a bank fraud-detection system, [RAG](https://qdrant.tech/articles/what-is-rag-in-ai/) for e-commerce, or services for the federal government - you will need to leverage a multitenant architecture to scale your product. In the world of SaaS and enterprise apps, this setup is the norm. It will considerably increase your application’s performance and lower your hosting costs.
## Multitenancy & custom sharding with Qdrant
We have developed two major features just for this. **You can now scale a single Qdrant cluster and support all of your customers worldwide.** Under [multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/), each customer’s data is completely isolated and only accessible by them. At times, if this data is location-sensitive, Qdrant also gives you the option to divide your cluster by region or other criteria that further secure your customer’s access. This is called [custom sharding](https://qdrant.tech/documentation/guides/distributed_deployment/#user-defined-sharding).
Combining these two will result in an efficiently-partitioned architecture that further leverages the convenience of a single Qdrant cluster. This article will briefly explain the benefits and show how you can get started using both features.
## One collection, many tenants
When working with Qdrant, you can upsert all your data to a single collection, and then partition each vector via its payload. This means that all your users are leveraging the power of a single Qdrant cluster, but their data is still isolated within the collection. Let’s take a look at a two-tenant collection:
**Figure 1:** Each individual vector is assigned a specific payload that denotes which tenant it belongs to. This is how a large number of different tenants can share a single Qdrant collection. ![Qdrant Multitenancy](https://qdrant.tech/articles_data/multitenancy/multitenancy-single.png)
Qdrant is built to excel in a single collection with a vast number of tenants. You should only create multiple collections when your data is not homogenous or if users’ vectors are created by different embedding models. Creating too many collections may result in resource overhead and cause dependencies. This can increase costs and affect overall performance.
## Sharding your database
With Qdrant, you can also specify a shard for each vector individually. This feature is useful if you want to [control where your data is kept in the cluster](https://qdrant.tech/documentation/guides/distributed_deployment/#sharding). For example, one set of vectors can be assigned to one shard on its own node, while another set can be on a completely different node.
During vector search, your operations will be able to hit only the subset of shards they actually need. In massive-scale deployments, **this can significantly improve the performance of operations that do not require the whole collection to be scanned**.
This works in the other direction as well. Whenever you search for something, you can specify a shard or several shards and Qdrant will know where to find them. It will avoid asking all machines in your cluster for results. This will minimize overhead and maximize performance.
### Common use cases
A clear use-case for this feature is managing a multitenant collection, where each tenant (let it be a user or organization) is assumed to be segregated, so they can have their data stored in separate shards. Sharding solves the problem of region-based data placement, whereby certain data needs to be kept within specific locations. To do this, however, you will need to [move your shards between nodes](https://qdrant.tech/documentation/guides/distributed_deployment/#moving-shards).
**Figure 2:** Users can both upsert and query shards that are relevant to them, all within the same collection. Regional sharding can help avoid cross-continental traffic. ![Qdrant Multitenancy](https://qdrant.tech/articles_data/multitenancy/shards.png)
Custom sharding also gives you precise control over other use cases. A time-based data placement means that data streams can index shards that represent latest updates. If you organize your shards by date, you can have great control over the recency of retrieved data. This is relevant for social media platforms, which greatly rely on time-sensitive data.
## Before I go any further…..how secure is my user data?
By design, Qdrant offers three levels of isolation. We initially introduced collection-based isolation, but your scaled setup has to move beyond this level. In this scenario, you will leverage payload-based isolation (from multitenancy) and resource-based isolation (from sharding). The ultimate goal is to have a single collection, where you can manipulate and customize placement of shards inside your cluster more precisely and avoid any kind of overhead. The diagram below shows the arrangement of your data within a two-tier isolation arrangement.
**Figure 3:** Users can query the collection based on two filters: the `group_id` and the individual `shard_key_selector`. This gives your data two additional levels of isolation. ![Qdrant Multitenancy](https://qdrant.tech/articles_data/multitenancy/multitenancy.png)
## Create custom shards for a single collection
When creating a collection, you will need to configure user-defined sharding. This lets you control the shard placement of your data, so that operations can hit only the subset of shards they actually need. In big clusters, this can significantly improve the performance of operations, since you won’t need to go through the entire collection to retrieve data.
```
client.create_collection(
    collection_name="{tenant_data}",
    shard_number=2,
    sharding_method=models.ShardingMethod.CUSTOM,
    # ... other collection parameters
)
client.create_shard_key("{tenant_data}", "canada")
client.create_shard_key("{tenant_data}", "germany")

```
In this example, your cluster is divided between Germany and Canada. Canadian and German law differ when it comes to international data transfer. Let’s say you are creating a RAG application that supports the healthcare industry. Your Canadian customer data will have to be clearly separated for compliance purposes from your German customer.
Even though it is part of the same collection, data from each shard is isolated from other shards and can be retrieved as such. For additional examples on shards and retrieval, consult [Distributed Deployments](https://qdrant.tech/documentation/guides/distributed_deployment/) documentation and [Qdrant Client specification](https://python-client.qdrant.tech).
## Configure a multitenant setup for users
Let’s continue and start adding data. As you upsert your vectors to your new collection, you can add a `group_id` field to each vector. If you do this, Qdrant will assign each vector to its respective group.
Additionally, each vector can now be allocated to a shard. You can specify the `shard_key_selector` for each individual vector. In this example, you are upserting data belonging to `tenant_1` to the Canadian region.
```
client.upsert(
    collection_name="{tenant_data}",
    points=[
        models.PointStruct(
            id=1,
            payload={"group_id": "tenant_1"},
            vector=[0.9, 0.1, 0.1], 
        ),
        models.PointStruct(
            id=2,
            payload={"group_id": "tenant_1"},
            vector=[0.1, 0.9, 0.1],
        ),
    ],
    shard_key_selector="canada",
)

```
Keep in mind that the data for each `group_id` is isolated. In the example below, `tenant_1` vectors are kept separate from `tenant_2`. The first tenant will be able to access their data in the Canadian portion of the cluster. However, as shown below `tenant_2 `might only be able to retrieve information hosted in Germany.
```
client.upsert(
    collection_name="{tenant_data}",
    points=[
        models.PointStruct(
            id=3,
            payload={"group_id": "tenant_2"},
            vector=[0.1, 0.1, 0.9],
        ),
    ],
    shard_key_selector="germany",
)

```
## Retrieve data via filters
The access control setup is completed as you specify the criteria for data retrieval. When searching for vectors, you need to use a `query_filter` along with `group_id` to filter vectors for each user.
```
client.search(
    collection_name="{tenant_data}",
    query_filter=models.Filter(
        must=[
            models.FieldCondition(
                key="group_id",
                match=models.MatchValue(
                    value="tenant_1",
                ),
            ),
        ]
    ),
    query_vector=[0.1, 0.1, 0.9],
    limit=10,
)

```
## Performance considerations
The speed of indexation may become a bottleneck if you are adding large amounts of data in this way, as each user’s vector will be indexed into the same collection. To avoid this bottleneck, consider _bypassing the construction of a global vector index_ for the entire collection and building it only for individual groups instead.
By adopting this strategy, Qdrant will index vectors for each user independently, significantly accelerating the process.
To implement this approach, you should:
  1. Set `payload_m` in the HNSW configuration to a non-zero value, such as 16.
  2. Set `m` in hnsw config to 0. This will disable building global index for the whole collection.
```
from qdrant_client import QdrantClient, models
client = QdrantClient("localhost", port=6333)
client.create_collection(
    collection_name="{tenant_data}",
    vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE),
    hnsw_config=models.HnswConfigDiff(
        payload_m=16,
        m=0,
    ),
)

```
  1. Create keyword payload index for `group_id` field.
```
client.create_payload_index(
    collection_name="{tenant_data}",
    field_name="group_id",
    field_schema=models.PayloadSchemaType.KEYWORD,
)

```
> Note: Keep in mind that global requests (without the `group_id` filter) will be slower since they will necessitate scanning all groups to identify the nearest neighbors.
## Explore multitenancy and custom sharding in Qdrant for scalable solutions
Qdrant is ready to support a massive-scale architecture for your machine learning project. If you want to see whether our [vector database](https://qdrant.tech/) is right for you, try the [quickstart tutorial](https://qdrant.tech/documentation/quick-start/) or read our [docs and tutorials](https://qdrant.tech/documentation/).
To spin up a free instance of Qdrant, sign up for 
Get support or share ideas in our 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/multitenancy.md) this page on GitHub, or 
On this page:
  * [Multitenancy & custom sharding with Qdrant](https://qdrant.tech/articles/multitenancy/#multitenancy--custom-sharding-with-qdrant)
  * [One collection, many tenants](https://qdrant.tech/articles/multitenancy/#one-collection-many-tenants)
  * [Sharding your database](https://qdrant.tech/articles/multitenancy/#sharding-your-database)
    * [Common use cases](https://qdrant.tech/articles/multitenancy/#common-use-cases)
  * [Before I go any further…..how secure is my user data?](https://qdrant.tech/articles/multitenancy/#before-i-go-any-furtherhow-secure-is-my-user-data)
  * [Create custom shards for a single collection](https://qdrant.tech/articles/multitenancy/#create-custom-shards-for-a-single-collection)
  * [Configure a multitenant setup for users](https://qdrant.tech/articles/multitenancy/#configure-a-multitenant-setup-for-users)
  * [Retrieve data via filters](https://qdrant.tech/articles/multitenancy/#retrieve-data-via-filters)
  * [Performance considerations](https://qdrant.tech/articles/multitenancy/#performance-considerations)
  * [Explore multitenancy and custom sharding in Qdrant for scalable solutions](https://qdrant.tech/articles/multitenancy/#explore-multitenancy-and-custom-sharding-in-qdrant-for-scalable-solutions)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/multitenancy/)
                    ## 📄 `https-qdrant-tech-articles-neural-search-tutorial.md`
                    ```md
                    # https://qdrant.tech/articles/neural-search-tutorial/
  * [Articles](https://qdrant.tech/articles/)
  * Neural Search 101: A Complete Guide and Step-by-Step Tutorial
# Neural Search 101: A Complete Guide and Step-by-Step Tutorial
Andrey Vasnetsov
·
June 10, 2021
![Neural Search 101: A Complete Guide and Step-by-Step Tutorial](https://qdrant.tech/articles_data/neural-search-tutorial/preview/title.jpg)
# Neural Search 101: A Comprehensive Guide and Step-by-Step Tutorial
Information retrieval technology is one of the main technologies that enabled the modern Internet to exist. These days, search technology is the heart of a variety of applications. From web-pages search to product recommendations. For many years, this technology didn’t get much change until neural networks came into play.
In this guide we are going to find answers to these questions:
  * What is the difference between regular and neural search?
  * What neural networks could be used for search?
  * In what tasks is neural network search useful?
  * How to build and deploy own neural search service step-by-step?
## What is neural search?
A regular full-text search, such as Google’s, consists of searching for keywords inside a document. For this reason, the algorithm can not take into account the real meaning of the query and documents. Many documents that might be of interest to the user are not found because they use different wording.
Neural search tries to solve exactly this problem - it attempts to enable searches not by keywords but by meaning. To achieve this, the search works in 2 steps. In the first step, a specially trained neural network encoder converts the query and the searched objects into a vector representation called embeddings. The encoder must be trained so that similar objects, such as texts with the same meaning or alike pictures get a close vector representation.
![Encoders and embedding space](https://gist.githubusercontent.com/generall/c229cc94be8c15095286b0c55a3f19d7/raw/e52e3f1a320cd985ebc96f48955d7f355de8876c/encoders.png)
Having this vector representation, it is easy to understand what the second step should be. To find documents similar to the query you now just need to find the nearest vectors. The most convenient way to determine the distance between two vectors is to calculate the cosine distance. The usual Euclidean distance can also be used, but it is not so efficient due to 
## Which model could be used?
It is ideal to use a model specially trained to determine the closeness of meanings. For example, models trained on Semantic Textual Similarity (STS) datasets. Current state-of-the-art models can be found on this 
However, not only specially trained models can be used. If the model is trained on a large enough dataset, its internal features can work as embeddings too. So, for instance, you can take any pre-trained on ImageNet model and cut off the last layer from it. In the penultimate layer of the neural network, as a rule, the highest-level features are formed, which, however, do not correspond to specific classes. The output of this layer can be used as an embedding.
## What tasks is neural search good for?
Neural search has the greatest advantage in areas where the query cannot be formulated precisely. Querying a table in an SQL database is not the best place for neural search.
On the contrary, if the query itself is fuzzy, or it cannot be formulated as a set of conditions - neural search can help you. If the search query is a picture, sound file or long text, neural network search is almost the only option.
If you want to build a recommendation system, the neural approach can also be useful. The user’s actions can be encoded in vector space in the same way as a picture or text. And having those vectors, it is possible to find semantically similar users and determine the next probable user actions.
## Step-by-step neural search tutorial using Qdrant
With all that said, let’s make our neural network search. As an example, I decided to make a search for startups by their description. In this demo, we will see the cases when text search works better and the cases when neural network search works better.
I will use data from 
### Step 1: Prepare data for neural search
To be able to search for our descriptions in vector space, we must get vectors first. We need to encode the descriptions into a vector representation. As the descriptions are textual data, we can use a pre-trained language model. As mentioned above, for the task of text search there is a whole set of pre-trained models specifically tuned for semantic similarity.
One of the easiest libraries to work with pre-trained language models, in my opinion, is the 
We will use a model called `all-MiniLM-L6-v2`. This model is an all-round model tuned for many use-cases. Trained on a large and diverse dataset of over 1 billion training pairs. It is optimized for low memory consumption and fast inference.
The complete code for data preparation with detailed comments can be found and run in 
### Step 2: Incorporate a Vector search engine
Now as we have a vector representation for all our records, we need to store them somewhere. In addition to storing, we may also need to add or delete a vector, save additional information with the vector. And most importantly, we need a way to search for the nearest vectors.
The vector search engine can take care of all these tasks. It provides a convenient API for searching and managing vectors. In our tutorial, we will use 
The easiest way to use Qdrant is to run a pre-built image. So make sure you have Docker installed on your system.
To start Qdrant, use the instructions on its 
Download image from 
```
docker pull qdrant/qdrant

```
And run the service inside the docker:
```
docker run -p 6333:6333 \
$(pwd)/qdrant_storage:/qdrant/storage \

```
You should see output like this
```
...
[2021-02-05T00:08:51Z INFO  actix_server::builder] Starting 12 workers
[2021-02-05T00:08:51Z INFO  actix_server::builder] Starting "actix-web-service-0.0.0.0:6333" service on 0.0.0.0:6333

```
This means that the service is successfully launched and listening port 6333. To make sure you can test 
All uploaded to Qdrant data is saved into the `./qdrant_storage` directory and will be persisted even if you recreate the container.
### Step 3: Upload data to Qdrant
Now once we have the vectors prepared and the search engine running, we can start uploading the data. To interact with Qdrant from python, I recommend using an out-of-the-box client library.
To install it, use the following command
At this point, we should have startup records in file `startups.json`, encoded vectors in file `startup_vectors.npy`, and running Qdrant on a local machine. Let’s write a script to upload all startup data and vectors into the search engine.
First, let’s create a client object for Qdrant.
```
# Import client library
from qdrant_client import QdrantClient
from qdrant_client.models import VectorParams, Distance
qdrant_client = QdrantClient(host='localhost', port=6333)

```
Qdrant allows you to combine vectors of the same purpose into collections. Many independent vector collections can exist on one service at the same time.
Let’s create a new collection for our startup vectors.
```
if not qdrant_client.collection_exists('startups'):
    qdrant_client.create_collection(
        collection_name='startups', 
        vectors_config=VectorParams(size=384, distance=Distance.COSINE),
    )

```
The `vector_size` parameter is very important. It tells the service the size of the vectors in that collection. All vectors in a collection must have the same size, otherwise, it is impossible to calculate the distance between them. `384` is the output dimensionality of the encoder we are using.
The `distance` parameter allows specifying the function used to measure the distance between two points.
The Qdrant client library defines a special function that allows you to load datasets into the service. However, since there may be too much data to fit a single computer memory, the function takes an iterator over the data as input.
Let’s create an iterator over the startup data and vectors.
```
import numpy as np
import json
fd = open('./startups.json')
# payload is now an iterator over startup data
payload = map(json.loads, fd)
# Here we load all vectors into memory, numpy array works as iterable for itself.
# Other option would be to use Mmap, if we don't want to load all data into RAM
vectors = np.load('./startup_vectors.npy')

```
And the final step - data uploading
```
qdrant_client.upload_collection(
    collection_name='startups',
    vectors=vectors,
    payload=payload,
    ids=None,  # Vector ids will be assigned automatically
    batch_size=256  # How many vectors will be uploaded in a single request?
)

```
Now we have vectors uploaded to the vector search engine. In the next step, we will learn how to actually search for the closest vectors.
The full code for this step can be found 
### Step 4: Make a search API
Now that all the preparations are complete, let’s start building a neural search class.
First, install all the requirements:
```
pip install sentence-transformers numpy

```
In order to process incoming requests neural search will need 2 things. A model to convert the query into a vector and Qdrant client, to perform a search queries.
```
# File: neural_searcher.py
from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer
class NeuralSearcher:
    def __init__(self, collection_name):
        self.collection_name = collection_name
        # Initialize encoder model
        self.model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')
        # initialize Qdrant client
        self.qdrant_client = QdrantClient(host='localhost', port=6333)

```
The search function looks as simple as possible:
```
    def search(self, text: str):
        # Convert text query into vector
        vector = self.model.encode(text).tolist()
        # Use `vector` for search for closest vectors in the collection
        search_result = self.qdrant_client.search(
            collection_name=self.collection_name,
            query_vector=vector,
            query_filter=None,  # We don't want any filters for now
            top=5  # 5 the most closest results is enough
        )
        # `search_result` contains found vector ids with similarity scores along with the stored payload
        # In this function we are interested in payload only
        payloads = [hit.payload for hit in search_result]
        return payloads

```
With Qdrant it is also feasible to add some conditions to the search. For example, if we wanted to search for startups in a certain city, the search query could look like this:
```
from qdrant_client.models import Filter
    ...
    city_of_interest = "Berlin"
    # Define a filter for cities
    city_filter = Filter(**{
        "must": [{
            "key": "city", # We store city information in a field of the same name 
            "match": { # This condition checks if payload field have requested value
                "keyword": city_of_interest
            }
        }]
    })
    search_result = self.qdrant_client.search(
        collection_name=self.collection_name,
        query_vector=vector,
        query_filter=city_filter,
        top=5
    )
    ...

```
We now have a class for making neural search queries. Let’s wrap it up into a service.
### Step 5: Deploy as a service
To build the service we will use the FastAPI framework. It is super easy to use and requires minimal code writing.
To install it, use the command
```
pip install fastapi uvicorn

```
Our service will have only one API endpoint and will look like this:
```
# File: service.py
from fastapi import FastAPI
# That is the file where NeuralSearcher is stored
from neural_searcher import NeuralSearcher
app = FastAPI()
# Create an instance of the neural searcher
neural_searcher = NeuralSearcher(collection_name='startups')
@app.get("/api/search")
def search_startup(q: str):
    return {
        "result": neural_searcher.search(text=q)
    }
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

```
Now, if you run the service with
```
python service.py

```
and open your browser at 
![FastAPI Swagger interface](https://gist.githubusercontent.com/generall/c229cc94be8c15095286b0c55a3f19d7/raw/d866e37a60036ebe65508bd736faff817a5d27e9/fastapi_neural_search.png)
Feel free to play around with it, make queries and check out the results. This concludes the tutorial.
### Experience Neural Search With Qdrant’s Free Demo
Excited to see neural search in action? Take the next step and book a 
Our demo will help you grow intuition for cases when the neural search is useful. The demo contains a switch that selects between neural and full-text searches. You can turn neural search on and off to compare the result with regular full-text search. Try to use a startup description to find similar ones.
Join our 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/neural-search-tutorial.md) this page on GitHub, or 
On this page:
  * [What is neural search?](https://qdrant.tech/articles/neural-search-tutorial/#what-is-neural-search)
  * [Which model could be used?](https://qdrant.tech/articles/neural-search-tutorial/#which-model-could-be-used)
  * [What tasks is neural search good for?](https://qdrant.tech/articles/neural-search-tutorial/#what-tasks-is-neural-search-good-for)
  * [Step-by-step neural search tutorial using Qdrant](https://qdrant.tech/articles/neural-search-tutorial/#step-by-step-neural-search-tutorial-using-qdrant)
    * [Step 1: Prepare data for neural search](https://qdrant.tech/articles/neural-search-tutorial/#step-1-prepare-data-for-neural-search)
    * [Step 2: Incorporate a Vector search engine](https://qdrant.tech/articles/neural-search-tutorial/#step-2-incorporate-a-vector-search-engine)
    * [Step 3: Upload data to Qdrant](https://qdrant.tech/articles/neural-search-tutorial/#step-3-upload-data-to-qdrant)
    * [Step 4: Make a search API](https://qdrant.tech/articles/neural-search-tutorial/#step-4-make-a-search-api)
    * [Step 5: Deploy as a service](https://qdrant.tech/articles/neural-search-tutorial/#step-5-deploy-as-a-service)
    * [Experience Neural Search With Qdrant’s Free Demo](https://qdrant.tech/articles/neural-search-tutorial/#experience-neural-search-with-qdrants-free-demo)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/neural-search-tutorial/)
                    ## 📄 `https-qdrant-tech-articles-practicle-examples.md`
                    ```md
                    # https://qdrant.tech/articles/practicle-examples/
  * [Articles](https://qdrant.tech/articles/)
  * Practical Examples
#### Practical Examples
Building blocks and reference implementations to help you get started with Qdrant. Learn how to use Qdrant to solve real-world problems and build the next generation of AI applications.
[![Preview](https://qdrant.tech/articles_data/binary-quantization-openai/preview/preview.jpg) Optimizing OpenAI Embeddings: Enhance Efficiency with Qdrant's Binary Quantization Explore how Qdrant's Binary Quantization can significantly improve the efficiency and performance of OpenAI's Ada-003 embeddings. Learn best practices for real-time search applications. Nirant Kasliwal February 21, 2024 ](https://qdrant.tech/articles/binary-quantization-openai/)[![Preview](https://qdrant.tech/articles_data/food-discovery-demo/preview/preview.jpg) Food Discovery Demo Feeling hungry? Find the perfect meal with Qdrant's multimodal semantic search. Kacper Łukawski September 05, 2023 ](https://qdrant.tech/articles/food-discovery-demo/)[![Preview](https://qdrant.tech/articles_data/search-as-you-type/preview/preview.jpg) Semantic Search As You Type To show off Qdrant's performance, we show how to do a quick search-as-you-type that will come back within a few milliseconds. Andre Bogus August 14, 2023 ](https://qdrant.tech/articles/search-as-you-type/)[![Preview](https://qdrant.tech/articles_data/serverless/preview/preview.jpg) Serverless Semantic Search Create a serverless semantic search engine using nothing but Qdrant and free cloud services. Andre Bogus July 12, 2023 ](https://qdrant.tech/articles/serverless/)[![Preview](https://qdrant.tech/articles_data/chatgpt-plugin/preview/preview.jpg) Extending ChatGPT with a Qdrant-based knowledge base ChatGPT factuality might be improved with semantic search. Here is how. Kacper Łukawski March 23, 2023 ](https://qdrant.tech/articles/chatgpt-plugin/)[![Preview](https://qdrant.tech/articles_data/langchain-integration/preview/preview.jpg) Using LangChain for Question Answering with Qdrant We combined LangChain, a pre-trained LLM from OpenAI, SentenceTransformers & Qdrant to create a question answering system with just a few lines of code. Learn more! Kacper Łukawski January 31, 2023 ](https://qdrant.tech/articles/langchain-integration/)[![Preview](https://qdrant.tech/articles_data/qa-with-cohere-and-qdrant/preview/preview.jpg) Question Answering as a Service with Cohere and Qdrant End-to-end Question Answering system for the biomedical data with SaaS tools: Cohere co.embed API and Qdrant Kacper Łukawski November 29, 2022 ](https://qdrant.tech/articles/qa-with-cohere-and-qdrant/)[![Preview](https://qdrant.tech/articles_data/faq-question-answering/preview/preview.jpg) Q&A with Similarity Learning A complete guide to building a Q&A system using Quaterion and SentenceTransformers. George Panchuk June 28, 2022 ](https://qdrant.tech/articles/faq-question-answering/)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/practicle-examples/)
                    ## 📄 `https-qdrant-tech-articles-product-quantization-clustering.md`
                    ```md
                    # https://qdrant.tech/articles/product-quantization/#clustering
  * [Articles](https://qdrant.tech/articles/)
  * Product Quantization in Vector Search | Qdrant
# Product Quantization in Vector Search | Qdrant
Kacper Łukawski
·
May 30, 2023
![Product Quantization in Vector Search | Qdrant](https://qdrant.tech/articles_data/product-quantization/preview/title.jpg)
# Product Quantization Demystified: Streamlining Efficiency in Data Management
Qdrant 1.1.0 brought the support of [Scalar Quantization](https://qdrant.tech/articles/scalar-quantization/), a technique of reducing the memory footprint by even four times, by using `int8` to represent the values that would be normally represented by `float32`.
The memory usage in [vector search](https://qdrant.tech/solutions/) might be reduced even further! Please welcome **Product Quantization** , a brand-new feature of Qdrant 1.2.0!
## What is Product Quantization?
Product Quantization converts floating-point numbers into integers like every other quantization method. However, the process is slightly more complicated than [Scalar Quantization](https://qdrant.tech/articles/scalar-quantization/) and is more customizable, so you can find the sweet spot between memory usage and search precision. This article covers all the steps required to perform Product Quantization and the way it’s implemented in Qdrant.
## How Does Product Quantization Work?
Let’s assume we have a few vectors being added to the collection and that our optimizer decided to start creating a new segment.
![A list of raw vectors](https://qdrant.tech/articles_data/product-quantization/raw-vectors.png)
### Cutting the vector into pieces
First of all, our vectors are going to be divided into **chunks** aka **subvectors**. The number of chunks is configurable, but as a rule of thumb - the lower it is, the higher the compression rate. That also comes with reduced search precision, but in some cases, you may prefer to keep the memory usage as low as possible.
![A list of chunked vectors](https://qdrant.tech/articles_data/product-quantization/chunked-vectors.png)
Qdrant API allows choosing the compression ratio from 4x up to 64x. In our example, we selected 16x, so each subvector will consist of 4 floats (16 bytes), and it will eventually be represented by a single byte.
### Clustering
The chunks of our vectors are then used as input for clustering. Qdrant uses the K-means algorithm, with K=256. It was selected a priori, as this is the maximum number of values a single byte represents. As a result, we receive a list of 256 centroids for each chunk and assign each of them a unique id. **The clustering is done separately for each group of chunks.**
![Clustered chunks of vectors](https://qdrant.tech/articles_data/product-quantization/chunks-clustering.png)
Each chunk of a vector might now be mapped to the closest centroid. That’s where we lose the precision, as a single point will only represent a whole subspace. Instead of using a subvector, we can store the id of the closest centroid. If we repeat that for each chunk, we can approximate the original embedding as a vector of subsequent ids of the centroids. The dimensionality of the created vector is equal to the number of chunks, in our case 2.
![A new vector built from the ids of the centroids](https://qdrant.tech/articles_data/product-quantization/vector-of-ids.png)
### Full process
All those steps build the following pipeline of Product Quantization:
![Full process of Product Quantization](https://qdrant.tech/articles_data/product-quantization/full-process.png)
## Measuring the distance
Vector search relies on the distances between the points. Enabling Product Quantization slightly changes the way it has to be calculated. The query vector is divided into chunks, and then we figure the overall distance as a sum of distances between the subvectors and the centroids assigned to the specific id of the vector we compare to. We know the coordinates of the centroids, so that’s easy.
![Calculating the distance of between the query and the stored vector](https://qdrant.tech/articles_data/product-quantization/distance-calculation.png)
#### Qdrant implementation
Search operation requires calculating the distance to multiple points. Since we calculate the distance to a finite set of centroids, those might be precomputed and reused. Qdrant creates a lookup table for each query, so it can then simply sum up several terms to measure the distance between a query and all the centroids.
Centroid 0 | Centroid 1 | …  
---|---|---  
**Chunk 0** | 0.14213 | 0.51242  
**Chunk 1** | 0.08421 | 0.00142  
**…** | … | … | …  
## Product Quantization Benchmarks
Product Quantization comes with a cost - there are some additional operations to perform so that the performance might be reduced. However, memory usage might be reduced drastically as well. As usual, we did some benchmarks to give you a brief understanding of what you may expect.
Again, we reused the same pipeline as in [the other benchmarks we published](https://qdrant.tech/benchmarks/). We selected EF=128. The results are summarized in the tables:
#### Glove-100
Original | 1D clusters | 2D clusters | 3D clusters  
---|---|---|---  
Mean precision | 0.7158 | 0.7143 | 0.6731 | 0.5854  
Mean search time | 2336 µs | 2750 µs | 2597 µs | 2534 µs  
Compression | x1 | x4 | x8 | x12  
Upload & indexing time | 147 s | 339 s | 217 s | 178 s  
Product Quantization increases both indexing and searching time. The higher the compression ratio, the lower the search precision. The main benefit is undoubtedly the reduced usage of memory.
#### Arxiv-titles-384-angular-no-filters
Original | 1D clusters | 2D clusters | 4D clusters | 8D clusters  
---|---|---|---|---  
Mean precision | 0.9837 | 0.9677 | 0.9143 | 0.8068 | 0.6618  
Mean search time | 2719 µs | 4134 µs | 2947 µs | 2175 µs | 2053 µs  
Compression | x1 | x4 | x8 | x16 | x32  
Upload & indexing time | 332 s | 921 s | 597 s | 481 s | 474 s  
It turns out that in some cases, Product Quantization may not only reduce the memory usage, but also the search time.
## Product Quantization vs Scalar Quantization
Compared to [Scalar Quantization](https://qdrant.tech/articles/scalar-quantization/), Product Quantization offers a higher compression rate. However, this comes with considerable trade-offs in accuracy, and at times, in-RAM search speed.
Product Quantization tends to be favored in certain specific scenarios:
  * Deployment in a low-RAM environment where the limiting factor is the number of disk reads rather than the vector comparison itself
  * Situations where the dimensionality of the original vectors is sufficiently high
  * Cases where indexing speed is not a critical factor
In circumstances that do not align with the above, Scalar Quantization should be the preferred choice.
## Using Qdrant for Product Quantization
If you’re already a Qdrant user, we have, documentation on [Product Quantization](https://qdrant.tech/documentation/guides/quantization/#setting-up-product-quantization) that will help you to set and configure the new quantization for your data and achieve even up to 64x memory reduction.
Ready to experience the power of Product Quantization? 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/product-quantization.md) this page on GitHub, or 
On this page:
  * [What is Product Quantization?](https://qdrant.tech/articles/product-quantization/#what-is-product-quantization)
  * [How Does Product Quantization Work?](https://qdrant.tech/articles/product-quantization/#how-does-product-quantization-work)
    * [Cutting the vector into pieces](https://qdrant.tech/articles/product-quantization/#cutting-the-vector-into-pieces)
    * [Clustering](https://qdrant.tech/articles/product-quantization/#clustering)
    * [Full process](https://qdrant.tech/articles/product-quantization/#full-process)
  * [Measuring the distance](https://qdrant.tech/articles/product-quantization/#measuring-the-distance)
  * [Product Quantization Benchmarks](https://qdrant.tech/articles/product-quantization/#product-quantization-benchmarks)
  * [Product Quantization vs Scalar Quantization](https://qdrant.tech/articles/product-quantization/#product-quantization-vs-scalar-quantization)
  * [Using Qdrant for Product Quantization](https://qdrant.tech/articles/product-quantization/#using-qdrant-for-product-quantization)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/product-quantization/)
                    ## 📄 `https-qdrant-tech-articles-product-quantization-cutting-the-vector-into-pieces.md`
                    ```md
                    # https://qdrant.tech/articles/product-quantization/#cutting-the-vector-into-pieces
                    ## 📄 `https-qdrant-tech-articles-product-quantization-full-process.md`
                    ```md
                    # https://qdrant.tech/articles/product-quantization/#full-process
                    ## 📄 `https-qdrant-tech-articles-product-quantization-how-does-product-quantization-work.md`
                    ```md
                    # https://qdrant.tech/articles/product-quantization/#how-does-product-quantization-work
                    ## 📄 `https-qdrant-tech-articles-product-quantization-measuring-the-distance.md`
                    ```md
                    # https://qdrant.tech/articles/product-quantization/#measuring-the-distance
                    ## 📄 `https-qdrant-tech-articles-product-quantization-product-quantization-benchmarks.md`
                    ```md
                    # https://qdrant.tech/articles/product-quantization/#product-quantization-benchmarks
                    ## 📄 `https-qdrant-tech-articles-product-quantization-product-quantization-vs-scalar-quantization.md`
                    ```md
                    # https://qdrant.tech/articles/product-quantization/#product-quantization-vs-scalar-quantization
                    ## 📄 `https-qdrant-tech-articles-product-quantization-using-qdrant-for-product-quantization.md`
                    ```md
                    # https://qdrant.tech/articles/product-quantization/#using-qdrant-for-product-quantization
                    ## 📄 `https-qdrant-tech-articles-product-quantization-what-is-product-quantization.md`
                    ```md
                    # https://qdrant.tech/articles/product-quantization/#what-is-product-quantization
                    ## 📄 `https-qdrant-tech-articles-product-quantization.md`
                    ```md
                    # https://qdrant.tech/articles/product-quantization/
                    ## 📄 `https-qdrant-tech-articles-qdrant-internals.md`
                    ```md
                    # https://qdrant.tech/articles/qdrant-internals/
  * [Articles](https://qdrant.tech/articles/)
  * Qdrant Internals
#### Qdrant Internals
Take a look under the hood of Qdrant’s high-performance vector search engine. Explore the architecture, components, and design principles the Qdrant Vector Search Engine is built on.
[![Preview](https://qdrant.tech/articles_data/dedicated-vector-search/preview/preview.jpg) Built for Vector Search Why add-on vector search looks good — until you actually use it. Evgeniya Sukhodolskaya & Andrey Vasnetsov February 17, 2025 ](https://qdrant.tech/articles/dedicated-vector-search/)[![Preview](https://qdrant.tech/articles_data/gridstore-key-value-storage/preview/preview.jpg) Introducing Gridstore: Qdrant's Custom Key-Value Store Why and how we built our own key-value store. A short technical report on our procedure and results. Luis Cossio, Arnaud Gourlay & David Myriel February 05, 2025 ](https://qdrant.tech/articles/gridstore-key-value-storage/)[![Preview](https://qdrant.tech/articles_data/immutable-data-structures/preview/preview.jpg) Qdrant Internals: Immutable Data Structures Learn how immutable data structures improve vector search performance in Qdrant. Andrey Vasnetsov August 20, 2024 ](https://qdrant.tech/articles/immutable-data-structures/)[![Preview](https://qdrant.tech/articles_data/dedicated-service/preview/preview.jpg) Vector Search as a dedicated service Why vector search requires a dedicated service. Andrey Vasnetsov November 30, 2023 ](https://qdrant.tech/articles/dedicated-service/)[![Preview](https://qdrant.tech/articles_data/geo-polygon-filter-gsoc/preview/preview.jpg) Google Summer of Code 2023 - Polygon Geo Filter for Qdrant Vector Database A Summary of my work and experience at Qdrant's Gsoc '23. Zein Wen October 12, 2023 ](https://qdrant.tech/articles/geo-polygon-filter-gsoc/)[![Preview](https://qdrant.tech/articles_data/binary-quantization/preview/preview.jpg) Binary Quantization - Vector Search, 40x Faster Binary Quantization is a newly introduced mechanism of reducing the memory footprint and increasing performance Nirant Kasliwal September 18, 2023 ](https://qdrant.tech/articles/binary-quantization/)[![Preview](https://qdrant.tech/articles_data/io_uring/preview/preview.jpg) Qdrant under the hood: io_uring Slow disk decelerating your Qdrant deployment? Get on top of IO overhead with this one trick! Andre Bogus June 21, 2023 ](https://qdrant.tech/articles/io_uring/)[![Preview](https://qdrant.tech/articles_data/product-quantization/preview/preview.jpg) Product Quantization in Vector Search | Qdrant Discover product quantization in vector search technology. Learn how it optimizes storage and accelerates search processes for high-dimensional data. Kacper Łukawski May 30, 2023 ](https://qdrant.tech/articles/product-quantization/)[![Preview](https://qdrant.tech/articles_data/scalar-quantization/preview/preview.jpg) Scalar Quantization: Background, Practices & More | Qdrant Discover the efficiency of scalar quantization for optimized data storage and enhanced performance. Learn about its data compression benefits and efficiency improvements. Kacper Łukawski March 27, 2023 ](https://qdrant.tech/articles/scalar-quantization/)[![Preview](https://qdrant.tech/articles_data/memory-consumption/preview/preview.jpg) Minimal RAM you need to serve a million vectors How to properly measure RAM usage and optimize Qdrant for memory consumption. Andrei Vasnetsov December 07, 2022 ](https://qdrant.tech/articles/memory-consumption/)[![Preview](https://qdrant.tech/articles_data/filtrable-hnsw/preview/preview.jpg) Filtrable HNSW How to make ANN search with custom filtering? Search in selected subsets without loosing the results. Andrei Vasnetsov November 24, 2019 ](https://qdrant.tech/articles/filtrable-hnsw/)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/qdrant-internals/)
                    ## 📄 `https-qdrant-tech-articles-rag-and-genai.md`
                    ```md
                    # https://qdrant.tech/articles/rag-and-genai/
  * [Articles](https://qdrant.tech/articles/)
  * RAG & GenAI
#### RAG & GenAI
Leverage Qdrant for Retrieval-Augmented Generation (RAG) and build AI Agents
[![Preview](https://qdrant.tech/articles_data/agentic-rag/preview/preview.jpg) What is Agentic RAG? Building Agents with Qdrant Agents are a new paradigm in AI, and they are changing how we build RAG systems. Learn how to build agents with Qdrant and which framework to choose. Kacper Łukawski November 22, 2024 ](https://qdrant.tech/articles/agentic-rag/)[![Preview](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/preview/preview.jpg) Optimizing RAG Through an Evaluation-Based Methodology Learn how Qdrant-powered RAG applications can be tested and iteratively improved using LLM evaluation tools like Quotient. Atita Arora June 12, 2024 ](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/)[![Preview](https://qdrant.tech/articles_data/semantic-cache-ai-data-retrieval/preview/preview.jpg) Semantic Cache: Accelerating AI with Lightning-Fast Data Retrieval Semantic cache is reshaping AI applications by enabling rapid data retrieval. Discover how its implementation benefits your RAG setup. Daniel Romero, David Myriel May 07, 2024 ](https://qdrant.tech/articles/semantic-cache-ai-data-retrieval/)[![Preview](https://qdrant.tech/articles_data/what-is-rag-in-ai/preview/preview.jpg) What is RAG: Understanding Retrieval-Augmented Generation Explore how RAG enables LLMs to retrieve and utilize relevant external data when generating responses, rather than being limited to their original training data alone. Sabrina Aquino March 19, 2024 ](https://qdrant.tech/articles/what-is-rag-in-ai/)[![Preview](https://qdrant.tech/articles_data/rag-is-dead/preview/preview.jpg) Is RAG Dead? The Role of Vector Databases in Vector Search | Qdrant Uncover the necessity of vector databases for RAG and learn how Qdrant's vector database empowers enterprise AI with unmatched accuracy and cost-effectiveness. David Myriel February 27, 2024 ](https://qdrant.tech/articles/rag-is-dead/)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/rag-and-genai/)
                    ## 📄 `https-qdrant-tech-articles-rapid-rag-optimization-with-qdrant-and-quotient.md`
                    ```md
                    # https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/
  * [Articles](https://qdrant.tech/articles/)
  * Optimizing RAG Through an Evaluation-Based Methodology
# Optimizing RAG Through an Evaluation-Based Methodology
Atita Arora
·
June 12, 2024
![Optimizing RAG Through an Evaluation-Based Methodology](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/preview/title.jpg)
In today’s fast-paced, information-rich world, AI is revolutionizing knowledge management. The systematic process of capturing, distributing, and effectively using knowledge within an organization is one of the fields in which AI provides exceptional value today.
> The potential for AI-powered knowledge management increases when leveraging [Retrieval Augmented Generation (RAG)](https://qdrant.tech/rag/rag-evaluation-guide/), a methodology that enables LLMs to access a vast, diverse repository of factual information from knowledge stores, such as vector databases.
This process enhances the accuracy, relevance, and reliability of generated text, thereby mitigating the risk of faulty, incorrect, or nonsensical results sometimes associated with traditional LLMs. This method not only ensures that the answers are contextually relevant but also up-to-date, reflecting the latest insights and data available.
While RAG enhances the accuracy, relevance, and reliability of traditional LLM solutions, **an evaluation strategy can further help teams ensure their AI products meet these benchmarks of success.**
## Relevant tools for this experiment
In this article, we’ll break down a RAG Optimization workflow experiment that demonstrates that evaluation is essential to build a successful RAG strategy. We will use Qdrant and Quotient for this experiment.
[Qdrant](https://qdrant.tech/) is a vector database and vector similarity search engine designed for efficient storage and retrieval of high-dimensional vectors. Because Qdrant offers efficient indexing and searching capabilities, it is ideal for implementing RAG solutions, where quickly and accurately retrieving relevant information from extremely large datasets is crucial. Qdrant also offers a wealth of additional features, such as quantization, multivector support and multi-tenancy.
Alongside Qdrant we will use Quotient, which provides a seamless way to evaluate your RAG implementation, accelerating and improving the experimentation process.
[evaluation frameworks](https://qdrant.tech/rag/rag-evaluation-guide/) and conduct experiments on their products. Evaluation is how teams surface the shortcomings of their applications and improve performance in key benchmarks such as faithfulness, and semantic similarity. Iteration is key to building innovative AI products that will deliver value to end users.
> 💡 The 
## Summary of key findings
  1. **Irrelevance and Hallucinations** : When the documents retrieved are irrelevant, evidenced by low scores in both Chunk Relevance and Context Relevance, the model is prone to generating inaccurate or fabricated information.
  2. **Optimizing Document Retrieval** : By retrieving a greater number of documents and reducing the chunk size, we observed improved outcomes in the model’s performance.
  3. **Adaptive Retrieval Needs** : Certain queries may benefit from accessing more documents. Implementing a dynamic retrieval strategy that adjusts based on the query could enhance accuracy.
  4. **Influence of Model and Prompt Variations** : Alterations in language models or the prompts used can significantly impact the quality of the generated responses, suggesting that fine-tuning these elements could optimize performance.
Let us walk you through how we arrived at these findings!
## Building a RAG pipeline
To evaluate a RAG pipeline, we will have to build a RAG Pipeline first. In the interest of simplicity, we are building a Naive RAG in this article. There are certainly other versions of RAG :
![shades_of_rag.png](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/shades_of_rag.png)
The illustration below depicts how we can leverage a [RAG Evaluation framework](https://qdrant.tech/rag/rag-evaluation-guide/) to assess the quality of RAG Application.
![qdrant_and_quotient.png](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/qdrant_and_quotient.png)
We are going to build a RAG application using Qdrant’s Documentation and the premeditated 
To prepare our knowledge store we will use Qdrant, which can be leveraged in 3 different ways as below :
```
##Uncomment to initialise qdrant client in memory
#client = qdrant_client.QdrantClient(
#    location=":memory:",
#)
##Uncomment below to connect to Qdrant Cloud
client = qdrant_client.QdrantClient(
    os.environ.get("QDRANT_URL"),
    api_key=os.environ.get("QDRANT_API_KEY"),
)
## Uncomment below to connect to local Qdrant
#client = qdrant_client.QdrantClient("http://localhost:6333")

```
We will be using `QDRANT_URL` and `QDRANT_API_KEY` as environment variables for easier access.
Moving on, we will need to define the collection name as :
```
COLLECTION_NAME = "qdrant-docs-quotient"

```
In this case , we may need to create different collections based on the experiments we conduct.
To help us provide seamless embedding creations throughout the experiment, we will use Qdrant’s native embedding provider 
We can initialize and switch the embedding model of our choice as below :
```
## Declaring the intended Embedding Model with Fastembed
from fastembed.embedding import TextEmbedding
## General Fastembed specific operations
##Initilising embedding model
## Using Default Model - BAAI/bge-small-en-v1.5
embedding_model = TextEmbedding()
## For custom model supported by Fastembed
#embedding_model = TextEmbedding(model_name="BAAI/bge-small-en", max_length=512)
#embedding_model = TextEmbedding(model_name="sentence-transformers/all-MiniLM-L6-v2", max_length=384)
## Verify the chosen Embedding model
embedding_model.model_name

```
Before implementing RAG, we need to prepare and index our data in Qdrant.
This involves converting textual data into vectors using a suitable encoder (e.g., sentence transformers), and storing these vectors in Qdrant for retrieval.
```
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document as LangchainDocument
## Load the dataset with qdrant documentation
dataset = load_dataset("atitaarora/qdrant_doc", split="train")
## Dataset to langchain document
langchain_docs = [
    LangchainDocument(page_content=doc["text"], metadata={"source": doc["source"]})
    for doc in dataset
]
len(langchain_docs)
#Outputs
#240

```
You can preview documents in the dataset as below :
```
## Here's an example of what a document in our dataset looks like
print(dataset[100]['text'])

```
## Evaluation dataset
To measure the quality of our RAG setup, we will need a representative evaluation dataset. This dataset should contain realistic questions and the expected answers.
Additionally, including the expected contexts for which your RAG pipeline is designed to retrieve information would be beneficial.
We will be using a 
If you are struggling to make an evaluation dataset for your use case , you can use your documents and some techniques described in this 
### Building the RAG pipeline
We establish the data preprocessing parameters essential for the RAG pipeline and configure the Qdrant vector database according to the specified criteria.
Key parameters under consideration are:
  * **Chunk size**
  * **Chunk overlap**
  * **Embedding model**
  * **Number of documents retrieved (retrieval window)**
Following the ingestion of data in Qdrant, we proceed to retrieve pertinent documents corresponding to each query. These documents are then seamlessly integrated into our evaluation dataset, enriching the contextual information within the designated **`context`**column to fulfil the evaluation aspect.
Next we define methods to take care of logistics with respect to adding documents to Qdrant
```
def add_documents(client, collection_name, chunk_size, chunk_overlap, embedding_model_name):
    """
    This function adds documents to the desired Qdrant collection given the specified RAG parameters.
    """
    ## Processing each document with desired TEXT_SPLITTER_ALGO, CHUNK_SIZE, CHUNK_OVERLAP
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        add_start_index=True,
        separators=["\n\n", "\n", ".", " ", ""],
    )
    docs_processed = []
    for doc in langchain_docs:
        docs_processed += text_splitter.split_documents([doc])
    ## Processing documents to be encoded by Fastembed
    docs_contents = []
    docs_metadatas = []
    for doc in docs_processed:
        if hasattr(doc, 'page_content') and hasattr(doc, 'metadata'):
            docs_contents.append(doc.page_content)
            docs_metadatas.append(doc.metadata)
        else:
            # Handle the case where attributes are missing
            print("Warning: Some documents do not have 'page_content' or 'metadata' attributes.")
    print("processed: ", len(docs_processed))
    print("content: ", len(docs_contents))
    print("metadata: ", len(docs_metadatas))
    ## Adding documents to Qdrant using desired embedding model
    client.set_model(embedding_model_name=embedding_model_name)
    client.add(collection_name=collection_name, metadata=docs_metadatas, documents=docs_contents)

```
and retrieving documents from Qdrant during our RAG Pipeline assessment.
```
def get_documents(collection_name, query, num_documents=3):
    """
    This function retrieves the desired number of documents from the Qdrant collection given a query.
    It returns a list of the retrieved documents.
    """
    search_results = client.query(
        collection_name=collection_name,
        query_text=query,
        limit=num_documents,
    )
    results = [r.metadata["document"] for r in search_results]
    return results

```
### Setting up Quotient
You will need an account log in, which you can get by requesting access on `quotient authenticate` CLI command.
💡 Be sure to save your API key, since it will only be displayed once (Note: you will not have to repeat this step again until your API key expires).
**Once you have your API key, make sure to set it as an environment variable called`QUOTIENT_API_KEY`**
```
# Import QuotientAI client and connect to QuotientAI
from quotientai.client import QuotientClient
from quotientai.utils import show_job_progress
# IMPORTANT: be sure to set your API key as an environment variable called QUOTIENT_API_KEY
# You will need this set before running the code below. You may also uncomment the following line and insert your API key:
# os.environ['QUOTIENT_API_KEY'] = "YOUR_API_KEY"
quotient = QuotientClient()

```
**QuotientAI** provides a seamless way to integrate _RAG evaluation_ into your applications. Here, we’ll see how to use it to evaluate text generated from an LLM, based on retrieved knowledge from the Qdrant vector database.
After retrieving the top similar documents and populating the `context` column, we can submit the evaluation dataset to Quotient and execute an evaluation job. To run a job, all you need is your evaluation dataset and a `recipe`.
_**A recipe is a combination of a prompt template and a specified LLM.**_
**Quotient** orchestrates the evaluation run and handles version control and asset management throughout the experimentation process.
_**Prior to assessing our RAG solution, it’s crucial to outline our optimization goals.**_
In the context of _question-answering on Qdrant documentation_ , our focus extends beyond merely providing helpful responses. Ensuring the absence of any _inaccurate or misleading information_ is paramount.
In other words, **we want to minimize hallucinations** in the LLM outputs.
For our evaluation, we will be considering the following metrics, with a focus on **Faithfulness** :
  * **Context Relevance**
  * **Chunk Relevance**
  * **Faithfulness**
  * **ROUGE-L**
  * **BERT Sentence Similarity**
  * **BERTScore**
### Evaluation in action
The function below takes an evaluation dataset as input, which in this case contains questions and their corresponding answers. It retrieves relevant documents based on the questions in the dataset and populates the context field with this information from Qdrant. The prepared dataset is then submitted to QuotientAI for evaluation for the chosen metrics. After the evaluation is complete, the function displays aggregated statistics on the evaluation metrics followed by the summarized evaluation results.
```
def run_eval(eval_df, collection_name, recipe_id, num_docs=3, path="eval_dataset_qdrant_questions.csv"):
    """
    This function evaluates the performance of a complete RAG pipeline on a given evaluation dataset.
    Given an evaluation dataset (containing questions and ground truth answers),
    this function retrieves relevant documents, populates the context field, and submits the dataset to QuotientAI for evaluation.
    Once the evaluation is complete, aggregated statistics on the evaluation metrics are displayed.
    The evaluation results are returned as a pandas dataframe.
    """
    # Add context to each question by retrieving relevant documents
    eval_df['documents'] = eval_df.apply(lambda x: get_documents(collection_name=collection_name,
                                                                query=x['input_text'],
                                                                num_documents=num_docs), axis=1)
    eval_df['context'] = eval_df.apply(lambda x: "\n".join(x['documents']), axis=1)
    # Now we'll save the eval_df to a CSV
    eval_df.to_csv(path, index=False)
    # Upload the eval dataset to QuotientAI
    dataset = quotient.create_dataset(
        file_path=path,
        name="qdrant-questions-eval-v1",
    )
    # Create a new task for the dataset
    task = quotient.create_task(
        dataset_id=dataset['id'],
        name='qdrant-questions-qa-v1',
        task_type='question_answering'
    )
    # Run a job to evaluate the model
    job = quotient.create_job(
        task_id=task['id'],
        recipe_id=recipe_id,
        num_fewshot_examples=0,
        limit=500,
        metric_ids=[5, 7, 8, 11, 12, 13, 50],
    )
    # Show the progress of the job
    show_job_progress(quotient, job['id'])
    # Once the job is complete, we can get our results
    data = quotient.get_eval_results(job_id=job['id'])
    # Add the results to a pandas dataframe to get statistics on performance
    df = pd.json_normalize(data, "results")
    df_stats = df[df.columns[df.columns.str.contains("metric|completion_time")]]
    df.columns = df.columns.str.replace("metric.", "")
    df_stats.columns = df_stats.columns.str.replace("metric.", "")
    metrics = {
        'completion_time_ms':'Completion Time (ms)',
        'chunk_relevance': 'Chunk Relevance',
        'selfcheckgpt_nli_relevance':"Context Relevance",
        'selfcheckgpt_nli':"Faithfulness",
        'rougeL_fmeasure':"ROUGE-L",
        'bert_score_f1':"BERTScore",
        'bert_sentence_similarity': "BERT Sentence Similarity",
        'completion_verbosity':"Completion Verbosity",
        'verbosity_ratio':"Verbosity Ratio",}
    df = df.rename(columns=metrics)
    df_stats = df_stats.rename(columns=metrics)
    display(df_stats[metrics.values()].describe())
    return df
main_metrics = [
      'Context Relevance',
      'Chunk Relevance',
      'Faithfulness',
      'ROUGE-L',
      'BERT Sentence Similarity',
      'BERTScore',
      ]

```
## Experimentation
Our approach is rooted in the belief that improvement thrives in an environment of exploration and discovery. By systematically testing and tweaking various components of the RAG pipeline, we aim to incrementally enhance its capabilities and performance.
In the following section, we dive into the details of our experimentation process, outlining the specific experiments conducted and the insights gained.
### Experiment 1 - Baseline
Parameters
  * **Embedding Model:`bge-small-en`**
  * **Chunk size:`512`**
  * **Chunk overlap:`64`**
  * **Number of docs retrieved (Retireval Window):`3`**
  * **LLM:`Mistral-7B-Instruct`**
We’ll process our documents based on configuration above and ingest them into Qdrant using `add_documents` method introduced earlier
```
#experiment1 - base config
chunk_size = 512
chunk_overlap = 64
embedding_model_name = "BAAI/bge-small-en"
num_docs = 3
COLLECTION_NAME = f"experiment_{chunk_size}_{chunk_overlap}_{embedding_model_name.split('/')[1]}"
add_documents(client,
              collection_name=COLLECTION_NAME,
              chunk_size=chunk_size,
              chunk_overlap=chunk_overlap,
              embedding_model_name=embedding_model_name)
#Outputs
#processed: 4504
#content:   4504
#metadata:  4504

```
Notice the `COLLECTION_NAME` which helps us segregate and identify our collections based on the experiments conducted.
To proceed with the evaluation, let’s create the `evaluation recipe` up next
```
# Create a recipe for the generator model and prompt template
recipe_mistral = quotient.create_recipe(
    model_id=10,
    prompt_template_id=1,
    name='mistral-7b-instruct-qa-with-rag',
    description='Mistral-7b-instruct using a prompt template that includes context.'
)
recipe_mistral
#Outputs recipe JSON with the used prompt template
#'prompt_template': {'id': 1,
#  'name': 'Default Question Answering Template',
#  'variables': '["input_text","context"]',
#  'created_at': '2023-12-21T22:01:54.632367',
#  'template_string': 'Question: {input_text}\\n\\nContext: {context}\\n\\nAnswer:',
#  'owner_profile_id': None}

```
To get a list of your existing recipes, you can simply run:
```
quotient.list_recipes()

```
Notice the recipe template is a simplest prompt using `Question` from evaluation template `Context` from document chunks retrieved from Qdrant and `Answer` generated by the pipeline.
To kick off the evaluation
```
# Kick off an evaluation job
experiment_1 = run_eval(eval_df,
                        collection_name=COLLECTION_NAME,
                        recipe_id=recipe_mistral['id'],
                        num_docs=num_docs,
                        path=f"{COLLECTION_NAME}_{num_docs}_mistral.csv")

```
This may take few minutes (depending on the size of evaluation dataset!)
We can look at the results from our first (baseline) experiment as below :
![experiment1_eval.png](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/experiment1_eval.png)
Notice that we have a pretty **low average Chunk Relevance** and **very large standard deviations for both Chunk Relevance and Context Relevance**.
Let’s take a look at some of the lower performing datapoints with **poor Faithfulness** :
```
with pd.option_context('display.max_colwidth', 0):
    display(experiment_1[['content.input_text', 'content.answer','content.documents','Chunk Relevance','Context Relevance','Faithfulness']
                ].sort_values(by='Faithfulness').head(2))

```
![experiment1_bad_examples.png](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/experiment1_bad_examples.png)
In instances where the retrieved documents are **irrelevant (where both Chunk Relevance and Context Relevance are low)** , the model also shows **tendencies to hallucinate** and **produce poor quality responses**.
The quality of the retrieved text directly impacts the quality of the LLM-generated answer. Therefore, our focus will be on enhancing the RAG setup by **adjusting the chunking parameters**.
### Experiment 2 - Adjusting the chunk parameter
Keeping all other parameters constant, we changed the `chunk size` and `chunk overlap` to see if we can improve our results.
Parameters :
  * **Embedding Model :`bge-small-en`**
  * **Chunk size:`1024`**
  * **Chunk overlap:`128`**
  * **Number of docs retrieved (Retireval Window):`3`**
  * **LLM:`Mistral-7B-Instruct`**
We will reprocess the data with the updated parameters above:
```
## for iteration 2 - lets modify chunk configuration
## We will start with creating seperate collection to store vectors
chunk_size = 1024
chunk_overlap = 128
embedding_model_name = "BAAI/bge-small-en"
num_docs = 3
COLLECTION_NAME = f"experiment_{chunk_size}_{chunk_overlap}_{embedding_model_name.split('/')[1]}"
add_documents(client,
              collection_name=COLLECTION_NAME,
              chunk_size=chunk_size,
              chunk_overlap=chunk_overlap,
              embedding_model_name=embedding_model_name)
#Outputs
#processed: 2152
#content:   2152
#metadata:  2152

```
Followed by running evaluation :
![experiment2_eval.png](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/experiment2_eval.png)
and **comparing it with the results from Experiment 1:**
![graph_exp1_vs_exp2.png](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/graph_exp1_vs_exp2.png)
We observed slight enhancements in our LLM completion metrics (including BERT Sentence Similarity, BERTScore, ROUGE-L, and Knowledge F1) with the increase in _chunk size_. However, it’s noteworthy that there was a significant decrease in _Faithfulness_ , which is the primary metric we are aiming to optimize.
Moreover, _Context Relevance_ demonstrated an increase, indicating that the RAG pipeline retrieved more relevant information required to address the query. Nonetheless, there was a considerable drop in _Chunk Relevance_ , implying that a smaller portion of the retrieved documents contained pertinent information for answering the question.
**The correlation between the rise in Context Relevance and the decline in Chunk Relevance suggests that retrieving more documents using the smaller chunk size might yield improved results.**
### Experiment 3 - Increasing the number of documents retrieved (retrieval window)
This time, we are using the same RAG setup as `Experiment 1`, but increasing the number of retrieved documents from **3** to **5**.
Parameters :
  * **Embedding Model :`bge-small-en`**
  * **Chunk size:`512`**
  * **Chunk overlap:`64`**
  * **Number of docs retrieved (Retrieval Window):`5`**
  * **LLM: :`Mistral-7B-Instruct`**
We can use the collection from Experiment 1 and run evaluation with modified `num_docs` parameter as :
```
#collection name from Experiment 1
COLLECTION_NAME = f"experiment_{chunk_size}_{chunk_overlap}_{embedding_model_name.split('/')[1]}"
#running eval for experiment 3
experiment_3 = run_eval(eval_df,
                        collection_name=COLLECTION_NAME,
                        recipe_id=recipe_mistral['id'],
                        num_docs=num_docs,
                        path=f"{COLLECTION_NAME}_{num_docs}_mistral.csv")

```
Observe the results as below :
![experiment_3_eval.png](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/experiment_3_eval.png)
Comparing the results with Experiment 1 and 2 :
![graph_exp1_exp2_exp3.png](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/graph_exp1_exp2_exp3.png)
As anticipated, employing the smaller chunk size while retrieving a larger number of documents resulted in achieving the highest levels of both _Context Relevance_ and _Chunk Relevance._ Additionally, it yielded the **best** (albeit marginal) _Faithfulness_ score, indicating a _reduced occurrence of inaccuracies or hallucinations_.
Looks like we have achieved a good hold on our chunking parameters but it is worth testing another embedding model to see if we can get better results.
### Experiment 4 - Changing the embedding model
Let us try using **MiniLM** for this experiment ****Parameters :
  * **Embedding Model :`MiniLM-L6-v2`**
  * **Chunk size:`512`**
  * **Chunk overlap:`64`**
  * **Number of docs retrieved (Retrieval Window):`5`**
  * **LLM: :`Mistral-7B-Instruct`**
We will have to create another collection for this experiment :
```
#experiment-4
chunk_size=512
chunk_overlap=64
embedding_model_name="sentence-transformers/all-MiniLM-L6-v2"
num_docs=5
COLLECTION_NAME = f"experiment_{chunk_size}_{chunk_overlap}_{embedding_model_name.split('/')[1]}"
add_documents(client,
              collection_name=COLLECTION_NAME,
              chunk_size=chunk_size,
              chunk_overlap=chunk_overlap,
              embedding_model_name=embedding_model_name)
#Outputs
#processed: 4504
#content:   4504
#metadata:  4504

```
We will observe our evaluations as :
![experiment4_eval.png](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/experiment4_eval.png)
Comparing these with our previous experiments :
![graph_exp1_exp2_exp3_exp4.png](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/graph_exp1_exp2_exp3_exp4.png)
It appears that `bge-small` was more proficient in capturing the semantic nuances of the Qdrant Documentation.
Up to this point, our experimentation has focused solely on the _retrieval aspect_ of our RAG pipeline. Now, let’s explore altering the _generation aspect_ or LLM while retaining the optimal parameters identified in Experiment 3.
### Experiment 5 - Changing the LLM
Parameters :
  * **Embedding Model :`bge-small-en`**
  * **Chunk size:`512`**
  * **Chunk overlap:`64`**
  * **Number of docs retrieved (Retrieval Window):`5`**
  * **LLM: :`GPT-3.5-turbo`**
For this we can repurpose our collection from Experiment 3 while the evaluations to use a new recipe with **GPT-3.5-turbo** model.
```
#collection name from Experiment 3
COLLECTION_NAME = f"experiment_{chunk_size}_{chunk_overlap}_{embedding_model_name.split('/')[1]}"
# We have to create a recipe using the same prompt template and GPT-3.5-turbo
recipe_gpt = quotient.create_recipe(
    model_id=5,
    prompt_template_id=1,
    name='gpt3.5-qa-with-rag-recipe-v1',
    description='GPT-3.5 using a prompt template that includes context.'
)
recipe_gpt
#Outputs
#{'id': 495,
# 'name': 'gpt3.5-qa-with-rag-recipe-v1',
# 'description': 'GPT-3.5 using a prompt template that includes context.',
# 'model_id': 5,
# 'prompt_template_id': 1,
# 'created_at': '2024-05-03T12:14:58.779585',
# 'owner_profile_id': 34,
# 'system_prompt_id': None,
# 'prompt_template': {'id': 1,
#  'name': 'Default Question Answering Template',
#  'variables': '["input_text","context"]',
#  'created_at': '2023-12-21T22:01:54.632367',
#  'template_string': 'Question: {input_text}\\n\\nContext: {context}\\n\\nAnswer:',
#  'owner_profile_id': None},
# 'model': {'id': 5,
#  'name': 'gpt-3.5-turbo',
#  'endpoint': 'https://api.openai.com/v1/chat/completions',
#  'revision': 'placeholder',
#  'created_at': '2024-02-06T17:01:21.408454',
#  'model_type': 'OpenAI',
#  'description': 'Returns a maximum of 4K output tokens.',
#  'owner_profile_id': None,
#  'external_model_config_id': None,
#  'instruction_template_cls': 'NoneType'}}

```
Running the evaluations as :
```
experiment_5 = run_eval(eval_df,
                        collection_name=COLLECTION_NAME,
                        recipe_id=recipe_gpt['id'],
                        num_docs=num_docs,
                        path=f"{COLLECTION_NAME}_{num_docs}_gpt.csv")

```
We observe :
![experiment5_eval.png](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/experiment5_eval.png)
and comparing all the 5 experiments as below :
![graph_exp1_exp2_exp3_exp4_exp5.png](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/graph_exp1_exp2_exp3_exp4_exp5.png)
**GPT-3.5 surpassed Mistral-7B in all metrics**! Notably, Experiment 5 exhibited the **lowest occurrence of hallucination**.
## Conclusions
Let’s take a look at our results from all 5 experiments above
![overall_eval_results.png](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/overall_eval_results.png)
We still have a long way to go in improving the retrieval performance of RAG, as indicated by our generally poor results thus far. It might be beneficial to **explore alternative embedding models** or **different retrieval strategies** to address this issue.
The significant variations in _Context Relevance_ suggest that **certain questions may necessitate retrieving more documents than others**. Therefore, investigating a **dynamic retrieval strategy** could be worthwhile.
Furthermore, there’s ongoing **exploration required on the generative aspect** of RAG. Modifying LLMs or prompts can substantially impact the overall quality of responses.
This iterative process demonstrates how, starting from scratch, continual evaluation and adjustments throughout experimentation can lead to the development of an enhanced RAG system.
## Watch this workshop on YouTube
> A workshop version of this article is 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/rapid-rag-optimization-with-qdrant-and-quotient.md) this page on GitHub, or 
On this page:
  * [Relevant tools for this experiment](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#relevant-tools-for-this-experiment)
  * [Summary of key findings](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#summary-of-key-findings)
  * [Building a RAG pipeline](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#building-a-rag-pipeline)
  * [Evaluation dataset](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#evaluation-dataset)
    * [Building the RAG pipeline](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#building-the-rag-pipeline)
    * [Setting up Quotient](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#setting-up-quotient)
    * [Evaluation in action](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#evaluation-in-action)
  * [Experimentation](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#experimentation)
    * [Experiment 1 - Baseline](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#experiment-1---baseline)
    * [Experiment 2 - Adjusting the chunk parameter](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#experiment-2---adjusting-the-chunk-parameter)
    * [Experiment 3 - Increasing the number of documents retrieved (retrieval window)](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#experiment-3---increasing-the-number-of-documents-retrieved-retrieval-window)
    * [Experiment 4 - Changing the embedding model](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#experiment-4---changing-the-embedding-model)
    * [Experiment 5 - Changing the LLM](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#experiment-5---changing-the-llm)
  * [Conclusions](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#conclusions)
  * [Watch this workshop on YouTube](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/#watch-this-workshop-on-youtube)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/)
                    ## 📄 `https-qdrant-tech-articles-scalar-quantization-accessing-best-practices.md`
                    ```md
                    # https://qdrant.tech/articles/scalar-quantization/#accessing-best-practices
  * [Articles](https://qdrant.tech/articles/)
  * Scalar Quantization: Background, Practices & More | Qdrant
# Scalar Quantization: Background, Practices & More | Qdrant
Kacper Łukawski
·
March 27, 2023
![Scalar Quantization: Background, Practices & More | Qdrant](https://qdrant.tech/articles_data/scalar-quantization/preview/title.jpg)
# Efficiency Unleashed: The Power of Scalar Quantization
High-dimensional vector embeddings can be memory-intensive, especially when working with large datasets consisting of millions of vectors. Memory footprint really starts being a concern when we scale things up. A simple choice of the data type used to store a single number impacts even billions of numbers and can drive the memory requirements crazy. The higher the precision of your type, the more accurately you can represent the numbers. The more accurate your vectors, the more precise is the distance calculation. But the advantages stop paying off when you need to order more and more memory.
Qdrant chose `float32` as a default type used to store the numbers of your embeddings. So a single number needs 4 bytes of the memory and a 512-dimensional vector occupies 2 kB. That’s only the memory used to store the vector. There is also an overhead of the HNSW graph, so as a rule of thumb we estimate the memory size with the following formula:
```
memory_size = 1.5 * number_of_vectors * vector_dimension * 4 bytes

```
While Qdrant offers various options to store some parts of the data on disk, starting from version 1.1.0, you can also optimize your memory by compressing the embeddings. We’ve implemented the mechanism of **Scalar Quantization**! It turns out to have not only a positive impact on memory but also on the performance.
## Scalar quantization
Scalar quantization is a data compression technique that converts floating point values into integers. In case of Qdrant `float32` gets converted into `int8`, so a single number needs 75% less memory. It’s not a simple rounding though! It’s a process that makes that transformation partially reversible, so we can also revert integers back to floats with a small loss of precision.
### Theoretical background
Assume we have a collection of `float32` vectors and denote a single value as `f32`. In reality neural embeddings do not cover a whole range represented by the floating point numbers, but rather a small subrange. Since we know all the other vectors, we can establish some statistics of all the numbers. For example, the distribution of the values will be typically normal:
![A distribution of the vector values](https://qdrant.tech/articles_data/scalar-quantization/float32-distribution.png)
Our example shows that 99% of the values come from a `[-2.0, 5.0]` range. And the conversion to `int8` will surely lose some precision, so we rather prefer keeping the representation accuracy within the range of 99% of the most probable values and ignoring the precision of the outliers. There might be a different choice of the range width, actually, any value from a range `[0, 1]`, where `0` means empty range, and `1` would keep all the values. That’s a hyperparameter of the procedure called `quantile`. A value of `0.95` or `0.99` is typically a reasonable choice, but in general `quantile ∈ [0, 1]`.
#### Conversion to integers
Let’s talk about the conversion to `int8`. Integers also have a finite set of values that might be represented. Within a single byte they may represent up to 256 different values, either from `[-128, 127]` or `[0, 255]`.
![Value ranges represented by int8](https://qdrant.tech/articles_data/scalar-quantization/int8-value-range.png)
Since we put some boundaries on the numbers that might be represented by the `f32`, and `i8` has some natural boundaries, the process of converting the values between those two ranges is quite natural:
f32=α×i8+offset
i8=f32−offsetα
The parameters α and offset has to be calculated for a given set of vectors, but that comes easily by putting the minimum and maximum of the represented range for both `f32` and `i8`.
![Float32 to int8 conversion](https://qdrant.tech/articles_data/scalar-quantization/float32-to-int8-conversion.png)
For the unsigned `int8` it will go as following:
{−2=α×0+offset5=α×255+offset
In case of signed `int8`, we’ll just change the represented range boundaries:
{−2=α×(−128)+offset5=α×127+offset
For any set of vector values we can simply calculate the α and offset and those values have to be stored along with the collection to enable to conversion between the types.
#### Distance calculation
We do not store the vectors in the collections represented by `int8` instead of `float32` just for the sake of compressing the memory. But the coordinates are being used while we calculate the distance between the vectors. Both dot product and cosine distance requires multiplying the corresponding coordinates of two vectors, so that’s the operation we perform quite often on `float32`. Here is how it would look like if we perform the conversion to `int8`:
f32×f32′= =(α×i8+offset)×(α×i8′+offset)= =α2×i8×i8′+offset×α×i8′+offset×α×i8+offset2⏟pre-compute
The first term, α2×i8×i8′ has to be calculated when we measure the distance as it depends on both vectors. However, both the second and the third term (offset×α×i8′ and offset×α×i8 respectively), depend only on a single vector and those might be precomputed and kept for each vector. The last term, offset2 does not depend on any of the values, so it might be even computed once and reused.
If we had to calculate all the terms to measure the distance, the performance could have been even worse than without the conversion. But thanks for the fact we can precompute the majority of the terms, things are getting simpler. And in turns out the scalar quantization has a positive impact not only on the memory usage, but also on the performance. As usual, we performed some benchmarks to support this statement!
## Benchmarks
We simply used the same approach as we use in all [the other benchmarks we publish](https://qdrant.tech/benchmarks/). Both 
#### Arxiv-titles-384-angular-no-filters
ef = 128 | ef = 256 | ef = 512  
---|---|---  
Upload and indexing time | Mean search precision | Mean search time | Mean search precision | Mean search time | Mean search precision | Mean search time  
Non-quantized vectors | 649 s | 0.989 | 0.0094 | 0.994 | 0.0932 | 0.996 | 0.161  
Scalar Quantization | 496 s | 0.986 | 0.0037 | 0.993 | 0.060 | 0.996 | 0.115  
Difference | -23.57% | -0.3% | -60.64% | -0.1% | -35.62% | 0% | -28.57%  
A slight decrease in search precision results in a considerable improvement in the latency. Unless you aim for the highest precision possible, you should not notice the difference in your search quality.
#### Gist-960
ef = 128 | ef = 256 | ef = 512  
---|---|---  
Upload and indexing time | Mean search precision | Mean search time | Mean search precision | Mean search time | Mean search precision | Mean search time  
Non-quantized vectors | 452 | 0.802 | 0.077 | 0.887 | 0.135 | 0.941 | 0.231  
Scalar Quantization | 312 | 0.802 | 0.043 | 0.888 | 0.077 | 0.941 | 0.135  
Difference | -30.79% | 0% | -44,16% | +0.11% | -42.96% | 0% | -41,56%  
In all the cases, the decrease in search precision is negligible, but we keep a latency reduction of at least 28.57%, even up to 60,64%, while searching. As a rule of thumb, the higher the dimensionality of the vectors, the lower the precision loss.
### Oversampling and rescoring
A distinctive feature of the Qdrant architecture is the ability to combine the search for quantized and original vectors in a single query. This enables the best combination of speed, accuracy, and RAM usage.
Qdrant stores the original vectors, so it is possible to rescore the top-k results with the original vectors after doing the neighbours search in quantized space. That obviously has some impact on the performance, but in order to measure how big it is, we made the comparison in different search scenarios. We used a machine with a very slow network-mounted disk and tested the following scenarios with different amounts of allowed RAM:
Setup | RPS | Precision  
---|---|---  
4.5GB memory | 600 | 0.99  
4.5GB memory + SQ + rescore | 1000 | 0.989  
And another group with more strict memory limits:
Setup | RPS | Precision  
---|---|---  
2GB memory | 2 | 0.99  
2GB memory + SQ + rescore | 30 | 0.989  
2GB memory + SQ + no rescore | 1200 | 0.974  
In those experiments, throughput was mainly defined by the number of disk reads, and quantization efficiently reduces it by allowing more vectors in RAM. Read more about on-disk storage in Qdrant and how we measure its performance in our article: [Minimal RAM you need to serve a million vectors ](https://qdrant.tech/articles/memory-consumption/).
The mechanism of Scalar Quantization with rescoring disabled pushes the limits of low-end machines even further. It seems like handling lots of requests does not require an expensive setup if you can agree to a small decrease in the search precision.
### Accessing best practices
Qdrant documentation on [Scalar Quantization](https://qdrant.tech/documentation/quantization/#setting-up-quantization-in-qdrant) is a great resource describing different scenarios and strategies to achieve up to 4x lower memory footprint and even up to 2x performance increase.
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/scalar-quantization.md) this page on GitHub, or 
On this page:
  * [Scalar quantization](https://qdrant.tech/articles/scalar-quantization/#scalar-quantization)
    * [Theoretical background](https://qdrant.tech/articles/scalar-quantization/#theoretical-background)
  * [Benchmarks](https://qdrant.tech/articles/scalar-quantization/#benchmarks)
    * [Oversampling and rescoring](https://qdrant.tech/articles/scalar-quantization/#oversampling-and-rescoring)
    * [Accessing best practices](https://qdrant.tech/articles/scalar-quantization/#accessing-best-practices)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/scalar-quantization/)
                    ## 📄 `https-qdrant-tech-articles-scalar-quantization-benchmarks.md`
                    ```md
                    # https://qdrant.tech/articles/scalar-quantization/#benchmarks
                    ## 📄 `https-qdrant-tech-articles-scalar-quantization-oversampling-and-rescoring.md`
                    ```md
                    # https://qdrant.tech/articles/scalar-quantization/#oversampling-and-rescoring
#### Conversion to integers
Let’s talk about the conversion to `int8`. Integers also have a finite set of values that might be represented. Within a single byte they may represent up to 256 different values, either from `[-128, 127]` or `[0, 255]`.
![Value ranges represented by int8](https://qdrant.tech/articles_data/scalar-quantization/int8-value-range.png)
Since we put some boundaries on the numbers that might be represented by the `f32`, and `i8` has some natural boundaries, the process of converting the values between those two ranges is quite natural:
f32=α×i8+offset
i8=f32−offsetα
The parameters $ \alpha $ and $ offset $ has to be calculated for a given set of vectors, but that comes easily by putting the minimum and maximum of the represented range for both `f32` and `i8`.
![Float32 to int8 conversion](https://qdrant.tech/articles_data/scalar-quantization/float32-to-int8-conversion.png)
For the unsigned `int8` it will go as following:
{−2=α×0+offset5=α×255+offset
In case of signed `int8`, we’ll just change the represented range boundaries:
{−2=α×(−128)+offset5=α×127+offset
For any set of vector values we can simply calculate the $ \alpha $ and $ offset $ and those values have to be stored along with the collection to enable to conversion between the types.
#### Distance calculation
We do not store the vectors in the collections represented by `int8` instead of `float32` just for the sake of compressing the memory. But the coordinates are being used while we calculate the distance between the vectors. Both dot product and cosine distance requires multiplying the corresponding coordinates of two vectors, so that’s the operation we perform quite often on `float32`. Here is how it would look like if we perform the conversion to `int8`:
f32×f32′= =(α×i8+offset)×(α×i8′+offset)= =α2×i8×i8′+offset×α×i8′+offset×α×i8+offset2⏟pre-compute
The first term, $ \alpha^{2} \times i8 \times i8’ $ has to be calculated when we measure the distance as it depends on both vectors. However, both the second and the third term ($ offset \times \alpha \times i8’ $ and $ offset \times \alpha \times i8 $ respectively), depend only on a single vector and those might be precomputed and kept for each vector. The last term, $ offset^{2} $ does not depend on any of the values, so it might be even computed once and reused.
If we had to calculate all the terms to measure the distance, the performance could have been even worse than without the conversion. But thanks for the fact we can precompute the majority of the terms, things are getting simpler. And in turns out the scalar quantization has a positive impact not only on the memory usage, but also on the performance. As usual, we performed some benchmarks to support this statement!
                    ## 📄 `https-qdrant-tech-articles-scalar-quantization-scalar-quantization.md`
                    ```md
                    # https://qdrant.tech/articles/scalar-quantization/#scalar-quantization
                    ## 📄 `https-qdrant-tech-articles-scalar-quantization-theoretical-background.md`
                    ```md
                    # https://qdrant.tech/articles/scalar-quantization/#theoretical-background
                    ## 📄 `https-qdrant-tech-articles-scalar-quantization.md`
                    ```md
                    # https://qdrant.tech/articles/scalar-quantization/
                    ## 📄 `https-qdrant-tech-articles-search-as-you-type.md`
                    ```md
                    # https://qdrant.tech/articles/search-as-you-type/
  * [Articles](https://qdrant.tech/articles/)
  * Semantic Search As You Type
# Semantic Search As You Type
Andre Bogus
·
August 14, 2023
![Semantic Search As You Type](https://qdrant.tech/articles_data/search-as-you-type/preview/title.jpg)
Qdrant is one of the fastest vector search engines out there, so while looking for a demo to show off, we came upon the idea to do a search-as-you-type box with a fully semantic search backend. Now we already have a semantic/keyword hybrid search on our website. But that one is written in Python, which incurs some overhead for the interpreter. Naturally, I wanted to see how fast I could go using Rust.
Since Qdrant doesn’t embed by itself, I had to decide on an embedding model. The prior version used the 
The workflow looks like this:
![Search Qdrant by Embedding](https://qdrant.tech/articles_data/search-as-you-type/Qdrant_Search_by_Embedding.png)
This will, after tokenizing and embedding send a `/collections/site/points/search` POST request to Qdrant, sending the following JSON:
```
POST collections/site/points/search
{
  "vector": [-0.06716014,-0.056464013, ...(382 values omitted)],
  "limit": 5,
  "with_payload": true,
}

```
Even with avoiding a network round-trip, the embedding still takes some time. As always in optimization, if you cannot do the work faster, a good solution is to avoid work altogether (please don’t tell my employer). This can be done by pre-computing common prefixes and calculating embeddings for them, then storing them in a `prefix_cache` collection. Now the [`recommend`](https://api.qdrant.tech/api-reference/search/recommend-points) API method can find the best matches without doing any embedding. For now, I use short (up to and including 5 letters) prefixes, but I can also parse the logs to get the most common search terms and add them to the cache later.
![Qdrant Recommendation](https://qdrant.tech/articles_data/search-as-you-type/Qdrant_Recommendation.png)
Making that work requires setting up the `prefix_cache` collection with points that have the prefix as their `point_id` and the embedding as their `vector`, which lets us do the lookup with no search or index. The `prefix_to_id` function currently uses the `u64` variant of `PointId`, which can hold eight bytes, enough for this use. If the need arises, one could instead encode the names as UUID, hashing the input. Since I know all our prefixes are within 8 bytes, I decided against this for now.
The `recommend` endpoint works roughly the same as `search_points`, but instead of searching for a vector, Qdrant searches for one or more points (you can also give negative example points the search engine will try to avoid in the results). It was built to help drive recommendation engines, saving the round-trip of sending the current point’s vector back to Qdrant to find more similar ones. However Qdrant goes a bit further by allowing us to select a different collection to lookup the points, which allows us to keep our `prefix_cache` collection separate from the site data. So in our case, Qdrant first looks up the point from the `prefix_cache`, takes its vector and searches for that in the `site` collection, using the precomputed embeddings from the cache. The API endpoint expects a POST of the following JSON to `/collections/site/points/recommend`:
```
POST collections/site/points/recommend
{
  "positive": [1936024932],
  "limit": 5,
  "with_payload": true,
  "lookup_from": {
    "collection": "prefix_cache"
  }
}

```
Now I have, in the best Rust tradition, a blazingly fast semantic search.
To demo it, I used our [Qdrant documentation website](https://qdrant.tech/documentation/)’s page search, replacing our previous Python implementation. So in order to not just spew empty words, here is a benchmark, showing different queries that exercise different code paths.
Since the operations themselves are far faster than the network whose fickle nature would have swamped most measurable differences, I benchmarked both the Python and Rust services locally. I’m measuring both versions on the same AMD Ryzen 9 5900HX with 16GB RAM running Linux. The table shows the average time and error bound in milliseconds. I only measured up to a thousand concurrent requests. None of the services showed any slowdown with more requests in that range. I do not expect our service to become DDOS’d, so I didn’t benchmark with more load.
Without further ado, here are the results:
query length | Short | Long  
---|---|---  
Python 🐍 | 16 ± 4 ms | 16 ± 4 ms  
Rust 🦀 | 1½ ± ½ ms | 5 ± 1 ms  
The Rust version consistently outperforms the Python version and offers a semantic search even on few-character queries. If the prefix cache is hit (as in the short query length), the semantic search can even get more than ten times faster than the Python version. The general speed-up is due to both the relatively lower overhead of Rust + Actix Web compared to Python + FastAPI (even if that already performs admirably), as well as using ONNX Runtime instead of SentenceTransformers for the embedding. The prefix cache gives the Rust version a real boost by doing a semantic search without doing any embedding work.
As an aside, while the millisecond differences shown here may mean relatively little for our users, whose latency will be dominated by the network in between, when typing, every millisecond more or less can make a difference in user perception. Also search-as-you-type generates between three and five times as much load as a plain search, so the service will experience more traffic. Less time per request means being able to handle more of them.
Mission accomplished! But wait, there’s more!
### Prioritizing Exact Matches and Headings
To improve on the quality of the results, Qdrant can do multiple searches in parallel, and then the service puts the results in sequence, taking the first best matches. The extended code searches:
  1. Text matches in titles
  2. Text matches in body (paragraphs or lists)
  3. Semantic matches in titles
  4. Any Semantic matches
Those are put together by taking them in the above order, deduplicating as necessary.
![merge workflow](https://qdrant.tech/articles_data/search-as-you-type/sayt_merge.png)
Instead of sending a `search` or `recommend` request, one can also send a `search/batch` or `recommend/batch` request, respectively. Each of those contain a `"searches"` property with any number of search/recommend JSON requests:
```
POST collections/site/points/search/batch
{
  "searches": [
    {
      "vector": [-0.06716014,-0.056464013, ...],
      "filter": {
        "must": [ 
          { "key": "text", "match": { "text": <query> }},
          { "key": "tag", "match": { "any": ["h1", "h2", "h3"] }},
        ]
      }
      ...,
    },
    {
      "vector": [-0.06716014,-0.056464013, ...],
      "filter": {
        "must": [ { "key": "body", "match": { "text": <query> }} ]
      }
      ...,
    },
    {
      "vector": [-0.06716014,-0.056464013, ...],
      "filter": {
        "must": [ { "key": "tag", "match": { "any": ["h1", "h2", "h3"] }} ]
      }
      ...,
    },
    {
      "vector": [-0.06716014,-0.056464013, ...],
      ...,
    },
  ]
}

```
As the queries are done in a batch request, there isn’t any additional network overhead and only very modest computation overhead, yet the results will be better in many cases.
The only additional complexity is to flatten the result lists and take the first 5 results, deduplicating by point ID. Now there is one final problem: The query may be short enough to take the recommend code path, but still not be in the prefix cache. In that case, doing the search _sequentially_ would mean two round-trips between the service and the Qdrant instance. The solution is to _concurrently_ start both requests and take the first successful non-empty result.
![sequential vs. concurrent flow](https://qdrant.tech/articles_data/search-as-you-type/sayt_concurrency.png)
While this means more load for the Qdrant vector search engine, this is not the limiting factor. The relevant data is already in cache in many cases, so the overhead stays within acceptable bounds, and the maximum latency in case of prefix cache misses is measurably reduced.
The code is available on the 
To sum up: Rust is fast, recommend lets us use precomputed embeddings, batch requests are awesome and one can do a semantic search in mere milliseconds.
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/search-as-you-type.md) this page on GitHub, or 
On this page:
  *     * [Prioritizing Exact Matches and Headings](https://qdrant.tech/articles/search-as-you-type/#prioritizing-exact-matches-and-headings)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/search-as-you-type/)
                    ## 📄 `https-qdrant-tech-articles-search-feedback-loop.md`
                    ```md
                    # https://qdrant.tech/articles/search-feedback-loop/
  * [Articles](https://qdrant.tech/articles/)
  * Relevance Feedback in Informational Retrieval
# Relevance Feedback in Informational Retrieval
Evgeniya Sukhodolskaya
·
March 27, 2025
![Relevance Feedback in Informational Retrieval](https://qdrant.tech/articles_data/search-feedback-loop/preview/title.jpg)
> A problem well stated is a problem half solved.
This quote applies as much to life as it does to information retrieval.
With a well-formulated query, retrieving the relevant document becomes trivial. In reality, however, most users struggle to precisely define what they are searching for.
While users may struggle to formulate a perfect request — especially in unfamiliar topics — they can easily judge whether a retrieved answer is relevant or not.
**Relevance is a powerful feedback mechanism for a retrieval system** to iteratively refine results in the direction of user interest.
In 2025, with social media flooded with daily AI breakthroughs, it almost seems like information retrieval is solved, agents can iteratively adjust their search queries while assessing the relevance.
Of course, there’s a catch: these models still rely on retrieval systems (_RAG isn’t dead yet, despite daily predictions of its demise_). They receive only a handful of top-ranked results provided by a far simpler and cheaper retriever. As a result, the success of guided retrieval still mainly depends on the retrieval system itself.
So, we should find a way of effectively and efficiently incorporating relevance feedback directly into a retrieval system. In this article, we’ll explore the approaches proposed in the research literature and try to answer the following question:
_If relevance feedback in search is so widely studied and praised as effective, why is it practically not used in dedicated vector search solutions?_
## Dismantling the Relevance Feedback
Both industry and academia tend to reinvent the wheel here and there. So, we first took some time to study and categorize different methods — just in case there was something we could plug directly into Qdrant. The resulting taxonomy isn’t set in stone, but we aim to make it useful.
![Types of Relevance Feedback](https://qdrant.tech/articles_data/search-feedback-loop/relevance-feedback.png)
Types of Relevance Feedback
### Pseudo-Relevance Feedback (PRF)
Pseudo-Relevance feedback takes the top-ranked documents from the initial retrieval results and treats them as relevant. This approach might seem naive, but it provides a noticeable performance boost in lexical retrieval while being relatively cheap to compute.
### Binary Relevance Feedback
The most straightforward way to gather feedback is to ask users directly if document is relevant. There are two main limitations to this approach:
First, users are notoriously reluctant to provide feedback. Did you know that 
Second, even if users are willing to provide feedback, no relevant documents might be present in the initial retrieval results. In this case, the user can’t provide a meaningful signal.
Instead of asking users, we can ask a smart model to provide binary relevance judgements, but this would limit its potential to generate granular judgements.
### Re-scored Relevance Feedback
We can also apply more sophisticated methods to extract relevance feedback from the top-ranked documents - machine learning models can provide a relevance score for each document.
The obvious concern here is twofold:
  1. How accurately can the automated judge determine relevance (or irrelevance)?
  2. How cost-efficient is it? After all, you can’t expect GPT-4o to re-rank thousands of documents for every user query — unless you’re filthy rich.
Nevertheless, automated re-scored feedback could be a scalable way to improve search when explicit binary feedback is not accessible.
## Has the Problem Already Been Solved?
Digging through research materials, we expected anything else but to discover that the first relevance feedback study dates back 
**Neural search** — aka [vector search](https://qdrant.tech/articles/neural-search-tutorial/) — gained traction in the industry around 5 years ago. Hence, vector-specific relevance feedback techniques might still be in their early stages, awaiting production-grade validation and industry adoption.
As a [dedicated vector search engine](https://qdrant.tech/articles/dedicated-vector-search/), we would like to be these adopters. Our focus is neural search, but approaches in both lexical and neural retrieval seem worth exploring, as cross-field studies are always insightful, with the potential to reuse well-established methods of one field in another.
We found some interesting methods applicable to neural search solutions and additionally revealed a **gap in the neural search-based relevance feedback approaches**. Stick around, and we’ll share our findings!
## Two Ways to Approach the Problem
Retrieval as a recipe can be broken down into three main ingredients:
  1. Query
  2. Documents
  3. Similarity scoring between them.
![Research Field Taxonomy Overview](https://qdrant.tech/articles_data/search-feedback-loop/taxonomy-overview.png)
Research Field Taxonomy Overview
Query formulation is a subjective process – it can be done in infinite configurations, making the relevance of a document unpredictable until the query is formulated and submitted to the system.
So, adapting documents (or the search index) to relevance feedback would require per-request dynamic changes, which is impractical, considering that modern retrieval systems store billions of documents.
Thus, approaches for incorporating relevance feedback in search fall into two categories: **refining a query** and **refining the similarity scoring function** between the query and documents.
## Query Refinement
There are several ways to refine a query based on relevance feedback. Globally, we prefer to distinguish between two approaches: modifying the query as text and modifying the vector representation of the query.
![Incorporating Relevance Feedback in Query](https://qdrant.tech/articles_data/search-feedback-loop/query.png)
Incorporating Relevance Feedback in Query
### Query As Text
In **term-based retrieval** , an intuitive way to improve a query would be to **expand it with relevant terms**. It resembled the “ _aha, so that’s what it’s called_ ” stage in the discovery search.
Before the deep learning era of this century, expansion terms were mainly selected using statistical or probabilistic models. The idea was to:
  1. Either extract the **most frequent** terms from (pseudo-)relevant documents;
  2. Or the **most specific** ones (for example, according to IDF);
  3. Or the **most probable** ones (most likely to be in query according to a relevance set).
Well-known methods of those times come from the family of 
The most famous one, `RM3` – interpolation of expansion terms probability with their probability in a query – is still appearing in papers of the last few years as a (noticeably decent) baseline in term-based retrieval, usually as part of 
![Simplified Query Expansion](https://qdrant.tech/articles_data/search-feedback-loop/relevance-models.png)
Simplified Query Expansion
With the time approaching the modern machine learning era, 
Started with simple classifiers based on hand-crafted features, this trend naturally led to use the famous `BERT-QE` (Query Expansion) authors came up with this schema:
  1. Get pseudo-relevance feedback from the finetuned BERT reranker (~10 documents);
  2. Chunk these pseudo-relevant documents (~100 words) and score query-chunk relevance with the same reranker;
  3. Expand the query with the most relevant chunks;
  4. Rerank 1000 documents with the reranker using the expanded query.
This approach significantly outperformed BM25 + RM3 baseline in experiments (+11% NDCG@20). However, it required **11.01x** more computation than just using BERT for reranking, and reranking 1000 documents with BERT would take around 9 seconds alone.
Query term expansion can _hypothetically_ work for neural retrieval as well. New terms might shift the query vector closer to that of the desired document. However, 
It definitely works if **query refining is done by a model operating in the same vector space** , which typically requires offline training of a retriever. The goal is to extend the query encoder input to also include feedback documents, producing an adjusted query embedding. Examples include 
![Generating a new relevance-aware query vector](https://qdrant.tech/articles_data/search-feedback-loop/updated-encoder.png)
Generating a new relevance-aware query vector
The reason why you’re most probably not familiar with these models – their absence in the industry – is that their **training** itself is a **high upfront cost** , and even though it was “paid”, these models 
Alternatively, one could skip a step — and work directly with vectors.
### Query As Vector
Instead of modifying the initial query, a more scalable approach is to directly adjust the query vector. It is easily applicable across modalities and suitable for both lexical and neural retrieval.
Although vector search has become a trend in recent years, its core principles have existed in the field for decades. For example, the SMART retrieval system used by 
![Roccio’s Relevance Feedback Method](https://qdrant.tech/articles_data/search-feedback-loop/Roccio.png)
Roccio’s Relevance Feedback Method
**Rocchio’s idea** — to update the query vector by adding a difference between the centroids of relevant and non-relevant documents — seems to translate well to modern dual encoders-based dense retrieval systems. Researchers seem to agree: a study from 2022 demonstrated that the 
However, parameters (centroids and query weights) in the dense retrieval version of Roccio’s method must be tuned for each dataset and, ideally, also for each request.
#### Gradient Descent-Based Methods
The efficient way of doing so on-the-fly remained an open question until the introduction of a **gradient-descent-based Roccio’s method generalization** : _retrieve → rerank → gradient descent step_), guided by a reranker’s relevance judgments.
![An overview of TOUR iteratively optimizing initial query representation based on pseudo relevance feedback.
Figure adapted from Sung et al., 2023, Optimizing Test-Time Query Representations for Dense Retrieval](https://qdrant.tech/articles_data/search-feedback-loop/TOUR.png)
An overview of TOUR iteratively optimizing initial query representation based on pseudo relevance feedback.  
Figure adapted from Sung et al., 2023, 
The next iteration of gradient-based methods of query refinement – _retrieve → rerank → gradient descent_ sequence to only one iteration. The retriever’s query vector is updated through matching (via 
![An overview of ReFit, a gradient-based method for query refinement](https://qdrant.tech/articles_data/search-feedback-loop/refit.png)
An overview of ReFit, a gradient-based method for query refinement
Gradient descent-based methods seem like a production-viable option, an alternative to finetuning the retriever (distilling it from a reranker). Indeed, it doesn’t require in-advance training and is compatible with any re-ranking models.
However, a few limitations baked into these methods prevented a broader adoption in the industry.
The gradient descent-based methods modify elements of the query vector as if it were model parameters; therefore, they require a substantial amount of feedback documents to converge to a stable solution.
On top of that, the gradient descent-based methods are sensitive to the choice of hyperparameters, leading to **query drift** , where the query may drift entirely away from the user’s intent.
## Similarity Scoring
![Incorporating Relevance Feedback in Similarity Scoring](https://qdrant.tech/articles_data/search-feedback-loop/similairty-scoring.png)
Incorporating Relevance Feedback in Similarity Scoring
Another family of approaches is built around the idea of incorporating relevance feedback directly into the similarity scoring function. It might be desirable in cases where we want to preserve the original query intent, but still adjust the similarity score based on relevance feedback.
In **lexical retrieval** , this can be as simple as boosting documents that share more terms with those judged as relevant.
Its **neural search counterpart** is a 
In experiments, the knn-based method is treated as a reranker. In all other papers, we also found that adjusting similarity scores based on relevance feedback is centred around [reranking](https://qdrant.tech/documentation/search-precision/reranking-semantic-search/) – **training or finetuning rerankers to become relevance feedback-aware**. Typically, experiments include cross-encoders, though 
Methods typically fall into two categories:
  1. **Training rerankers offline** to ingest relevance feedback as an additional input at inference time, 
  2. **Finetuning rerankers** on relevance feedback from the first retrieval stage, 
The biggest limitation here is that these reranker-based methods cannot retrieve relevant documents beyond those returned in the initial search, and using rerankers on thousands of documents in production is a no-go – it’s too expensive. Ideally, to avoid that, a similarity scoring function updated with relevance feedback should be used directly in the second retrieval iteration. However, in every research paper we’ve come across, retrieval systems are **treated as black boxes** — ingesting queries, returning results, and offering no built-in mechanism to modify scoring.
## So, what are the takeaways?
Pseudo Relevance Feedback (PRF) is known to improve the effectiveness of lexical retrievers. Several PRF-based approaches – mainly query terms expansion-based – are successfully integrated into traditional retrieval systems. At the same time, there are **no known industry-adopted analogues in neural (vector) search dedicated solutions** ; neural search-compatible methods remain stuck in research papers.
The gap we noticed while studying the field is that researchers have **no direct access to retrieval systems** , forcing them to design wrappers around the black-box-like retrieval oracles. This is sufficient for query-adjusting methods but not for similarity scoring function adjustment.
Perhaps relevance feedback methods haven’t made it into the neural search systems for trivial reasons — like no one having the time to find the right balance between cost and efficiency.
Getting it to work in a production setting means experimenting, building interfaces, and adapting architectures. Simply put, it needs to look worth it. And unlike 2D vector math, high-dimensional vector spaces are anything but intuitive. The curse of dimensionality is real. So is query drift. Even methods that make perfect sense on paper might not work in practice.
A real-world solution should be simple. Maybe just a little bit smarter than a rule-based approach, but still practical. It shouldn’t require fine-tuning thousands of parameters or feeding paragraphs of text into transformers. **And for it to be effective, it needs to be integrated directly into the retrieval system itself.**
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/search-feedback-loop.md) this page on GitHub, or 
On this page:
  * [Dismantling the Relevance Feedback](https://qdrant.tech/articles/search-feedback-loop/#dismantling-the-relevance-feedback)
    * [Pseudo-Relevance Feedback (PRF)](https://qdrant.tech/articles/search-feedback-loop/#pseudo-relevance-feedback-prf)
    * [Binary Relevance Feedback](https://qdrant.tech/articles/search-feedback-loop/#binary-relevance-feedback)
    * [Re-scored Relevance Feedback](https://qdrant.tech/articles/search-feedback-loop/#re-scored-relevance-feedback)
  * [Has the Problem Already Been Solved?](https://qdrant.tech/articles/search-feedback-loop/#has-the-problem-already-been-solved)
  * [Two Ways to Approach the Problem](https://qdrant.tech/articles/search-feedback-loop/#two-ways-to-approach-the-problem)
  * [Query Refinement](https://qdrant.tech/articles/search-feedback-loop/#query-refinement)
    * [Query As Text](https://qdrant.tech/articles/search-feedback-loop/#query-as-text)
    * [Query As Vector](https://qdrant.tech/articles/search-feedback-loop/#query-as-vector)
  * [Similarity Scoring](https://qdrant.tech/articles/search-feedback-loop/#similarity-scoring)
  * [So, what are the takeaways?](https://qdrant.tech/articles/search-feedback-loop/#so-what-are-the-takeaways)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/search-feedback-loop/)
                    ## 📄 `https-qdrant-tech-articles-semantic-cache-ai-data-retrieval.md`
                    ```md
                    # https://qdrant.tech/articles/semantic-cache-ai-data-retrieval/
  * [Articles](https://qdrant.tech/articles/)
  * Semantic Cache: Accelerating AI with Lightning-Fast Data Retrieval
# Semantic Cache: Accelerating AI with Lightning-Fast Data Retrieval
Daniel Romero, David Myriel
·
May 07, 2024
![Semantic Cache: Accelerating AI with Lightning-Fast Data Retrieval](https://qdrant.tech/articles_data/semantic-cache-ai-data-retrieval/preview/title.jpg)
## What is Semantic Cache?
**Semantic cache** is a method of retrieval optimization, where similar queries instantly retrieve the same appropriate response from a knowledge base.
Semantic cache differs from traditional caching methods. In computing, **cache** refers to high-speed memory that efficiently stores frequently accessed data. In the context of [vector databases](https://qdrant.tech/articles/what-is-a-vector-database/), a **semantic cache** improves AI application performance by storing previously retrieved results along with the conditions under which they were computed. This allows the application to reuse those results when the same or similar conditions occur again, rather than finding them from scratch.
> The term **“semantic”** implies that the cache takes into account the meaning or semantics of the data or computation being cached, rather than just its syntactic representation. This can lead to more efficient caching strategies that exploit the structure or relationships within the data or computation.
![semantic-cache-question](https://qdrant.tech/articles_data/semantic-cache-ai-data-retrieval/semantic-cache-question.png)
Traditional caches operate on an exact match basis, while semantic caches search for the meaning of the key rather than an exact match. For example, **“What is the capital of Brazil?”** and **“Can you tell me the capital of Brazil?”** are semantically equivalent, but not exact matches. A semantic cache recognizes such semantic equivalence and provides the correct result.
In this blog and video, we will walk you through how to use Qdrant to implement a basic semantic cache system. You can also try the 
## Semantic Cache in RAG: the Key-Value Mechanism
Semantic cache is increasingly used in Retrieval-Augmented Generation (RAG) applications. In RAG, when a user asks a question, we embed it and search our vector database, either by using keyword, semantic, or hybrid search methods. The matched context is then passed to a Language Model (LLM) along with the prompt and user question for response generation.
Qdrant is recommended for setting up semantic cache as semantically [evaluates](https://qdrant.tech/rag/rag-evaluation-guide/) the response. When semantic cache is implemented, we store common questions and their corresponding answers in a key-value cache. This way, when a user asks a question, we can retrieve the response from the cache if it already exists.
**Diagram:** Semantic cache improves [RAG](https://qdrant.tech/rag/rag-evaluation-guide/) by directly retrieving stored answers to the user. **Follow along with the gif** and see how semantic cache stores and retrieves answers.
![Alt Text](https://qdrant.tech/articles_data/semantic-cache-ai-data-retrieval/semantic-cache.gif)
When using a key-value cache, it’s important to consider that slight variations in question wording can lead to different hash values. The two questions convey the same query but differ in wording. A naive cache search might fail due to distinct hashed versions of the questions. Implementing a more nuanced approach is necessary to accommodate phrasing variations and ensure accurate responses.
To address this challenge, a semantic cache can be employed instead of relying solely on exact matches. This entails storing questions, answers, and their embeddings in a key-value structure.
When a user poses a question, a semantic search by Qdrant is conducted across all cached questions to identify the most similar one. If the similarity score surpasses a predefined threshold, the system assumes equivalence between the user’s question and the matched one, providing the corresponding answer accordingly.
## Benefits of Semantic Cache for AI Applications
Semantic cache contributes to scalability in AI applications by making it simpler to retrieve common queries from vast datasets. The retrieval process can be computationally intensive and implementing a cache component can reduce the load.
For instance, if hundreds of users repeat the same question, the system can retrieve the precomputed answer from the cache rather than re-executing the entire process. This cache stores questions as keys and their corresponding answers as values, providing an efficient means to handle repeated queries.
> There are **potential cost savings** associated with utilizing semantic cache. Using a semantic cache eliminates the need for repeated searches and generation processes for similar or duplicate questions, thus saving time and LLM API resources, especially when employing costly language model calls like OpenAI’s.
## When to Use Semantic Cache?
For applications like question-answering systems where facts are retrieved from documents, caching is beneficial due to the consistent nature of the queries. _However, for text generation tasks requiring varied responses, caching may not be ideal as it returns previous responses, potentially limiting variation._ Thus, the decision to use caching depends on the specific use case.
Using a cache might not be ideal for applications where diverse responses are desired across multiple queries. However, in question-answering systems, caching is advantageous since variations are insignificant. It serves as an effective performance optimization tool for chatbots by storing frequently accessed data.
One strategy involves creating ad-hoc patches for chatbot dialogues, where commonly asked questions are pre-mapped to prepared responses in the cache. This allows the chatbot to swiftly retrieve and deliver responses without relying on a Language Model (LLM) for each query.
## Implement Semantic Cache: A Step-by-Step Guide
The first part of this video explains how caching works. In the second part, you can follow along with the code with our 
## Embrace the Future of AI Data Retrieval
[documentation](https://qdrant.tech/documentation/cloud/).
You can also deploy Qdrant locally and manage via our UI. To do this, check our [Hybrid Cloud](https://qdrant.tech/blog/hybrid-cloud/)!
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/semantic-cache-ai-data-retrieval.md) this page on GitHub, or 
On this page:
  * [What is Semantic Cache?](https://qdrant.tech/articles/semantic-cache-ai-data-retrieval/#what-is-semantic-cache)
  * [Semantic Cache in RAG: the Key-Value Mechanism](https://qdrant.tech/articles/semantic-cache-ai-data-retrieval/#semantic-cache-in-rag-the-key-value-mechanism)
  * [Benefits of Semantic Cache for AI Applications](https://qdrant.tech/articles/semantic-cache-ai-data-retrieval/#benefits-of-semantic-cache-for-ai-applications)
  * [When to Use Semantic Cache?](https://qdrant.tech/articles/semantic-cache-ai-data-retrieval/#when-to-use-semantic-cache)
  * [Implement Semantic Cache: A Step-by-Step Guide](https://qdrant.tech/articles/semantic-cache-ai-data-retrieval/#implement-semantic-cache-a-step-by-step-guide)
  * [Embrace the Future of AI Data Retrieval](https://qdrant.tech/articles/semantic-cache-ai-data-retrieval/#embrace-the-future-of-ai-data-retrieval)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/semantic-cache-ai-data-retrieval/)
                    ## 📄 `https-qdrant-tech-articles-serverless.md`
                    ```md
                    # https://qdrant.tech/articles/serverless/
  * [Articles](https://qdrant.tech/articles/)
  * Serverless Semantic Search
# Serverless Semantic Search
Andre Bogus
·
July 12, 2023
![Serverless Semantic Search](https://qdrant.tech/articles_data/serverless/preview/title.jpg)
Do you want to insert a semantic search function into your website or online app? Now you can do so - without spending any money! In this example, you will learn how to create a free prototype search engine for your own non-commercial purposes.
## Ingredients
  * A 
  * `cargo install cargo-lambda`)
  * The 
  * Qdrant instance (
  * An embedding provider service of your choice (see our [Embeddings docs](https://qdrant.tech/documentation/embeddings/). You may be able to get credits from 
  * AWS Lambda account (12-month free tier available)
## What you’re going to build
You’ll combine the embedding provider and the Qdrant instance to a neat semantic search, calling both services from a small Lambda function.
![lambda integration diagram](https://qdrant.tech/articles_data/serverless/lambda_integration.png)
Now lets look at how to work with each ingredient before connecting them.
## Rust and cargo-lambda
You want your function to be quick, lean and safe, so using Rust is a no-brainer. To compile Rust code for use within Lambda functions, the `cargo-lambda` subcommand has been built. `cargo-lambda` can put your Rust code in a zip file that AWS Lambda can then deploy on a no-frills `provided.al2` runtime.
To interface with AWS Lambda, you will need a Rust project with the following dependencies in your `Cargo.toml`:
```
[dependencies]
tokio = { version = "1", features = ["macros"] }
lambda_http = { version = "0.8", default-features = false, features = ["apigw_http"] }
lambda_runtime = "0.8"

```
This gives you an interface consisting of an entry point to start the Lambda runtime and a way to register your handler for HTTP calls. Put the following snippet into `src/helloworld.rs`:
```
uselambda_http::{run,service_fn,Body,Error,Request,RequestExt,Response};/// This is your callback function for responding to requests at your URL
asyncfn function_handler(_req: Request)Result<Response<Body>,Error>{Response::from_text("Hello, Lambda!")}#[tokio::main]asyncfn main(){run(service_fn(function_handler)).await}
```
You can also use a closure to bind other arguments to your function handler (the `service_fn` call then becomes `service_fn(|req| function_handler(req, ...))`). Also if you want to extract parameters from the request, you can do so using the `query_string_parameters` or `query_string_parameters_ref`).
Add the following to your `Cargo.toml` to define the binary:
```
[[bin]]
name = "helloworld"
path = "src/helloworld.rs"

```
On the AWS side, you need to setup a Lambda and IAM role to use with your function.
![create lambda web page](https://qdrant.tech/articles_data/serverless/create_lambda.png)
Choose your function name, select “Provide your own bootstrap on Amazon Linux 2”. As architecture, use `arm64`. You will also activate a function URL. Here it is up to you if you want to protect it via IAM or leave it open, but be aware that open end points can be accessed by anyone, potentially costing money if there is too much traffic.
By default, this will also create a basic role. To look up the role, you can go into the Function overview:
![function overview](https://qdrant.tech/articles_data/serverless/lambda_overview.png)
Click on the “Info” link near the “▸ Function overview” heading, and select the “Permissions” tab on the left.
You will find the “Role name” directly under _Execution role_. Note it down for later.
![function overview](https://qdrant.tech/articles_data/serverless/lambda_role.png)
To test that your “Hello, Lambda” service works, you can compile and upload the function:
```
$ export LAMBDA_FUNCTION_NAME=hello
$ export LAMBDA_ROLE=<role name from lambda web ui>
$ export LAMBDA_REGION=us-east-1
$ cargo lambda build --release --arm --bin helloworld --output-format zip
  Downloaded libc v0.2.137
# [..] output omitted for brevity
    Finished release [optimized] target(s) in 1m 27s
$ # Delete the old empty definition
$ aws lambda delete-function-url-config --region $LAMBDA_REGION --function-name $LAMBDA_FUNCTION_NAME
$ aws lambda delete-function --region $LAMBDA_REGION --function-name $LAMBDA_FUNCTION_NAME
$ # Upload the function
$ aws lambda create-function --function-name $LAMBDA_FUNCTION_NAME \
\
\
\
\
$LAMBDA_REGION \
$LAMBDA_ROLE \
Mode=Active
$ # Add the function URL
$ aws lambda add-permission \
$LAMBDA_FUNCTION_NAME \
\
"*" \
"NONE" \
$LAMBDA_REGION \
$ # Here for simplicity unauthenticated URL access. Beware!
$ aws lambda create-function-url-config \
$LAMBDA_FUNCTION_NAME \
$LAMBDA_REGION \
"AllowOrigins=*,AllowMethods=*,AllowHeaders=*" \

```
Now you can go to your _Function Overview_ and click on the Function URL. You should see something like this:
```
Hello, Lambda!

```
Bearer ! You have set up a Lambda function in Rust. On to the next ingredient:
## Embedding
Most providers supply a simple https GET or POST interface you can use with an API key, which you have to supply in an authentication header. If you are using this for non-commercial purposes, the rate limited trial key from Cohere is just a few clicks away. Go to [cohere dashboard](https://qdrant.tech/articles_data/serverless/cohere-dashboard.png)
From there you can click on the ⎘ symbol next to your API key to copy it to the clipboard. _Don’t put your API key in the code!_ Instead read it from an env variable you can set in the lambda environment. This avoids accidentally putting your key into a public repo. Now all you need to get embeddings is a bit of code. First you need to extend your dependencies with `reqwest` and also add `anyhow` for easier error handling:
```
anyhow = "1.0"
reqwest =  { version = "0.11.18", default-features = false, features = ["json", "rustls-tls"] }
serde = "1.0"

```
Now given the API key from above, you can make a call to get the embedding vectors:
```
useanyhow::Result;useserde::Deserialize;usereqwest::Client;#[derive(Deserialize)]struct CohereResponse{outputs: Vec<Vec<f32>>}pubasyncfn embed(client: &Client,text: &str,api_key: &str)Result<Vec<Vec<f32>>>{letCohereResponse{outputs}=client.post("https://api.cohere.ai/embed").header("Authorization",&format!("Bearer {api_key}")).header("Content-Type","application/json").header("Cohere-Version","2021-11-08").body(format!("{{\"text\":[\"{text}\"],\"model\":\"small\"}}")).send().await?.json().await?;Ok(outputs)}
```
Note that this may return multiple vectors if the text overflows the input dimensions. Cohere’s `small` model has 1024 output dimensions.
Other providers have similar interfaces. Consult our [Embeddings docs](https://qdrant.tech/documentation/embeddings/) for further information. See how little code it took to get the embedding?
While you’re at it, it’s a good idea to write a small test to check if embedding works and the vectors are of the expected size:
```
#[tokio::test]asyncfn check_embedding(){// ignore this test if API_KEY isn't set
letOk(api_key)=&std::env::var("API_KEY")else{return;}letembedding=crate::embed("What is semantic search?",api_key).unwrap()[0];// Cohere's `small` model has 1024 output dimensions.
assert_eq!(1024,embedding.len());}
```
Run this while setting the `API_KEY` environment variable to check if the embedding works.
## Qdrant search
Now that you have embeddings, it’s time to put them into your Qdrant. You could of course use `curl` or `python` to set up your collection and upload the points, but as you already have Rust including some code to obtain the embeddings, you can stay in Rust, adding `qdrant-client` to the mix.
```
useanyhow::Result;useqdrant_client::prelude::*;useqdrant_client::qdrant::{VectorsConfig,VectorParams};useqdrant_client::qdrant::vectors_config::Config;usestd::collections::HashMap;fn setup<'i>(embed_client: &reqwest::Client,embed_api_key: &str,qdrant_url: &str,api_key: Option<&str>,collection_name: &str,data: implIterator<Item=(&'istr,HashMap<String,Value>)>,)Result<()>{letmutconfig=QdrantClientConfig::from_url(qdrant_url);config.api_key=api_key;letclient=QdrantClient::new(Some(config))?;// create the collections
if!client.has_collection(collection_name).await?{client.create_collection(&CreateCollection{collection_name: collection_name.into(),vectors_config: Some(VectorsConfig{config: Some(Config::Params(VectorParams{size: 1024,// output dimensions from above
distance: Distance::Cosineasi32,..Default::default()})),}),..Default::default()}).await?;}letmutid_counter=0_u64;letpoints=data.map(|(text,payload)|{letid=std::mem::replace(&mutid_counter,*id_counter+1);letvectors=Some(embed(embed_client,text,embed_api_key).unwrap());PointStruct{id,vectors,payload}}).collect();client.upsert_points(collection_name,points,None).await?;Ok(())}
```
Depending on whether you want to efficiently filter the data, you can also add some indexes. I’m leaving this out for brevity. Also this does not implement chunking (splitting the data to upsert in multiple requests, which avoids timeout errors).
Add a suitable `main` method and you can run this code to insert the points (or just use the binary from the example). Be sure to include the port in the `qdrant_url`.
Now that you have the points inserted, you can search them by embedding:
```
useanyhow::Result;useqdrant_client::prelude::*;pubasyncfn search(text: &str,collection_name: String,client: &Client,api_key: &str,qdrant: &QdrantClient,)Result<Vec<ScoredPoint>>{Ok(qdrant.search_points(&SearchPoints{collection_name,limit: 5,// use what fits your use case here
with_payload: Some(true.into()),vector: embed(client,text,api_key)?,..Default::default()}).await?.result)}
```
You can also filter by adding a `filter: ...` field to the `SearchPoints`, and you will likely want to process the result further, but the example code already does that, so feel free to start from there in case you need this functionality.
## Putting it all together
Now that you have all the parts, it’s time to join them up. Now copying and wiring up the snippets above is left as an exercise to the reader.
You’ll want to extend the `main` method a bit to connect with the Client once at the start, also get API keys from the environment so you don’t need to compile them into the code. To do that, you can get them with `std::env::var(_)` from the rust code and set the environment from the AWS console.
```
$ export QDRANT_URI=<qour Qdrant instance URI including port>
$ export QDRANT_API_KEY=<your Qdrant API key>
$ export COHERE_API_KEY=<your Cohere API key>
$ export COLLECTION_NAME=site-cohere
$ aws lambda update-function-configuration \
$LAMBDA_FUNCTION_NAME \
"Variables={QDRANT_URI=$QDRANT_URI,\
        QDRANT_API_KEY=$QDRANT_API_KEY,COHERE_API_KEY=${COHERE_API_KEY},\
        COLLECTION_NAME=${COLLECTION_NAME}"`

```
In any event, you will arrive at one command line program to insert your data and one Lambda function. The former can just be `cargo run` to set up the collection. For the latter, you can again call `cargo lambda` and the AWS console:
```
$ export LAMBDA_FUNCTION_NAME=search
$ export LAMBDA_REGION=us-east-1
$ cargo lambda build --release --arm --output-format zip
  Downloaded libc v0.2.137
# [..] output omitted for brevity
    Finished release [optimized] target(s) in 1m 27s
$ # Update the function
$ aws lambda update-function-code --function-name $LAMBDA_FUNCTION_NAME \
\
$LAMBDA_REGION

```
## Discussion
Lambda works by spinning up your function once the URL is called, so they don’t need to keep the compute on hand unless it is actually used. This means that the first call will be burdened by some 1-2 seconds of latency for loading the function, later calls will resolve faster. Of course, there is also the latency for calling the embeddings provider and Qdrant. On the other hand, the free tier doesn’t cost a thing, so you certainly get what you pay for. And for many use cases, a result within one or two seconds is acceptable.
Rust minimizes the overhead for the function, both in terms of file size and runtime. Using an embedding service means you don’t need to care about the details. Knowing the URL, API key and embedding size is sufficient. Finally, with free tiers for both Lambda and Qdrant as well as free credits for the embedding provider, the only cost is your time to set everything up. Who could argue with free?
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/serverless.md) this page on GitHub, or 
On this page:
  * [Ingredients](https://qdrant.tech/articles/serverless/#ingredients)
  * [What you’re going to build](https://qdrant.tech/articles/serverless/#what-youre-going-to-build)
  * [Rust and cargo-lambda](https://qdrant.tech/articles/serverless/#rust-and-cargo-lambda)
  * [Embedding](https://qdrant.tech/articles/serverless/#embedding)
  * [Qdrant search](https://qdrant.tech/articles/serverless/#qdrant-search)
  * [Putting it all together](https://qdrant.tech/articles/serverless/#putting-it-all-together)
  * [Discussion](https://qdrant.tech/articles/serverless/#discussion)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/serverless/)
                    ## 📄 `https-qdrant-tech-articles-sparse-vectors.md`
                    ```md
                    # https://qdrant.tech/articles/sparse-vectors/
  * [Articles](https://qdrant.tech/articles/)
  * What is a Sparse Vector? How to Achieve Vector-based Hybrid Search
# What is a Sparse Vector? How to Achieve Vector-based Hybrid Search
Nirant Kasliwal
·
December 09, 2023
![What is a Sparse Vector? How to Achieve Vector-based Hybrid Search](https://qdrant.tech/articles_data/sparse-vectors/preview/title.jpg)
Think of a library with a vast index card system. Each index card only has a few keywords marked out (sparse vector) of a large possible set for each book (document). This is what sparse vectors enable for text.
## What are sparse and dense vectors?
Sparse vectors are like the Marie Kondo of data—keeping only what sparks joy (or relevance, in this case).
Consider a simplified example of 2 documents, each with 200 words. A dense vector would have several hundred non-zero values, whereas a sparse vector could have, much fewer, say only 20 non-zero values.
In this example: We assume it selects only 2 words or tokens from each document. The rest of the values are zero. This is why it’s called a sparse vector.
```
dense = [0.2, 0.3, 0.5, 0.7, ...]  # several hundred floats
sparse = [{331: 0.5}, {14136: 0.7}]  # 20 key value pairs

```
The numbers 331 and 14136 map to specific tokens in the vocabulary e.g. `['chocolate', 'icecream']`. The rest of the values are zero. This is why it’s called a sparse vector.
The tokens aren’t always words though, sometimes they can be sub-words: `['ch', 'ocolate']` too.
They’re pivotal in information retrieval, especially in ranking and search systems. BM25, a standard ranking function used by search engines like 
BM25’s capabilities are well-established, yet it has its limitations.
BM25 relies solely on the frequency of words in a document and does not attempt to comprehend the meaning or the contextual importance of the words. Additionally, it requires the computation of the entire corpus’s statistics in advance, posing a challenge for large datasets.
Sparse vectors harness the power of neural networks to surmount these limitations while retaining the ability to query exact words and phrases. They excel in handling large text data, making them crucial in modern data processing a and marking an advancement over traditional methods such as BM25.
## Understanding sparse vectors
Sparse Vectors are a representation where each dimension corresponds to a word or subword, greatly aiding in interpreting document rankings. This clarity is why sparse vectors are essential in modern search and recommendation systems, complimenting the meaning-rich embedding or dense vectors.
Dense vectors from models like OpenAI Ada-002 or Sentence Transformers contain non-zero values for every element. In contrast, sparse vectors focus on relative word weights per document, with most values being zero. This results in a more efficient and interpretable system, especially in text-heavy applications like search.
Sparse Vectors shine in domains and scenarios where many rare keywords or specialized terms are present. For example, in the medical domain, many rare terms are not present in the general vocabulary, so general-purpose dense vectors cannot capture the nuances of the domain.
Feature | Sparse Vectors | Dense Vectors  
---|---|---  
**Data Representation** | Majority of elements are zero | All elements are non-zero  
**Computational Efficiency** | Generally higher, especially in operations involving zero elements | Lower, as operations are performed on all elements  
**Information Density** | Less dense, focuses on key features | Highly dense, capturing nuanced relationships  
**Example Applications** | Text search, Hybrid search |  [RAG](https://qdrant.tech/articles/what-is-rag-in-ai/), many general machine learning tasks  
Where do sparse vectors fail though? They’re not great at capturing nuanced relationships between words. For example, they can’t capture the relationship between “king” and “queen” as well as dense vectors.
## SPLADE
Let’s check out 
Model | MRR@10 (MS MARCO Dev) | Type  
---|---|---  
BM25 | 0.184 | Sparse  
TCT-ColBERT | 0.359 | Dense  
doc2query-T5  | 0.277 | Sparse  
SPLADE | 0.322 | Sparse  
SPLADE-max | 0.340 | Sparse  
SPLADE-doc | 0.322 | Sparse  
DistilSPLADE-max | 0.368 | Sparse  
All numbers are from 
SPLADE is quite flexible as a method, with regularization knobs that can be tuned to obtain 
> SPLADE is more a class of models rather than a model per se: depending on the regularization magnitude, we can obtain different models (from very sparse to models doing intense query/doc expansion) with different properties and performance.
First, let’s look at how to create a sparse vector. Then, we’ll look at the concepts behind SPLADE.
## Creating a sparse vector
We’ll explore two different ways to create a sparse vector. The higher performance way to create a sparse vector from dedicated document and query encoders. We’ll look at a simpler approach – here we will use the same model for both document and query. We will get a dictionary of token ids and their corresponding weights for a sample text - representing a document.
If you’d like to follow along, here’s a 
### Setting Up
```
from transformers import AutoModelForMaskedLM, AutoTokenizer
model_id = "naver/splade-cocondenser-ensembledistil"
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForMaskedLM.from_pretrained(model_id)
text = """Arthur Robert Ashe Jr. (July 10, 1943 – February 6, 1993) was an American professional tennis player. He won three Grand Slam titles in singles and two in doubles."""

```
### Computing the sparse vector
```
import torch
def compute_vector(text):
    """
    Computes a vector from logits and attention mask using ReLU, log, and max operations.
    """
    tokens = tokenizer(text, return_tensors="pt")
    output = model(**tokens)
    logits, attention_mask = output.logits, tokens.attention_mask
    relu_log = torch.log(1 + torch.relu(logits))
    weighted_log = relu_log * attention_mask.unsqueeze(-1)
    max_val, _ = torch.max(weighted_log, dim=1)
    vec = max_val.squeeze()
    return vec, tokens
vec, tokens = compute_vector(text)
print(vec.shape)

```
You’ll notice that there are 38 tokens in the text based on this tokenizer. This will be different from the number of tokens in the vector. In a TF-IDF, we’d assign weights only to these tokens or words. In SPLADE, we assign weights to all the tokens in the vocabulary using this vector using our learned model.
## Term expansion and weights
```
def extract_and_map_sparse_vector(vector, tokenizer):
    """
    Extracts non-zero elements from a given vector and maps these elements to their human-readable tokens using a tokenizer. The function creates and returns a sorted dictionary where keys are the tokens corresponding to non-zero elements in the vector, and values are the weights of these elements, sorted in descending order of weights.
    This function is useful in NLP tasks where you need to understand the significance of different tokens based on a model's output vector. It first identifies non-zero values in the vector, maps them to tokens, and sorts them by weight for better interpretability.
    Args:
    vector (torch.Tensor): A PyTorch tensor from which to extract non-zero elements.
    tokenizer: The tokenizer used for tokenization in the model, providing the mapping from tokens to indices.
    Returns:
    dict: A sorted dictionary mapping human-readable tokens to their corresponding non-zero weights.
    """
    # Extract indices and values of non-zero elements in the vector
    cols = vector.nonzero().squeeze().cpu().tolist()
    weights = vector[cols].cpu().tolist()
    # Map indices to tokens and create a dictionary
    idx2token = {idx: token for token, idx in tokenizer.get_vocab().items()}
    token_weight_dict = {
        idx2token[idx]: round(weight, 2) for idx, weight in zip(cols, weights)
    }
    # Sort the dictionary by weights in descending order
    sorted_token_weight_dict = {
        k: v
        for k, v in sorted(
            token_weight_dict.items(), key=lambda item: item[1], reverse=True
        )
    }
    return sorted_token_weight_dict
# Usage example
sorted_tokens = extract_and_map_sparse_vector(vec, tokenizer)
sorted_tokens

```
There will be 102 sorted tokens in total. This has expanded to include tokens that weren’t in the original text. This is the term expansion we will talk about next.
Here are some terms that are added: “Berlin”, and “founder” - despite having no mention of Arthur’s race (which leads to Owen’s Berlin win) and his work as the founder of Arthur Ashe Institute for Urban Health. Here are the top few `sorted_tokens` with a weight of more than 1:
```
{
    "ashe": 2.95,
    "arthur": 2.61,
    "tennis": 2.22,
    "robert": 1.74,
    "jr": 1.55,
    "he": 1.39,
    "founder": 1.36,
    "doubles": 1.24,
    "won": 1.22,
    "slam": 1.22,
    "died": 1.19,
    "singles": 1.1,
    "was": 1.07,
    "player": 1.06,
    "titles": 0.99, 
    ...
}

```
If you’re interested in using the higher-performance approach, check out the following models:
## Why SPLADE works: term expansion
Consider a query “solar energy advantages”. SPLADE might expand this to include terms like “renewable,” “sustainable,” and “photovoltaic,” which are contextually relevant but not explicitly mentioned. This process is called term expansion, and it’s a key component of SPLADE.
SPLADE learns the query/document expansion to include other relevant terms. This is a crucial advantage over other sparse methods which include the exact word, but completely miss the contextually relevant ones.
This expansion has a direct relationship with what we can control when making a SPLADE model: Sparsity via Regularisation. The number of tokens (BERT wordpieces) we use to represent each document. If we use more tokens, we can represent more terms, but the vectors become denser. This number is typically between 20 to 200 per document. As a reference point, the dense BERT vector is 768 dimensions, OpenAI Embedding is 1536 dimensions, and the sparse vector is 30 dimensions.
For example, assume a 1M document corpus. Say, we use 100 sparse token ids + weights per document. Correspondingly, dense BERT vector would be 768M floats, the OpenAI Embedding would be 1.536B floats, and the sparse vector would be a maximum of 100M integers + 100M floats. This could mean a **10x reduction in memory usage** , which is a huge win for large-scale systems:
Vector Type | Memory (GB)  
---|---  
Dense BERT Vector | 6.144  
OpenAI Embedding | 12.288  
Sparse Vector | 1.12  
### How SPLADE works: leveraging BERT
SPLADE leverages a transformer architecture to generate sparse representations of documents and queries, enabling efficient retrieval. Let’s dive into the process.
The output logits from the transformer backbone are inputs upon which SPLADE builds. The transformer architecture can be something familiar like BERT. Rather than producing dense probability distributions, SPLADE utilizes these logits to construct sparse vectors—think of them as a distilled essence of tokens, where each dimension corresponds to a term from the vocabulary and its associated weight in the context of the given document or query.
This sparsity is critical; it mirrors the probability distributions from a typical 
  1. Contextually relevant: Terms that represent a document well should be given more weight.
  2. Discriminative across documents: Terms that a document has, and other documents don’t, should be given more weight.
The token-level distributions that you’d expect in a standard transformer model are now transformed into token-level importance scores in SPLADE. These scores reflect the significance of each term in the context of the document or query, guiding the model to allocate more weight to terms that are likely to be more meaningful for retrieval purposes.
The resulting sparse vectors are not only memory-efficient but also tailored for precise matching in the high-dimensional space of a search engine like Qdrant.
### Interpreting SPLADE
A downside of dense vectors is that they are not interpretable, making it difficult to understand why a document is relevant to a query.
SPLADE importance estimation can provide insights into the ‘why’ behind a document’s relevance to a query. By shedding light on which tokens contribute most to the retrieval score, SPLADE offers some degree of interpretability alongside performance, a rare feat in the realm of neural IR systems. For engineers working on search, this transparency is invaluable.
## Known limitations of SPLADE
### Pooling strategy
The switch to max pooling in SPLADE improved its performance on the MS MARCO and TREC datasets. However, this indicates a potential limitation of the baseline SPLADE pooling method, suggesting that SPLADE’s performance is sensitive to the choice of pooling strategy​​.
### Document and query Eecoder
The SPLADE model variant that uses a document encoder with max pooling but no query encoder reaches the same performance level as the prior SPLADE model. This suggests a limitation in the necessity of a query encoder, potentially affecting the efficiency of the model​​.
### Other sparse vector methods
SPLADE is not the only method to create sparse vectors.
Essentially, sparse vectors are a superset of TF-IDF and BM25, which are the most popular text retrieval methods. In other words, you can create a sparse vector using the term frequency and inverse document frequency (TF-IDF) to reproduce the BM25 score exactly.
Additionally, attention weights from Sentence Transformers can be used to create sparse vectors. This method preserves the ability to query exact words and phrases but avoids the computational overhead of query expansion used in SPLADE.
We will cover these methods in detail in a future article.
## Leveraging sparse vectors in Qdrant for hybrid search
Qdrant supports a separate index for Sparse Vectors. This enables you to use the same collection for both dense and sparse vectors. Each “Point” in Qdrant can have both dense and sparse vectors.
But let’s first take a look at how you can work with sparse vectors in Qdrant.
## Practical implementation in Python
Let’s dive into how Qdrant handles sparse vectors with an example. Here is what we will cover:
  1. Setting Up Qdrant Client: Initially, we establish a connection with Qdrant using the QdrantClient. This setup is crucial for subsequent operations.
  2. Creating a Collection with Sparse Vector Support: In Qdrant, a collection is a container for your vectors. Here, we create a collection specifically designed to support sparse vectors. This is done using the create_collection method where we define the parameters for sparse vectors, such as setting the index configuration.
  3. Inserting Sparse Vectors: Once the collection is set up, we can insert sparse vectors into it. This involves defining the sparse vector with its indices and values, and then upserting this point into the collection.
  4. Querying with Sparse Vectors: To perform a search, we first prepare a query vector. This involves computing the vector from a query text and extracting its indices and values. We then use these details to construct a query against our collection.
  5. Retrieving and Interpreting Results: The search operation returns results that include the id of the matching document, its score, and other relevant details. The score is a crucial aspect, reflecting the similarity between the query and the documents in the collection.
### 1. Set up
```
# Qdrant client setup
client = QdrantClient(":memory:")
# Define collection name
COLLECTION_NAME = "example_collection"
# Insert sparse vector into Qdrant collection
point_id = 1  # Assign a unique ID for the point

```
### 2. Create a collection with sparse vector support
```
client.create_collection(
    collection_name=COLLECTION_NAME,
    vectors_config={},
    sparse_vectors_config={
        "text": models.SparseVectorParams(
            index=models.SparseIndexParams(
                on_disk=False,
            )
        )
    },
)

```
### 3. Insert sparse vectors
Here, we see the process of inserting a sparse vector into the Qdrant collection. This step is key to building a dataset that can be quickly retrieved in the first stage of the retrieval process, utilizing the efficiency of sparse vectors. Since this is for demonstration purposes, we insert only one point with Sparse Vector and no dense vector.
```
client.upsert(
    collection_name=COLLECTION_NAME,
    points=[
        models.PointStruct(
            id=point_id,
            payload={},  # Add any additional payload if necessary
            vector={
                "text": models.SparseVector(
                    indices=indices.tolist(), values=values.tolist()
                )
            },
        )
    ],
)

```
By upserting points with sparse vectors, we prepare our dataset for rapid first-stage retrieval, laying the groundwork for subsequent detailed analysis using dense vectors. Notice that we use “text” to denote the name of the sparse vector.
Those familiar with the Qdrant API will notice that the extra care taken to be consistent with the existing named vectors API – this is to make it easier to use sparse vectors in existing codebases. As always, you’re able to **apply payload filters** , shard keys, and other advanced features you’ve come to expect from Qdrant. To make things easier for you, the indices and values don’t have to be sorted before upsert. Qdrant will sort them when the index is persisted e.g. on disk.
### 4. Query with sparse vectors
We use the same process to prepare a query vector as well. This involves computing the vector from a query text and extracting its indices and values. We then use these details to construct a query against our collection.
```
# Preparing a query vector
query_text = "Who was Arthur Ashe?"
query_vec, query_tokens = compute_vector(query_text)
query_vec.shape
query_indices = query_vec.nonzero().numpy().flatten()
query_values = query_vec.detach().numpy()[query_indices]

```
In this example, we use the same model for both document and query. This is not a requirement, but it’s a simpler approach.
### 5. Retrieve and interpret results
After setting up the collection and inserting sparse vectors, the next critical step is retrieving and interpreting the results. This process involves executing a search query and then analyzing the returned results.
```
# Searching for similar documents
result = client.search(
    collection_name=COLLECTION_NAME,
    query_vector=models.NamedSparseVector(
        name="text",
        vector=models.SparseVector(
            indices=query_indices,
            values=query_values,
        ),
    ),
    with_vectors=True,
)
result

```
In the above code, we execute a search against our collection using the prepared sparse vector query. The `client.search` method takes the collection name and the query vector as inputs. The query vector is constructed using the `models.NamedSparseVector`, which includes the indices and values derived from the query text. This is a crucial step in efficiently retrieving relevant documents.
```
ScoredPoint(
    id=1,
    version=0,
    score=3.4292831420898438,
    payload={},
    vector={
        "text": SparseVector(
            indices=[2001, 2002, 2010, 2018, 2032, ...],
            values=[
                1.0660614967346191,
                1.391068458557129,
                0.8903818726539612,
                0.2502821087837219,
                ...,
            ],
        )
    },
)

```
The result, as shown above, is a `ScoredPoint` object containing the ID of the retrieved document, its version, a similarity score, and the sparse vector. The score is a key element as it quantifies the similarity between the query and the document, based on their respective vectors.
To understand how this scoring works, we use the familiar dot product method:
Similarity(Query,Document)=∑i∈IQueryi×Documenti
This formula calculates the similarity score by multiplying corresponding elements of the query and document vectors and summing these products. This method is particularly effective with sparse vectors, where many elements are zero, leading to a computationally efficient process. The higher the score, the greater the similarity between the query and the document, making it a valuable metric for assessing the relevance of the retrieved documents.
## Hybrid search: combining sparse and dense vectors
By combining search results from both dense and sparse vectors, you can achieve a hybrid search that is both efficient and accurate. Results from sparse vectors will guarantee, that all results with the required keywords are returned, while dense vectors will cover the semantically similar results.
The mixture of dense and sparse results can be presented directly to the user, or used as a first stage of a two-stage retrieval process.
Let’s see how you can make a hybrid search query in Qdrant.
First, you need to create a collection with both dense and sparse vectors:
```
client.create_collection(
    collection_name=COLLECTION_NAME,
    vectors_config={
        "text-dense": models.VectorParams(
            size=1536,  # OpenAI Embeddings
            distance=models.Distance.COSINE,
        )
    },
    sparse_vectors_config={
        "text-sparse": models.SparseVectorParams(
            index=models.SparseIndexParams(
                on_disk=False,
            )
        )
    },
)

```
Then, assuming you have upserted both dense and sparse vectors, you can query them together:
```
query_text = "Who was Arthur Ashe?"
# Compute sparse and dense vectors
query_indices, query_values = compute_sparse_vector(query_text)
query_dense_vector = compute_dense_vector(query_text)
client.search_batch(
    collection_name=COLLECTION_NAME,
    requests=[
        models.SearchRequest(
            vector=models.NamedVector(
                name="text-dense",
                vector=query_dense_vector,
            ),
            limit=10,
        ),
        models.SearchRequest(
            vector=models.NamedSparseVector(
                name="text-sparse",
                vector=models.SparseVector(
                    indices=query_indices,
                    values=query_values,
                ),
            ),
            limit=10,
        ),
    ],
)

```
The result will be a pair of result lists, one for dense and one for sparse vectors.
Having those results, there are several ways to combine them:
### Mixing or fusion
You can mix the results from both dense and sparse vectors, based purely on their relative scores. This is a simple and effective approach, but it doesn’t take into account the semantic similarity between the results. Among the 
```
- Reciprocal Ranked Fusion (RRF)
- Relative Score Fusion (RSF)
- Distribution-Based Score Fusion (DBSF)

```
![Relative Score Fusion](https://qdrant.tech/articles_data/sparse-vectors/mixture.png)
Relative Score Fusion
### Re-ranking
You can use obtained results as a first stage of a two-stage retrieval process. In the second stage, you can re-rank the results from the first stage using a more complex model, such as 
And that’s it! You’ve successfully achieved hybrid search with Qdrant!
## Additional resources
For those who want to dive deeper, here are the top papers on the topic most of which have code available:
  1. Problem Motivation: 
  2. Late Interaction - 
**Why just read when you can try it out?**
We’ve packed an easy-to-use Colab for you on how to make a Sparse Vector: 
## Conclusion
Alright, folks, let’s wrap it up. Better search isn’t a ’nice-to-have,’ it’s a game-changer, and Qdrant can get you there.
Got questions? Our 
If you enjoyed reading this, why not sign up for our [newsletter](https://qdrant.tech/subscribe/?utm_source=qdrant&utm_medium=website&utm_campaign=sparse-vectors&utm_content=article&utm_term=sparse-vectors) to stay ahead of the curve.
And, of course, a big thanks to you, our readers, for pushing us to make ranking better for everyone.
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/sparse-vectors.md) this page on GitHub, or 
On this page:
  * [What are sparse and dense vectors?](https://qdrant.tech/articles/sparse-vectors/#what-are-sparse-and-dense-vectors)
  * [Understanding sparse vectors](https://qdrant.tech/articles/sparse-vectors/#understanding-sparse-vectors)
  * [SPLADE](https://qdrant.tech/articles/sparse-vectors/#splade)
  * [Creating a sparse vector](https://qdrant.tech/articles/sparse-vectors/#creating-a-sparse-vector)
    * [Setting Up](https://qdrant.tech/articles/sparse-vectors/#setting-up)
    * [Computing the sparse vector](https://qdrant.tech/articles/sparse-vectors/#computing-the-sparse-vector)
  * [Term expansion and weights](https://qdrant.tech/articles/sparse-vectors/#term-expansion-and-weights)
  * [Why SPLADE works: term expansion](https://qdrant.tech/articles/sparse-vectors/#why-splade-works-term-expansion)
    * [How SPLADE works: leveraging BERT](https://qdrant.tech/articles/sparse-vectors/#how-splade-works-leveraging-bert)
    * [Interpreting SPLADE](https://qdrant.tech/articles/sparse-vectors/#interpreting-splade)
  * [Known limitations of SPLADE](https://qdrant.tech/articles/sparse-vectors/#known-limitations-of-splade)
    * [Pooling strategy](https://qdrant.tech/articles/sparse-vectors/#pooling-strategy)
    * [Document and query Eecoder](https://qdrant.tech/articles/sparse-vectors/#document-and-query-eecoder)
    * [Other sparse vector methods](https://qdrant.tech/articles/sparse-vectors/#other-sparse-vector-methods)
  * [Leveraging sparse vectors in Qdrant for hybrid search](https://qdrant.tech/articles/sparse-vectors/#leveraging-sparse-vectors-in-qdrant-for-hybrid-search)
  * [Practical implementation in Python](https://qdrant.tech/articles/sparse-vectors/#practical-implementation-in-python)
    * [1. Set up](https://qdrant.tech/articles/sparse-vectors/#1-set-up)
    * [2. Create a collection with sparse vector support](https://qdrant.tech/articles/sparse-vectors/#2-create-a-collection-with-sparse-vector-support)
    * [3. Insert sparse vectors](https://qdrant.tech/articles/sparse-vectors/#3-insert-sparse-vectors)
    * [4. Query with sparse vectors](https://qdrant.tech/articles/sparse-vectors/#4-query-with-sparse-vectors)
    * [5. Retrieve and interpret results](https://qdrant.tech/articles/sparse-vectors/#5-retrieve-and-interpret-results)
  * [Hybrid search: combining sparse and dense vectors](https://qdrant.tech/articles/sparse-vectors/#hybrid-search-combining-sparse-and-dense-vectors)
    * [Mixing or fusion](https://qdrant.tech/articles/sparse-vectors/#mixing-or-fusion)
    * [Re-ranking](https://qdrant.tech/articles/sparse-vectors/#re-ranking)
  * [Additional resources](https://qdrant.tech/articles/sparse-vectors/#additional-resources)
  * [Conclusion](https://qdrant.tech/articles/sparse-vectors/#conclusion)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/sparse-vectors/)
                    ## 📄 `https-qdrant-tech-articles-storing-multiple-vectors-per-object-in-qdrant.md`
                    ```md
                    # https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/
  * [Articles](https://qdrant.tech/articles/)
  * Optimizing Semantic Search by Managing Multiple Vectors
# Optimizing Semantic Search by Managing Multiple Vectors
Kacper Łukawski
·
October 05, 2022
![Optimizing Semantic Search by Managing Multiple Vectors](https://qdrant.tech/articles_data/storing-multiple-vectors-per-object-in-qdrant/preview/title.jpg)
# How to Optimize Vector Storage by Storing Multiple Vectors Per Object
In a real case scenario, a single object might be described in several different ways. If you run an e-commerce business, then your items will typically have a name, longer textual description and also a bunch of photos. While cooking, you may care about the list of ingredients, and description of the taste but also the recipe and the way your meal is going to look. Up till now, if you wanted to enable [semantic search](https://qdrant.tech/documentation/tutorials/search-beginners/) with multiple vectors per object, Qdrant would require you to create separate collections for each vector type, even though they could share some other attributes in a payload. However, since Qdrant 0.10 you are able to store all those vectors together in the same collection and share a single copy of the payload!
Running the new version of Qdrant is as simple as it always was. By running the following command, you are able to set up a single instance that will also expose the HTTP API:
```
docker run -p 6333:6333 qdrant/qdrant:v0.10.1

```
## Creating a collection
Adding new functionalities typically requires making some changes to the interfaces, so no surprise we had to do it to enable the multiple vectors support. Currently, if you want to create a collection, you need to define the configuration of all the vectors you want to store for each object. Each vector type has its own name and the distance function used to measure how far the points are.
```
from qdrant_client import QdrantClient
from qdrant_client.http.models import VectorParams, Distance
client = QdrantClient()
client.create_collection(
   collection_name="multiple_vectors",
   vectors_config={
       "title": VectorParams(
           size=100,
           distance=Distance.EUCLID,
       ),
       "image": VectorParams(
           size=786,
           distance=Distance.COSINE,
       ),
   }
)

```
In case you want to keep a single vector per collection, you can still do it without putting a name though.
```
client.create_collection(
   collection_name="single_vector",
   vectors_config=VectorParams(
       size=100,
       distance=Distance.COSINE,
   )
)

```
All the search-related operations have slightly changed their interfaces as well, so you can choose which vector to use in a specific request. However, it might be easier to see all the changes by following an end-to-end Qdrant usage on a real-world example.
## Building service with multiple embeddings
Quite a common approach to building search engines is to combine semantic textual capabilities with image search as well. For that purpose, we need a dataset containing both images and their textual descriptions. There are several datasets available with 
```
from datasets import load_dataset
dataset = load_dataset("ChristophSchuhmann/MS_COCO_2017_URL_TEXT")

```
Right now, we have a dataset with a structure containing the image URL and its textual description in English. For simplicity, we can convert it to the DataFrame, as this structure might be quite convenient for future processing.
```
import pandas as pd
dataset_df = pd.DataFrame(dataset["train"])

```
The dataset consists of two columns:  _TEXT_ and  _URL_. Thus, each data sample is described by two separate pieces of information and each of them has to be encoded with a different model.
## Processing the data with pretrained models
Thanks to 
```
from pathlib import Path
from urllib.request import urlretrieve
from embetter.base import EmbetterBase
class DownloadFile(EmbetterBase):
   def __init__(self, out_dir: Path):
       self.out_dir = out_dir
   def transform(self, X, y=None):
       output_paths = []
       for x in X:
           output_file = self.out_dir / Path(x).name
           urlretrieve(x, output_file)
           output_paths.append(str(output_file))
       return output_paths

```
Now we’re ready to define the pipelines to process our images and texts using  _all-MiniLM-L6-v2_ and  _vit_base_patch16_224_ models respectively. First of all, let’s start with Qdrant configuration.
## Creating Qdrant collection
We’re going to put two vectors per object (one for image and another one for text), so we need to create a collection with a configuration allowing us to do so.
```
from qdrant_client import QdrantClient
from qdrant_client.http.models import VectorParams, Distance
client = QdrantClient(timeout=None)
client.create_collection(
   collection_name="ms-coco-2017",
   vectors_config={
       "text": VectorParams(
           size=384,
           distance=Distance.EUCLID,
       ),
       "image": VectorParams(
           size=1000,
           distance=Distance.COSINE,
       ),
   },
)

```
## Defining the pipelines
And since we have all the puzzles already in place, we can start the processing to convert raw data into the embeddings we need. The pretrained models come in handy.
```
from sklearn.pipeline import make_pipeline
from embetter.grab import ColumnGrabber
from embetter.vision import ImageLoader, TimmEncoder
from embetter.text import SentenceEncoder
output_directory = Path("./images")
image_pipeline = make_pipeline(
   ColumnGrabber("URL"),
   DownloadFile(output_directory),
   ImageLoader(),
   TimmEncoder("vit_base_patch16_224"),
)
text_pipeline = make_pipeline(
   ColumnGrabber("TEXT"),
   SentenceEncoder("all-MiniLM-L6-v2"),
)

```
Thanks to the scikit-learn API, we can simply call each pipeline on the created DataFrame and put created vectors into Qdrant to enable fast vector search. For convenience, we’re going to put the vectors as other columns in our DataFrame.
```
sample_df = dataset_df.sample(n=2000, random_state=643)
image_vectors = image_pipeline.transform(sample_df)
text_vectors = text_pipeline.transform(sample_df)
sample_df["image_vector"] = image_vectors.tolist()
sample_df["text_vector"] = text_vectors.tolist()

```
The created vectors might be easily put into Qdrant. For the sake of simplicity, we’re going to skip it, but if you are interested in details, please check out the 
## Searching with multiple vectors
If you decided to describe each object with several [neural embeddings](https://qdrant.tech/articles/neural-search-tutorial/), then at each search operation you need to provide the vector name along with the [vector embedding](https://qdrant.tech/articles/what-are-embeddings/), so the engine knows which one to use. The interface of the search operation is pretty straightforward and requires an instance of NamedVector.
```
from qdrant_client.http.models import NamedVector
text_results = client.search(
   collection_name="ms-coco-2017",
   query_vector=NamedVector(
       name="text",
       vector=row["text_vector"],
   ),
   limit=5,
   with_vectors=False,
   with_payload=True,
)

```
If we, on the other hand, decided to search using the image embedding, then we just provide the vector name we have chosen while creating the collection, so instead of “text”, we would provide “image”, as this is how we configured it at the very beginning.
## The results: image vs text search
Since we have two different vectors describing each object, we can perform the search query using any of those. That shouldn’t be surprising then, that the results are different depending on the chosen embedding method. The images below present the results returned by Qdrant for the image/text on the left-hand side.
### Image search
If we query the system using image embedding, then it returns the following results:
![](https://qdrant.tech/blog/from_cms/0_5nqlmjznjkvdrjhj.webp)Image search results
### Text search
However, if we use textual description embedding, then the results are slightly different:
![](https://qdrant.tech/blog/from_cms/0_3sdgctswb99xtexl.webp)Text search However, if we use textual description embedding, then the results are slightly different:
It is not surprising that a method used for creating neural encoding plays an important role in the search process and its quality. If your data points might be described using several vectors, then the latest release of Qdrant gives you an opportunity to store them together and reuse the payloads, instead of creating several collections and querying them separately.
### Summary:
  * Qdrant 0.10 introduces efficient vector storage optimization, allowing seamless management of multiple vectors per object within a single collection.
  * This update streamlines semantic search capabilities by eliminating the need for separate collections for each vector type, enhancing search accuracy and performance.
  * With Qdrant’s new features, users can easily configure vector parameters, including size and distance functions, for each vector type, optimizing search results and user experience.
If you’d like to check out some other examples, please check out our 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/storing-multiple-vectors-per-object-in-qdrant.md) this page on GitHub, or 
On this page:
  * [Creating a collection](https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/#creating-a-collection)
  * [Building service with multiple embeddings](https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/#building-service-with-multiple-embeddings)
  * [Processing the data with pretrained models](https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/#processing-the-data-with-pretrained-models)
  * [Creating Qdrant collection](https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/#creating-qdrant-collection)
  * [Defining the pipelines](https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/#defining-the-pipelines)
  * [Searching with multiple vectors](https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/#searching-with-multiple-vectors)
  * [The results: image vs text search](https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/#the-results-image-vs-text-search)
    * [Image search](https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/#image-search)
    * [Text search](https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/#text-search)
    * [Summary:](https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/#summary)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/)
                    ## 📄 `https-qdrant-tech-articles-vector-search-filtering.md`
                    ```md
                    # https://qdrant.tech/articles/vector-search-filtering/
  * [Articles](https://qdrant.tech/articles/)
  * A Complete Guide to Filtering in Vector Search
# A Complete Guide to Filtering in Vector Search
Sabrina Aquino, David Myriel
·
September 10, 2024
![A Complete Guide to Filtering in Vector Search](https://qdrant.tech/articles_data/vector-search-filtering/preview/title.jpg)
Imagine you sell computer hardware. To help shoppers easily find products on your website, you need to have a **user-friendly[search engine](https://qdrant.tech)**.
![vector-search-ecommerce](https://qdrant.tech/articles_data/vector-search-filtering/vector-search-ecommerce.png)
If you’re selling computers and have extensive data on laptops, desktops, and accessories, your search feature should guide customers to the exact device they want - or at least a **very similar** match.
When storing data in Qdrant, each product is a point, consisting of an `id`, a `vector` and `payload`:
```
{
  "id": 1, 
  "vector": [0.1, 0.2, 0.3, 0.4],
  "payload": {
    "price": 899.99,
    "category": "laptop"
  }
}

```
The `id` is a unique identifier for the point in your collection. The `vector` is a mathematical representation of similarity to other points in the collection. Finally, the `payload` holds metadata that directly describes the point.
Though we may not be able to decipher the vector, we are able to derive additional information about the item from its metadata, In this specific case, **we are looking at a data point for a laptop that costs $899.99**.
## What is filtering?
When searching for the perfect computer, your customers may end up with results that are mathematically similar to the search entry, but not exact. For example, if they are searching for **laptops under $1000** , a simple [vector search](https://qdrant.tech/advanced-search/) without constraints might still show other laptops over $1000.
This is why [semantic search](https://qdrant.tech/advanced-search/) alone **may not be enough**. In order to get the exact result, you would need to enforce a payload filter on the `price`. Only then can you be sure that the search results abide by the chosen characteristic.
> This is called **filtering** and it is one of the key features of [vector databases](https://qdrant.tech).
Here is how a **filtered vector search** looks behind the scenes. We’ll cover its mechanics in the following section.
```
POST /collections/online_store/points/search
{
  "vector": [ 0.2, 0.1, 0.9, 0.7 ],
  "filter": {
    "must": [
      {
        "key": "category",
        "match": { "value": "laptop" }
      },
      {
        "key": "price",
        "range": {
          "gt": null,
          "gte": null,
          "lt": null,
          "lte": 1000
        }
      }
    ]
  },
  "limit": 3,
  "with_payload": true,
  "with_vector": false
}

```
The filtered result will be a combination of the semantic search and the filtering conditions imposed upon the query. In the following pages, we will show that **filtering is a key practice in vector search for two reasons:**
  1. With filtering in Qdrant, you can **dramatically increase search precision**. More on this in the next section.  
  2. Filtering helps control resources and **reduce compute use**. More on this in [**Payload Indexing**](https://qdrant.tech/articles/vector-search-filtering/#filtering-with-the-payload-index).
## What you will learn in this guide:
In [vector search](https://qdrant.tech/advanced-search/), filtering and sorting are more interdependent than they are in traditional databases. While databases like SQL use commands such as `WHERE` and `ORDER BY`, the interplay between these processes in vector search is a bit more complex.
Most people use default settings and build vector search apps that aren’t properly configured or even setup for precise retrieval. In this guide, we will show you how to **use filtering to get the most out of vector search** with some basic and advanced strategies that are easy to implement.
#### Remember to run all tutorial code in Qdrant’s Dashboard
The easiest way to reach that “Hello World” moment is to [**try filtering in a live cluster**](https://qdrant.tech/documentation/quickstart-cloud/). Our interactive tutorial will show you how to create a cluster, add data and try some filtering clauses.
![qdrant-filtering-tutorial](https://qdrant.tech/articles_data/vector-search-filtering/qdrant-filtering-tutorial.png)
## Qdrant’s approach to filtering
Qdrant follows a specific method of searching and filtering through dense vectors.
Let’s take a look at this **3-stage diagram**. In this case, we are trying to find the nearest neighbour to the query vector **(green)**. Your search journey starts at the bottom **(orange)**.
By default, Qdrant connects all your data points within the [**vector index**](https://qdrant.tech/documentation/concepts/indexing/). After you [**introduce filters**](https://qdrant.tech/documentation/concepts/filtering/), some data points become disconnected. Vector search can’t cross the grayed out area and it won’t reach the nearest neighbor. How can we bridge this gap?
**Figure 1:** How Qdrant maintains a filterable vector index. ![filterable-vector-index](https://qdrant.tech/articles_data/vector-search-filtering/filterable-vector-index.png)
[**Filterable vector index**](https://qdrant.tech/documentation/concepts/indexing/): This technique builds additional links **(orange)** between leftover data points. The filtered points which stay behind are now traversible once again. Qdrant uses special category-based methods to connect these data points.
### Qdrant’s approach vs traditional filtering methods
![stepping-lens](https://qdrant.tech/articles_data/vector-search-filtering/stepping-lens.png)
The filterable vector index is Qdrant’s solves pre and post-filtering problems by adding specialized links to the search graph. It aims to maintain the speed advantages of vector search while allowing for precise filtering, addressing the inefficiencies that can occur when applying filters after the vector search.
#### Pre-filtering
In pre-filtering, a search engine first narrows down the dataset based on chosen metadata values, and then searches within that filtered subset. This reduces unnecessary computation over a dataset that is potentially much larger.
The choice between pre-filtering and using the filterable HNSW index depends on filter cardinality. When metadata cardinality is too low, the filter becomes restrictive and it can disrupt the connections within the graph. This leads to fragmented search paths (as in **Figure 1**). When the semantic search process begins, it won’t be able to travel to those locations.
However, Qdrant still benefits from pre-filtering **under certain conditions**. In cases of low cardinality, Qdrant’s query planner stops using HNSW and switches over to the payload index alone. This makes the search process much cheaper and faster than if using HNSW.
**Figure 2:** On the user side, this is how filtering looks. We start with five products with different prices. First, the $1000 price **filter** is applied, narrowing down the selection of laptops. Then, a vector search finds the relevant **results** within this filtered set.
![pre-filtering-vector-search](https://qdrant.tech/articles_data/vector-search-filtering/pre-filtering.png)
In conclusion, pre-filtering is efficient in specific cases when you use small datasets with low cardinality metadata. However, pre-filtering should not be used over large datasets as it breaks too many links in the HNSW graph, causing lower accuracy.
#### Post-filtering
In post-filtering, a search engine first looks for similar vectors and retrieves a larger set of results. Then, it applies filters to those results based on metadata. The problem with post-filtering becomes apparent when using low-cardinality filters.
> When you apply a low-cardinality filter after performing a vector search, you often end up discarding a large portion of the results that the vector search returned.
**Figure 3:** In the same example, we have five laptops. First, the vector search finds the top two relevant **results** , but they may not meet the price match. When the $1000 price **filter** is applied, other potential results are discarded.
![post-filtering-vector-search](https://qdrant.tech/articles_data/vector-search-filtering/post-filtering.png)
The system will waste computational resources by first finding similar vectors and then discarding many that don’t meet the filter criteria. You’re also limited to filtering only from the initial set of [vector search](https://qdrant.tech/advanced-search/) results. If your desired items aren’t in this initial set, you won’t find them, even if they exist in the database.
## Basic filtering example: ecommerce and laptops
We know that there are three possible laptops that suit our price point. Let’s see how Qdrant’s filterable vector index works and why it is the best method of capturing all available results.
First, add five new laptops to your online store. Here is a sample input:
```
laptops = [
    (1, [0.1, 0.2, 0.3, 0.4], {"price": 899.99, "category": "laptop"}),
    (2, [0.2, 0.3, 0.4, 0.5], {"price": 1299.99, "category": "laptop"}),
    (3, [0.3, 0.4, 0.5, 0.6], {"price": 799.99, "category": "laptop"}),
    (4, [0.4, 0.5, 0.6, 0.7], {"price": 1099.99, "category": "laptop"}),
    (5, [0.5, 0.6, 0.7, 0.8], {"price": 949.99, "category": "laptop"})
]

```
The four-dimensional vector can represent features like laptop CPU, RAM or battery life, but that isn’t specified. The payload, however, specifies the exact price and product category.
Now, set the filter to “price is less than $1000”:
```
{
  "key": "price",
  "range": {
    "gt": null,
    "gte": null,
    "lt": null,
    "lte": 1000
  }
}

```
When a price filter of equal/less than $1000 is applied, vector search returns the following results:
```
[
  {
    "id": 3,
    "score": 0.9978443564622781,
    "payload": {
      "price": 799.99,
      "category": "laptop"
    }
  },
  {
    "id": 1,
    "score": 0.9938079894227599,
    "payload": {
      "price": 899.99,
      "category": "laptop"
    }
  },
  {
    "id": 5,
    "score": 0.9903751498208603,
    "payload": {
      "price": 949.99,
      "category": "laptop"
    }
  }
]

```
As you can see, Qdrant’s filtering method has a greater chance of capturing all possible search results.
This specific example uses the `range` condition for filtering. Qdrant, however, offers many other possible ways to structure a filter
**For detailed usage examples,[filtering](https://qdrant.tech/documentation/concepts/filtering/) docs are the best resource.**
### Scrolling instead of searching
You don’t need to use our `search` and `query` APIs to filter through data. The `scroll` API is another option that lets you retrieve lists of points which meet the filters.
If you aren’t interested in finding similar points, you can simply list the ones that match a given filter. While search gives you the most similar points based on some query vector, scroll will give you all points matching your filter not considering similarity.
In Qdrant, scrolling is used to iteratively **retrieve large sets of points from a collection**. It is particularly useful when you’re dealing with a large number of points and don’t want to load them all at once. Instead, Qdrant provides a way to scroll through the points **one page at a time**.
You start by sending a scroll request to Qdrant with specific conditions like filtering by payload, vector search, or other criteria.
Let’s retrieve a list of top 10 laptops ordered by price in the store:
```
POST /collections/online_store/points/scroll
{
    "filter": {
        "must": [
            {
                "key": "category",
                "match": {
                    "value": "laptop"
                }
            }
        ]
    },
    "limit": 10,
    "with_payload": true,
    "with_vector": false,
    "order_by": [
        {
            "key": "price",
        }
    ]
}

```
The response contains a batch of points that match the criteria and a reference (offset or next page token) to retrieve the next set of points.
> [**Scrolling**](https://qdrant.tech/documentation/concepts/points/#scroll-points) is designed to be efficient. It minimizes the load on the server and reduces memory consumption on the client side by returning only manageable chunks of data at a time.
#### Available filtering conditions
**Condition** | **Usage** | **Condition** | **Usage**  
---|---|---|---  
**Match** | Exact value match. | **Range** | Filter by value range.  
**Match Any** | Match multiple values. | **Datetime Range** | Filter by date range.  
**Match Except** | Exclude specific values. | **UUID Match** | Filter by unique ID.  
**Nested Key** | Filter by nested data. | **Geo** | Filter by location.  
**Nested Object** | Filter by nested objects. | **Values Count** | Filter by element count.  
**Full Text Match** | Search in text fields. | **Is Empty** | Filter empty fields.  
**Has ID** | Filter by unique ID. | **Is Null** | Filter null values.  
> All clauses and conditions are outlined in Qdrant’s [filtering](https://qdrant.tech/documentation/concepts/filtering/) documentation.
#### Filtering clauses to remember
**Clause** | **Description** | **Clause** | **Description**  
---|---|---|---  
**Must** | Includes items that meet the condition  
(similar to `AND`). | **Should** | Filters if at least one condition is met  
(similar to `OR`).  
**Must Not** | Excludes items that meet the condition  
(similar to `NOT`). | **Clauses Combination** | Combines multiple clauses to refine filtering  
(similar to `AND`).  
## Advanced filtering example: dinosaur diets
![advanced-payload-filtering](https://qdrant.tech/articles_data/vector-search-filtering/advanced-payload-filtering.png)
We can also use nested filtering to query arrays of objects within the payload. In this example, we have two points. They each represent a dinosaur with a list of food preferences (diet) that indicate what type of food they like or dislike:
```
[
  {
    "id": 1,
    "dinosaur": "t-rex",
    "diet": [
      { "food": "leaves", "likes": false},
      { "food": "meat", "likes": true}
    ]
  },
  {
    "id": 2,
    "dinosaur": "diplodocus",
    "diet": [
      { "food": "leaves", "likes": true},
      { "food": "meat", "likes": false}
    ]
  }
]

```
To ensure that both conditions are applied to the same array element (e.g., food = meat and likes = true must refer to the same diet item), you need to use a nested filter.
Nested filters are used to apply conditions within an array of objects. They ensure that the conditions are evaluated per array element, rather than across all elements.
httppythontypescriptrustjavacsharp
```
POST /collections/dinosaurs/points/scroll
{
    "filter": {
        "must": [
            {
                "key": "diet[].food",
                  "match": {
                    "value": "meat"
                }
            },
            {
                "key": "diet[].likes",
                  "match": {
                    "value": true
                }
            }
        ]
    }
}

```
```
client.scroll(
    collection_name="dinosaurs",
    scroll_filter=models.Filter(
        must=[
            models.FieldCondition(
                key="diet[].food", match=models.MatchValue(value="meat")
            ),
            models.FieldCondition(
                key="diet[].likes", match=models.MatchValue(value=True)
            ),
        ],
    ),
)

```
```
client.scroll("dinosaurs", {
  filter: {
    must: [
      {
        key: "diet[].food",
        match: { value: "meat" },
      },
      {
        key: "diet[].likes",
        match: { value: true },
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,ScrollPointsBuilder};client.scroll(ScrollPointsBuilder::new("dinosaurs").filter(Filter::must([Condition::matches("diet[].food","meat".to_string()),Condition::matches("diet[].likes",true),])),).await?;
```
```
importjava.util.List;import staticio.qdrant.client.ConditionFactory.match;import staticio.qdrant.client.ConditionFactory.matchKeyword;importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.ScrollPoints;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.scrollAsync(ScrollPoints.newBuilder().setCollectionName("dinosaurs").setFilter(Filter.newBuilder().addAllMust(List.of(matchKeyword("diet[].food","meat"),match("diet[].likes",true))).build()).build()).get();
```
```
using Qdrant.Client;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.ScrollAsync(
	collectionName: "dinosaurs",
	filter: MatchKeyword("diet[].food", "meat") & Match("diet[].likes", true)
);

```
This happens because both points are matching the two conditions:
  * the “t-rex” matches food=meat on `diet[1].food` and likes=true on `diet[1].likes`
  * the “diplodocus” matches food=meat on `diet[1].food` and likes=true on `diet[0].likes`
To retrieve only the points where the conditions apply to a specific element within an array (such as the point with id 1 in this example), you need to use a nested object filter.
Nested object filters enable querying arrays of objects independently, ensuring conditions are checked within individual array elements.
This is done by using the `nested` condition type, which consists of a payload key that targets an array and a filter to apply. The key should reference an array of objects and can be written with or without bracket notation (e.g., “data” or “data[]”).
httppythontypescriptrustjavacsharp
```
POST /collections/dinosaurs/points/scroll
{
    "filter": {
        "must": [{
            "nested": {
                "key": "diet",
                "filter":{
                    "must": [
                        {
                            "key": "food",
                            "match": {
                                "value": "meat"
                            }
                        },
                        {
                            "key": "likes",
                            "match": {
                                "value": true
                            }
                        }
                    ]
                }
            }
        }]
    }
}

```
```
client.scroll(
    collection_name="dinosaurs",
    scroll_filter=models.Filter(
        must=[
            models.NestedCondition(
                nested=models.Nested(
                    key="diet",
                    filter=models.Filter(
                        must=[
                            models.FieldCondition(
                                key="food", match=models.MatchValue(value="meat")
                            ),
                            models.FieldCondition(
                                key="likes", match=models.MatchValue(value=True)
                            ),
                        ]
                    ),
                )
            )
        ],
    ),
)

```
```
client.scroll("dinosaurs", {
  filter: {
    must: [
      {
        nested: {
          key: "diet",
          filter: {
            must: [
              {
                key: "food",
                match: { value: "meat" },
              },
              {
                key: "likes",
                match: { value: true },
              },
            ],
          },
        },
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,NestedCondition,ScrollPointsBuilder};client.scroll(ScrollPointsBuilder::new("dinosaurs").filter(Filter::must([NestedCondition{key: "diet".to_string(),filter: Some(Filter::must([Condition::matches("food","meat".to_string()),Condition::matches("likes",true),])),}.into()])),).await?;
```
```
importjava.util.List;import staticio.qdrant.client.ConditionFactory.match;import staticio.qdrant.client.ConditionFactory.matchKeyword;import staticio.qdrant.client.ConditionFactory.nested;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.ScrollPoints;client.scrollAsync(ScrollPoints.newBuilder().setCollectionName("dinosaurs").setFilter(Filter.newBuilder().addMust(nested("diet",Filter.newBuilder().addAllMust(List.of(matchKeyword("food","meat"),match("likes",true))).build())).build()).build()).get();
```
```
using Qdrant.Client;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.ScrollAsync(
	collectionName: "dinosaurs",
	filter: Nested("diet", MatchKeyword("food", "meat") & Match("likes", true))
);

```
The matching logic is adjusted to operate at the level of individual elements within an array in the payload, rather than on all array elements together.
Nested filters function as though each element of the array is evaluated separately. The parent document will be considered a match if at least one array element satisfies all the nested filter conditions.
## Other creative uses for filters
You can use filters to retrieve data points without knowing their `id`. You can search through data and manage it, solely by using filters. Let’s take a look at some creative uses for filters:
Action | Description | Action | Description  
---|---|---|---  
[Delete Points](https://qdrant.tech/documentation/concepts/points/#delete-points) | Deletes all points matching the filter. | [Set Payload](https://qdrant.tech/documentation/concepts/payload/#set-payload) | Adds payload fields to all points matching the filter.  
[Scroll Points](https://qdrant.tech/documentation/concepts/points/#scroll-points) | Lists all points matching the filter. | [Update Payload](https://qdrant.tech/documentation/concepts/payload/#overwrite-payload) | Updates payload fields for points matching the filter.  
[Order Points](https://qdrant.tech/documentation/concepts/points/#order-points-by-payload-key) | Lists all points, sorted by the filter. | [Delete Payload](https://qdrant.tech/documentation/concepts/payload/#delete-payload-keys) | Deletes fields for points matching the filter.  
[Count Points](https://qdrant.tech/documentation/concepts/points/#counting-points) | Totals the points matching the filter.  
## Filtering with the payload index
![vector-search-filtering-vector-search](https://qdrant.tech/articles_data/vector-search-filtering/scanning-lens.png)
When you start working with Qdrant, your data is by default organized in a vector index. In addition to this, we recommend adding a secondary data structure - **the payload index**.
Just how the vector index organizes vectors, the payload index will structure your metadata.
**Figure 4:** The payload index is an additional data structure that supports vector search. A payload index (in green) organizes candidate results by cardinality, so that semantic search (in red) can traverse the vector index quickly.
![payload-index-vector-search](https://qdrant.tech/articles_data/vector-search-filtering/payload-index-vector-search.png)
On its own, semantic searching over terabytes of data can take up lots of RAM. [**Filtering**](https://qdrant.tech/documentation/concepts/filtering/) and [**Indexing**](https://qdrant.tech/documentation/concepts/indexing/) are two easy strategies to reduce your compute usage and still get the best results. Remember, this is only a guide. For an exhaustive list of filtering options, you should read the [filtering documentation](https://qdrant.tech/documentation/concepts/filtering/).
Here is how you can create a single index for a metadata field “category”:
httppython
```
PUT /collections/computers/index
{
    "field_name": "category",
    "field_schema": "keyword"
}

```
```
from qdrant_client import QdrantClient
client = QdrantClient(url="http://localhost:6333")
client.create_payload_index(
   collection_name="computers",
   field_name="category",
   field_schema="keyword",
)

```
Once you mark a field indexable, **you don’t need to do anything else**. Qdrant will handle all optimizations in the background.
#### Why should you index metadata?
![payload-index-filtering](https://qdrant.tech/articles_data/vector-search-filtering/payload-index-filtering.png)
The payload index acts as a secondary data structure that speeds up retrieval. Whenever you run vector search with a filter, Qdrant will consult a payload index - if there is one.
Indexing your metadata has a significant positive effect on search performance when searching with filters.
As your dataset grows in complexity, Qdrant takes up additional resources to go through all data points. Without a proper data structure, the search can take longer - or run out of resources.
#### Payload indexing helps evaluate the most restrictive filters
The payload index is also used to accurately estimate **filter cardinality** , which helps the query planning choose a search strategy. **Filter cardinality** refers to the number of distinct values that a filter can match within a dataset. Qdrant’s search strategy can switch from **HNSW search** to **payload index-based search** if the cardinality is too low.
**How it affects your queries:** Depending on the filter used in the search - there are several possible scenarios for query execution. Qdrant chooses one of the query execution options depending on the available indexes, the complexity of the conditions and the cardinality of the filtering result.
  * The planner estimates the cardinality of a filtered result before selecting a strategy.
  * Qdrant retrieves points using the **payload index** if cardinality is below threshold.
  * Qdrant uses the **filterable vector index** if the cardinality is above a threshold
Our default full scan threshold is 10 kilobytes.
#### What happens if you don’t use payload indexes?
When using filters while querying, Qdrant needs to estimate cardinality of those filters to define a proper query plan. If you don’t create a payload index, Qdrant will not be able to do this. It may end up choosing a sub-optimal way of searching causing extremely slow search times or low accuracy results.
If you only rely on **searching for the nearest vector** , Qdrant will have to go through the entire vector index. It will calculate similarities against each vector in the collection, relevant or not. Alternatively, when you filter with the help of a payload index, the HSNW algorithm won’t have to evaluate every point. Furthermore, the payload index will help HNSW construct the graph with additional links.
## How does the payload index look?
A payload index is similar to conventional document-oriented databases. It connects metadata fields with their corresponding point id’s for quick retrieval.
In this example, you are indexing all of your computer hardware inside of the `computers` collection. Let’s take a look at a sample payload index for the field `category`.
```
Payload Index by keyword:
+------------+-------------+
| category   | id          |
+------------+-------------+
| laptop     | 1, 4, 7     |
| desktop    | 2, 5, 9     |
| speakers   | 3, 6, 8     |
| keyboard   | 10, 11      |
+------------+-------------+

```
When fields are properly indexed, the search engine roughly knows where it can start its journey. It can start looking up points that contain relevant metadata, and it doesn’t need to scan the entire dataset. This reduces the engine’s workload by a lot. As a result, query results are faster and the system can easily scale.
> You may create as many payload indexes as you want, and we recommend you do so for each field that you filter by.
If your users are often filtering by **laptop** when looking up a product **category** , indexing all computer metadata will speed up retrieval and make the results more precise.
#### Different types of payload indexes
Index Type | Description  
---|---  
[Full-text Index](https://qdrant.tech/documentation/concepts/indexing/#full-text-index) | Enables efficient text search in large datasets.  
[Tenant Index](https://qdrant.tech/documentation/concepts/indexing/#tenant-index) | For data isolation and retrieval efficiency in multi-tenant architectures.  
[Principal Index](https://qdrant.tech/documentation/concepts/indexing/#principal-index) | Manages data based on primary entities like users or accounts.  
[On-Disk Index](https://qdrant.tech/documentation/concepts/indexing/#on-disk-payload-index) | Stores indexes on disk to manage large datasets without memory usage.  
[Parameterized Index](https://qdrant.tech/documentation/concepts/indexing/#parameterized-index) | Allows for dynamic querying, where the index can adapt based on different parameters or conditions provided by the user. Useful for numeric data like prices or timestamps.  
### Indexing payloads in multitenant setups
Some applications need to have data segregated, whereby different users need to see different data inside of the same program. When setting up storage for such a complex application, many users think they need multiple databases for segregated users.
We see this quite often. Users very frequently make the mistake of creating a separate collection for each tenant inside of the same cluster. This can quickly exhaust the cluster’s resources. Running vector search through too many collections can start using up too much RAM. You may start seeing out-of-memory (OOM) errors and degraded performance.
To mitigate this, we offer extensive support for multitenant systems, so that you can build an entire global application in one single Qdrant collection.
When creating or updating a collection, you can mark a metadata field as indexable. To mark `user_id` as a tenant in a shared collection, do the following:
```
PUT /collections/{collection_name}/index
{
   "field_name": "user_id",
   "field_schema": {
       "type": "keyword",
       "is_tenant": true
   }
}

```
Additionally, we offer a way of organizing data efficiently by means of the tenant index. This is another variant of the payload index that makes tenant data more accessible. This time, the request will specify the field as a tenant. This means that you can mark various customer types and user id’s as `is_tenant: true`.
Read more about setting up [tenant defragmentation](https://qdrant.tech/documentation/concepts/indexing/?q=tenant#tenant-index) in multitenant environments,
## Key takeaways in filtering and indexing
![best-practices](https://qdrant.tech/articles_data/vector-search-filtering/best-practices.png)
### Filtering with float-point (decimal) numbers
If you filter by the float data type, your search precision may be limited and inaccurate.
Float Datatype numbers have a decimal point and are 64 bits in size. Here is an example:
```
{
   "price": 11.99
}

```
When you filter for a specific float number, such as 11.99, you may get a different result, like 11.98 or 12.00. With decimals, numbers are rounded differently, so logically identical values may appear different. Unfortunately, searching for exact matches can be unreliable in this case.
To avoid inaccuracies, use a different filtering method. We recommend that you try Range Based Filtering instead of exact matches. This method accounts for minor variations in data, and it boosts performance - especially with large datasets.
Here is a sample JSON range filter for values greater than or equal to 11.99 and less than or equal to the same number. This will retrieve any values within the range of 11.99, including those with additional decimal places.
```
{
 "key": "price",
 "range": {
   "gt": null,
   "gte": 11.99,
   "lt": null,
   "lte": 11.99
  }
}

```
### Working with pagination in queries
When you’re implementing pagination in filtered queries, indexing becomes even more critical. When paginating results, you often need to exclude items you’ve already seen. This is typically managed by applying filters that specify which IDs should not be included in the next set of results.
However, an interesting aspect of Qdrant’s data model is that a single point can have multiple values for the same field, such as different color options for a product. This means that during filtering, an ID might appear multiple times if it matches on different values of the same field.
Proper indexing ensures that these queries are efficient, preventing duplicate results and making pagination smoother.
## Conclusion: Real-life use cases of filtering
Filtering in a [vector database](https://qdrant.tech) like Qdrant can significantly enhance search capabilities by enabling more precise and efficient retrieval of data.
As a conclusion to this guide, let’s look at some real-life use cases where filtering is crucial:
**Use Case** | **Vector Search** | **Filtering**  
---|---|---  
[E-Commerce Product Search](https://qdrant.tech/advanced-search/) | Search for products by style or visual similarity | Filter by price, color, brand, size, ratings  
[Recommendation Systems](https://qdrant.tech/recommendations/) | Recommend similar content (e.g., movies, songs) | Filter by release date, genre, etc. (e.g., movies after 2020)  
[Geospatial Search in Ride-Sharing](https://qdrant.tech/articles/geo-polygon-filter-gsoc/) | Find similar drivers or delivery partners | Filter by rating, distance radius, vehicle type  
[Fraud & Anomaly Detection](https://qdrant.tech/data-analysis-anomaly-detection/) | Detect transactions similar to known fraud cases | Filter by amount, time, location  
#### Before you go - all the code is in Qdrant’s Dashboard
The easiest way to reach that “Hello World” moment is to [**try filtering in a live cluster**](https://qdrant.tech/documentation/quickstart-cloud/). Our interactive tutorial will show you how to create a cluster, add data and try some filtering clauses.
**It’s all in your free cluster!**
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/vector-search-filtering.md) this page on GitHub, or 
On this page:
  * [What is filtering?](https://qdrant.tech/articles/vector-search-filtering/#what-is-filtering)
  * [What you will learn in this guide:](https://qdrant.tech/articles/vector-search-filtering/#what-you-will-learn-in-this-guide)
  * [Qdrant’s approach to filtering](https://qdrant.tech/articles/vector-search-filtering/#qdrants-approach-to-filtering)
    * [Qdrant’s approach vs traditional filtering methods](https://qdrant.tech/articles/vector-search-filtering/#qdrants-approach-vs-traditional-filtering-methods)
  * [Basic filtering example: ecommerce and laptops](https://qdrant.tech/articles/vector-search-filtering/#basic-filtering-example-ecommerce-and-laptops)
    * [Scrolling instead of searching](https://qdrant.tech/articles/vector-search-filtering/#scrolling-instead-of-searching)
  * [Advanced filtering example: dinosaur diets](https://qdrant.tech/articles/vector-search-filtering/#advanced-filtering-example-dinosaur-diets)
  * [Other creative uses for filters](https://qdrant.tech/articles/vector-search-filtering/#other-creative-uses-for-filters)
  * [Filtering with the payload index](https://qdrant.tech/articles/vector-search-filtering/#filtering-with-the-payload-index)
  * [How does the payload index look?](https://qdrant.tech/articles/vector-search-filtering/#how-does-the-payload-index-look)
    * [Indexing payloads in multitenant setups](https://qdrant.tech/articles/vector-search-filtering/#indexing-payloads-in-multitenant-setups)
  * [Key takeaways in filtering and indexing](https://qdrant.tech/articles/vector-search-filtering/#key-takeaways-in-filtering-and-indexing)
    * [Filtering with float-point (decimal) numbers](https://qdrant.tech/articles/vector-search-filtering/#filtering-with-float-point-decimal-numbers)
    * [Working with pagination in queries](https://qdrant.tech/articles/vector-search-filtering/#working-with-pagination-in-queries)
  * [Conclusion: Real-life use cases of filtering](https://qdrant.tech/articles/vector-search-filtering/#conclusion-real-life-use-cases-of-filtering)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/vector-search-filtering/)
                    ## 📄 `https-qdrant-tech-articles-vector-search-manuals.md`
                    ```md
                    # https://qdrant.tech/articles/vector-search-manuals/
  * [Articles](https://qdrant.tech/articles/)
  * Vector Search Manuals
#### Vector Search Manuals
Take full control of your vector data with Qdrant. Learn how to easily store, organize, and optimize vectors for high-performance similarity search.
[![Preview](https://qdrant.tech/articles_data/indexing-optimization/preview/preview.jpg) Optimizing Memory for Bulk Uploads Efficient memory management is key when handling large-scale vector data. Learn how to optimize memory consumption during bulk uploads in Qdrant and keep your deployments performant under heavy load. Sabrina Aquino February 13, 2025 ](https://qdrant.tech/articles/indexing-optimization/)[![Preview](https://qdrant.tech/articles_data/vector-search-resource-optimization/preview/preview.jpg) Vector Search Resource Optimization Guide Learn how to get the most from Qdrant's optimization features. Discover key tricks and best practices to boost vector search performance and reduce Qdrant's resource usage. David Myriel February 09, 2025 ](https://qdrant.tech/articles/vector-search-resource-optimization/)[![Preview](https://qdrant.tech/articles_data/what-is-a-vector-database/preview/preview.jpg) An Introduction to Vector Databases Discover what a vector database is, its core functionalities, and real-world applications. Sabrina Aquino October 09, 2024 ](https://qdrant.tech/articles/what-is-a-vector-database/)[![Preview](https://qdrant.tech/articles_data/what-is-vector-quantization/preview/preview.jpg) What is Vector Quantization? In this article, we'll teach you about compression methods like Scalar, Product, and Binary Quantization. Learn how to choose the best method for your specific application. Sabrina Aquino September 25, 2024 ](https://qdrant.tech/articles/what-is-vector-quantization/)[![Preview](https://qdrant.tech/articles_data/vector-search-filtering/preview/preview.jpg) A Complete Guide to Filtering in Vector Search Learn everything about filtering in Qdrant. Discover key tricks and best practices to boost semantic search performance and reduce Qdrant's resource usage. Sabrina Aquino, David Myriel September 10, 2024 ](https://qdrant.tech/articles/vector-search-filtering/)[![Preview](https://qdrant.tech/articles_data/hybrid-search/preview/preview.jpg) Hybrid Search Revamped - Building with Qdrant's Query API Our new Query API allows you to build a hybrid search system that uses different search methods to improve search quality & experience. Learn more here. Kacper Łukawski July 25, 2024 ](https://qdrant.tech/articles/hybrid-search/)[![Preview](https://qdrant.tech/articles_data/data-privacy/preview/preview.jpg) Data Privacy with Qdrant: Implementing Role-Based Access Control (RBAC) Discover how Qdrant's Role-Based Access Control (RBAC) ensures data privacy and compliance for your AI applications. Build secure and scalable systems with ease. Read more now! Qdrant Team June 18, 2024 ](https://qdrant.tech/articles/data-privacy/)[![Preview](https://qdrant.tech/articles_data/what-are-embeddings/preview/preview.jpg) What are Vector Embeddings? - Revolutionize Your Search Experience Discover the power of vector embeddings. Learn how to harness the potential of numerical machine learning representations to create a personalized Neural Search Service with FastEmbed. Sabrina Aquino February 06, 2024 ](https://qdrant.tech/articles/what-are-embeddings/)[![Preview](https://qdrant.tech/articles_data/multitenancy/preview/preview.jpg) How to Implement Multitenancy and Custom Sharding in Qdrant Discover how multitenancy and custom sharding in Qdrant can streamline your machine-learning operations. Learn how to scale efficiently and manage data securely. David Myriel February 06, 2024 ](https://qdrant.tech/articles/multitenancy/)[![Preview](https://qdrant.tech/articles_data/sparse-vectors/preview/preview.jpg) What is a Sparse Vector? How to Achieve Vector-based Hybrid Search Learn what sparse vectors are, how they work, and their importance in modern data processing. Explore methods like SPLADE for creating and leveraging sparse vectors efficiently. Nirant Kasliwal December 09, 2023 ](https://qdrant.tech/articles/sparse-vectors/)[![Preview](https://qdrant.tech/articles_data/storing-multiple-vectors-per-object-in-qdrant/preview/preview.jpg) Optimizing Semantic Search by Managing Multiple Vectors Discover the power of vector storage optimization and learn how to efficiently manage multiple vectors per object for enhanced semantic search capabilities. Kacper Łukawski October 05, 2022 ](https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/)[![Preview](https://qdrant.tech/articles_data/batch-vector-search-with-qdrant/preview/preview.jpg) Mastering Batch Search for Vector Optimization Discover how to optimize your vector search capabilities with efficient batch search. Learn optimization strategies for faster, more accurate results. Kacper Łukawski September 26, 2022 ](https://qdrant.tech/articles/batch-vector-search-with-qdrant/)[![Preview](https://qdrant.tech/articles_data/neural-search-tutorial/preview/preview.jpg) Neural Search 101: A Complete Guide and Step-by-Step Tutorial Discover the power of neural search. Learn what neural search is and follow our tutorial to build a neural search service using BERT, Qdrant, and FastAPI. Andrey Vasnetsov June 10, 2021 ](https://qdrant.tech/articles/neural-search-tutorial/)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/vector-search-manuals/)
                    ## 📄 `https-qdrant-tech-articles-vector-search-resource-optimization.md`
                    ```md
                    # https://qdrant.tech/articles/vector-search-resource-optimization/
  * [Articles](https://qdrant.tech/articles/)
  * Vector Search Resource Optimization Guide
# Vector Search Resource Optimization Guide
David Myriel
·
February 09, 2025
![Vector Search Resource Optimization Guide](https://qdrant.tech/articles_data/vector-search-resource-optimization/preview/title.jpg)
## What’s in This Guide?
[**Resource Management Strategies:**](https://qdrant.tech/articles/vector-search-resource-optimization/#storage-disk-vs-ram) If you are trying to scale your app on a budget - this is the guide for you. We will show you how to avoid wasting compute resources and get the maximum return on your investment.
[**Performance Improvement Tricks:**](https://qdrant.tech/articles/vector-search-resource-optimization/#configure-indexing-for-faster-searches) We’ll dive into advanced techniques like indexing, compression, and partitioning. Our tips will help you get better results at scale, while reducing total resource expenditure.
[**Query Optimization Methods:**](https://qdrant.tech/articles/vector-search-resource-optimization/#query-optimization) Improving your vector database setup isn’t just about saving costs. We’ll show you how to build search systems that deliver consistently high precision while staying adaptable.
#### Remember: Optimization is a Balancing Act
In this guide, we will show you how to use Qdrant’s features to meet your performance needs. However - there are resource tradeoffs and you can’t have it all. It is up to you to choose the optimization strategy that best fits your goals.
![optimization](https://qdrant.tech/articles_data/vector-search-resource-optimization/optimization.png)
Let’s take a look at some common goals and optimization strategies:
Intended Result | Optimization Strategy  
---|---  
[**On-Disk Indexing**](https://qdrant.tech/documentation/guides/optimize/#1-high-speed-search-with-low-memory-usage)  
[**Low Memory Expenditure + Fast Search Speed**](https://qdrant.tech/documentation/guides/quantization/) | [**Quantization**](https://qdrant.tech/documentation/guides/quantization/)  
[**High Search Precision + Fast Search Speed**](https://qdrant.tech/documentation/guides/optimize/#3-high-precision-with-high-speed-search) | [**RAM Storage + Quantization**](https://qdrant.tech/documentation/guides/optimize/#3-high-precision-with-high-speed-search)  
[**Balance Latency vs Throughput**](https://qdrant.tech/documentation/guides/optimize/#balancing-latency-and-throughput) | [**Segment Configuration**](https://qdrant.tech/documentation/guides/optimize/#balancing-latency-and-throughput)  
After this article, check out the code samples in our docs on [**Qdrant’s Optimization Methods**](https://qdrant.tech/documentation/guides/optimize/).
## Configure Indexing for Faster Searches
![indexing](https://qdrant.tech/articles_data/vector-search-resource-optimization/index.png)
A vector index is the central location where Qdrant calculates vector similarity. It is the backbone of your search process, retrieving relevant results from vast amounts of data.
Qdrant uses the [**HNSW (Hierarchical Navigable Small World Graph) algorithm**](https://qdrant.tech/documentation/concepts/indexing/#vector-index) as its dense vector index, which is both powerful and scalable.
**Figure 2:** A sample HNSW vector index with three layers. Follow the blue arrow on the top layer to see how a query travels throughout the database index. The closest result is on the bottom level, nearest to the gray query point.
![hnsw](https://qdrant.tech/articles_data/vector-search-resource-optimization/hnsw.png)
#### Vector Index Optimization Parameters
Working with massive datasets that contain billions of vectors demands significant resources—and those resources come with a price. While Qdrant provides reasonable defaults, tailoring them to your specific use case can unlock optimal performance. Here’s what you need to know.
The following parameters give you the flexibility to fine-tune Qdrant’s performance for your specific workload. You can modify them directly in Qdrant’s [**configuration**](https://qdrant.tech/documentation/guides/configuration/) files or at the collection and named vector levels for more granular control.
**Figure 3:** A description of three key HNSW parameters.
![hnsw-parameters](https://qdrant.tech/articles_data/vector-search-resource-optimization/hnsw-parameters.png)
#### 1. The `m` parameter determines edges per node
This controls the number of edges in the graph. A higher value enhances search accuracy but demands more memory and build time. Fine-tune this to balance memory usage and precision.
#### 2. The `ef_construct` parameter controls the index build range
This parameter sets how many neighbors are considered during index construction. A larger value improves the accuracy of the index but increases the build time. Use this to customize your indexing speed versus quality.
You need to set both the `m` and `ef parameters` as you create the collection:
```
client.update_collection(
    collection_name="{collection_name}",
    vectors_config={
        "my_vector": models.VectorParamsDiff(
            hnsw_config=models.HnswConfigDiff(
                m=32,
                ef_construct=123,
            ),
        ),
    }
)

```
#### 3. The `ef` parameter updates vector search range
This determines how many neighbors are evaluated during a search query. You can adjust this to balance query speed and accuracy.
The `ef` parameter is configured during the search process:
```
client.query_points(
   collection_name="{collection_name}",
   query=[...]
   search_params=models.SearchParams(hnsw_ef=128, exact=False),
)

```
* * *
These are just the basics of HNSW. Learn More about [**Indexing**](https://qdrant.tech/documentation/concepts/indexing/).
* * *
## Data Compression Techniques
![compression](https://qdrant.tech/articles_data/vector-search-resource-optimization/compress.png)
Efficient data compression is a cornerstone of resource optimization in vector databases. By reducing memory usage, you can achieve faster query performance without sacrificing too much accuracy.
One powerful technique is [**quantization**](https://qdrant.tech/documentation/guides/quantization/), which transforms high-dimensional vectors into compact representations while preserving relative similarity. Let’s explore the quantization options available in Qdrant.
#### Scalar Quantization
Scalar quantization strikes an excellent balance between compression and performance, making it the go-to choice for most use cases.
This method minimizes the number of bits used to represent each vector component. For instance, Qdrant compresses 32-bit floating-point values (**float32**) into 8-bit unsigned integers (**uint8**), slashing memory usage by an impressive 75%.
**Figure 4:** The top example shows a float32 vector with a size of 40 bytes. Converting it to int8 format reduces its size by a factor of four, while maintaining approximate similarity relationships between vectors. The loss in precision compared to the original representation is typically negligible for most practical applications.
![scalar-quantization](https://qdrant.tech/articles_data/vector-search-resource-optimization/scalar-quantization.png)
#### Benefits of Scalar Quantization:
Benefit | Description  
---|---  
**Memory usage will drop** | Compression cuts memory usage by a factor of 4. Qdrant compresses 32-bit floating-point values (float32) into 8-bit unsigned integers (uint8).  
**Accuracy loss is minimal** | Converting from float32 to uint8 introduces a small loss in precision. Typical error rates remain below 1%, making this method highly efficient.  
**Best for specific use cases** | To be used with high-dimensional vectors where minor accuracy losses are acceptable.  
#### Set it up as you create the collection:
```
client.create_collection(
   collection_name="{collection_name}",
   vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE),
   quantization_config=models.ScalarQuantization(
       scalar=models.ScalarQuantizationConfig(
           type=models.ScalarType.INT8,
           quantile=0.99,
           always_ram=True,
       ),
   ),
)

```
When working with Qdrant, you can fine-tune the quantization configuration to optimize precision, memory usage, and performance. Here’s what the key configuration options include:
Configuration Option | Description  
---|---  
`type` | Specifies the quantized vector type (currently supports only int8).  
`quantile` | Sets bounds for quantization, excluding outliers. For example, 0.99 excludes the top 1% of extreme values to maintain better accuracy.  
`always_ram` | Keeps quantized vectors in RAM to speed up searches.  
Adjust these settings to strike the right balance between precision and efficiency for your specific workload.
* * *
Learn More about [**Scalar Quantization**](https://qdrant.tech/documentation/guides/quantization/)
* * *
#### Binary Quantization
**Binary quantization** takes scalar quantization to the next level by compressing each vector component into just **a single bit**. This method achieves unparalleled memory efficiency and query speed, reducing memory usage by a factor of 32 and enabling searches up to 40x faster.
#### **Benefits of Binary Quantization:**
Binary quantization is ideal for large-scale datasets and compatible embedding models, where compression and speed are paramount.
**Figure 5:** This method causes maximum compression. It reduces memory usage by 32x and speeds up searches by up to 40x.
![binary-quantization](https://qdrant.tech/articles_data/vector-search-resource-optimization/binary-quantization.png)
Benefit | Description  
---|---  
**Efficient similarity calculations** | Emulates Hamming distance through dot product comparisons, making it fast and effective.  
**Perfect for high-dimensional vectors** | Works well with embedding models like OpenAI’s text-embedding-ada-002 or Cohere’s embed-english-v3.0.  
**Precision management** | Consider rescoring or oversampling to offset precision loss.  
Here’s how you can enable binary quantization in Qdrant:
```
client.create_collection(
   collection_name="{collection_name}",
   vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE),
   quantization_config=models.BinaryQuantization(
       binary=models.BinaryQuantizationConfig(
           always_ram=True,
       ),
   ),
)

```
> By default, quantized vectors load like original vectors unless you set `always_ram` to `True` for instant access and faster queries.
* * *
Learn more about [**Binary Quantization**](https://qdrant.tech/documentation/guides/quantization/)
* * *
## Scaling the Database
![sharding](https://qdrant.tech/articles_data/vector-search-resource-optimization/shards.png)
Efficiently managing large datasets in distributed systems like Qdrant requires smart strategies for data isolation. **Multitenancy** and **Sharding** are essential tools to help you handle high volumes of user-specific data while maintaining performance and scalability.
#### Multitenancy
**Multitenancy** is a software architecture where multiple independent users (or tenants) share the same resources or environment. In Qdrant, a single collection with logical partitioning is often the most efficient setup for multitenant use cases.
**Figure 5:** Each individual vector is assigned a specific payload that denotes which tenant it belongs to. This is how a large number of different tenants can share a single Qdrant collection.
![multitenancy](https://qdrant.tech/articles_data/vector-search-resource-optimization/multitenancy.png)
**Why Choose Multitenancy?**
  * **Logical Isolation** : Ensures each tenant’s data remains separate while residing in the same collection.
  * **Minimized Overhead** : Reduces resource consumption compared to maintaining separate collections for each user.
  * **Scalability** : Handles high user volumes without compromising performance.
Here’s how you can implement multitenancy efficiently in Qdrant:
```
client.create_payload_index(
    collection_name="{collection_name}",
    field_name="group_id",
    field_schema=models.KeywordIndexParams(
        type="keyword",
        is_tenant=True,
    ),
)

```
Creating a keyword payload index, with the `is_tenant` parameter set to `True`, modifies the way the vectors will be logically stored. Storage structure will be organized to co-locate vectors of the same tenant together.
Now, each point stored in Qdrant should have the `group_id` payload attribute set:
```
client.upsert(
   collection_name="{collection_name}",
   points=[
       models.PointStruct(
           id=1,
           payload={"group_id": "user_1"},
           vector=[0.9, 0.1, 0.1],
       ),
       models.PointStruct(
           id=2,
           payload={"group_id": "user_2"},
           vector=[0.5, 0.9, 0.4],
       )
   ]
)

```
* * *
To ensure proper data isolation in a multitenant environment, you can assign a unique identifier, such as a **group_id** , to each vector. This approach ensures that each user’s data remains segregated, allowing users to access only their own data. You can further enhance this setup by applying filters during queries to restrict access to the relevant data.
* * *
Learn More about [**Multitenancy**](https://qdrant.tech/documentation/guides/multiple-partitions/)
* * *
#### Sharding
Sharding is a critical strategy in Qdrant for splitting collections into smaller units, called **shards** , to efficiently distribute data across multiple nodes. It’s a powerful tool for improving scalability and maintaining performance in large-scale systems.
#### User-Defined Sharding:
**User-Defined Sharding** allows you to take control of data placement by specifying a shard key. This feature is particularly useful in multi-tenant setups, as it enables the isolation of each tenant’s data within separate shards, ensuring better organization and enhanced data security.
**Figure 6:** Users can both upsert and query shards that are relevant to them, all within the same collection. Regional sharding can help avoid cross-continental traffic.
![user-defined-sharding](https://qdrant.tech/articles_data/vector-search-resource-optimization/user-defined-sharding.png)
**Example:**
```
client.create_collection(
    collection_name="my_custom_sharded_collection",
    shard_number=1,
    sharding_method=models.ShardingMethod.CUSTOM
)
client.create_shard_key("my_custom_sharded_collection", "tenant_id")

```
* * *
When implementing user-defined sharding in Qdrant, two key parameters are critical to achieving efficient data distribution:
  1. **Shard Key** :
The shard key determines how data points are distributed across shards. For example, using a key like `tenant_id` allows you to control how Qdrant partitions the data. Each data point added to the collection will be assigned to a shard based on the value of this key, ensuring logical isolation of data.
  2. **Shard Number** :
This defines the total number of physical shards for each shard key, influencing resource allocation and query performance.
Here’s how you can add a data point to a collection with user-defined sharding:
```
client.upsert(
    collection_name="my_custom_sharded_collection", 
    points=[
        models.PointStruct(
            id=1111, 
            vector=[0.1, 0.2, 0.3]
        )
    ], 
    shard_key_selector="tenant_1"
)

```
* * *
This code assigns the point to a specific shard based on the `tenant_1` shard key, ensuring proper data placement.
Here’s how to choose the shard_number:
Recommendation | Description  
---|---  
**Match Shards to Nodes** | The number of shards should align with the number of nodes in your cluster to balance resource utilization and query performance.  
**Plan for Scalability** | Start with at least **2 shards per node** to allow room for future growth.  
**Future-Proofing** | Starting with around **12 shards** is a good rule of thumb. This setup allows your system to scale seamlessly from 1 to 12 nodes without requiring re-sharding.  
Learn more about [**Sharding in Distributed Deployment**](https://qdrant.tech/documentation/guides/distributed_deployment/)
* * *
## Query Optimization
![qdrant](https://qdrant.tech/articles_data/vector-search-resource-optimization/query.png) Improving vector database performance is critical when dealing with large datasets and complex queries. By leveraging techniques like **filtering** , **batch processing** , **reranking** , **rescoring** , and **oversampling** , so you can ensure fast response times and maintain efficiency even at scale.
#### Filtering
Filtering allows you to select only the required fields in your query results. By limiting the output size, you can significantly reduce response time and improve performance.
The filterable vector index is Qdrant’s solves pre and post-filtering problems by adding specialized links to the search graph. It aims to maintain the speed advantages of vector search while allowing for precise filtering, addressing the inefficiencies that can occur when applying filters after the vector search.
**Example:**
```
results = client.search(
    collection_name="my_collection",
    query_vector=[0.1, 0.2, 0.3],
    query_filter=models.Filter(must=[
        models.FieldCondition(
            key="category",
            match=models.MatchValue(value="my-category-name"),
        )
    ]),
    limit=10, 
)

```
**Figure 7:** The filterable vector index adds specialized links to the search graph to speed up traversal.
![filterable-vector-index](https://qdrant.tech/articles_data/vector-search-resource-optimization/filterable-vector-index.png)
[**Filterable vector index**](https://qdrant.tech/documentation/concepts/indexing/): This technique builds additional links **(orange)** between leftover data points. The filtered points which stay behind are now traversible once again. Qdrant uses special category-based methods to connect these data points.
* * *
Read more about [**Filtering Docs**](https://qdrant.tech/documentation/concepts/filtering/) and check out the [**Complete Filtering Guide**](https://qdrant.tech/articles/vector-search-filtering/).
* * *
#### Batch Processing
Batch processing consolidates multiple operations into a single execution cycle, reducing request overhead and enhancing throughput. It’s an effective strategy for both data insertion and query execution.
![batch-processing](https://qdrant.tech/articles_data/vector-search-resource-optimization/batch-processing.png)
**Batch Insertions** : Instead of inserting vectors individually, group them into medium-sized batches to minimize the number of database requests and the overhead of frequent writes.
**Example:**
```
vectors = [
   [.1, .0, .0, .0],
   [.0, .1, .0, .0],
   [.0, .0, .1, .0],
   [.0, .0, .0, .1],
   …
]
client.upload_collection(
   collection_name="test_collection",
   vectors=vectors,
)

```
This reduces write operations and ensures faster data ingestion.
**Batch Queries** : Similarly, you can batch multiple queries together rather than executing them one by one. This reduces the number of round trips to the database, optimizing performance and reducing latency.
**Example:**
```
results = client.search_batch(
   collection_name="test_collection",
   requests=[
       SearchRequest(
           vector=[0., 0., 2., 0.],
           limit=1,
       ),
       SearchRequest(
           vector=[0., 0., 0., 0.01],
           with_vector=True,
           limit=2,
       )
   ]
)

```
Batch queries are particularly useful when processing a large number of similar queries or when handling multiple user requests simultaneously.
#### Hybrid Search
Hybrid search combines **keyword filtering** with **vector similarity search** , enabling faster and more precise results. Keywords help narrow down the dataset quickly, while vector similarity ensures semantic accuracy. This search method combines [**dense and sparse vectors**](https://qdrant.tech/documentation/concepts/vectors/).
Hybrid search in Qdrant uses both fusion and reranking. The former is about combining the results from different search methods, based solely on the scores returned by each method. That usually involves some normalization, as the scores returned by different methods might be in different ranges.
**Figure 8** : Hybrid Search Architecture
![hybrid-search](https://qdrant.tech/articles_data/vector-search-resource-optimization/hybrid-search.png)
After that, there is a formula that takes the relevancy measures and calculates the final score that we use later on to reorder the documents. Qdrant has built-in support for the Reciprocal Rank Fusion method, which is the de facto standard in the field.
* * *
Learn more about [**Hybrid Search**](https://qdrant.tech/articles/hybrid-search/) and read out [**Hybrid Queries docs**](https://qdrant.tech/documentation/concepts/hybrid-queries/).
* * *
#### Oversampling
Oversampling is a technique that helps compensate for any precision lost due to quantization. Since quantization simplifies vectors, some relevant matches could be missed in the initial search. To avoid this, you can **retrieve more candidates** , increasing the chances that the most relevant vectors make it into the final results.
You can control the number of extra candidates by setting an `oversampling` parameter. For example, if your desired number of results (`limit`) is 4 and you set an `oversampling` factor of 2, Qdrant will retrieve 8 candidates (4 × 2).
You can adjust the oversampling factor to control how many extra vectors Qdrant includes in the initial pool. More candidates mean a better chance of obtaining high-quality top-K results, especially after rescoring with the original vectors.
* * *
Learn more about [**Oversampling**](https://qdrant.tech/articles/what-is-vector-quantization/#2-oversampling).
* * *
#### Rescoring
After oversampling to gather more potential matches, each candidate is re-evaluated based on additional criteria to ensure higher accuracy and relevance to the query.
The rescoring process maps the quantized vectors to their corresponding original vectors, allowing you to consider factors like context, metadata, or additional relevance that wasn’t included in the initial search, leading to more accurate results.
**Example of Rescoring and Oversampling:** :
```
client.query_points(
    collection_name="my_collection",
    query_vector=[0.22, -0.01, -0.98, 0.37],
    search_params=models.SearchParams(
        quantization=models.QuantizationSearchParams(
            rescore=True,   # Enables rescoring with original vectors
            oversampling=2  # Retrieves extra candidates for rescoring
        )
    ),
    limit=4  # Desired number of final results
)

```
* * *
Learn more about [**Rescoring**](https://qdrant.tech/articles/what-is-vector-quantization/#3-rescoring-with-original-vectors).
* * *
#### Reranking
Reranking adjusts the order of search results based on additional criteria, ensuring the most relevant results are prioritized.
This method is about taking the results from different search methods and reordering them based on some additional processing using the content of the documents, not just the scores. This processing may rely on an additional neural model, such as a cross-encoder which would be inefficient enough to be used on the whole dataset.
![reranking](https://qdrant.tech/articles_data/vector-search-resource-optimization/reranking.png)
These methods are practically applicable only when used on a smaller subset of candidates returned by the faster search methods. Late interaction models, such as ColBERT, are way more efficient in this case, as they can be used to rerank the candidates without the need to access all the documents in the collection.
**Example:**
```
client.query_points(
       "collection-name",
       prefetch=prefetch, # Previous results
       query=late_vectors, # Colbert converted query
       using="colbertv2.0",
       with_payload=True,
       limit=10,
)

```
* * *
Learn more about [**Reranking**](https://qdrant.tech/documentation/search-precision/reranking-hybrid-search/#rerank).
* * *
## Storage: Disk vs RAM
![disk](https://qdrant.tech/articles_data/vector-search-resource-optimization/disk.png)
Storage | Description  
---|---  
**RAM** | Crucial for fast access to frequently used data, such as indexed vectors. The amount of RAM required can be estimated based on your dataset size and dimensionality. For example, storing **1 million vectors with 1024 dimensions** would require approximately **5.72 GB of RAM**.  
**Disk** | Suitable for less frequently accessed data, such as payloads and non-critical information. Disk-backed storage reduces memory demands but can introduce slight latency.  
#### Which Disk Type?
**Local SSDs** are recommended for optimal performance, as they provide the fastest query response times with minimal latency. While network-attached storage is also viable, it typically introduces additional latency that can affect performance, so local SSDs are preferred when possible, particularly for workloads requiring high-speed random access.
#### Memory Management for Vectors and Payload
As your data scales, effective resource management becomes crucial to keeping costs low while ensuring your application remains reliable and performant. One of the key areas to focus on is **memory management**.
Understanding how Qdrant handles memory can help you make informed decisions about scaling your vector database. Qdrant supports two main methods for storing vectors:
#### 1. In-Memory Storage
  * **How it works** : All data is stored in RAM, providing the fastest access times for queries and operations.
  * **When to use it** : This setup is ideal for applications where performance is critical, and your RAM capacity can accommodate all data.
  * **Advantages** : Maximum speed for queries and updates.
  * **Limitations** : RAM usage can become a bottleneck as your dataset grows.
#### 2. Memmap Storage
  * **How it works** : Instead of loading all data into memory, memmap storage maps data files directly to a virtual address space on disk. The system’s page cache handles data access, making it highly efficient.
  * **When to use it** : Perfect for storing large collections that exceed your available RAM while still maintaining near in-memory performance when enough RAM is available.
  * **Advantages** : Balances performance and memory usage, allowing you to work with datasets larger than your physical RAM.
  * **Limitations** : Slightly slower than pure in-memory storage but significantly more scalable.
To enable memmap vector storage in Qdrant, you can set the **on_disk** parameter to `true` when creating or updating a collection.
```
client.create_collection(
   collection_name="{collection_name}",
   vectors_config=models.VectorParams(
      …
      on_disk=True
   )
)

```
To do the same for payloads:
```
client.create_collection(
    collection_name="{collection_name}",
    on_disk_payload= True
)

```
The general guideline for selecting a storage method in Qdrant is to use **InMemory storage** when high performance is a priority, and sufficient RAM is available to accommodate the dataset. This approach ensures the fastest access speeds by keeping data readily accessible in memory.
However, for larger datasets or scenarios where memory is limited, **Memmap** and **OnDisk storage** are more suitable. These methods significantly reduce memory usage by storing data on disk while leveraging advanced techniques like page caching and indexing to maintain efficient and relatively fast data access.
## Monitoring the Database
![monitoring](https://qdrant.tech/articles_data/vector-search-resource-optimization/monitor.png)
Continuous monitoring is essential for maintaining system health and identifying potential issues before they escalate. Tools like **Prometheus** and **Grafana** are widely used to achieve this.
  * **Prometheus** : An open-source monitoring and alerting toolkit, Prometheus collects and stores metrics in a time-series database. It scrapes metrics from predefined endpoints and supports powerful querying and visualization capabilities.
  * **Grafana** : Often paired with Prometheus, Grafana provides an intuitive interface for visualizing metrics and creating interactive dashboards.
Qdrant exposes metrics in the **Prometheus/OpenMetrics** format through the /metrics endpoint. Prometheus can scrape this endpoint to monitor various aspects of the Qdrant system.
For a local Qdrant instance, the metrics endpoint is typically available at:
```
http://localhost:6333/metrics

```
* * *
Here are some important metrics to monitor:
**Metric Name** | **Meaning**  
---|---  
collections_total | Total number of collections  
collections_vector_total | Total number of vectors in all collections  
rest_responses_avg_duration_seconds | Average response duration in REST API  
grpc_responses_avg_duration_seconds | Average response duration in gRPC API  
rest_responses_fail_total | Total number of failed responses (REST)  
Read more about [**Qdrant Open Source Monitoring**](https://qdrant.tech/documentation/guides/monitoring/) and [**Qdrant Cloud Monitoring**](https://qdrant.tech/documentation/cloud/cluster-monitoring/) for managed clusters.
* * *
## Recap: When Should You Optimize?
![solutions](https://qdrant.tech/articles_data/vector-search-resource-optimization/solutions.png)
Scenario | Description  
---|---  
**When You Scale Up** | As data grows and the request surge, optimizing resource usage ensures your systems stay responsive and cost-efficient, even under heavy loads.  
**If Facing Budget Constraints** | Strike the perfect balance between performance and cost, cutting unnecessary expenses while maintaining essential capabilities.  
**You Need Better Performance** | If you’re noticing slow query speeds, latency issues, or frequent timeouts, it’s time to fine-tune your resource allocation.  
**When System Stability is Paramount** | To manage high-traffic environments you will need to prevent crashes or failures caused by resource exhaustion.  
## Get the Cheatsheet
Want to download a printer-friendly version of this guide? [**Download it now.**](https://try.qdrant.tech/resource-optimization-guide).
[![downloadable vector search resource optimization guide](https://qdrant.tech/articles_data/vector-search-resource-optimization/downloadable-guide.jpg)](https://try.qdrant.tech/resource-optimization-guide)
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/vector-search-resource-optimization.md) this page on GitHub, or 
On this page:
  * [What’s in This Guide?](https://qdrant.tech/articles/vector-search-resource-optimization/#whats-in-this-guide)
  * [Configure Indexing for Faster Searches](https://qdrant.tech/articles/vector-search-resource-optimization/#configure-indexing-for-faster-searches)
  * [Data Compression Techniques](https://qdrant.tech/articles/vector-search-resource-optimization/#data-compression-techniques)
  * [Scaling the Database](https://qdrant.tech/articles/vector-search-resource-optimization/#scaling-the-database)
  * [Query Optimization](https://qdrant.tech/articles/vector-search-resource-optimization/#query-optimization)
  * [Storage: Disk vs RAM](https://qdrant.tech/articles/vector-search-resource-optimization/#storage-disk-vs-ram)
  * [Monitoring the Database](https://qdrant.tech/articles/vector-search-resource-optimization/#monitoring-the-database)
  * [Recap: When Should You Optimize?](https://qdrant.tech/articles/vector-search-resource-optimization/#recap-when-should-you-optimize)
  * [Get the Cheatsheet](https://qdrant.tech/articles/vector-search-resource-optimization/#get-the-cheatsheet)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/vector-search-resource-optimization/)
                    ## 📄 `https-qdrant-tech-articles-vector-similarity-beyond-search.md`
                    ```md
                    # https://qdrant.tech/articles/vector-similarity-beyond-search/
  * [Articles](https://qdrant.tech/articles/)
  * Vector Similarity: Going Beyond Full-Text Search | Qdrant
# Vector Similarity: Going Beyond Full-Text Search | Qdrant
Luis Cossío
·
August 08, 2023
![Vector Similarity: Going Beyond Full-Text Search | Qdrant](https://qdrant.tech/articles_data/vector-similarity-beyond-search/preview/title.jpg)
# Vector Similarity: Unleashing Data Insights Beyond Traditional Search
When making use of unstructured data, there are traditional go-to solutions that are well-known for developers:
  * **Full-text search** when you need to find documents that contain a particular word or phrase.
  * **[Vector search](https://qdrant.tech/documentation/overview/vector-search/)** when you need to find documents that are semantically similar to a given query.
Sometimes people mix those two approaches, so it might look like the vector similarity is just an extension of full-text search. However, in this article, we will explore some promising new techniques that can be used to expand the use-case of unstructured data and demonstrate that vector similarity creates its own stack of data exploration tools.
## What is vector similarity search?
Vector similarity offers a range of powerful functions that go far beyond those available in traditional full-text search engines. From dissimilarity search to diversity and recommendation, these methods can expand the cases in which vectors are useful.
Vector Databases, which are designed to store and process immense amounts of vectors, are the first candidates to implement these new techniques and allow users to exploit their data to its fullest.
## Vector similarity search vs. full-text search
While there is an intersection in the functionality of these two approaches, there is also a vast area of functions that is unique to each of them. For example, the exact phrase matching and counting of results are native to full-text search, while vector similarity support for this type of operation is limited. On the other hand, vector similarity easily allows cross-modal retrieval of images by text or vice-versa, which is impossible with full-text search.
This mismatch in expectations might sometimes lead to confusion. Attempting to use a vector similarity as a full-text search can result in a range of frustrations, from slow response times to poor search results, to limited functionality. As an outcome, they are getting only a fraction of the benefits of vector similarity.
![Full-text search and Vector Similarity Functionality overlap](https://qdrant.tech/articles_data/vector-similarity-beyond-search/venn-diagram.png)
Full-text search and Vector Similarity Functionality overlap
Below we will explore why the vector similarity stack deserves new interfaces and design patterns that will unlock the full potential of this technology, which can still be used in conjunction with full-text search.
## New ways to interact with similarities
Having a vector representation of unstructured data unlocks new ways of interacting with it. For example, it can be used to measure semantic similarity between words, to cluster words or documents based on their meaning, to find related images, or even to generate new text. However, these interactions can go beyond finding their nearest neighbors (kNN).
There are several other techniques that can be leveraged by vector representations beyond the traditional kNN search. These include dissimilarity search, diversity search, recommendations, and discovery functions.
## Dissimilarity ssearch
The Dissimilarity —or farthest— search is the most straightforward concept after the nearest search, which can’t be reproduced in a traditional full-text search. It aims to find the most un-similar or distant documents across the collection.
![Dissimilarity Search](https://qdrant.tech/articles_data/vector-similarity-beyond-search/dissimilarity.png)
Dissimilarity Search
Unlike full-text match, Vector similarity can compare any pair of documents (or points) and assign a similarity score. It doesn’t rely on keywords or other metadata. With vector similarity, we can easily achieve a dissimilarity search by inverting the search objective from maximizing similarity to minimizing it.
The dissimilarity search can find items in areas where previously no other search could be used. Let’s look at a few examples.
### Case: mislabeling detection
For example, we have a dataset of furniture in which we have classified our items into what kind of furniture they are: tables, chairs, lamps, etc. To ensure our catalog is accurate, we can use a dissimilarity search to highlight items that are most likely mislabeled.
To do this, we only need to search for the most dissimilar items using the embedding of the category title itself as a query. This can be too broad, so, by combining it with filters —a [Qdrant superpower](https://qdrant.tech/articles/filtrable-hnsw/)—, we can narrow down the search to a specific category.
![Mislabeling Detection](https://qdrant.tech/articles_data/vector-similarity-beyond-search/mislabelling.png)
Mislabeling Detection
The output of this search can be further processed with heavier models or human supervision to detect actual mislabeling.
### Case: outlier detection
In some cases, we might not even have labels, but it is still possible to try to detect anomalies in our dataset. Dissimilarity search can be used for this purpose as well.
![Anomaly Detection](https://qdrant.tech/articles_data/vector-similarity-beyond-search/anomaly-detection.png)
Anomaly Detection
The only thing we need is a bunch of reference points that we consider “normal”. Then we can search for the most dissimilar points to this reference set and use them as candidates for further analysis.
## Diversity search
Even with no input provided vector, (dis-)similarity can improve an overall selection of items from the dataset.
The naive approach is to do random sampling. However, unless our dataset has a uniform distribution, the results of such sampling might be biased toward more frequent types of items.
![Example of random sampling](https://qdrant.tech/articles_data/vector-similarity-beyond-search/diversity-random.png)
Example of random sampling
The similarity information can increase the diversity of those results and make the first overview more interesting. That is especially useful when users do not yet know what they are looking for and want to explore the dataset.
![Example of similarity-based sampling](https://qdrant.tech/articles_data/vector-similarity-beyond-search/diversity-force.png)
Example of similarity-based sampling
The power of vector similarity, in the context of being able to compare any two points, allows making a diverse selection of the collection possible without any labeling efforts. By maximizing the distance between all points in the response, we can have an algorithm that will sequentially output dissimilar results.
![Diversity Search](https://qdrant.tech/articles_data/vector-similarity-beyond-search/diversity.png)
Diversity Search
Some forms of diversity sampling are already used in the industry and are known as 
## Vector similarity recommendations
Vector similarity can go above a single query vector. It can combine multiple positive and negative examples for a more accurate retrieval. Building a recommendation API in a vector database can take advantage of using already stored vectors as part of the queries, by specifying the point id. Doing this, we can skip query-time neural network inference, and make the recommendation search faster.
There are multiple ways to implement recommendations with vectors.
### Vector-features recommendations
The first approach is to take all positive and negative examples and average them to create a single query vector. In this technique, the more significant components of positive vectors are canceled out by the negative ones, and the resulting vector is a combination of all the features present in the positive examples, but not in the negative ones.
![Vector-Features Based Recommendations](https://qdrant.tech/articles_data/vector-similarity-beyond-search/feature-based-recommendations.png)
Vector-Features Based Recommendations
This approach is already implemented in Qdrant, and while it works great when the vectors are assumed to have each of their dimensions represent some kind of feature of the data, sometimes distances are a better tool to judge negative and positive examples.
### Relative distance recommendations
Another approach is to use the distance between negative examples to the candidates to help them create exclusion areas. In this technique, we perform searches near the positive examples while excluding the points that are closer to a negative example than to a positive one.
![Relative Distance Recommendations](https://qdrant.tech/articles_data/vector-similarity-beyond-search/relative-distance-recommendations.png)
Relative Distance Recommendations
The main use-case of both approaches —of course— is to take some history of user interactions and recommend new items based on it.
## Discovery
In many exploration scenarios, the desired destination is not known in advance. The search process in this case can consist of multiple steps, where each step would provide a little more information to guide the search in the right direction.
To get more intuition about the possible ways to implement this approach, let’s take a look at how similarity modes are trained in the first place:
The most well-known loss function used to train similarity models is a 
![Triplet Loss](https://qdrant.tech/articles_data/vector-similarity-beyond-search/triplet-loss.png)
Triplet Loss
Using the same mechanics, we can look at the training process from the other side. Given a trained model, the user can provide positive and negative examples, and the goal of the discovery process is then to find suitable anchors across the stored collection of vectors.
![Reversed triplet loss](https://qdrant.tech/articles_data/vector-similarity-beyond-search/discovery.png)
Reversed triplet loss
Multiple positive-negative pairs can be provided to make the discovery process more accurate. Worth mentioning, that as well as in NN training, the dataset may contain noise and some portion of contradictory information, so a discovery process should be tolerant of this kind of data imperfections.
![Sample pairs](https://qdrant.tech/articles_data/vector-similarity-beyond-search/discovery-noise.png)
Sample pairs
The important difference between this and the recommendation method is that the positive-negative pairs in the discovery method don’t assume that the final result should be close to positive, it only assumes that it should be closer than the negative one.
![Discovery vs Recommendation](https://qdrant.tech/articles_data/vector-similarity-beyond-search/discovery-vs-recommendations.png)
Discovery vs Recommendation
In combination with filtering or similarity search, the additional context information provided by the discovery pairs can be used as a re-ranking factor.
## A new API stack for vector databases
When you introduce vector similarity capabilities into your text search engine, you extend its functionality. However, it doesn’t work the other way around, as the vector similarity as a concept is much broader than some task-specific implementations of full-text search.
[Vector databases](https://qdrant.tech/), which introduce built-in full-text functionality, must make several compromises:
  * Choose a specific full-text search variant.
  * Either sacrifice API consistency or limit vector similarity functionality to only basic kNN search.
  * Introduce additional complexity to the system.
Qdrant, on the contrary, puts vector similarity in the center of its API and architecture, such that it allows us to move towards a new stack of vector-native operations. We believe that this is the future of vector databases, and we are excited to see what new use-cases will be unlocked by these techniques.
  * Vector similarity offers advanced data exploration tools beyond traditional full-text search, including dissimilarity search, diversity sampling, and recommendation systems.
  * Practical applications of vector similarity include improving data quality through mislabeling detection and anomaly identification.
  * Enhanced user experiences are achieved by leveraging advanced search techniques, providing users with intuitive data exploration, and improving decision-making processes.
Ready to unlock the full potential of your data? [Try a free demo](https://qdrant.tech/contact-us/) to explore how vector similarity can revolutionize your data insights and drive smarter decision-making.
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/vector-similarity-beyond-search.md) this page on GitHub, or 
On this page:
  * [What is vector similarity search?](https://qdrant.tech/articles/vector-similarity-beyond-search/#what-is-vector-similarity-search)
  * [Vector similarity search vs. full-text search](https://qdrant.tech/articles/vector-similarity-beyond-search/#vector-similarity-search-vs-full-text-search)
  * [New ways to interact with similarities](https://qdrant.tech/articles/vector-similarity-beyond-search/#new-ways-to-interact-with-similarities)
  * [Dissimilarity ssearch](https://qdrant.tech/articles/vector-similarity-beyond-search/#dissimilarity-ssearch)
    * [Case: mislabeling detection](https://qdrant.tech/articles/vector-similarity-beyond-search/#case-mislabeling-detection)
    * [Case: outlier detection](https://qdrant.tech/articles/vector-similarity-beyond-search/#case-outlier-detection)
  * [Diversity search](https://qdrant.tech/articles/vector-similarity-beyond-search/#diversity-search)
  * [Vector similarity recommendations](https://qdrant.tech/articles/vector-similarity-beyond-search/#vector-similarity-recommendations)
    * [Vector-features recommendations](https://qdrant.tech/articles/vector-similarity-beyond-search/#vector-features-recommendations)
    * [Relative distance recommendations](https://qdrant.tech/articles/vector-similarity-beyond-search/#relative-distance-recommendations)
  * [Discovery](https://qdrant.tech/articles/vector-similarity-beyond-search/#discovery)
  * [A new API stack for vector databases](https://qdrant.tech/articles/vector-similarity-beyond-search/#a-new-api-stack-for-vector-databases)
  * [Key takeaways:](https://qdrant.tech/articles/vector-similarity-beyond-search/#key-takeaways)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/vector-similarity-beyond-search/)
                    ## 📄 `https-qdrant-tech-articles-web-ui-gsoc.md`
                    ```md
                    # https://qdrant.tech/articles/web-ui-gsoc/
  * [Articles](https://qdrant.tech/articles/)
  * Google Summer of Code 2023 - Web UI for Visualization and Exploration
# Google Summer of Code 2023 - Web UI for Visualization and Exploration
Kartik Gupta
·
August 28, 2023
![Google Summer of Code 2023 - Web UI for Visualization and Exploration](https://qdrant.tech/articles_data/web-ui-gsoc/preview/title.jpg)
## Introduction
Hello everyone! My name is Kartik Gupta, and I am thrilled to share my coding journey as part of the Google Summer of Code 2023 program. This summer, I had the incredible opportunity to work on an exciting project titled “Web UI for Visualization and Exploration” for Qdrant, a vector search engine. In this article, I will take you through my experience, challenges, and achievements during this enriching coding journey.
## Project Overview
Qdrant is a powerful vector search engine widely used for similarity search and clustering. However, it lacked a user-friendly web-based UI for data visualization and exploration. My project aimed to bridge this gap by developing a web-based user interface that allows users to easily interact with and explore their vector data.
## Milestones and Achievements
The project was divided into six milestones, each focusing on a specific aspect of the web UI development. Let’s go through each of them and my achievements during the coding period.
**1. Designing a friendly UI on Figma**
I started by designing the user interface on Figma, ensuring it was easy to use, visually appealing, and responsive on different devices. I focused on usability and accessibility to create a seamless user experience. ( 
**2. Building the layout**
The layout route served as a landing page with an overview of the application’s features and navigation links to other routes.
**3. Creating a view collection route**
This route enabled users to view a list of collections available in the application. Users could click on a collection to see more details, including the data and vectors associated with it.
![Collection Page](https://qdrant.tech/articles_data/web-ui-gsoc/collections-page.png)
Collection Page
**4. Developing a data page with “find similar” functionality**
I implemented a data page where users could search for data and find similar data using a recommendation API. The recommendation API suggested similar data based on the Data’s selected ID, providing valuable insights.
![Points Page](https://qdrant.tech/articles_data/web-ui-gsoc/points-page.png)
Points Page
**5. Developing query editor page libraries**
This milestone involved creating a query editor page that allowed users to write queries in a custom language. The editor provided syntax highlighting, autocomplete, and error-checking features for a seamless query writing experience.
![Query Editor Page](https://qdrant.tech/articles_data/web-ui-gsoc/console-page.png)
Query Editor Page
**6. Developing a route for visualizing vector data points**
This is done by the reduction of n-dimensional vector in 2-D points and they are displayed with their respective payloads.
![visualization-page](https://qdrant.tech/articles_data/web-ui-gsoc/visualization-page.png)
Vector Visuliztion Page
## Challenges and Learning
Throughout the project, I encountered a series of challenges that stretched my engineering capabilities and provided unique growth opportunities. From mastering new libraries and technologies to ensuring the user interface (UI) was both visually appealing and user-friendly, every obstacle became a stepping stone toward enhancing my skills as a developer. However, each challenge provided an opportunity to learn and grow as a developer. I acquired valuable experience in vector search and dimension reduction techniques.
The most significant learning for me was the importance of effective project management. Setting realistic timelines, collaborating with mentors, and staying proactive with feedback allowed me to complete the milestones efficiently.
### Technical Learning and Skill Development
One of the most significant aspects of this journey was diving into the intricate world of vector search and dimension reduction techniques. These areas, previously unfamiliar to me, required rigorous study and exploration. Learning how to process vast amounts of data efficiently and extract meaningful insights through these techniques was both challenging and rewarding.
### Effective Project Management
Undoubtedly, the most impactful lesson was the art of effective project management. I quickly grasped the importance of setting realistic timelines and goals. Collaborating closely with mentors and maintaining proactive communication proved indispensable. This approach enabled me to navigate the complex development process and successfully achieve the project’s milestones.
### Overcoming Technical Challenges
#### Autocomplete Feature in Console
One particularly intriguing challenge emerged while working on the autocomplete feature within the console. Finding a solution was proving elusive until a breakthrough came from an unexpected direction. My mentor, Andrey, proposed creating a separate module that could support autocomplete based on OpenAPI for our custom language. This ingenious approach not only resolved the issue but also showcased the power of collaborative problem-solving.
#### Optimization with Web Workers
The high-processing demands of vector reduction posed another significant challenge. Initially, this task was straining browsers and causing performance issues. The solution materialized in the form of web workers—an independent processing instance that alleviated the strain on browsers. However, a new question arose: how to terminate these workers effectively? With invaluable insights from my mentor, I gained a deeper understanding of web worker dynamics and successfully tackled this challenge.
#### Console Integration Complexity
Integrating the console interaction into the application presented multifaceted challenges. Crafting a custom language in Monaco, parsing text to make API requests, and synchronizing the entire process demanded meticulous attention to detail. Overcoming these hurdles was a testament to the complexity of real-world engineering endeavours.
#### Codelens Multiplicity Issue
An unexpected issue cropped up during the development process: the codelen (run button) registered multiple times, leading to undesired behaviour. This hiccup underscored the importance of thorough testing and debugging, even in seemingly straightforward features.
### Key Learning Points
Amidst these challenges, I garnered valuable insights that have significantly enriched my engineering prowess:
**Vector Reduction Techniques** : Navigating the realm of vector reduction techniques provided a deep understanding of how to process and interpret data efficiently. This knowledge opens up new avenues for developing data-driven applications in the future.
**Web Workers Efficiency** : Mastering the intricacies of web workers not only resolved performance concerns but also expanded my repertoire of optimization strategies. This newfound proficiency will undoubtedly find relevance in various future projects.
**Monaco Editor and UI Frameworks** : Working extensively with the Monaco Editor, Material-UI (MUI), and Vite enriched my familiarity with these essential tools. I honed my skills in integrating complex UI components seamlessly into applications.
## Areas for Improvement and Future Enhancements
While reflecting on this transformative journey, I recognize several areas that offer room for improvement and future enhancements:
  1. Enhanced Autocomplete: Further refining the autocomplete feature to support key-value suggestions in JSON structures could greatly enhance the user experience.
  2. Error Detection in Console: Integrating the console’s error checker with OpenAPI could enhance its accuracy in identifying errors and offering precise suggestions for improvement.
  3. Expanded Vector Visualization: Exploring additional visualization methods and optimizing their performance could elevate the utility of the vector visualization route.
## Conclusion
Participating in the Google Summer of Code 2023 and working on the “Web UI for Visualization and Exploration” project has been an immensely rewarding experience. I am grateful for the opportunity to contribute to Qdrant and develop a user-friendly interface for vector data exploration.
I want to express my gratitude to my mentors and the entire Qdrant community for their support and guidance throughout this journey. This experience has not only improved my coding skills but also instilled a deeper passion for web development and data analysis.
As my coding journey continues beyond this project, I look forward to applying the knowledge and experience gained here to future endeavours. I am excited to see how Qdrant evolves with the newly developed web UI and how it positively impacts users worldwide.
Thank you for joining me on this coding adventure, and I hope to share more exciting projects in the future! Happy coding!
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/web-ui-gsoc.md) this page on GitHub, or 
On this page:
  * [Introduction](https://qdrant.tech/articles/web-ui-gsoc/#introduction)
  * [Project Overview](https://qdrant.tech/articles/web-ui-gsoc/#project-overview)
  * [Milestones and Achievements](https://qdrant.tech/articles/web-ui-gsoc/#milestones-and-achievements)
  * [Challenges and Learning](https://qdrant.tech/articles/web-ui-gsoc/#challenges-and-learning)
    * [Technical Learning and Skill Development](https://qdrant.tech/articles/web-ui-gsoc/#technical-learning-and-skill-development)
    * [Effective Project Management](https://qdrant.tech/articles/web-ui-gsoc/#effective-project-management)
    * [Overcoming Technical Challenges](https://qdrant.tech/articles/web-ui-gsoc/#overcoming-technical-challenges)
    * [Key Learning Points](https://qdrant.tech/articles/web-ui-gsoc/#key-learning-points)
  * [Areas for Improvement and Future Enhancements](https://qdrant.tech/articles/web-ui-gsoc/#areas-for-improvement-and-future-enhancements)
  * [Conclusion](https://qdrant.tech/articles/web-ui-gsoc/#conclusion)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/web-ui-gsoc/)
                    ## 📄 `https-qdrant-tech-articles-what-are-embeddings.md`
                    ```md
                    # https://qdrant.tech/articles/what-are-embeddings/
  * [Articles](https://qdrant.tech/articles/)
  * What are Vector Embeddings? - Revolutionize Your Search Experience
# What are Vector Embeddings? - Revolutionize Your Search Experience
Sabrina Aquino
·
February 06, 2024
![What are Vector Embeddings? - Revolutionize Your Search Experience](https://qdrant.tech/articles_data/what-are-embeddings/preview/title.jpg)
> **Embeddings** are numerical machine learning representations of the semantic of the input data. They capture the meaning of complex, high-dimensional data, like text, images, or audio, into vectors. Enabling algorithms to process and analyze the data more efficiently.
You know when you’re scrolling through your social media feeds and the content just feels incredibly tailored to you? There’s the news you care about, followed by a perfect tutorial with your favorite tech stack, and then a meme that makes you laugh so hard you snort.
Or what about how YouTube recommends videos you ended up loving. It’s by creators you’ve never even heard of and you didn’t even send YouTube a note about your ideal content lineup.
This is the magic of embeddings.
These are the result of **deep learning models** analyzing the data of your interactions online. From your likes, shares, comments, searches, the kind of content you linger on, and even the content you decide to skip. It also allows the algorithm to predict future content that you are likely to appreciate.
The same embeddings can be repurposed for search, ads, and other features, creating a highly personalized user experience.
![How embeddings are applied to perform recommendantions and other use cases](https://qdrant.tech/articles_data/what-are-embeddings/Embeddings-Use-Case.jpg)
They make **unstructured** data.
## Why use vector embeddings?
The **nuances** of natural language or the hidden **meaning** in large datasets of images, sounds, or user interactions are hard to fit into a table. Traditional relational databases can’t efficiently query most types of data being currently used and produced, making the **retrieval** of this information very limited.
In the embeddings space, synonyms tend to appear in similar contexts and end up having similar embeddings. The space is a system smart enough to understand that “pretty” and “attractive” are playing for the same team. Without being explicitly told so.
That’s the magic.
At their core, vector embeddings are about semantics. They take the idea that “a word is known by the company it keeps” and apply it on a grand scale.
![Example of how synonyms are placed closer together in the embeddings space](https://qdrant.tech/articles_data/what-are-embeddings/Similar-Embeddings.jpg)
This capability is crucial for creating search systems, recommendation engines, retrieval augmented generation (RAG) and any application that benefits from a deep understanding of content.
## How do embeddings work?
Embeddings are created through neural networks. They capture complex relationships and semantics into **high-dimensional** space, specifically, a [Vector Database](https://qdrant.tech/articles/what-is-a-vector-database/).
![The process for turning raw data into embeddings and placing them into the vector space](https://qdrant.tech/articles_data/what-are-embeddings/How-Embeddings-Work.jpg)
The meaning of a data point is implicitly defined by its **position** on the vector space. After the vectors are stored, we can use their spatial properties to perform 
> The quality of the vector representations drives the performance. The embedding model that works best for you depends on your use case.
### Creating vector embeddings
Embeddings translate the complexities of human language to a format that computers can understand. It uses neural networks to assign **numerical values** to the input data, in a way that similar data has similar values.
![The process of using Neural Networks to create vector embeddings](https://qdrant.tech/articles_data/what-are-embeddings/How-Do-Embeddings-Work_.jpg)
For example, if I want to make my computer understand the word ‘right’, I can assign a number like 1.3. So when my computer sees 1.3, it sees the word ‘right’.
Now I want to make my computer understand the context of the word ‘right’. I can use a two-dimensional vector, such as [1.3, 0.8], to represent ‘right’. The first number 1.3 still identifies the word ‘right’, but the second number 0.8 specifies the context.
We can introduce more dimensions to capture more nuances. For example, a third dimension could represent formality of the word, a fourth could indicate its emotional connotation (positive, neutral, negative), and so on.
The evolution of this concept led to the development of embedding models like 
![How Word2Vec model creates the embeddings for a word](https://qdrant.tech/articles_data/what-are-embeddings/Word2Vec-model.jpg)
However, these models still have limitations. They generate a single vector per word, based on its usage across texts. This means all the nuances of the word “right” are blended into one vector representation. That is not enough information for computers to fully understand the context.
So, how do we help computers grasp the nuances of language in different contexts? In other words, how do we differentiate between:
  * “your answer is right”
  * “turn right at the corner”
  * “everyone has the right to freedom of speech”
Each of these sentences use the word ‘right’, with different meanings.
More advanced models like **surroundings** , and then creates different embeddings for each.
![How the BERT model creates the embeddings for a word](https://qdrant.tech/articles_data/what-are-embeddings/BERT-model.jpg)
But how does this process of understanding and interpreting work in practice? Think of the term: “biophilic design”, for example. To generate its embedding, the transformer architecture can use the following contexts:
  * “Biophilic design incorporates natural elements into architectural planning.”
  * “Offices with biophilic design elements report higher employee well-being.”
  * “…plant life, natural light, and water features are key aspects of biophilic design.”
And then it compares contexts to known architectural and design principles:
  * “Sustainable designs prioritize environmental harmony.”
  * “Ergonomic spaces enhance user comfort and health.”
The model creates a vector embedding for “biophilic design” that encapsulates the concept of integrating natural elements into man-made environments. Augmented with attributes that highlight the correlation between this integration and its positive impact on health, well-being, and environmental sustainability.
### Integration with embedding APIs
Selecting the right embedding model for your use case is crucial to your application performance. Qdrant makes it easier by offering seamless integration with the best selection of embedding APIs, including [Cohere](https://qdrant.tech/documentation/embeddings/cohere/), [Gemini](https://qdrant.tech/documentation/embeddings/gemini/), [Jina Embeddings](https://qdrant.tech/documentation/embeddings/jina-embeddings/), [OpenAI](https://qdrant.tech/documentation/embeddings/openai/), [Aleph Alpha](https://qdrant.tech/documentation/embeddings/aleph-alpha/), [AWS Bedrock](https://qdrant.tech/documentation/embeddings/bedrock/).
If you’re looking for NLP and rapid prototyping, including language translation, question-answering, and text generation, OpenAI is a great choice. Gemini is ideal for image search, duplicate detection, and clustering tasks.
Fastembed, which we’ll use on the example below, is designed for efficiency and speed, great for applications needing low-latency responses, such as autocomplete and instant content recommendations.
We plan to go deeper into selecting the best model based on performance, cost, integration ease, and scalability in a future post.
## Create a neural search service with Fastmbed
Now that you’re familiar with the core concepts around vector embeddings, how about start building your own [Neural Search Service](https://qdrant.tech/documentation/tutorials/neural-search/)?
Tutorial guides you through a practical application of how to use Qdrant for document management based on descriptions of companies from 
Check out what the final version of this project looks like on the 
Let us know what you’re building with embeddings! Join our 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/what-are-embeddings.md) this page on GitHub, or 
On this page:
  * [Why use vector embeddings?](https://qdrant.tech/articles/what-are-embeddings/#why-use-vector-embeddings)
  * [How do embeddings work?](https://qdrant.tech/articles/what-are-embeddings/#how-do-embeddings-work)
    * [Creating vector embeddings](https://qdrant.tech/articles/what-are-embeddings/#creating-vector-embeddings)
    * [Integration with embedding APIs](https://qdrant.tech/articles/what-are-embeddings/#integration-with-embedding-apis)
  * [Create a neural search service with Fastmbed](https://qdrant.tech/articles/what-are-embeddings/#create-a-neural-search-service-with-fastmbed)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/what-are-embeddings/)
                    ## 📄 `https-qdrant-tech-articles-what-is-a-vector-database.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-a-vector-database/
  * [Articles](https://qdrant.tech/articles/)
  * An Introduction to Vector Databases
# An Introduction to Vector Databases
Sabrina Aquino
·
October 09, 2024
![An Introduction to Vector Databases](https://qdrant.tech/articles_data/what-is-a-vector-database/preview/title.jpg)
## What Is a Vector Database?
![vector-database-architecture](https://qdrant.tech/articles_data/what-is-a-vector-database/vector-database-1.jpeg)
Most of the millions of terabytes of data we generate each day is **unstructured**. Think of the meal photos you snap, the PDFs shared at work, or the podcasts you save but may never listen to. None of it fits neatly into rows and columns.
Unstructured data lacks a strict format or schema, making it challenging for conventional databases to manage. Yet, this unstructured data holds immense potential for **AI** , **machine learning** , and **modern search engines**.
> A [Vector Database](https://qdrant.tech/qdrant-vector-database/) is a specialized system designed to efficiently handle high-dimensional vector data. It excels at indexing, querying, and retrieving this data, enabling advanced analysis and similarity searches that traditional databases cannot easily perform.
### The Challenge with Traditional Databases
Traditional `name`, `address`, `phone number`, and `purchase history`.
![Structure of OLTP and OLAP databases](https://qdrant.tech/articles_data/what-is-a-vector-database/oltp-and-olap.png)
But when data can’t be easily categorized, like the content inside a PDF file, things start to get complicated.
You can always store the PDF file as raw data, perhaps with some metadata attached. However, the database still wouldn’t be able to understand what’s inside the document, categorize it, or even search for the information that it contains.
Also, this applies to more than just PDF documents. Think about the vast amounts of text, audio, and image data you generate every day. If a database can’t grasp the **meaning** of this data, how can you search for or find relationships within the data?
![Structure of a Vector Database](https://qdrant.tech/articles_data/what-is-a-vector-database/vector-db-structure.png)
Vector databases allow you to understand the **context** or **conceptual similarity** of unstructured data by representing them as vectors, enabling advanced analysis and retrieval based on data similarity.
## When to Use a Vector Database
Not sure if you should use a vector database or a traditional database? This chart may help.
**Feature** | **OLTP Database** | **OLAP Database** | **Vector Database**  
---|---|---|---  
**Data Structure** | Rows and columns | Rows and columns | Vectors  
**Type of Data** | Structured | Structured/Partially Unstructured | Unstructured  
**Query Method** | SQL-based (Transactional Queries) | SQL-based (Aggregations, Analytical Queries) | Vector Search (Similarity-Based)  
**Storage Focus** | Schema-based, optimized for updates | Schema-based, optimized for reads | Context and Semantics  
**Performance** | Optimized for high-volume transactions | Optimized for complex analytical queries | Optimized for unstructured data retrieval  
**Use Cases** | Inventory, order processing, CRM | Business intelligence, data warehousing | Similarity search, recommendations, RAG, anomaly detection, etc.  
## What Is a Vector?
![vector-database-vector](https://qdrant.tech/articles_data/what-is-a-vector-database/vector-database-7.jpeg)
When a machine needs to process unstructured data - an image, a piece of text, or an audio file, it first has to translate that data into a format it can work with: **vectors**.
> A **vector** is a numerical representation of data that can capture the **context** and **semantics** of data.
When you deal with unstructured data, traditional databases struggle to understand its meaning. However, a vector can translate that data into something a machine can process. For example, a vector generated from text can represent relationships and meaning between words, making it possible for a machine to compare and understand their context.
There are three key elements that define a vector in a vector database: the **ID** , the **dimensions** , and the **payload**. These components work together to represent a vector effectively within the system. Together, they form a **point** , which is the core unit of data stored and retrieved in a vector database.
![Representation of a Point in Qdrant](https://qdrant.tech/articles_data/what-is-a-vector-database/point.png)
Each one of these parts plays an important role in how vectors are stored, retrieved, and interpreted. Let’s see how.
### 1. The ID: Your Vector’s Unique Identifier
Just like in a relational database, each vector in a vector database gets a unique ID. Think of it as your vector’s name tag, a **primary key** that ensures the vector can be easily found later. When a vector is added to the database, the ID is created automatically.
While the ID itself doesn’t play a part in the similarity search (which operates on the vector’s numerical data), it is essential for associating the vector with its corresponding “real-world” data, whether that’s a document, an image, or a sound file.
After a search is performed and similar vectors are found, their IDs are returned. These can then be used to **fetch additional details or metadata** tied to the result.
### 2. The Dimensions: The Core Representation of the Data
At the core of every vector is a set of numbers, which together form a representation of the data in a **multi-dimensional** space.
#### From Text to Vectors: How Does It Work?
These numbers are generated by **embedding models** , such as deep learning algorithms, and capture the essential patterns or relationships within the data. That’s why the term **embedding** is often used interchangeably with vector when referring to the output of these models.
To represent textual data, for example, an embedding will encapsulate the nuances of language, such as semantics and context within its dimensions.
![Creation of a vector based on a sentence with an embedding model](https://qdrant.tech/articles_data/what-is-a-vector-database/embedding-model.png)
For that reason, when comparing two similar sentences, their embeddings will turn out to be very similar, because they have similar **linguistic elements**.
![Comparison of the embeddings of 2 similar sentences](https://qdrant.tech/articles_data/what-is-a-vector-database/two-similar-vectors.png)
That’s the beauty of embeddings. Tthe complexity of the data is distilled into something that can be compared across a multi-dimensional space.
### 3. The Payload: Adding Context with Metadata
Sometimes you’re going to need more than just numbers to fully understand or refine a search. While the dimensions capture the essence of the data, the payload holds **metadata** for structured information.
It could be textual data like descriptions, tags, categories, or it could be numerical values like dates or prices. This extra information is vital when you want to filter or rank search results based on criteria that aren’t directly encoded in the vector.
> This metadata is invaluable when you need to apply additional **filters** or **sorting** criteria.
For example, if you’re searching for a picture of a dog, the vector helps the database find images that are visually similar. But let’s say you want results showing only images taken within the last year, or those tagged with “vacation.”
![Filtering Example](https://qdrant.tech/articles_data/what-is-a-vector-database/filtering-example.png)
The payload can help you narrow down those results by ignoring vectors that doesn’t match your query vector filtering criteria. If you want the full picture of how filtering works in Qdrant, check out our [Complete Guide to Filtering.](https://qdrant.tech/articles/vector-search-filtering/)
## The Architecture of a Vector Database
A vector database is made of multiple different entities and relations. Let’s understand a bit of what’s happening here: ![Architecture Diagram of a Vector Database](https://qdrant.tech/articles_data/what-is-a-vector-database/architecture-vector-db.png)
### Collections
A [collection](https://qdrant.tech/documentation/concepts/collections/) is essentially a group of **vectors** (or “[points](https://qdrant.tech/documentation/concepts/points/)”) that are logically grouped together **based on similarity or a specific task**. Every vector within a collection shares the same dimensionality and can be compared using a single metric. Avoid creating multiple collections unless necessary; instead, consider techniques like **sharding** for scaling across nodes or **multitenancy** for handling different use cases within the same infrastructure.
### Distance Metrics
These metrics defines how similarity between vectors is calculated. The choice of distance metric is made when creating a collection and the right choice depends on the type of data you’re working with and how the vectors were created. Here are the three most common distance metrics:
  * **Euclidean Distance:** The straight-line path. It’s like measuring the physical distance between two points in space. Pick this one when the actual distance (like spatial data) matters.
  * **Cosine Similarity:** This one is about the angle, not the length. It measures how two vectors point in the same direction, so it works well for text or documents when you care more about meaning than magnitude. For example, if two things are _similar_ , _opposite_ , or _unrelated_ :
![Cosine Similarity Example](https://qdrant.tech/articles_data/what-is-a-vector-database/cosine-similarity.png)
  * **Dot Product:** This looks at how much two vectors align. It’s popular in recommendation systems where you’re interested in how much two things “agree” with each other.
### RAM-Based and Memmap Storage
By default, Qdrant stores vectors in RAM, delivering incredibly fast access for datasets that fit comfortably in memory. But when your dataset exceeds RAM capacity, Qdrant offers Memmap as an alternative.
Memmap allows you to store vectors **on disk** , yet still access them efficiently by mapping the data directly into memory if you have enough RAM. To enable it, you only need to set `"on_disk": true` when you are **creating a collection:**
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url='http://localhost:6333')
client.create_collection(
    collection_name="{collection_name}",
    vectors_config=models.VectorParams(
        size=768, distance=models.Distance.COSINE, on_disk=True
    ),
)

```
For other configurations like `hnsw_config.on_disk` or `memmap_threshold`, see the Qdrant documentation for [Storage.](https://qdrant.tech/documentation/concepts/storage/)
### SDKs
Qdrant offers a range of SDKs. You can use the programming language you’re most comfortable with, whether you’re coding in 
## The Core Functionalities of Vector Databases
![vector-database-functions](https://qdrant.tech/articles_data/what-is-a-vector-database/vector-database-3.jpeg)
When you think of a traditional database, the operations are familiar: you **create** , **read** , **update** , and **delete** records. These are the fundamentals. And guess what? In many ways, vector databases work the same way, but the operations are translated for the complexity of vectors.
### 1. Indexing: HNSW Index and Sending Data to Qdrant
Indexing your vectors is like creating an entry in a traditional database. But for vector databases, this step is very important. Vectors need to be indexed in a way that makes them easy to search later on.
**HNSW** (Hierarchical Navigable Small World) is a powerful indexing algorithm that most vector databases rely on to organize vectors for fast and efficient search.
It builds a multi-layered graph, where each vector is a node and connections represent similarity. The higher layers connect broadly similar vectors, while lower layers link vectors that are closely related, making searches progressively more refined as they go deeper.
![Indexing Data with the HNSW algorithm](https://qdrant.tech/articles_data/what-is-a-vector-database/hnsw.png)
When you run a search, HNSW starts at the top, quickly narrowing down the search by hopping between layers. It focuses only on relevant vectors as it goes deeper, refining the search with each step.
### 1.1 Payload Indexing
In Qdrant, indexing is modular. You can configure indexes for **both vectors and payloads independently**. The payload index is responsible for optimizing filtering based on metadata. Each payload index is built for a specific field and allows you to quickly filter vectors based on specific conditions.
![Searching Data with the HNSW algorithm](https://qdrant.tech/articles_data/what-is-a-vector-database/hnsw-search.png)
You need to build the payload index for **each field** you’d like to search. The magic here is in the combination: HNSW finds similar vectors, and the payload index makes sure only the ones that fit your criteria come through. Learn more about Qdrant’s [Filtrable HNSW](https://qdrant.tech/articles/filtrable-hnsw/) and why it was built like this.
> Combining [full-text search](https://qdrant.tech/documentation/concepts/indexing/#full-text-index) with vector-based search gives you even more versatility. You can simultaneously search for conceptually similar documents while ensuring specific keywords are present, all within the same query.
### 2. Searching: Approximate Nearest Neighbors (ANN) Search
Similarity search allows you to search by **meaning**. This way you can do searches such as similar songs that evoke the same mood, finding images that match your artistic vision, or even exploring emotional patterns in text.
![Similar words grouped together](https://qdrant.tech/articles_data/what-is-a-vector-database/similarity.png)
The way it works is, when the user queries the database, this query is also converted into a vector. The algorithm quickly identifies the area of the graph likely to contain vectors closest to the **query vector**.
![Approximate Nearest Neighbors \(ANN\) Search Graph](https://qdrant.tech/articles_data/what-is-a-vector-database/ann-search.png)
The search then moves down progressively narrowing down to more closely related and relevant vectors. Once the closest vectors are identified at the bottom layer, these points translate back to actual data, representing your **top-scored documents**.
Here’s a high-level overview of this process:
![Vector Database Searching Functionality](https://qdrant.tech/articles_data/what-is-a-vector-database/simple-arquitecture.png)
### 3. Updating Vectors: Real-Time and Bulk Adjustments
Data isn’t static, and neither are vectors. Keeping your vectors up to date is crucial for maintaining relevance in your searches.
Vector updates don’t always need to happen instantly, but when they do, Qdrant handles real-time modifications efficiently with a simple API call:
```
client.upsert(
    collection_name='product_collection',
    points=[PointStruct(id=product_id, vector=new_vector, payload=new_payload)]
)

```
For large-scale changes, like re-indexing vectors after a model update, batch updating allows you to update multiple vectors in one operation without impacting search performance:
```
batch_of_updates = [
    PointStruct(id=product_id_1, vector=updated_vector_1, payload=new_payload_1),
    PointStruct(id=product_id_2, vector=updated_vector_2, payload=new_payload_2),
    # Add more points...
]
client.upsert(
    collection_name='product_collection',
    points=batch_of_updates
)

```
### 4. Deleting Vectors: Managing Outdated and Duplicate Data
Efficient vector management is key to keeping your searches accurate and your database lean. Deleting vectors that represent outdated or irrelevant data, such as expired products, old news articles, or archived profiles, helps maintain both performance and relevance.
In Qdrant, removing vectors is straightforward, requiring only the vector IDs to be specified:
```
client.delete(
    collection_name='data_collection',
    points_selector=[point_id_1, point_id_2]
)

```
You can use deletion to remove outdated data, clean up duplicates, and manage the lifecycle of vectors by automatically deleting them after a set period to keep your dataset relevant and focused.
## Dense vs. Sparse Vectors
![vector-database-dense-sparse](https://qdrant.tech/articles_data/what-is-a-vector-database/vector-database-4.jpeg)
Now that you understand what vectors are and how they are created, let’s learn more about the two possible types of vectors you can use: **dense** or **sparse**. The main difference between the two are:
### 1. Dense Vectors
Dense vectors are, quite literally, dense with information. Every element in the vector contributes to the **semantic meaning** , **relationships** and **nuances** of the data. A dense vector representation of this sentence might look like this:
![Representation of a Dense Vector](https://qdrant.tech/articles_data/what-is-a-vector-database/dense-1.png)
Each number holds weight. Together, they convey the overall meaning of the sentence, and are better for identifying contextually similar items, even if the words don’t match exactly.
### 2. Sparse Vectors
Sparse vectors operate differently. They focus only on the essentials. In most sparse vectors, a large number of elements are zeros. When a feature or token is present, it’s marked—otherwise, zero.
In the image, you can see a sentence, _“I love Vector Similarity,”_ broken down into tokens like _“i,” “love,” “vector”_ through tokenization. Each token is assigned a unique `ID` from a large vocabulary. For example, _“i”_ becomes `193`, and _“vector”_ becomes `15012`.
![How Sparse Vectors are Created](https://qdrant.tech/articles_data/what-is-a-vector-database/sparse.png)
Sparse vectors, are used for **exact matching** and specific token-based identification. The values on the right, such as `193: 0.04` and `9182: 0.12`, are the scores or weights for each token, showing how relevant or important each token is in the context. The final result is a sparse vector:
```
{
   193: 0.04,
   9182: 0.12,
   15012: 0.73,
   6731: 0.69,
   454: 0.21
}

```
Everything else in the vector space is assumed to be zero.
Sparse vectors are ideal for tasks like **keyword search** or **metadata filtering** , where you need to check for the presence of specific tokens without needing to capture the full meaning or context. They suited for exact matches within the **data itself** , rather than relying on external metadata, which is handled by payload filtering.
## Benefits of Hybrid Search
![vector-database-get-started](https://qdrant.tech/articles_data/what-is-a-vector-database/vector-database-5.jpeg)
Sometimes context alone isn’t enough. Sometimes you need precision, too. Dense vectors are fantastic when you need to retrieve results based on the context or meaning behind the data. Sparse vectors are useful when you also need **keyword or specific attribute matching**.
> With hybrid search you don’t have to choose one over the othe and use both to get searches that are more **relevant** and **filtered**.
To achieve this balance, Qdrant uses **normalization** and **fusion** techniques to blend results from multiple search methods. One common approach is **Reciprocal Rank Fusion (RRF)** , where results from different methods are merged, giving higher importance to items ranked highly by both methods. This ensures that the best candidates, whether identified through dense or sparse vectors, appear at the top of the results.
Qdrant combines dense and sparse vector results through a process of **normalization** and **fusion**.
![Hybrid Search API - How it works](https://qdrant.tech/articles_data/what-is-a-vector-database/hybrid-search-2.png)
### How to Use Hybrid Search in Qdrant
Qdrant makes it easy to implement hybrid search through its Query API. Here’s how you can make it happen in your own project:
![Hybrid Query Example](https://qdrant.tech/articles_data/what-is-a-vector-database/hybrid-query-1.png)
**Example Hybrid Query:** Let’s say a researcher is looking for papers on NLP, but the paper must specifically mention “transformers” in the content:
```
search_query = {
    "vector": query_vector,  # Dense vector for semantic search
    "filter": {  # Filtering for specific terms
        "must": [
            {"key": "text", "match": "transformers"}  # Exact keyword match in the paper
        ]
    }
}

```
In this query the dense vector search finds papers related to the broad topic of NLP and the sparse vector filtering ensures that the papers specifically mention “transformers”.
This is just a simple example and there’s so much more you can do with it. See our complete [article on Hybrid Search](https://qdrant.tech/articles/hybrid-search/) guide to see what’s happening behind the scenes and all the possibilities when building a hybrid search system.
## Quantization: Get 40x Faster Results
![vector-database-architecture](https://qdrant.tech/articles_data/what-is-a-vector-database/vector-database-2.jpeg)
As your vector dataset grow larger, so do the computational demands of searching through it.
Quantized vectors are much smaller and easier to compare. With methods like [**Binary Quantization**](https://qdrant.tech/articles/binary-quantization/), you can see **search speeds improve by up to 40x while memory usage decreases by 32x**. Improvements that can be decicive when dealing with large datasets or needing low-latency results.
It works by converting high-dimensional vectors, which typically use `4 bytes` per dimension, into binary representations, using just `1 bit` per dimension. Values above zero become “1”, and everything else becomes “0”.
![ Binary Quantization example](https://qdrant.tech/articles_data/what-is-a-vector-database/binary-quantization.png)
Quantization reduces data precision, and yes, this does lead to some loss of accuracy. However, for binary quantization, **OpenAI embeddings** achieves this performance improvement at a cost of only 5% of accuracy. If you apply techniques like **oversampling** and **rescoring** , this loss can be brought down even further.
However, binary quantization isn’t the only available option. Techniques like [**Scalar Quantization**](https://qdrant.tech/documentation/guides/quantization/#scalar-quantization) and [**Product Quantization**](https://qdrant.tech/documentation/guides/quantization/#product-quantization) are also popular alternatives when optimizing vector compression.
You can set up your chosen quantization method using the `quantization_config` parameter when creating a new collection:
```
client.create_collection(
    collection_name="{collection_name}",
    vectors_config=models.VectorParams(
        size=1536,  
        distance=models.Distance.COSINE
    ),
    # Choose your preferred quantization method
    quantization_config=models.BinaryQuantization(  
        binary=models.BinaryQuantizationConfig(
            always_ram=True,  # Store the quantized vectors in RAM for faster access
        ),
    ),
)

```
You can store original vectors on disk within the `vectors_config` by setting `on_disk=True` to save RAM space, while keeping quantized vectors in RAM for faster access
We recommend checking out our [Vector Quantization guide](https://qdrant.tech/articles/what-is-vector-quantization/) for a full breakdown of methods and tips on **optimizing performance** for your specific use case.
## Distributed Deployment
When thinking about scaling, the key factors to consider are **fault tolerance** , **load balancing** , and **availability**. One node, no matter how powerful, can only take you so far. Eventually, you’ll need to spread the workload across multiple machines to ensure the system remains fast and stable.
### Sharding: Distributing Data Across Nodes
In a distributed Qdrant cluster, data is split into smaller units called **shards** , which are distributed across different nodes. which helps balance the load and ensures that queries can be processed in parallel.
Each collection—a group of related data points—can be split into non-overlapping subsets, which are then managed by different nodes.
![ Distributed vector database with sharding and Raft consensus](https://qdrant.tech/articles_data/what-is-a-vector-database/sharding-raft.png)
**Raft Consensus** ensures that all the nodes stay in sync and have a consistent view of the data. Each node knows where every shard is, and Raft ensures that all nodes are in sync. If one node fails, the others know where the missing data is located and can take over.
By default, the number of shards in your Qdrant system matches the number of nodes in your cluster. But if you need more control, you can choose the `shard_number` manually when creating a collection.
```
client.create_collection(
    collection_name="{collection_name}",
    vectors_config=models.VectorParams(size=300, distance=models.Distance.COSINE),
    shard_number=4, # Custom number of shards
)

```
There are two main types of sharding:
  1. **Automatic Sharding:** Points (vectors) are automatically distributed across shards using consistent hashing. Each shard contains non-overlapping subsets of the data.
  2. **User-defined Sharding:** Specify how points are distributed, enabling more control over your data organization, especially for use cases like **multitenancy** , where each tenant (a user, client, or organization) has their own isolated data.
Each shard is divided into **segments**. They are a smaller storage unit within a shard, storing a subset of vectors and their associated payloads (metadata). When a query is executed, it targets the only relevant segments, processing them in parallel.
![Segments act as smaller storage units within a shard](https://qdrant.tech/articles_data/what-is-a-vector-database/segments.png)
### Replication: High Availability and Data Integrity
You don’t want a single failure to take down your system, right? Replication keeps multiple copies of the same data across different nodes to ensure **high availability**.
In Qdrant, **Replica Sets** manage these copies of shards across different nodes. If one replica becomes unavailable, others are there to take over and keep the system running. Whether the data is local or remote is mainly influenced by how you’ve configured the cluster.
![ Replica Set and Replication diagram](https://qdrant.tech/articles_data/what-is-a-vector-database/replication.png)
When a query is made, if the relevant data is stored locally, the local shard handles the operation. If the data is on a remote shard, it’s retrieved via gRPC.
You can control how many copies you want with the `replication_factor`. For example, creating a collection with 4 shards and a replication factor of 2 will result in 8 physical shards distributed across the cluster:
```
client.create_collection(
    collection_name="{collection_name}",
    vectors_config=models.VectorParams(size=300, distance=models.Distance.COSINE),
    shard_number=4,
    replication_factor=2, 
)

```
We recommend using sharding and replication together so that your data is both split across nodes and replicated for availability.
For more details on features like **user-defined sharding, node failure recovery** , and **consistency guarantees** , see our guide on [Distributed Deployment.](https://qdrant.tech/documentation/guides/distributed_deployment/)
## Multitenancy: Data Isolation for Multi-Tenant Architectures
![vector-database-get-started](https://qdrant.tech/articles_data/what-is-a-vector-database/vector-database-6.png)
Sharding efficiently distributes data across nodes, while replication guarantees redundancy and fault tolerance. But what happens when you’ve got multiple clients or user groups, and you need to keep their data isolated within the same infrastructure?
**Multitenancy** allows you to keep data for different tenants (users, clients, or organizations) isolated within a single cluster. Instead of creating separate collections for `Tenant 1` and `Tenant 2`, you store their data in the same collection but tag each vector with a `group_id` to identify which tenant it belongs to.
![Multitenancy dividing data between 2 tenants](https://qdrant.tech/articles_data/what-is-a-vector-database/multitenancy-1.png)
In the backend, Qdrant can store `Tenant 1`’s data in Shard 1 located in Canada (perhaps for compliance reasons like GDPR), while `Tenant 2`’s data is stored in Shard 2 located in Germany. The data will be physically separated but still within the same infrastructure.
To implement this, you tag each vector with a tenant-specific `group_id` during the upsert operation:
```
client.upsert(
    collection_name="tenant_data",
    points=[models.PointStruct(
        id=2, 
        payload={"group_id": "tenant_1"}, 
        vector=[0.1, 0.9, 0.1]
    )],
    shard_key_selector="canada"
)

```
Each tenant’s data remains isolated while still benefiting from the shared infrastructure. Optimizing for data privacy, compliance with local regulations, and scalability, without the need to create excessive collections or maintain separate clusters for each tenant.
If you want to learn more about working with a multitenant setup in Qdrant, you can check out our [Multitenancy and Custom Sharding dedicated guide.](https://qdrant.tech/articles/multitenancy/)
## Data Security and Access Control
A common security risk in vector databases is the possibility of **embedding inversion attacks** , where attackers could reconstruct the original data from embeddings. There are many layers of protection you can use to secure your instance that are very important before getting your vector database into production.
For quick security in simpler use cases, you can use the **API key authentication**. To enable it, set up the API key in the configuration or environment variable.
```
service:api_key:your_secret_api_key_hereenable_tls:true# Make sure to enable TLS to protect the API key from being exposed
```
Once this is set up, remember to include the API key in all your requests:
```
from qdrant_client import QdrantClient
client = QdrantClient(
    url="https://localhost:6333",
    api_key="your_secret_api_key_here"
)

```
In more advanced setups, Qdrant uses **JWT (JSON Web Tokens)** to enforce **Role-Based Access Control (RBAC)**.
RBAC defines roles and assigns permissions, while JWT securely encodes these roles into tokens. Each request is validated against the user’s JWT, ensuring they can only access or modify data based on their assigned permissions.
You can easily setup you access tokens and secure access to sensitive data through the **Qdrant Web UI:**
![Qdrant Web UI for generating a new access token.](https://qdrant.tech/articles_data/what-is-a-vector-database/jwt-web-ui.png)
By default, Qdrant instances are **unsecured** , so it’s important to configure security measures before moving to production. To learn more about how to configure security for your Qdrant instance and other advanced options, please check out the [official Qdrant documentation on security.](https://qdrant.tech/documentation/guides/security/)
## Time to Experiment
As we’ve seen in this article, a vector database is definitely not **just** a database as we traditionally know it. It opens up a world of possibilities, from advanced similarity search to hybrid search that allows content retrieval with both context and precision.
But there’s no better way to learn than by doing. Try building a [semantic search engine](https://qdrant.tech/documentation/tutorials/search-beginners/) or experiment deploying a [hybrid search service](https://qdrant.tech/documentation/tutorials/hybrid-search-fastembed/) from zero. You’ll realize there are endless ways you can take advantage of vectors.
**Use Case** | **How It Works** | **Examples**  
---|---|---  
**Similarity Search** | Finds similar data points using vector distances | Find similar product images, retrieve documents based on themes, discover related topics  
**Anomaly Detection** | Identifies outliers based on deviations in vector space | Detect unusual user behavior in banking, spot irregular patterns  
**Recommendation Systems** | Uses vector embeddings to learn and model user preferences | Personalized movie or music recommendations, e-commerce product suggestions  
**RAG (Retrieval-Augmented Generation)** | Combines vector search with large language models (LLMs) for contextually relevant answers | Customer support, auto-generate summaries of documents, research reports  
**Multimodal Search** | Search across different types of data like text, images, and audio in a single query. | Search for products with a description and image, retrieve images based on audio or text  
**Voice & Audio Recognition** | Uses vector representations to recognize and retrieve audio content | Speech-to-text transcription, voice-controlled smart devices, identify and categorize sounds  
**Knowledge Graph Augmentation** | Links unstructured data to concepts in knowledge graphs using vectors | Link research papers to related studies, connect customer reviews to product features, organize patents by innovation trends  
You can also watch our video tutorial and get started with Qdrant to generate semantic search results and recommendations from a sample dataset.
Phew! I hope you found some of the concepts here useful. If you have any questions feel free to send them in our 
> Remember, don’t get lost in vector space! 🚀
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/what-is-a-vector-database.md) this page on GitHub, or 
On this page:
  * [What Is a Vector Database?](https://qdrant.tech/articles/what-is-a-vector-database/#what-is-a-vector-database)
    * [The Challenge with Traditional Databases](https://qdrant.tech/articles/what-is-a-vector-database/#the-challenge-with-traditional-databases)
  * [When to Use a Vector Database](https://qdrant.tech/articles/what-is-a-vector-database/#when-to-use-a-vector-database)
  * [What Is a Vector?](https://qdrant.tech/articles/what-is-a-vector-database/#what-is-a-vector)
    * [1. The ID: Your Vector’s Unique Identifier](https://qdrant.tech/articles/what-is-a-vector-database/#1-the-id-your-vectors-unique-identifier)
    * [2. The Dimensions: The Core Representation of the Data](https://qdrant.tech/articles/what-is-a-vector-database/#2-the-dimensions-the-core-representation-of-the-data)
    * [3. The Payload: Adding Context with Metadata](https://qdrant.tech/articles/what-is-a-vector-database/#3-the-payload-adding-context-with-metadata)
  * [The Architecture of a Vector Database](https://qdrant.tech/articles/what-is-a-vector-database/#the-architecture-of-a-vector-database)
    * [Collections](https://qdrant.tech/articles/what-is-a-vector-database/#collections)
    * [Distance Metrics](https://qdrant.tech/articles/what-is-a-vector-database/#distance-metrics)
    * [RAM-Based and Memmap Storage](https://qdrant.tech/articles/what-is-a-vector-database/#ram-based-and-memmap-storage)
    * [SDKs](https://qdrant.tech/articles/what-is-a-vector-database/#sdks)
  * [The Core Functionalities of Vector Databases](https://qdrant.tech/articles/what-is-a-vector-database/#the-core-functionalities-of-vector-databases)
    * [1. Indexing: HNSW Index and Sending Data to Qdrant](https://qdrant.tech/articles/what-is-a-vector-database/#1-indexing-hnsw-index-and-sending-data-to-qdrant)
    * [1.1 Payload Indexing](https://qdrant.tech/articles/what-is-a-vector-database/#11-payload-indexing)
    * [2. Searching: Approximate Nearest Neighbors (ANN) Search](https://qdrant.tech/articles/what-is-a-vector-database/#2-searching-approximate-nearest-neighbors-ann-search)
    * [3. Updating Vectors: Real-Time and Bulk Adjustments](https://qdrant.tech/articles/what-is-a-vector-database/#3-updating-vectors-real-time-and-bulk-adjustments)
    * [4. Deleting Vectors: Managing Outdated and Duplicate Data](https://qdrant.tech/articles/what-is-a-vector-database/#4-deleting-vectors-managing-outdated-and-duplicate-data)
  * [Dense vs. Sparse Vectors](https://qdrant.tech/articles/what-is-a-vector-database/#dense-vs-sparse-vectors)
    * [1. Dense Vectors](https://qdrant.tech/articles/what-is-a-vector-database/#1-dense-vectors)
    * [2. Sparse Vectors](https://qdrant.tech/articles/what-is-a-vector-database/#2-sparse-vectors)
  * [Benefits of Hybrid Search](https://qdrant.tech/articles/what-is-a-vector-database/#benefits-of-hybrid-search)
    * [How to Use Hybrid Search in Qdrant](https://qdrant.tech/articles/what-is-a-vector-database/#how-to-use-hybrid-search-in-qdrant)
  * [Quantization: Get 40x Faster Results](https://qdrant.tech/articles/what-is-a-vector-database/#quantization-get-40x-faster-results)
  * [Distributed Deployment](https://qdrant.tech/articles/what-is-a-vector-database/#distributed-deployment)
    * [Sharding: Distributing Data Across Nodes](https://qdrant.tech/articles/what-is-a-vector-database/#sharding-distributing-data-across-nodes)
    * [Replication: High Availability and Data Integrity](https://qdrant.tech/articles/what-is-a-vector-database/#replication-high-availability-and-data-integrity)
  * [Multitenancy: Data Isolation for Multi-Tenant Architectures](https://qdrant.tech/articles/what-is-a-vector-database/#multitenancy-data-isolation-for-multi-tenant-architectures)
  * [Data Security and Access Control](https://qdrant.tech/articles/what-is-a-vector-database/#data-security-and-access-control)
  * [Time to Experiment](https://qdrant.tech/articles/what-is-a-vector-database/#time-to-experiment)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/what-is-a-vector-database/)
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-1-initial-quantized-search.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-vector-quantization/#1-initial-quantized-search
  * [Articles](https://qdrant.tech/articles/)
  * What is Vector Quantization?
# What is Vector Quantization?
Sabrina Aquino
·
September 25, 2024
![What is Vector Quantization?](https://qdrant.tech/articles_data/what-is-vector-quantization/preview/title.jpg)
Vector quantization is a data compression technique used to reduce the size of high-dimensional data. Compressing vectors reduces memory usage while maintaining nearly all of the essential information. This method allows for more efficient storage and faster search operations, particularly in large datasets.
When working with high-dimensional vectors, such as embeddings from providers like OpenAI, a single 1536-dimensional vector requires **6 KB of memory**.
![1536-dimensional vector size is 6 KB](https://qdrant.tech/articles_data/what-is-vector-quantization/vector-size.png)
With 1 million vectors needing around 6 GB of memory, as your dataset grows to multiple **millions of vectors** , the memory and processing demands increase significantly.
To understand why this process is so computationally demanding, let’s take a look at the nature of the [HNSW index](https://qdrant.tech/documentation/concepts/indexing/#vector-index).
The **HNSW (Hierarchical Navigable Small World) index** organizes vectors in a layered graph, connecting each vector to its nearest neighbors. At each layer, the algorithm narrows down the search area until it reaches the lower layers, where it efficiently finds the closest matches to the query.
![HNSW Search visualization](https://qdrant.tech/articles_data/what-is-vector-quantization/hnsw.png)
Each time a new vector is added, the system must determine its position in the existing graph, a process similar to searching. This makes both inserting and searching for vectors complex operations.
One of the key challenges with the HNSW index is that it requires a lot of **random reads** and **sequential traversals** through the graph. This makes the process computationally expensive, especially when you’re dealing with millions of high-dimensional vectors.
The system has to jump between various points in the graph in an unpredictable manner. This unpredictability makes optimization difficult, and as the dataset grows, the memory and processing requirements increase significantly.
![HNSW Search visualization](https://qdrant.tech/articles_data/what-is-vector-quantization/hnsw-search2.png)
Since vectors need to be stored in **fast storage** like **RAM** or **SSD** for low-latency searches, as the size of the data grows, so does the cost of storing and processing it efficiently.
**Quantization** offers a solution by compressing vectors to smaller memory sizes, making the process more efficient.
There are several methods to achieve this, and here we will focus on three main ones:
![Types of Quantization: 1. Scalar Quantization, 2. Product Quantization, 3. Binary Quantization](https://qdrant.tech/articles_data/what-is-vector-quantization/types-of-quant.png)
## 1. What is Scalar Quantization?
![](https://qdrant.tech/articles_data/what-is-vector-quantization/astronaut-mars.jpg)
In Qdrant, each dimension is represented by a `float32` value, which uses **4 bytes** of memory. When using [Scalar Quantization](https://qdrant.tech/documentation/guides/quantization/#scalar-quantization), we map our vectors to a range that the smaller `int8` type can represent. An `int8` is only **1 byte** and can represent 256 values (from -128 to 127, or 0 to 255). This results in a **75% reduction** in memory size.
For example, if our data lies in the range of -1.0 to 1.0, Scalar Quantization will transform these values to a range that `int8` can represent, i.e., within -128 to 127. The system **maps** the `float32` values into this range.
Here’s a simple linear example of what this process looks like:
![Scalar Quantization example](https://qdrant.tech/articles_data/what-is-vector-quantization/scalar-quant.png)
To set up Scalar Quantization in Qdrant, you need to include the `quantization_config` section when creating or updating a collection:
httppython
```
PUT /collections/{collection_name}
{
    "vectors": {
      "size": 128,
      "distance": "Cosine"
    },
    "quantization_config": {
        "scalar": {
            "type": "int8",
            "quantile": 0.99,
            "always_ram": true
        }
    }
}

```
```
client.create_collection(
    collection_name="{collection_name}",
    vectors_config=models.VectorParams(size=128, distance=models.Distance.COSINE),
    quantization_config=models.ScalarQuantization(
        scalar=models.ScalarQuantizationConfig(
            type=models.ScalarType.INT8,
            quantile=0.99,
            always_ram=True,
        ),
    ),
)

```
The `quantile` parameter is used to calculate the quantization bounds. For example, if you specify a `0.99` quantile, the most extreme 1% of values will be excluded from the quantization bounds.
This parameter only affects the resulting precision, not the memory footprint. You can adjust it if you experience a significant decrease in search quality.
Scalar Quantization is a great choice if you’re looking to boost search speed and compression without losing much accuracy. It also slightly improves performance, as distance calculations (such as dot product or cosine similarity) using `int8` values are computationally simpler than using `float32` values.
While the performance gains of Scalar Quantization may not match those achieved with Binary Quantization (which we’ll discuss later), it remains an excellent default choice when Binary Quantization isn’t suitable for your use case.
## 2. What is Binary Quantization?
![Astronaut in surreal white environment](https://qdrant.tech/articles_data/what-is-vector-quantization/astronaut-white-surreal.jpg)
[Binary Quantization](https://qdrant.tech/documentation/guides/quantization/#binary-quantization) is an excellent option if you’re looking to **reduce memory** usage while also achieving a significant **boost in speed**. It works by converting high-dimensional vectors into simple binary (0 or 1) representations.
  * Values greater than zero are converted to 1.
  * Values less than or equal to zero are converted to 0.
Let’s consider our initial example of a 1536-dimensional vector that requires **6 KB** of memory (4 bytes for each `float32` value).
After Binary Quantization, each dimension is reduced to 1 bit (1/8 byte), so the memory required is:
1536 dimensions8 bits per byte=192 bytes
This leads to a **32x** memory reduction.
![Binary Quantization example](https://qdrant.tech/articles_data/what-is-vector-quantization/binary-quant.png)
Qdrant automates the Binary Quantization process during indexing. As vectors are added to your collection, each 32-bit floating-point component is converted into a binary value according to the configuration you define.
Here’s how you can set it up:
httppython
```
PUT /collections/{collection_name}
{
    "vectors": {
      "size": 1536,
      "distance": "Cosine"
    },
    "quantization_config": {
        "binary": {
            "always_ram": true
        }
    }
}

```
```
client.create_collection(
    collection_name="{collection_name}",
    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE),
    quantization_config=models.BinaryQuantization(
        binary=models.BinaryQuantizationConfig(
            always_ram=True,
        ),
    ),
)

```
Binary Quantization is by far the quantization method that provides the most significant processing **speed gains** compared to Scalar and Product Quantizations. This is because the binary representation allows the system to use highly optimized CPU instructions, such as 
It can speed up search operations by **up to 40x** , depending on the dataset and hardware.
Not all models are equally compatible with Binary Quantization, and in the comparison above, we are only using models that are compatible. Some models may experience a greater loss in accuracy when quantized. We recommend using Binary Quantization with models that have **at least 1024 dimensions** to minimize accuracy loss.
The models that have shown the best compatibility with this method include:
  * **OpenAI text-embedding-ada-002** (1536 dimensions)
  * **Cohere AI embed-english-v2.0** (4096 dimensions)
These models demonstrate minimal accuracy loss while still benefiting from substantial speed and memory gains.
Even though Binary Quantization is incredibly fast and memory-efficient, the trade-offs are in **precision** and **model compatibility** , so you may need to ensure search quality using techniques like oversampling and rescoring.
If you’re interested in exploring Binary Quantization in more detail—including implementation examples, benchmark results, and usage recommendations—check out our dedicated article on [Binary Quantization - Vector Search, 40x Faster](https://qdrant.tech/articles/binary-quantization/).
## 3. What is Product Quantization?
![](https://qdrant.tech/articles_data/what-is-vector-quantization/astronaut-centroids.jpg)
[Product Quantization](https://qdrant.tech/documentation/guides/quantization/#product-quantization) is a method used to compress high-dimensional vectors by representing them with a smaller set of representative points.
The process begins by splitting the original high-dimensional vectors into smaller **sub-vectors.** Each sub-vector represents a segment of the original vector, capturing different characteristics of the data.
![Creation of the Sub-vector](https://qdrant.tech/articles_data/what-is-vector-quantization/subvec.png)
For each sub-vector, a separate **codebook** is created, representing regions in the data space where common patterns occur.
The codebook in Qdrant is trained automatically during the indexing process. As vectors are added to the collection, Qdrant uses your specified quantization settings in the `quantization_config` to build the codebook and quantize the vectors. Here’s how you can set it up:
httppython
```
PUT /collections/{collection_name}
{
    "vectors": {
      "size": 1024,
      "distance": "Cosine"
    },
    "quantization_config": {
        "product": {
            "compression": "x32",
            "always_ram": true
        }
    }
}

```
```
client.create_collection(
    collection_name="{collection_name}",
    vectors_config=models.VectorParams(size=1024, distance=models.Distance.COSINE),
    quantization_config=models.ProductQuantization(
        product=models.ProductQuantizationConfig(
            compression=models.CompressionRatio.X32,
            always_ram=True,
        ),
    ),
)

```
Each region in the codebook is defined by a **centroid** , which serves as a representative point summarizing the characteristics of that region. Instead of treating every single data point as equally important, we can group similar sub-vectors together and represent them with a single centroid that captures the general characteristics of that group.
The centroids used in Product Quantization are determined using the 
![Codebook and Centroids example](https://qdrant.tech/articles_data/what-is-vector-quantization/code-book.png)
Qdrant always selects **K = 256** as the number of centroids in its implementation, based on the fact that 256 is the maximum number of unique values that can be represented by a single byte.
This makes the compression process efficient because each centroid index can be stored in a single byte.
The original high-dimensional vectors are quantized by mapping each sub-vector to the nearest centroid in its respective codebook.
![Vectors being mapped to their corresponding centroids example](https://qdrant.tech/articles_data/what-is-vector-quantization/mapping.png)
The compressed vector stores the index of the closest centroid for each sub-vector.
Here’s how a 1024-dimensional vector, originally taking up 4096 bytes, is reduced to just 128 bytes by representing it as 128 indexes, each pointing to the centroid of a sub-vector:
![Product Quantization example](https://qdrant.tech/articles_data/what-is-vector-quantization/product-quant.png)
After setting up quantization and adding your vectors, you can perform searches as usual. Qdrant will automatically use the quantized vectors, optimizing both speed and memory usage. Optionally, you can enable rescoring for better accuracy.
httppython
```
POST /collections/{collection_name}/points/search
{
    "query": [0.22, -0.01, -0.98, 0.37],
    "params": {
        "quantization": {
            "rescore": true
        }
    },
    "limit": 10
}

```
```
client.query_points(
    collection_name="my_collection",
    query_vector=[0.22, -0.01, -0.98, 0.37],  # Your query vector
    search_params=models.SearchParams(
        quantization=models.QuantizationSearchParams(
            rescore=True  # Enables rescoring with original vectors
        )
    ),
    limit=10  # Return the top 10 results
)

```
Product Quantization can significantly reduce memory usage, potentially offering up to **64x** compression in certain configurations. However, it’s important to note that this level of compression can lead to a noticeable drop in quality.
If your application requires high precision or real-time performance, Product Quantization may not be the best choice. However, if **memory savings** are critical and some accuracy loss is acceptable, it could still be an ideal solution.
Here’s a comparison of speed, accuracy, and compression for all three methods, adapted from [Qdrant’s documentation](https://qdrant.tech/documentation/guides/quantization/#how-to-choose-the-right-quantization-method):
Quantization method | Accuracy | Speed | Compression  
---|---|---|---  
Scalar | 0.99 | up to x2 | 4  
Product | 0.7 | 0.5 | up to 64  
Binary | 0.95* | up to x40 | 32  
* - for compatible models
For a more in-depth understanding of the benchmarks you can expect, check out our dedicated article on [Product Quantization in Vector Search](https://qdrant.tech/articles/product-quantization/).
## Rescoring, Oversampling, and Reranking
When we use quantization methods like Scalar, Binary, or Product Quantization, we’re compressing our vectors to save memory and improve performance. However, this compression removes some detail from the original vectors.
This can slightly reduce the accuracy of our similarity searches because the quantized vectors are approximations of the original data. To mitigate this loss of accuracy, you can use **oversampling** and **rescoring** , which help improve the accuracy of the final search results.
The original vectors are never deleted during this process, and you can easily switch between quantization methods or parameters by updating the collection configuration at any time.
Here’s how the process works, step by step:
### 1. Initial Quantized Search
When you perform a search, Qdrant retrieves the top candidates using the quantized vectors based on their similarity to the query vector, as determined by the quantized data. This step is fast because we’re using the quantized vectors.
![ANN Search with Quantization](https://qdrant.tech/articles_data/what-is-vector-quantization/ann-search-quantized.png)
### 2. Oversampling
Oversampling is a technique that helps compensate for any precision lost due to quantization. Since quantization simplifies vectors, some relevant matches could be missed in the initial search. To avoid this, you can **retrieve more candidates** , increasing the chances that the most relevant vectors make it into the final results.
You can control the number of extra candidates by setting an `oversampling` parameter. For example, if your desired number of results (`limit`) is 4 and you set an `oversampling` factor of 2, Qdrant will retrieve 8 candidates (4 × 2).
![ANN Search with Quantization and Oversampling](https://qdrant.tech/articles_data/what-is-vector-quantization/ann-search-quantized-oversampling.png)
You can adjust the oversampling factor to control how many extra vectors Qdrant includes in the initial pool. More candidates mean a better chance of obtaining high-quality top-K results, especially after rescoring with the original vectors.
### 3. Rescoring with Original Vectors
After oversampling to gather more potential matches, each candidate is re-evaluated based on additional criteria to ensure higher accuracy and relevance to the query.
The rescoring process **maps** the quantized vectors to their corresponding original vectors, allowing you to consider factors like context, metadata, or additional relevance that wasn’t included in the initial search, leading to more accurate results.
![Rescoring with Original Vectors](https://qdrant.tech/articles_data/what-is-vector-quantization/rescoring.png)
During rescoring, one of the lower-ranked candidates from oversampling might turn out to be a better match than some of the original top-K candidates.
Even though rescoring uses the original, larger vectors, the process remains much faster because only a very small number of vectors are read. The initial quantized search already identifies the specific vectors to read, rescore, and rerank.
### 4. Reranking
With the new similarity scores from rescoring, **reranking** is where the final top-K candidates are determined based on the updated similarity scores.
For example, in our case with a limit of 4, a candidate that ranked 6th in the initial quantized search might improve its score after rescoring because the original vectors capture more context or metadata. As a result, this candidate could move into the final top 4 after reranking, replacing a less relevant option from the initial search.
![Reranking with Original Vectors](https://qdrant.tech/articles_data/what-is-vector-quantization/reranking.png)
Here’s how you can set it up:
httppython
```
POST /collections/{collection_name}/points/search
{
  "query": [0.22, -0.01, -0.98, 0.37],
  "params": {
    "quantization": {
      "rescore": true,
      "oversampling": 2
    }
  },
  "limit": 4
}

```
You can adjust the `oversampling` factor to find the right balance between search speed and result accuracy.
If quantization is impacting performance in an application that requires high accuracy, combining oversampling with rescoring is a great choice. However, if you need faster searches and can tolerate some loss in accuracy, you might choose to use oversampling without rescoring, or adjust the oversampling factor to a lower value.
## Distributing Resources Between Disk & Memory
Qdrant stores both the quantized and original vectors. When you enable quantization, both the original and quantized vectors are stored in RAM by default. You can move the original vectors to disk to significantly reduce RAM usage and lower system costs. Simply enabling quantization is not enough—you need to explicitly move the original vectors to disk by setting `on_disk=True`.
Here’s an example configuration:
httppython
```
PUT /collections/{collection_name}
{
  "vectors": {
    "size": 1536,
    "distance": "Cosine",
    "on_disk": true  # Move original vectors to disk
  },
  "quantization_config": {
    "binary": {
      "always_ram": true  # Store only quantized vectors in RAM
    }
  }
}

```
```
client.update_collection(
    collection_name="my_collection",
    vectors_config=models.VectorParams(
        size=1536,
        distance=models.Distance.COSINE,
        on_disk=True  # Move original vectors to disk
    ),
    quantization_config=models.BinaryQuantization(
        binary=models.BinaryQuantizationConfig(
            always_ram=True  # Store only quantized vectors in RAM
        )
    )
)

```
Without explicitly setting `on_disk=True`, you won’t see any RAM savings, even with quantization enabled. So, make sure to configure both storage and quantization options based on your memory and performance needs. If your storage has high disk latency, consider disabling rescoring to maintain speed.
### Speeding Up Rescoring with io_uring
When dealing with large collections of quantized vectors, frequent disk reads are required to retrieve both original and compressed data for rescoring operations. While `mmap` helps with efficient I/O by reducing user-to-kernel transitions, rescoring can still be slowed down when working with large datasets on disk due to the need for frequent disk reads.
On Linux-based systems, `io_uring` allows multiple disk operations to be processed in parallel, significantly reducing I/O overhead. This optimization is particularly effective during rescoring, where multiple vectors need to be re-evaluated after the initial search. With io_uring, Qdrant can retrieve and rescore vectors from disk in the most efficient way, improving overall search performance.
When you perform vector quantization and store data on disk, Qdrant often needs to access multiple vectors in parallel. Without io_uring, this process can be slowed down due to the system’s limitations in handling many disk accesses.
To enable `io_uring` in Qdrant, add the following to your storage configuration:
```
storage:async_scorer:true# Enable io_uring for async storage
```
Without this configuration, Qdrant will default to using `mmap` for disk I/O operations.
For more information and benchmarks comparing io_uring with traditional I/O approaches like mmap, check out [Qdrant’s io_uring implementation article.](https://qdrant.tech/articles/io_uring/)
## Performance of Quantized vs. Non-Quantized Data
Qdrant uses the quantized vectors by default if they are available. If you want to evaluate how quantization affects your search results, you can temporarily disable it to compare results from quantized and non-quantized searches. To do this, set `ignore: true` in the query:
httppython
```
POST /collections/{collection_name}/points/query
{
    "query": [0.22, -0.01, -0.98, 0.37],
    "params": {
        "quantization": {
            "ignore": true,
        }
    },
    "limit": 4
}

```
```
client.query_points(
    collection_name="{collection_name}",
    query=[0.22, -0.01, -0.98, 0.37],
    search_params=models.SearchParams(
        quantization=models.QuantizationSearchParams(
            ignore=True
        )
    ),
)

```
### Switching Between Quantization Methods
Not sure if you’ve chosen the right quantization method? In Qdrant, you have the flexibility to remove quantization and rely solely on the original vectors, adjust the quantization type, or change compression parameters at any time without affecting your original vectors.
To switch to binary quantization and adjust the compression rate, for example, you can update the collection’s quantization configuration using the `update_collection` method:
httppython
```
PUT /collections/{collection_name}
{
  "vectors": {
    "size": 1536,
    "distance": "Cosine"
  },
  "quantization_config": {
    "binary": {
      "always_ram": true,
      "compression_rate": 0.8  # Set the new compression rate
    }
  }
}

```
```
client.update_collection(
    collection_name="my_collection",
    quantization_config=models.BinaryQuantization(
        binary=models.BinaryQuantizationConfig(
            always_ram=True,  # Store only quantized vectors in RAM
            compression_rate=0.8  # Set the new compression rate
        )
    ),
)

```
If you decide to **turn off quantization** and use only the original vectors, you can remove the quantization settings entirely with `quantization_config=None`:
httppython
```
PUT /collections/my_collection
{
  "vectors": {
    "size": 1536,
    "distance": "Cosine"
  },
  "quantization_config": null  # Remove quantization and use original vectors only
}

```
```
client.update_collection(
    collection_name="my_collection",
    quantization_config=None  # Remove quantization and rely on original vectors only
)

```
## Wrapping Up
![](https://qdrant.tech/articles_data/what-is-vector-quantization/astronaut-running.jpg)
Quantization methods like Scalar, Product, and Binary Quantization offer powerful ways to optimize memory usage and improve search performance when dealing with large datasets of high-dimensional vectors. Each method comes with its own trade-offs between memory savings, computational speed, and accuracy.
Here are some final thoughts to help you choose the right quantization method for your needs:
**Quantization Method** | **Key Features** | **When to Use**  
---|---|---  
**Binary Quantization** | • **Fastest method and most memory-efficient**  
• Up to **40x** faster search and **32x** reduced memory footprint | • Use with tested models like OpenAI’s `text-embedding-ada-002` and Cohere’s `embed-english-v2.0`  
• When speed and memory efficiency are critical  
**Scalar Quantization** | • **Minimal loss of accuracy**  
• Up to **4x** reduced memory footprint | • Safe default choice for most applications.  
• Offers a good balance between accuracy, speed, and compression.  
**Product Quantization** | • **Highest compression ratio**  
• Up to **64x** reduced memory footprint | • When minimizing memory usage is the top priority  
• Acceptable if some loss of accuracy and slower indexing is tolerable  
### Learn More
If you want to learn more about improving accuracy, memory efficiency, and speed when using quantization in Qdrant, we have a dedicated [Quantization tips](https://qdrant.tech/documentation/guides/quantization/#quantization-tips) section in our docs that explains all the quantization tips you can use to enhance your results.
Learn more about optimizing real-time precision with oversampling in Binary Quantization by watching this interview with Qdrant’s CTO, Andrey Vasnetsov:
Stay up-to-date on the latest in [vector search](https://qdrant.tech/advanced-search/) and quantization, share your projects, ask questions, 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/what-is-quantization.md) this page on GitHub, or 
On this page:
  * [1. What is Scalar Quantization?](https://qdrant.tech/articles/what-is-vector-quantization/#1-what-is-scalar-quantization)
  * [2. What is Binary Quantization?](https://qdrant.tech/articles/what-is-vector-quantization/#2-what-is-binary-quantization)
  * [3. What is Product Quantization?](https://qdrant.tech/articles/what-is-vector-quantization/#3-what-is-product-quantization)
  * [Rescoring, Oversampling, and Reranking](https://qdrant.tech/articles/what-is-vector-quantization/#rescoring-oversampling-and-reranking)
    * [1. Initial Quantized Search](https://qdrant.tech/articles/what-is-vector-quantization/#1-initial-quantized-search)
    * [2. Oversampling](https://qdrant.tech/articles/what-is-vector-quantization/#2-oversampling)
    * [3. Rescoring with Original Vectors](https://qdrant.tech/articles/what-is-vector-quantization/#3-rescoring-with-original-vectors)
    * [4. Reranking](https://qdrant.tech/articles/what-is-vector-quantization/#4-reranking)
  * [Distributing Resources Between Disk & Memory](https://qdrant.tech/articles/what-is-vector-quantization/#distributing-resources-between-disk--memory)
    * [Speeding Up Rescoring with io_uring](https://qdrant.tech/articles/what-is-vector-quantization/#speeding-up-rescoring-with-io_uring)
  * [Performance of Quantized vs. Non-Quantized Data](https://qdrant.tech/articles/what-is-vector-quantization/#performance-of-quantized-vs-non-quantized-data)
    * [Switching Between Quantization Methods](https://qdrant.tech/articles/what-is-vector-quantization/#switching-between-quantization-methods)
  * [Wrapping Up](https://qdrant.tech/articles/what-is-vector-quantization/#wrapping-up)
    * [Learn More](https://qdrant.tech/articles/what-is-vector-quantization/#learn-more)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/what-is-vector-quantization/)
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-1-what-is-scalar-quantization.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-vector-quantization/#1-what-is-scalar-quantization
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-2-oversampling.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-vector-quantization/#2-oversampling
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-2-what-is-binary-quantization.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-vector-quantization/#2-what-is-binary-quantization
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-3-rescoring-with-original-vectors.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-vector-quantization/#3-rescoring-with-original-vectors
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-3-what-is-product-quantization.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-vector-quantization/#3-what-is-product-quantization
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-4-reranking.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-vector-quantization/#4-reranking
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-distributing-resources-between-disk-memory.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-vector-quantization/#distributing-resources-between-disk--memory
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-learn-more.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-vector-quantization/#learn-more
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-performance-of-quantized-vs-non-quantized-data.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-vector-quantization/#performance-of-quantized-vs-non-quantized-data
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-rescoring-oversampling-and-reranking.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-vector-quantization/#rescoring-oversampling-and-reranking
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-speeding-up-rescoring-with-io-uring.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-vector-quantization/#speeding-up-rescoring-with-io_uring
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-switching-between-quantization-methods.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-vector-quantization/#switching-between-quantization-methods
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-wrapping-up.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-vector-quantization/#wrapping-up
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization.md`
                    ```md
                    # https://qdrant.tech/articles/what-is-vector-quantization/
                    ## 📄 `https-qdrant-tech-articles-why-rust.md`
                    ```md
                    # https://qdrant.tech/articles/why-rust/
  * [Articles](https://qdrant.tech/articles/)
  * Why Rust?
[](https://qdrant.tech/articles/)
# Why Rust?
Andre Bogus
·
May 11, 2023
![Why Rust?](https://qdrant.tech/articles_data/why-rust/preview/title.jpg)
# Building Qdrant in Rust
Looking at the 
**Java** is also more than 30 years old now. With a throughput-optimized VM it can often at least play in the same ball park as native services, and the tooling is phenomenal. Also portability is surprisingly good, although the GC is not suited for low-memory applications and will generally take good amount of RAM to deliver good performance. That said, the focus on throughput led to the dreaded GC pauses that cause latency spikes. Also the fat runtime incurs high start-up delays, which need to be worked around.
**Scala** also builds on the JVM, although there is a native compiler, there was the question of compatibility. So Scala shared the limitations of Java, and although it has some nice high-level amenities (of which Java only recently copied a subset), it still doesn’t offer the same level of control over memory layout as, say, C++, so it is similarly disqualified.
**Python** , being just a bit younger than Java, is ubiquitous in ML projects, mostly owing to its tooling (notably jupyter notebooks), being easy to learn and integration in most ML stacks. It doesn’t have a traditional garbage collector, opting for ubiquitous reference counting instead, which somewhat helps memory consumption. With that said, unless you only use it as glue code over high-perf modules, you may find yourself waiting for results. Also getting complex python services to perform stably under load is a serious technical challenge.
## Into the Unknown
So Andrey looked around at what younger languages would fit the challenge. After some searching, two contenders emerged: Go and Rust. Knowing neither, Andrey consulted the docs, and found hinself intrigued by Rust with its promise of Systems Programming without pervasive memory unsafety.
This early decision has been validated time and again. When first learning Rust, the compiler’s error messages are very helpful (and have only improved in the meantime). It’s easy to keep memory profile low when one doesn’t have to wrestle a garbage collector and has complete control over stack and heap. Apart from the much advertised memory safety, many footguns one can run into when writing C++ have been meticulously designed out. And it’s much easier to parallelize a task if one doesn’t have to fear data races.
With Qdrant written in Rust, we can offer cloud services that don’t keep us awake at night, thanks to Rust’s famed robustness. A current qdrant docker container comes in at just a bit over 50MB — try that for size. As for performance… have some [benchmarks](https://qdrant.tech/benchmarks/).
And we don’t have to compromise on ergonomics either, not for us nor for our users. Of course, there are downsides: Rust compile times are usually similar to C++’s, and though the learning curve has been considerably softened in the last years, it’s still no match for easy-entry languages like Python or Go. But learning it is a one-time cost. Contrast this with Go, where you may find 
## Smooth is Fast
The complexity of the type system pays large dividends in bugs that didn’t even make it to a commit. The ecosystem for web services is also already quite advanced, perhaps not at the same point as Java, but certainly matching or outcompeting Go.
Some people may think that the strict nature of Rust will slow down development, which is true only insofar as it won’t let you cut any corners. However, experience has conclusively shown that this is a net win. In fact, Rust lets us 
The job market for Rust programmers is certainly not as big as that for Java or Python programmers, but the language has finally reached the mainstream, and we don’t have any problems getting and retaining top talent. And being an open source project, when we get contributions, we don’t have to check for a wide variety of errors that Rust already rules out.
## In Rust We Trust
Finally, the Rust community is a very friendly bunch, and we are delighted to be part of that. And we don’t seem to be alone. Most large IT companies (notably Amazon, Google, Huawei, Meta and Microsoft) have already started investing in Rust. It’s in the Windows font system already and in the process of coming to the Linux kernel (build support has already been included). In machine learning applications, Rust has been tried and proven by the likes of Aleph Alpha and Huggingface, among many others.
To sum up, choosing Rust was a lucky guess that has brought huge benefits to Qdrant. Rust continues to be our not-so-secret weapon.
### Key Takeaways:
  * **Rust’s Advantages for Qdrant:** Rust provides memory safety and control without a garbage collector, which is crucial for Qdrant’s high-performance cloud services.
  * **Low Overhead:** Qdrant’s Rust-based system offers efficiency, with small Docker container sizes and robust performance benchmarks.
  * **Complexity vs. Simplicity:** Rust’s strict type system reduces bugs early in development, making it faster in the long run despite initial learning curves.
  * **Adoption by Major Players:** Large tech companies like Amazon, Google, and Microsoft are embracing Rust, further validating Qdrant’s choice.
  * **Community and Talent:** The supportive Rust community and increasing availability of Rust developers make it easier for Qdrant to grow and innovate.
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/why-rust.md) this page on GitHub, or 
On this page:
  * [Into the Unknown](https://qdrant.tech/articles/why-rust/#into-the-unknown)
  * [Smooth is Fast](https://qdrant.tech/articles/why-rust/#smooth-is-fast)
  * [In Rust We Trust](https://qdrant.tech/articles/why-rust/#in-rust-we-trust)
    * [Key Takeaways:](https://qdrant.tech/articles/why-rust/#key-takeaways)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/why-rust/)
                    ## 📄 `https-qdrant-tech-articles.md`
                    ```md
                    # https://qdrant.tech/articles/
#### Vector Search Manuals
Take full control of your vector data with Qdrant. Learn how to easily store, organize, and optimize vectors for high-performance similarity search.
[Learn More](https://qdrant.tech/articles/vector-search-manuals/)
[![Preview](https://qdrant.tech/articles_data/indexing-optimization/preview/preview.jpg) Optimizing Memory for Bulk Uploads Efficient memory management is key when handling large-scale vector data. Learn how to optimize memory consumption during bulk uploads in Qdrant and keep your deployments performant under heavy load. Sabrina Aquino February 13, 2025 ](https://qdrant.tech/articles/indexing-optimization/)[![Preview](https://qdrant.tech/articles_data/vector-search-resource-optimization/preview/preview.jpg) Vector Search Resource Optimization Guide Learn how to get the most from Qdrant's optimization features. Discover key tricks and best practices to boost vector search performance and reduce Qdrant's resource usage. David Myriel February 09, 2025 ](https://qdrant.tech/articles/vector-search-resource-optimization/)[![Preview](https://qdrant.tech/articles_data/what-is-a-vector-database/preview/preview.jpg) An Introduction to Vector Databases Discover what a vector database is, its core functionalities, and real-world applications. Sabrina Aquino October 09, 2024 ](https://qdrant.tech/articles/what-is-a-vector-database/)
#### Qdrant Internals
Take a look under the hood of Qdrant’s high-performance vector search engine. Explore the architecture, components, and design principles the Qdrant Vector Search Engine is built on.
[Learn More](https://qdrant.tech/articles/qdrant-internals/)
[![Preview](https://qdrant.tech/articles_data/dedicated-vector-search/preview/preview.jpg) Built for Vector Search Why add-on vector search looks good — until you actually use it. Evgeniya Sukhodolskaya & Andrey Vasnetsov February 17, 2025 ](https://qdrant.tech/articles/dedicated-vector-search/)[![Preview](https://qdrant.tech/articles_data/gridstore-key-value-storage/preview/preview.jpg) Introducing Gridstore: Qdrant's Custom Key-Value Store Why and how we built our own key-value store. A short technical report on our procedure and results. Luis Cossio, Arnaud Gourlay & David Myriel February 05, 2025 ](https://qdrant.tech/articles/gridstore-key-value-storage/)[![Preview](https://qdrant.tech/articles_data/immutable-data-structures/preview/preview.jpg) Qdrant Internals: Immutable Data Structures Learn how immutable data structures improve vector search performance in Qdrant. Andrey Vasnetsov August 20, 2024 ](https://qdrant.tech/articles/immutable-data-structures/)
#### Data Exploration
Learn how you can leverage vector similarity beyond just search. Reveal hidden patterns and insights in your data, provide recommendations, and navigate data space.
[Learn More](https://qdrant.tech/articles/data-exploration/)
[![Preview](https://qdrant.tech/articles_data/distance-based-exploration/preview/preview.jpg) Distance-based data exploration Explore your data under a new angle with Qdrant's tools for dimensionality reduction, clusterization, and visualization. Andrey Vasnetsov March 11, 2025 ](https://qdrant.tech/articles/distance-based-exploration/)[![Preview](https://qdrant.tech/articles_data/discovery-search/preview/preview.jpg) Discovery needs context Discovery Search, an innovative way to constrain the vector space in which a search is performed, relying only on vectors. Luis Cossío January 31, 2024 ](https://qdrant.tech/articles/discovery-search/)[![Preview](https://qdrant.tech/articles_data/vector-similarity-beyond-search/preview/preview.jpg) Vector Similarity: Going Beyond Full-Text Search | Qdrant Discover how vector similarity expands data exploration beyond full-text search. Explore diversity sampling and more for enhanced data discovery! Luis Cossío August 08, 2023 ](https://qdrant.tech/articles/vector-similarity-beyond-search/)
#### Machine Learning
Explore Machine Learning principles and practices which make modern semantic similarity search possible. Apply Qdrant and vector search capabilities to your ML projects.
[Learn More](https://qdrant.tech/articles/machine-learning/)
[![Preview](https://qdrant.tech/articles_data/search-feedback-loop/preview/preview.jpg) Relevance Feedback in Informational Retrieval Relerance feedback: from ancient history to LLMs. Why relevance feedback techniques are good on paper but not popular in neural search, and what we can do about it. Evgeniya Sukhodolskaya March 27, 2025 ](https://qdrant.tech/articles/search-feedback-loop/)[![Preview](https://qdrant.tech/articles_data/modern-sparse-neural-retrieval/preview/preview.jpg) Modern Sparse Neural Retrieval: From Theory to Practice A comprehensive guide to modern sparse neural retrievers: COIL, TILDEv2, SPLADE, and more. Find out how they work and learn how to use them effectively. Evgeniya Sukhodolskaya October 23, 2024 ](https://qdrant.tech/articles/modern-sparse-neural-retrieval/)[![Preview](https://qdrant.tech/articles_data/cross-encoder-integration-gsoc/preview/preview.jpg) Qdrant Summer of Code 2024 - ONNX Cross Encoders in Python A summary of my work and experience at Qdrant Summer of Code 2024. Huong (Celine) Hoang October 14, 2024 ](https://qdrant.tech/articles/cross-encoder-integration-gsoc/)
#### RAG & GenAI
Leverage Qdrant for Retrieval-Augmented Generation (RAG) and build AI Agents
[Learn More](https://qdrant.tech/articles/rag-and-genai/)
[![Preview](https://qdrant.tech/articles_data/agentic-rag/preview/preview.jpg) What is Agentic RAG? Building Agents with Qdrant Agents are a new paradigm in AI, and they are changing how we build RAG systems. Learn how to build agents with Qdrant and which framework to choose. Kacper Łukawski November 22, 2024 ](https://qdrant.tech/articles/agentic-rag/)[![Preview](https://qdrant.tech/articles_data/rapid-rag-optimization-with-qdrant-and-quotient/preview/preview.jpg) Optimizing RAG Through an Evaluation-Based Methodology Learn how Qdrant-powered RAG applications can be tested and iteratively improved using LLM evaluation tools like Quotient. Atita Arora June 12, 2024 ](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/)[![Preview](https://qdrant.tech/articles_data/semantic-cache-ai-data-retrieval/preview/preview.jpg) Semantic Cache: Accelerating AI with Lightning-Fast Data Retrieval Semantic cache is reshaping AI applications by enabling rapid data retrieval. Discover how its implementation benefits your RAG setup. Daniel Romero, David Myriel May 07, 2024 ](https://qdrant.tech/articles/semantic-cache-ai-data-retrieval/)
#### Practical Examples
Building blocks and reference implementations to help you get started with Qdrant. Learn how to use Qdrant to solve real-world problems and build the next generation of AI applications.
[Learn More](https://qdrant.tech/articles/practicle-examples/)
[![Preview](https://qdrant.tech/articles_data/binary-quantization-openai/preview/preview.jpg) Optimizing OpenAI Embeddings: Enhance Efficiency with Qdrant's Binary Quantization Explore how Qdrant's Binary Quantization can significantly improve the efficiency and performance of OpenAI's Ada-003 embeddings. Learn best practices for real-time search applications. Nirant Kasliwal February 21, 2024 ](https://qdrant.tech/articles/binary-quantization-openai/)[![Preview](https://qdrant.tech/articles_data/food-discovery-demo/preview/preview.jpg) Food Discovery Demo Feeling hungry? Find the perfect meal with Qdrant's multimodal semantic search. Kacper Łukawski September 05, 2023 ](https://qdrant.tech/articles/food-discovery-demo/)[![Preview](https://qdrant.tech/articles_data/search-as-you-type/preview/preview.jpg) Semantic Search As You Type To show off Qdrant's performance, we show how to do a quick search-as-you-type that will come back within a few milliseconds. Andre Bogus August 14, 2023 ](https://qdrant.tech/articles/search-as-you-type/)
#### Ecosystem
Tools, libraries and integrations around Qdrant vector search engine.
[Learn More](https://qdrant.tech/articles/ecosystem/)
[![Preview](https://qdrant.tech/articles_data/dimension-reduction-qsoc/preview/preview.jpg) Qdrant Summer of Code 2024 - WASM based Dimension Reduction My journey as a Qdrant Summer of Code 2024 participant working on enhancing vector visualization using WebAssembly (WASM) based dimension reduction. Jishan Bhattacharya August 31, 2024 ](https://qdrant.tech/articles/dimension-reduction-qsoc/)[![Preview](https://qdrant.tech/articles_data/fastembed/preview/preview.jpg) FastEmbed: Qdrant's Efficient Python Library for Embedding Generation Learn how to accurately and efficiently create text embeddings with FastEmbed. Nirant Kasliwal October 18, 2023 ](https://qdrant.tech/articles/fastembed/)[![Preview](https://qdrant.tech/articles_data/web-ui-gsoc/preview/preview.jpg) Google Summer of Code 2023 - Web UI for Visualization and Exploration My journey as a Google Summer of Code 2023 student working on the "Web UI for Visualization and Exploration" project for Qdrant. Kartik Gupta August 28, 2023 ](https://qdrant.tech/articles/web-ui-gsoc/)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/)
                    ## 📄 `https-qdrant-tech-benchmarks-are-we-biased.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#are-we-biased
# Vector Database Benchmarks
#  [](https://qdrant.tech/benchmarks/#benchmarking-vector-databases)Benchmarking Vector Databases
At Qdrant, performance is the top-most priority. We always make sure that we use system resources efficiently so you get the **fastest and most accurate results at the cheapest cloud costs**. So all of our decisions from [choosing Rust](https://qdrant.tech/articles/why-rust/), [io optimisations](https://qdrant.tech/articles/io_uring/), [serverless support](https://qdrant.tech/articles/serverless/), [binary quantization](https://qdrant.tech/articles/binary-quantization/), to our [fastembed library](https://qdrant.tech/articles/fastembed/) are all based on our principle. In this article, we will compare how Qdrant performs against the other vector search engines.
Here are the principles we followed while designing these benchmarks:
  * We do comparative benchmarks, which means we focus on **relative numbers** rather than absolute numbers.
  * We use affordable hardware, so that you can reproduce the results easily.
  * We run benchmarks on the same exact machines to avoid any possible hardware bias.
  * All the benchmarks are 
Scenarios we tested
  1. Upload & Search benchmark on single node [Benchmark](https://qdrant.tech/benchmarks/single-node-speed-benchmark/)
  2. Filtered search benchmark - [Benchmark](https://qdrant.tech/benchmarks/#filtered-search-benchmark)
  3. Memory consumption benchmark - Coming soon
  4. Cluster mode benchmark - Coming soon
Some of our experiment design decisions are described in the [F.A.Q Section](https://qdrant.tech/benchmarks/#benchmarks-faq). Reach out to us on our 
##  [](https://qdrant.tech/benchmarks/#single-node-benchmarks)Single node benchmarks
We benchmarked several vector databases using various configurations of them on different datasets to check how the results may vary. Those datasets may have different vector dimensionality but also vary in terms of the distance function being used. We also tried to capture the difference we can expect while using some different configuration parameters, for both the engine itself and the search operation separately.  
**Updated: January/June 2024**
Dataset: dbpedia-openai-1M-1536-angular deep-image-96-angular gist-960-euclidean glove-100-angular
Search threads: 100 1
Plot values:
RPS  Latency  p95 latency  Index time
Engine | Setup | Dataset | Upload Time(m) | Upload + Index Time(m) | Latency(ms) | P95(ms) | P99(ms) | RPS | Precision  
---|---|---|---|---|---|---|---|---|---  
qdrant | _qdrant-sq-rps-m-64-ef-512_ | dbpedia-openai-1M-1536-angular | 3.51 | 24.43 | 3.54 | 4.95 | 8.62 | 1238.0016 | 0.99  
weaviate | _latest-weaviate-m32_ | dbpedia-openai-1M-1536-angular | 13.94 | 13.94 | 4.99 | 7.16 | 11.33 | 1142.13 | 0.97  
elasticsearch | _elasticsearch-m-32-ef-128_ | dbpedia-openai-1M-1536-angular | 19.18 | 83.72 | 22.10 | 72.53 | 135.68 | 716.80 | 0.98  
redis | _redis-m-32-ef-256_ | dbpedia-openai-1M-1536-angular | 92.49 | 92.49 | 140.65 | 160.85 | 167.35 | 625.27 | 0.97  
milvus | _milvus-m-16-ef-128_ | dbpedia-openai-1M-1536-angular | 0.27 | 1.16 | 393.31 | 441.32 | 576.65 | 219.11 | 0.99  
_Download raw data:[here](https://qdrant.tech/benchmarks/results-1-100-thread-2024-06-15.json)_
##  [](https://qdrant.tech/benchmarks/#observations)Observations
Most of the engines have improved since [our last run](https://qdrant.tech/benchmarks/single-node-speed-benchmark-2022/). Both life and software have trade-offs but some clearly do better:
  * **`Qdrant`achives highest RPS and lowest latencies in almost all the scenarios, no matter the precision threshold and the metric we choose.** It has also shown 4x RPS gains on one of the datasets.
  * `Elasticsearch` has become considerably fast for many cases but it’s very slow in terms of indexing time. It can be 10x slower when storing 10M+ vectors of 96 dimensions! (32mins vs 5.5 hrs)
  * `Milvus` is the fastest when it comes to indexing time and maintains good precision. However, it’s not on-par with others when it comes to RPS or latency when you have higher dimension embeddings or more number of vectors.
  * `Redis` is able to achieve good RPS but mostly for lower precision. It also achieved low latency with single thread, however its latency goes up quickly with more parallel requests. Part of this speed gain comes from their custom protocol.
  * `Weaviate` has improved the least since our last run.
##  [](https://qdrant.tech/benchmarks/#how-to-read-the-results)How to read the results
  * Choose the dataset and the metric you want to check.
  * Select a precision threshold that would be satisfactory for your usecase. This is important because ANN search is all about trading precision for speed. This means in any vector search benchmark, **two results must be compared only when you have similar precision**. However most benchmarks miss this critical aspect.
  * The table is sorted by the value of the selected metric (RPS / Latency / p95 latency / Index time), and the first entry is always the winner of the category 🏆
###  [](https://qdrant.tech/benchmarks/#latency-vs-rps)Latency vs RPS
In our benchmark we test two main search usage scenarios that arise in practice.
  * **Requests-per-Second (RPS)** : Serve more requests per second in exchange of individual requests taking longer (i.e. higher latency). This is a typical scenario for a web application, where multiple users are searching at the same time. To simulate this scenario, we run client requests in parallel with multiple threads and measure how many requests the engine can handle per second.
  * **Latency** : React quickly to individual requests rather than serving more requests in parallel. This is a typical scenario for applications where server response time is critical. Self-driving cars, manufacturing robots, and other real-time systems are good examples of such applications. To simulate this scenario, we run client in a single thread and measure how long each request takes.
###  [](https://qdrant.tech/benchmarks/#tested-datasets)Tested datasets
Our 
Datasets | # Vectors | Dimensions | Distance  
---|---|---|---  
1M | 1536 | cosine  
10M | 96 | cosine  
1M | 960 | euclidean  
1.2M | 100 | cosine  
###  [](https://qdrant.tech/benchmarks/#setup)Setup
![Benchmarks configuration](https://qdrant.tech/benchmarks/client-server.png)
Benchmarks configuration
  * This was our setup for this experiment:
    * Client: 8 vcpus, 16 GiB memory, 64GiB storage (`Standard D8ls v5` on Azure Cloud)
    * Server: 8 vcpus, 32 GiB memory, 64GiB storage (`Standard D8s v3` on Azure Cloud)
  * The Python client uploads data to the server, waits for all required indexes to be constructed, and then performs searches with configured number of threads. We repeat this process with different configurations for each engine, and then select the best one for a given precision.
  * We ran all the engines in docker and limited their memory to 25GB. This was used to ensure fairness by avoiding the case of some engine configs being too greedy with RAM usage. This 25 GB limit is completely fair because even to serve the largest `dbpedia-openai-1M-1536-angular` dataset, one hardly needs `1M * 1536 * 4bytes * 1.5 = 8.6GB` of RAM (including vectors + index). Hence, we decided to provide all the engines with ~3x the requirement.
Please note that some of the configs of some engines crashed on some datasets because of the 25 GB memory limit. That’s why you might see fewer points for some engines on choosing higher precision thresholds.
#  [](https://qdrant.tech/benchmarks/#filtered-search-benchmark)Filtered search benchmark
Applying filters to search results brings a whole new level of complexity. It is no longer enough to apply one algorithm to plain data. With filtering, it becomes a matter of the _cross-integration_ of the different indices.
To measure how well different search engines perform in this scenario, we have prepared a set of **Filtered ANN Benchmark Datasets** - 
It is similar to the ones used in the 
###  [](https://qdrant.tech/benchmarks/#why-filtering-is-not-trivial)Why filtering is not trivial?
Not many ANN algorithms are compatible with filtering. HNSW is one of the few of them, but search engines approach its integration in different ways:
  * Some use **post-filtering** , which applies filters after ANN search. It doesn’t scale well as it either loses results or requires many candidates on the first stage.
  * Others use **pre-filtering** , which requires a binary mask of the whole dataset to be passed into the ANN algorithm. It is also not scalable, as the mask size grows linearly with the dataset size.
On top of it, there is also a problem with search accuracy. It appears if too many vectors are filtered out, so the HNSW graph becomes disconnected.
Qdrant uses a different approach, not requiring pre- or post-filtering while addressing the accuracy problem. Read more about the Qdrant approach in our [Filtrable HNSW](https://qdrant.tech/articles/filtrable-hnsw/) article.
## [](https://qdrant.tech/benchmarks/)
**Updated: Feb 2023**
Dataset: keyword-100 range-100 int-2048 100-kw-small-vocab keyword-2048 geo-radius-100 range-2048 geo-radius-2048 int-100 h-and-m-2048 arxiv-titles-384
Plot values:
Regular search  Filter search
_Download raw data:[here](https://qdrant.tech/benchmarks/filter-result-2023-02-03.json)_
##  [](https://qdrant.tech/benchmarks/#filtered-results)Filtered Results
As you can see from the charts, there are three main patterns:
  * **Speed boost** - for some engines/queries, the filtered search is faster than the unfiltered one. It might happen if the filter is restrictive enough, to completely avoid the usage of the vector index.
  * **Speed downturn** - some engines struggle to keep high RPS, it might be related to the requirement of building a filtering mask for the dataset, as described above.
  * **Accuracy collapse** - some engines are loosing accuracy dramatically under some filters. It is related to the fact that the HNSW graph becomes disconnected, and the search becomes unreliable.
Qdrant avoids all these problems and also benefits from the speed boost, as it implements an advanced [query planning strategy](https://qdrant.tech/documentation/search/#query-planning).
The Filtering Benchmark is all about changes in performance between filter and un-filtered queries. Please refer to the search benchmark for absolute speed comparison.
#  [](https://qdrant.tech/benchmarks/#benchmarks-faq)Benchmarks F.A.Q.
##  [](https://qdrant.tech/benchmarks/#are-we-biased)Are we biased?
Probably, yes. Even if we try to be objective, we are not experts in using all the existing vector databases. We build Qdrant and know the most about it. Due to that, we could have missed some important tweaks in different vector search engines.
However, we tried our best, kept scrolling the docs up and down, experimented with combinations of different configurations, and gave all of them an equal chance to stand out. If you believe you can do it better than us, our **benchmarks are fully**!
##  [](https://qdrant.tech/benchmarks/#what-do-we-measure)What do we measure?
There are several factors considered while deciding on which database to use. Of course, some of them support a different subset of functionalities, and those might be a key factor to make the decision. But in general, we all care about the search precision, speed, and resources required to achieve it.
There is one important thing - **the speed of the vector databases should to be compared only if they achieve the same precision**. Otherwise, they could maximize the speed factors by providing inaccurate results, which everybody would rather avoid. Thus, our benchmark results are compared only at a specific search precision threshold.
##  [](https://qdrant.tech/benchmarks/#how-we-select-hardware)How we select hardware?
In our experiments, we are not focusing on the absolute values of the metrics but rather on a relative comparison of different engines. What is important is the fact we used the same machine for all the tests. It was just wiped off between launching different engines.
We selected an average machine, which you can easily rent from almost any cloud provider. No extra quota or custom configuration is required.
##  [](https://qdrant.tech/benchmarks/#why-you-are-not-comparing-with-faiss-or-annoy)Why you are not comparing with FAISS or Annoy?
Libraries like FAISS provide a great tool to do experiments with vector search. But they are far away from real usage in production environments. If you are using FAISS in production, in the best case, you never need to update it in real-time. In the worst case, you have to create your custom wrapper around it to support CRUD, high availability, horizontal scalability, concurrent access, and so on.
Some vector search engines even use FAISS under the hood, but a search engine is much more than just an indexing algorithm.
We do, however, use the same benchmark datasets as the famous 
###  [](https://qdrant.tech/benchmarks/#why-we-decided-to-test-with-the-python-client)Why we decided to test with the Python client
There is no consensus when it comes to the best technology to run benchmarks. You’re free to choose Go, Java or Rust-based systems. But there are two main reasons for us to use Python for this:
  1. While generating embeddings you’re most likely going to use Python and python based ML frameworks.
  2. Based on GitHub stars, python clients are one of the most popular clients across all the engines.
From the user’s perspective, the crucial thing is the latency perceived while using a specific library - in most cases a Python client. Nobody can and even should redefine the whole technology stack, just because of using a specific search tool. That’s why we decided to focus primarily on official Python libraries, provided by the database authors. Those may use some different protocols under the hood, but at the end of the day, we do not care how the data is transferred, as long as it ends up in the target location.
##  [](https://qdrant.tech/benchmarks/#what-about-closed-source-saas-platforms)What about closed-source SaaS platforms?
There are some vector databases available as SaaS only so that we couldn’t test them on the same machine as the rest of the systems. That makes the comparison unfair. That’s why we purely focused on testing the Open Source vector databases, so everybody may reproduce the benchmarks easily.
This is not the final list, and we’ll continue benchmarking as many different engines as possible.
##  [](https://qdrant.tech/benchmarks/#how-to-reproduce-the-benchmark)How to reproduce the benchmark?
The source code is available on `README.md` file describing the process of running the benchmark for a specific engine.
##  [](https://qdrant.tech/benchmarks/#how-to-contribute)How to contribute?
We made the benchmark Open Source because we believe that it has to be transparent. We could have misconfigured one of the engines or just done it inefficiently. If you feel like you could help us out, check out our 
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/benchmarks/)
                    ## 📄 `https-qdrant-tech-benchmarks-benchmarking-vector-databases.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#benchmarking-vector-databases
                    ## 📄 `https-qdrant-tech-benchmarks-benchmarks-faq.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#benchmarks-faq
                    ## 📄 `https-qdrant-tech-benchmarks-filter-result-2023-02-03-json.md`
                    ```md
                    # https://qdrant.tech/benchmarks/filter-result-2023-02-03.json
```
[
  {
    "engine_name": "milvus",
    "p95_time": 0.12982259434756996,
    "rps": 120.77926866562062,
    "p99_time": 0.33030459305686277,
    "mean_time": 0.06471361731390061,
    "mean_precisions": 0.604392,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    },
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "range-100-filters",
    "parallel": 8,
    "upload_time": 59.75058772099874,
    "total_upload_time": 265.2509193040023
  },
  {
    "engine_name": "qdrant",
    "p95_time": 0.005608127002778929,
    "rps": 795.0263486175817,
    "p99_time": 0.006103408988128651,
    "mean_time": 0.004048252291577228,
    "mean_precisions": 0.9704,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    },
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "int-2048-filters",
    "parallel": 8,
    "upload_time": 22.219641577001312,
    "total_upload_time": 277.6293579379999
  },
  {
    "engine_name": "weaviate",
    "p95_time": 0.060869867632573,
    "rps": 282.92141504260036,
    "p99_time": 0.14476332241698436,
    "mean_time": 0.028075038691749796,
    "mean_precisions": 0.5733560000000001,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    },
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "100-kw-small-vocab-filters",
    "parallel": 8,
    "upload_time": 554.1917532700172,
    "total_upload_time": 554.191795871011
  },
  {
    "engine_name": "qdrant",
    "upload_time": 28.97847600300156,
    "total_upload_time": 249.3211906889992,
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "keyword-100-no-filters",
    "parallel": 8,
    "p95_time": 0.0031238170491633354,
    "rps": 2836.5722185742325,
    "p99_time": 0.0035361650094273512,
    "mean_time": 0.002697261688618528,
    "mean_precisions": 0.40851000000000004,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "p95_time": 0.022843891149932457,
    "rps": 448.9892266818918,
    "p99_time": 0.02490340400010382,
    "mean_time": 0.017448292600000106,
    "mean_precisions": 0.99998,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    },
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "int-2048-filters",
    "parallel": 8,
    "upload_time": 495.76699126700987,
    "total_upload_time": 495.7670325680083
  },
  {
    "engine_name": "weaviate",
    "upload_time": 143.62152541299292,
    "total_upload_time": 143.62156651400437,
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "keyword-2048-no-filters",
    "parallel": 8,
    "p95_time": 0.050718566452997035,
    "rps": 221.70151365075372,
    "p99_time": 0.060055405105522375,
    "mean_time": 0.035850639687350486,
    "mean_precisions": 0.3832,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "milvus",
    "upload_time": 54.541048525003134,
    "total_upload_time": 261.07416708700475,
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "keyword-100-no-filters",
    "parallel": 8,
    "p95_time": 0.012880113955179694,
    "rps": 774.6808321866039,
    "p99_time": 0.015853171006310736,
    "mean_time": 0.008910100677330047,
    "mean_precisions": 0.43728999999999996,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "elastic",
    "p95_time": 0.157336204846797,
    "rps": 140.35900315185233,
    "p99_time": 0.2360867739326205,
    "mean_time": 0.0555332157576835,
    "mean_precisions": 1.0,
    "engine_params": {
      "parallel": 8,
      "num_candidates": 128
    },
    "setup_name": "elastic-m-16-ef-128",
    "dataset_name": "geo-radius-100-filters",
    "parallel": 8,
    "upload_time": 475.7346445269941,
    "total_upload_time": 477.12151631200686
  },
  {
    "engine_name": "redis",
    "p95_time": 0.005800681004620855,
    "rps": 1510.4876239399598,
    "p99_time": 0.0064380440185777855,
    "mean_time": 0.005160128694916785,
    "mean_precisions": 0.35083000000000003,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    },
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "keyword-100-no-filters",
    "parallel": 8,
    "upload_time": 966.5737362880027,
    "total_upload_time": 966.5737733889982
  },
  {
    "engine_name": "redis",
    "p95_time": 1.5075310595915652,
    "rps": 10.113829593370602,
    "p99_time": 1.518353780086909,
    "mean_time": 0.7906458924697246,
    "mean_precisions": 0.8291,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    },
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "keyword-100-filters",
    "parallel": 8,
    "upload_time": 838.4703913549893,
    "total_upload_time": 838.4704293549876
  },
  {
    "engine_name": "weaviate",
    "upload_time": 122.63801413701731,
    "total_upload_time": 122.63805843700538,
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "int-2048-filters",
    "parallel": 8,
    "p95_time": 0.047128153949984146,
    "rps": 251.1394573007941,
    "p99_time": 0.056348523010124156,
    "mean_time": 0.0315921690511997,
    "mean_precisions": 0.999944,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "milvus",
    "p95_time": 0.8063753138980245,
    "rps": 20.109630573645852,
    "p99_time": 1.0353704040343301,
    "mean_time": 0.3962033908148063,
    "mean_precisions": 0.9971646666666667,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    },
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "keyword-100-filters",
    "parallel": 8,
    "upload_time": 57.57094088598387,
    "total_upload_time": 160.5499015499954
  },
  {
    "engine_name": "weaviate",
    "upload_time": 109.12138237699992,
    "total_upload_time": 109.12142707700013,
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "int-2048-no-filters",
    "parallel": 8,
    "p95_time": 0.04763528000003134,
    "rps": 242.01048594374012,
    "p99_time": 0.05722024617983607,
    "mean_time": 0.03280385269010212,
    "mean_precisions": 0.38561,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "milvus",
    "upload_time": 82.25150109099923,
    "total_upload_time": 336.9116750150024,
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "100-kw-small-vocab-no-filters",
    "parallel": 8,
    "p95_time": 0.029642398052965282,
    "rps": 406.3864266601771,
    "p99_time": 0.041818209090561165,
    "mean_time": 0.01826728132031967,
    "mean_precisions": 0.37186,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "p95_time": 0.006258136701580952,
    "rps": 1386.2124272850974,
    "p99_time": 0.006548661968990928,
    "mean_time": 0.005615831368296495,
    "mean_precisions": 0.34798,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    },
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "range-100-no-filters",
    "parallel": 8,
    "upload_time": 1061.5719955159984,
    "total_upload_time": 1061.572033217999
  },
  {
    "engine_name": "elastic",
    "upload_time": 1115.3281315459972,
    "total_upload_time": 1119.7822107840002,
    "setup_name": "elastic-m-16-ef-128",
    "dataset_name": "100-kw-small-vocab-no-filters",
    "parallel": 8,
    "p95_time": 0.5611648967978908,
    "rps": 18.175468376723188,
    "p99_time": 0.6163803898898187,
    "mean_time": 0.4386204439509835,
    "mean_precisions": 0.9102000000000002,
    "engine_params": {
      "parallel": 8,
      "num_candidates": 128
    }
  },
  {
    "engine_name": "weaviate",
    "upload_time": 1481.3664408480108,
    "total_upload_time": 1481.366480947996,
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "geo-radius-100-filters",
    "parallel": 8,
    "p95_time": 0.11494665406207782,
    "rps": 172.6765259126334,
    "p99_time": 0.14929579722404018,
    "mean_time": 0.04616029768351291,
    "mean_precisions": 0.2183205576601462,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "upload_time": 485.82856437400187,
    "total_upload_time": 485.8286052750045,
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "range-2048-filters",
    "parallel": 8,
    "p95_time": 0.6128989070057286,
    "rps": 16.118820859479097,
    "p99_time": 0.6613555148498563,
    "mean_time": 0.4947511775325373,
    "mean_precisions": 0.9999400000000002,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "qdrant",
    "p95_time": 0.005861685746276634,
    "rps": 786.0760783411241,
    "p99_time": 0.006173147998415516,
    "mean_time": 0.0047969017622002865,
    "mean_precisions": 0.4645,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    },
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "geo-radius-2048-no-filters",
    "parallel": 8,
    "upload_time": 21.70322822700109,
    "total_upload_time": 151.90829814300378
  },
  {
    "engine_name": "redis",
    "p95_time": 0.020169364349612806,
    "rps": 407.3920935567137,
    "p99_time": 0.020606488999956128,
    "mean_time": 0.019191185450904324,
    "mean_precisions": 0.3872,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    },
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "int-2048-no-filters",
    "parallel": 8,
    "upload_time": 406.9211787809995,
    "total_upload_time": 406.9212192809996
  },
  {
    "engine_name": "redis",
    "upload_time": 915.1605211479764,
    "total_upload_time": 915.1605836489762,
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "geo-radius-100-filters",
    "parallel": 8,
    "p95_time": 1.791391758150712,
    "rps": 8.656094524614728,
    "p99_time": 2.2478878810125753,
    "mean_time": 0.9236492921782454,
    "mean_precisions": 0.8333458160256981,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "upload_time": 445.8485472709872,
    "total_upload_time": 445.8485969720059,
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "geo-radius-2048-filters",
    "parallel": 8,
    "p95_time": 0.08984521183592732,
    "rps": 134.2993842755739,
    "p99_time": 0.10501881881238662,
    "mean_time": 0.05922382188074116,
    "mean_precisions": 0.9480563947397969,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "elastic",
    "p95_time": 0.18496641659585267,
    "rps": 66.04649323896643,
    "p99_time": 0.29601926347619156,
    "mean_time": 0.11973613396540023,
    "mean_precisions": 0.323644,
    "engine_params": {
      "parallel": 8,
      "num_candidates": 128
    },
    "setup_name": "elastic-m-16-ef-128",
    "dataset_name": "range-100-filters",
    "parallel": 8,
    "upload_time": 475.46510337200016,
    "total_upload_time": 476.54928892799944
  },
  {
    "engine_name": "weaviate",
    "upload_time": 520.9735126099986,
    "total_upload_time": 520.9735491110041,
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "keyword-100-no-filters",
    "parallel": 8,
    "p95_time": 0.009588372007419818,
    "rps": 1059.7365501858592,
    "p99_time": 0.015072612006333658,
    "mean_time": 0.007428906473929237,
    "mean_precisions": 0.34578000000000003,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "qdrant",
    "upload_time": 21.177114682999672,
    "total_upload_time": 206.47353705800197,
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "geo-radius-2048-filters",
    "parallel": 8,
    "p95_time": 0.017590238004049748,
    "rps": 732.1556444569409,
    "p99_time": 0.02283004900047672,
    "mean_time": 0.008105848879181575,
    "mean_precisions": 0.999944,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    }
  },
  {
    "engine_name": "milvus",
    "p95_time": 0.36310681910399567,
    "rps": 46.71067856047857,
    "p99_time": 0.41489248535042866,
    "mean_time": 0.1696174883954547,
    "mean_precisions": 0.99898,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    },
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "keyword-2048-filters",
    "parallel": 8,
    "upload_time": 32.16871961101424,
    "total_upload_time": 152.43981072001043
  },
  {
    "engine_name": "elastic",
    "p95_time": 0.07729883655847511,
    "rps": 222.5373744842224,
    "p99_time": 0.11192101585649655,
    "mean_time": 0.034516317807961605,
    "mean_precisions": 0.999992,
    "engine_params": {
      "parallel": 8,
      "num_candidates": 128
    },
    "setup_name": "elastic-m-16-ef-128",
    "dataset_name": "int-100-filters",
    "parallel": 8,
    "upload_time": 459.4876422609959,
    "total_upload_time": 462.42494055099087
  },
  {
    "engine_name": "milvus",
    "p95_time": 0.14734690299956127,
    "rps": 71.34278311847541,
    "p99_time": 0.15623546197166432,
    "mean_time": 0.11056773011035985,
    "mean_precisions": 0.7593840000000001,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    },
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "100-kw-small-vocab-filters",
    "parallel": 8,
    "upload_time": 81.69273303600494,
    "total_upload_time": 377.06389994500205
  },
  {
    "engine_name": "weaviate",
    "p95_time": 0.009620531499240312,
    "rps": 1062.2042728705608,
    "p99_time": 0.013875493130908585,
    "mean_time": 0.007407869619761914,
    "mean_precisions": 0.34663,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    },
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "geo-radius-100-no-filters",
    "parallel": 8,
    "upload_time": 519.872436575999,
    "total_upload_time": 519.8724719769998
  },
  {
    "engine_name": "qdrant",
    "upload_time": 29.99985824000032,
    "total_upload_time": 245.31883438799923,
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "int-100-no-filters",
    "parallel": 8,
    "p95_time": 0.0031639470023947062,
    "rps": 2858.269445677179,
    "p99_time": 0.0036200649984311907,
    "mean_time": 0.0026772695214829583,
    "mean_precisions": 0.41426999999999997,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    }
  },
  {
    "engine_name": "weaviate",
    "p95_time": 0.046353282072232084,
    "rps": 253.69823600613068,
    "p99_time": 0.053960035070485905,
    "mean_time": 0.03127259453528386,
    "mean_precisions": 0.9999720000000001,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    },
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "keyword-2048-filters",
    "parallel": 8,
    "upload_time": 122.54789987299591,
    "total_upload_time": 122.54794927401235
  },
  {
    "engine_name": "milvus",
    "p95_time": 0.1421076064452791,
    "rps": 88.12338820766736,
    "p99_time": 0.165830006032993,
    "mean_time": 0.08906599569499303,
    "mean_precisions": 0.7929414035087718,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    },
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "range-2048-filters",
    "parallel": 8,
    "upload_time": 30.720292894999147,
    "total_upload_time": 194.89683629100182
  },
  {
    "engine_name": "redis",
    "upload_time": 443.29204641900003,
    "total_upload_time": 443.29208861899997,
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "keyword-2048-filters",
    "parallel": 8,
    "p95_time": 0.0026592479844111945,
    "rps": 829.8828332820522,
    "p99_time": 0.002880225987173617,
    "mean_time": 0.002121267299880856,
    "mean_precisions": 0.999984,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "upload_time": 1412.8715842890088,
    "total_upload_time": 1412.8716218899935,
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "100-kw-small-vocab-filters",
    "parallel": 8,
    "p95_time": 0.297094133750943,
    "rps": 45.88637886156335,
    "p99_time": 0.35322255592676827,
    "mean_time": 0.1740547881387989,
    "mean_precisions": 0.648188,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "weaviate",
    "upload_time": 536.4639212910006,
    "total_upload_time": 536.4639586920002,
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "int-100-no-filters",
    "parallel": 8,
    "p95_time": 0.009744642949135594,
    "rps": 1014.3358031658341,
    "p99_time": 0.013857250001638025,
    "mean_time": 0.0077658940107003215,
    "mean_precisions": 0.34757000000000005,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "elastic",
    "p95_time": 0.024528585844382174,
    "rps": 559.7157977967821,
    "p99_time": 0.04912558073236155,
    "mean_time": 0.012910699559454224,
    "mean_precisions": 0.999992,
    "engine_params": {
      "parallel": 8,
      "num_candidates": 128
    },
    "setup_name": "elastic-m-16-ef-128",
    "dataset_name": "keyword-100-filters",
    "parallel": 8,
    "upload_time": 487.35247248600353,
    "total_upload_time": 488.02600539900595
  },
  {
    "engine_name": "weaviate",
    "upload_time": 143.9998227670003,
    "total_upload_time": 143.99986326800718,
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "geo-radius-2048-no-filters",
    "parallel": 8,
    "p95_time": 0.05146398955839686,
    "rps": 219.20944365209706,
    "p99_time": 0.06115044676029358,
    "mean_time": 0.03626423271731328,
    "mean_precisions": 0.39608000000000004,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "qdrant",
    "p95_time": 0.0037486149962205674,
    "rps": 790.3197043584108,
    "p99_time": 0.0039076181428390555,
    "mean_time": 0.002878892406875093,
    "mean_precisions": 0.999992,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    },
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "keyword-2048-filters",
    "parallel": 8,
    "upload_time": 20.6067078499982,
    "total_upload_time": 160.83375699700264
  },
  {
    "engine_name": "milvus",
    "p95_time": 0.6134412180981599,
    "rps": 25.186735037014266,
    "p99_time": 0.6538540944538546,
    "mean_time": 0.31596671214540545,
    "mean_precisions": 0.9492480000000001,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    },
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "int-100-filters",
    "parallel": 8,
    "upload_time": 51.12789311699453,
    "total_upload_time": 215.94835573100136
  },
  {
    "engine_name": "elastic",
    "upload_time": 515.2994288530026,
    "total_upload_time": 520.4804114120016,
    "setup_name": "elastic-m-16-ef-128",
    "dataset_name": "geo-radius-100-no-filters",
    "parallel": 8,
    "p95_time": 0.13859120500110292,
    "rps": 79.40998576370718,
    "p99_time": 0.17275558919009204,
    "mean_time": 0.09933309715480391,
    "mean_precisions": 0.92376,
    "engine_params": {
      "parallel": 8,
      "num_candidates": 128
    }
  },
  {
    "engine_name": "milvus",
    "upload_time": 52.60636030999922,
    "total_upload_time": 242.23675853200075,
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "range-100-no-filters",
    "parallel": 8,
    "p95_time": 0.012965567998617188,
    "rps": 772.6885397474952,
    "p99_time": 0.016011852002993696,
    "mean_time": 0.008927152314485284,
    "mean_precisions": 0.43555,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "weaviate",
    "upload_time": 467.7271795439883,
    "total_upload_time": 467.7272294439899,
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "int-100-filters",
    "parallel": 8,
    "p95_time": 0.03325140103843296,
    "rps": 403.46968528090326,
    "p99_time": 0.044790432089648724,
    "mean_time": 0.019682756938808596,
    "mean_precisions": 0.9999959999999999,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "qdrant",
    "p95_time": 0.010619221997512793,
    "rps": 1118.8951442866735,
    "p99_time": 0.024652249003083857,
    "mean_time": 0.00700474982189371,
    "mean_precisions": 0.4396960000000001,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    },
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "range-100-filters",
    "parallel": 8,
    "upload_time": 44.026487107999856,
    "total_upload_time": 680.002582219
  },
  {
    "engine_name": "weaviate",
    "p95_time": 0.01175759505276801,
    "rps": 1135.1996266598774,
    "p99_time": 0.0182420709944563,
    "mean_time": 0.006922761877891026,
    "mean_precisions": 0.9999959999999999,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    },
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "keyword-100-filters",
    "parallel": 8,
    "upload_time": 468.52291718201013,
    "total_upload_time": 468.522957683017
  },
  {
    "engine_name": "elastic",
    "p95_time": 0.13323969915800263,
    "rps": 81.09959186171024,
    "p99_time": 0.16343618290382442,
    "mean_time": 0.09723987749682128,
    "mean_precisions": 0.9246500000000002,
    "engine_params": {
      "parallel": 8,
      "num_candidates": 128
    },
    "setup_name": "elastic-m-16-ef-128",
    "dataset_name": "keyword-100-no-filters",
    "parallel": 8,
    "upload_time": 490.7401573880052,
    "total_upload_time": 494.65733043699584
  },
  {
    "engine_name": "milvus",
    "p95_time": 0.01574475729985352,
    "rps": 648.6680026858247,
    "p99_time": 0.019000872839897057,
    "mean_time": 0.01091605143629513,
    "mean_precisions": 0.4975,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    },
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "int-100-no-filters",
    "parallel": 8,
    "upload_time": 78.72983046599984,
    "total_upload_time": 232.64855881899894
  },
  {
    "engine_name": "redis",
    "upload_time": 1636.0822675710006,
    "total_upload_time": 1636.0823092719984,
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "100-kw-small-vocab-no-filters",
    "parallel": 8,
    "p95_time": 0.009207419752056011,
    "rps": 922.1595619227377,
    "p99_time": 0.009952401931259375,
    "mean_time": 0.008525551204292787,
    "mean_precisions": 0.19169,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "weaviate",
    "p95_time": 0.013235293002071557,
    "rps": 787.7313576674836,
    "p99_time": 0.018220572989375797,
    "mean_time": 0.010029493666002963,
    "mean_precisions": 0.19227000000000002,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    },
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "100-kw-small-vocab-no-filters",
    "parallel": 8,
    "upload_time": 639.563576671997,
    "total_upload_time": 639.5636130729981
  },
  {
    "engine_name": "qdrant",
    "p95_time": 0.005000024002220016,
    "rps": 786.7893069494593,
    "p99_time": 0.0054601339994405865,
    "mean_time": 0.004644836804032821,
    "mean_precisions": 0.44006000000000006,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    },
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "keyword-2048-no-filters",
    "parallel": 8,
    "upload_time": 21.16267428399442,
    "total_upload_time": 166.392119473996
  },
  {
    "engine_name": "qdrant",
    "p95_time": 0.003291835002710286,
    "rps": 2804.838598794213,
    "p99_time": 0.003676720998591918,
    "mean_time": 0.0027276493623990972,
    "mean_precisions": 0.39121999999999996,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    },
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "range-100-no-filters",
    "parallel": 8,
    "upload_time": 31.92236971999955,
    "total_upload_time": 217.20962560399857
  },
  {
    "engine_name": "qdrant",
    "upload_time": 52.32986951500061,
    "total_upload_time": 558.1255640999952,
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "100-kw-small-vocab-filters",
    "parallel": 8,
    "p95_time": 0.02944726935093058,
    "rps": 627.5556775093376,
    "p99_time": 0.031606826155111775,
    "mean_time": 0.012589726932167832,
    "mean_precisions": 0.597504,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "p95_time": 2.190688422401581,
    "rps": 5.290801100125922,
    "p99_time": 2.437438242052887,
    "mean_time": 1.5112793747136777,
    "mean_precisions": 0.318576,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    },
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "range-100-filters",
    "parallel": 8,
    "upload_time": 1054.5999018970033,
    "total_upload_time": 1054.5999398980057
  },
  {
    "engine_name": "qdrant",
    "p95_time": 0.009945446954225189,
    "rps": 769.1195207661337,
    "p99_time": 0.010730602990079207,
    "mean_time": 0.007922043598245363,
    "mean_precisions": 0.5479400000000001,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    },
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "range-2048-filters",
    "parallel": 8,
    "upload_time": 22.13764601600269,
    "total_upload_time": 262.5193815070015
  },
  {
    "engine_name": "redis",
    "p95_time": 0.005750621049628535,
    "rps": 1557.7678253131942,
    "p99_time": 0.007125831007033418,
    "mean_time": 0.00500020346040219,
    "mean_precisions": 0.34591,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    },
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "geo-radius-100-no-filters",
    "parallel": 8,
    "upload_time": 958.1770300280004,
    "total_upload_time": 958.1770738289997
  },
  {
    "engine_name": "qdrant",
    "p95_time": 0.0029541370022343467,
    "rps": 2928.093543670165,
    "p99_time": 0.0033542139967903495,
    "mean_time": 0.0026115019791730447,
    "mean_precisions": 0.40060999999999997,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    },
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "geo-radius-100-no-filters",
    "parallel": 8,
    "upload_time": 29.158808702995884,
    "total_upload_time": 249.50327014199866
  },
  {
    "engine_name": "qdrant",
    "upload_time": 22.486673500003235,
    "total_upload_time": 137.6705067340008,
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "int-2048-no-filters",
    "parallel": 8,
    "p95_time": 0.0059176620448852186,
    "rps": 797.945924918874,
    "p99_time": 0.0062274710012570735,
    "mean_time": 0.00485985884118345,
    "mean_precisions": 0.44228999999999996,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    }
  },
  {
    "engine_name": "qdrant",
    "upload_time": 89.46155621099751,
    "total_upload_time": 555.1911257719948,
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "geo-radius-100-filters",
    "parallel": 8,
    "p95_time": 0.1321094797498517,
    "rps": 179.98675630989246,
    "p99_time": 0.17196232572721784,
    "mean_time": 0.0442063328730801,
    "mean_precisions": 0.9999236666666668,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    }
  },
  {
    "engine_name": "elastic",
    "p95_time": 0.8161017308637383,
    "rps": 21.160287525288215,
    "p99_time": 0.9068239592094324,
    "mean_time": 0.37647403334884727,
    "mean_precisions": 0.99656,
    "engine_params": {
      "parallel": 8,
      "num_candidates": 128
    },
    "setup_name": "elastic-m-16-ef-128",
    "dataset_name": "100-kw-small-vocab-filters",
    "parallel": 8,
    "upload_time": 1033.7692494200019,
    "total_upload_time": 1035.096368094004
  },
  {
    "engine_name": "qdrant",
    "p95_time": 0.004165975997966597,
    "rps": 2276.172626254992,
    "p99_time": 0.005230250985259773,
    "mean_time": 0.0033863911997941616,
    "mean_precisions": 0.29512000000000005,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    },
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "100-kw-small-vocab-no-filters",
    "parallel": 8,
    "upload_time": 42.97816371600493,
    "total_upload_time": 248.2971040190023
  },
  {
    "engine_name": "milvus",
    "p95_time": 0.09291366845573065,
    "rps": 114.3922204123433,
    "p99_time": 0.11355346848882618,
    "mean_time": 0.06784756681115105,
    "mean_precisions": 0.74428,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    },
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "range-2048-no-filters",
    "parallel": 8,
    "upload_time": 30.47325847799948,
    "total_upload_time": 120.33686070599651
  },
  {
    "engine_name": "redis",
    "upload_time": 840.132846353983,
    "total_upload_time": 840.1328861539951,
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "int-100-filters",
    "parallel": 8,
    "p95_time": 0.05375603697320912,
    "rps": 171.46616001971617,
    "p99_time": 0.055994554973731285,
    "mean_time": 0.046456831378120116,
    "mean_precisions": 0.9999959999999999,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "qdrant",
    "p95_time": 0.0056671420010388825,
    "rps": 788.6556432165739,
    "p99_time": 0.006009624010839616,
    "mean_time": 0.004641086361414636,
    "mean_precisions": 0.45832,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    },
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "range-2048-no-filters",
    "parallel": 8,
    "upload_time": 21.835920031997375,
    "total_upload_time": 147.03254608400312
  },
  {
    "engine_name": "redis",
    "p95_time": 0.030877801495807943,
    "rps": 270.3147111630208,
    "p99_time": 0.031656928005832016,
    "mean_time": 0.02931836484870146,
    "mean_precisions": 0.3836,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    },
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "range-2048-no-filters",
    "parallel": 8,
    "upload_time": 506.6514792860107,
    "total_upload_time": 506.65152058700914
  },
  {
    "engine_name": "weaviate",
    "upload_time": 174.91833851399133,
    "total_upload_time": 174.9183873150032,
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "geo-radius-2048-filters",
    "parallel": 8,
    "p95_time": 0.11534301460051208,
    "rps": 137.67474193859243,
    "p99_time": 0.14974161304096928,
    "mean_time": 0.05782824723286612,
    "mean_precisions": 0.6744883101102057,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "milvus",
    "p95_time": 0.08406510010463533,
    "rps": 130.1308300203729,
    "p99_time": 0.09882820938204534,
    "mean_time": 0.05867269104287552,
    "mean_precisions": 0.74911,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    },
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "keyword-2048-no-filters",
    "parallel": 8,
    "upload_time": 47.417717465999885,
    "total_upload_time": 138.1754566890013
  },
  {
    "engine_name": "elastic",
    "upload_time": 548.7518933770007,
    "total_upload_time": 553.2957439420006,
    "setup_name": "elastic-m-16-ef-128",
    "dataset_name": "int-100-no-filters",
    "parallel": 8,
    "p95_time": 0.1446563163499377,
    "rps": 78.77330737337881,
    "p99_time": 0.17692758742143294,
    "mean_time": 0.10010966221569943,
    "mean_precisions": 0.9227900000000001,
    "engine_params": {
      "parallel": 8,
      "num_candidates": 128
    }
  },
  {
    "engine_name": "elastic",
    "upload_time": 519.3798396700004,
    "total_upload_time": 523.8665533050007,
    "setup_name": "elastic-m-16-ef-128",
    "dataset_name": "range-100-no-filters",
    "parallel": 8,
    "p95_time": 0.14603285754910755,
    "rps": 77.22252931266763,
    "p99_time": 0.1757026299299834,
    "mean_time": 0.10216345878650136,
    "mean_precisions": 0.9212400000000002,
    "engine_params": {
      "parallel": 8,
      "num_candidates": 128
    }
  },
  {
    "engine_name": "redis",
    "p95_time": 0.0060386829498384025,
    "rps": 1443.014195665719,
    "p99_time": 0.006477670540261897,
    "mean_time": 0.0053930150420992504,
    "mean_precisions": 0.34624,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    },
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "int-100-no-filters",
    "parallel": 8,
    "upload_time": 994.8033701059994,
    "total_upload_time": 994.8034092070011
  },
  {
    "engine_name": "redis",
    "upload_time": 502.58679859699623,
    "total_upload_time": 502.5868418979953,
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "geo-radius-2048-no-filters",
    "parallel": 8,
    "p95_time": 0.029857884999364613,
    "rps": 279.5674379732322,
    "p99_time": 0.03067927898999187,
    "mean_time": 0.02816103406593029,
    "mean_precisions": 0.39413000000000004,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "qdrant",
    "upload_time": 38.357689918997494,
    "total_upload_time": 258.7076136529977,
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "keyword-100-filters",
    "parallel": 8,
    "p95_time": 0.004413552999722014,
    "rps": 2286.9565803922014,
    "p99_time": 0.004748964000100387,
    "mean_time": 0.0033577877566040113,
    "mean_precisions": 1.0,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    }
  },
  {
    "engine_name": "qdrant",
    "upload_time": 48.3694588210019,
    "total_upload_time": 829.5508513530003,
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "int-100-filters",
    "parallel": 8,
    "p95_time": 0.00914454699941416,
    "rps": 1260.082373011253,
    "p99_time": 0.009769336033023138,
    "mean_time": 0.006203781836326016,
    "mean_precisions": 0.9999959999999999,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "upload_time": 515.9993545390025,
    "total_upload_time": 515.9994124410005,
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "keyword-2048-no-filters",
    "parallel": 8,
    "p95_time": 0.030991847954283003,
    "rps": 268.75913681611553,
    "p99_time": 0.031979337995580864,
    "mean_time": 0.028975626277393893,
    "mean_precisions": 0.37781,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "p95_time": 0.09209753295581319,
    "rps": 208.57316353186144,
    "p99_time": 0.12206588805944203,
    "mean_time": 0.036414387586255904,
    "mean_precisions": 0.4789638095238095,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    },
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "h-and-m-2048-filters",
    "parallel": 8,
    "upload_time": 178.78241364699988,
    "total_upload_time": 178.78244824700005
  },
  {
    "engine_name": "milvus",
    "p95_time": 0.040724509749861665,
    "rps": 270.00125654696876,
    "p99_time": 0.06324362501994076,
    "mean_time": 0.024818959924998763,
    "mean_precisions": 0.99939,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    },
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "h-and-m-2048-no-filters",
    "parallel": 8,
    "upload_time": 33.20797490899986,
    "total_upload_time": 84.7523144679999
  },
  {
    "engine_name": "milvus",
    "upload_time": 211.8904368180083,
    "total_upload_time": 805.1374587280006,
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "arxiv-titles-384-filters",
    "parallel": 8,
    "p95_time": 1.1218322960980003,
    "rps": 11.869472873506725,
    "p99_time": 1.3226210009596255,
    "mean_time": 0.6723157582414598,
    "mean_precisions": 0.99765,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "elastic",
    "upload_time": 786.3904986359994,
    "total_upload_time": 791.497461025996,
    "setup_name": "elastic-m-16-ef-128",
    "dataset_name": "arxiv-titles-384-filters",
    "parallel": 8,
    "p95_time": 0.21521003225498134,
    "rps": 89.69714523141516,
    "p99_time": 0.2744370680639987,
    "mean_time": 0.08775116350248281,
    "mean_precisions": 0.44247,
    "engine_params": {
      "parallel": 8,
      "num_candidates": 128
    }
  },
  {
    "engine_name": "qdrant",
    "upload_time": 183.96301186599885,
    "total_upload_time": 960.1803249129989,
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "arxiv-titles-384-filters",
    "parallel": 8,
    "p95_time": 0.008454260001417423,
    "rps": 1199.5911677177578,
    "p99_time": 0.00965474700820778,
    "mean_time": 0.0065190274561959085,
    "mean_precisions": 0.91241,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    }
  },
  {
    "engine_name": "elastic",
    "upload_time": 958.4382368149963,
    "total_upload_time": 958.450433222999,
    "setup_name": "elastic-m-16-ef-128",
    "dataset_name": "arxiv-titles-384-no-filters",
    "parallel": 8,
    "p95_time": 0.1387102062544727,
    "rps": 74.73647063060316,
    "p99_time": 0.1623315192028531,
    "mean_time": 0.10558298158119724,
    "mean_precisions": 0.62572,
    "engine_params": {
      "parallel": 8,
      "num_candidates": 128
    }
  },
  {
    "engine_name": "qdrant",
    "upload_time": 65.91457536999951,
    "total_upload_time": 110.98573015500006,
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "h-and-m-2048-no-filters",
    "parallel": 8,
    "p95_time": 0.0036513524491965654,
    "rps": 758.2523352203556,
    "p99_time": 0.003995483000217065,
    "mean_time": 0.003233249979300308,
    "mean_precisions": 0.99816,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    }
  },
  {
    "engine_name": "weaviate",
    "upload_time": 821.4987202839984,
    "total_upload_time": 821.4987622860062,
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "arxiv-titles-384-no-filters",
    "parallel": 8,
    "p95_time": 0.013648258440662175,
    "rps": 808.2050531985926,
    "p99_time": 0.02064537066500635,
    "mean_time": 0.009765109761140775,
    "mean_precisions": 0.9924,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "upload_time": 175.42912030099978,
    "total_upload_time": 175.42916640199974,
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "h-and-m-2048-no-filters",
    "parallel": 8,
    "p95_time": 0.0117712394502405,
    "rps": 764.7457132787102,
    "p99_time": 0.012644969089910774,
    "mean_time": 0.01005423590510004,
    "mean_precisions": 0.9986800000000001,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "upload_time": 4285.521239761991,
    "total_upload_time": 4285.5212792620005,
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "arxiv-titles-384-no-filters",
    "parallel": 8,
    "p95_time": 0.006318166994606145,
    "rps": 1412.585862917276,
    "p99_time": 0.007078137002681616,
    "mean_time": 0.005506940040709742,
    "mean_precisions": 0.99254,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "qdrant",
    "p95_time": 0.01563864300151181,
    "rps": 573.2371784236358,
    "p99_time": 0.017692109489617,
    "mean_time": 0.011756236765598078,
    "mean_precisions": 0.8986480000000001,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    },
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "h-and-m-2048-filters",
    "parallel": 8,
    "upload_time": 24.30409269899974,
    "total_upload_time": 369.89128604000143
  },
  {
    "engine_name": "qdrant",
    "p95_time": 0.004403223001281731,
    "rps": 2032.514361921886,
    "p99_time": 0.005016113001183841,
    "mean_time": 0.0038032377953910327,
    "mean_precisions": 0.9899700000000001,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "hnsw_ef": 128
      }
    },
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "arxiv-titles-384-no-filters",
    "parallel": 8,
    "upload_time": 135.61498762100018,
    "total_upload_time": 491.16749738
  },
  {
    "engine_name": "milvus",
    "upload_time": 187.15349870700447,
    "total_upload_time": 593.4174981420074,
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "arxiv-titles-384-no-filters",
    "parallel": 8,
    "p95_time": 0.04464091939153149,
    "rps": 312.53969702455674,
    "p99_time": 0.06507382202980813,
    "mean_time": 0.02411255849552399,
    "mean_precisions": 0.99365,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "weaviate",
    "p95_time": 2.9352467063014047,
    "rps": 6.0867942767604575,
    "p99_time": 3.2568878086292536,
    "mean_time": 1.3136171596057888,
    "mean_precisions": 0.99556,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    },
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "arxiv-titles-384-filters",
    "parallel": 8,
    "upload_time": 826.5599381060019,
    "total_upload_time": 826.5599835059984
  },
  {
    "engine_name": "weaviate",
    "upload_time": 80.04183274600655,
    "total_upload_time": 80.04187854600605,
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "h-and-m-2048-filters",
    "parallel": 8,
    "p95_time": 0.08480733054020675,
    "rps": 170.91161671588404,
    "p99_time": 0.11864908981078771,
    "mean_time": 0.04653029686248046,
    "mean_precisions": 0.9545878095238095,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "milvus",
    "upload_time": 37.37267245698604,
    "total_upload_time": 254.4448660609778,
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "h-and-m-2048-filters",
    "parallel": 8,
    "p95_time": 0.18038830443692858,
    "rps": 66.20959856685928,
    "p99_time": 0.19856844001449647,
    "mean_time": 0.1191696237471333,
    "mean_precisions": 0.9994880000000002,
    "engine_params": {
      "parallel": 8,
      "params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "upload_time": 4315.254399509999,
    "total_upload_time": 4315.254449611006,
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "arxiv-titles-384-filters",
    "parallel": 8,
    "p95_time": 0.14093640055216383,
    "rps": 209.12118412840363,
    "p99_time": 0.318152676022437,
    "mean_time": 0.03801539682005969,
    "mean_precisions": 0.4971,
    "engine_params": {
      "parallel": 8,
      "search_params": {
        "ef": 128
      }
    }
  },
  {
    "engine_name": "weaviate",
    "p95_time": 0.04614587849971482,
    "rps": 249.52705714555242,
    "p99_time": 0.05504403435969381,
    "mean_time": 0.03183474185019913,
    "mean_precisions": 0.99872,
    "engine_params": {
      "parallel": 8,
      "vectorIndexConfig": {
        "ef": 128
      }
    },
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "h-and-m-2048-no-filters",
    "parallel": 8,
    "upload_time": 73.00220887399973,
    "total_upload_time": 73.00225017399998
  }
]
```
                    ## 📄 `https-qdrant-tech-benchmarks-filtered-results.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#filtered-results
                    ## 📄 `https-qdrant-tech-benchmarks-filtered-search-benchmark.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#filtered-search-benchmark
                    ## 📄 `https-qdrant-tech-benchmarks-how-to-contribute.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#how-to-contribute
                    ## 📄 `https-qdrant-tech-benchmarks-how-to-read-the-results.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#how-to-read-the-results
                    ## 📄 `https-qdrant-tech-benchmarks-how-to-reproduce-the-benchmark.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#how-to-reproduce-the-benchmark
                    ## 📄 `https-qdrant-tech-benchmarks-how-we-select-hardware.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#how-we-select-hardware
                    ## 📄 `https-qdrant-tech-benchmarks-latency-vs-rps.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#latency-vs-rps
                    ## 📄 `https-qdrant-tech-benchmarks-observations.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#observations
                    ## 📄 `https-qdrant-tech-benchmarks-results-1-100-thread-2024-06-15-json.md`
                    ```md
                    # https://qdrant.tech/benchmarks/results-1-100-thread-2024-06-15.json
```
[
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1145.3786074520322,
    "total_upload_time": 4383.120810342021,
    "p95_time": 0.010520696034654978,
    "rps": 93.57448649504398,
    "parallel": 1,
    "p99_time": 0.07494790440658146,
    "mean_time": 0.010038831512676552,
    "mean_precisions": 0.97344,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1145.3786074520322,
    "total_upload_time": 4383.120810342021,
    "p95_time": 0.011761200975161045,
    "rps": 100.71195003866134,
    "parallel": 1,
    "p99_time": 0.012443096720380709,
    "mean_time": 0.009267044100002385,
    "mean_precisions": 0.9848599999999998,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1145.3786074520322,
    "total_upload_time": 4383.120810342021,
    "p95_time": 0.010895293002249675,
    "rps": 696.7401576855839,
    "parallel": 100,
    "p99_time": 0.013588398257270458,
    "mean_time": 0.00826493650705088,
    "mean_precisions": 0.97344,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1145.3786074520322,
    "total_upload_time": 4383.120810342021,
    "p95_time": 0.1383419398276601,
    "rps": 662.1882621169539,
    "parallel": 100,
    "p99_time": 0.18012848130892975,
    "mean_time": 0.11182394068993162,
    "mean_precisions": 0.9848600000000001,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1145.3786074520322,
    "total_upload_time": 4383.120810342021,
    "p95_time": 0.25602309123496525,
    "rps": 437.1837377708914,
    "parallel": 100,
    "p99_time": 0.3038724776601886,
    "mean_time": 0.18398057597314474,
    "mean_precisions": 0.9918399999999999,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1145.3786074520322,
    "total_upload_time": 4383.120810342021,
    "p95_time": 0.01801602688501589,
    "rps": 69.81991682843835,
    "parallel": 1,
    "p99_time": 0.019223949612351136,
    "mean_time": 0.013627465756167658,
    "mean_precisions": 0.9918399999999999,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 2425.2032582778484,
    "total_upload_time": 18502.08459948888,
    "p95_time": 0.008074002177454529,
    "rps": 146.92959095116274,
    "parallel": 1,
    "p99_time": 0.012053454364649954,
    "mean_time": 0.006722331247245893,
    "mean_precisions": 0.8905279999999999,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 2425.2032582778484,
    "total_upload_time": 18502.08459948888,
    "p95_time": 0.008870053896680474,
    "rps": 131.21630081688366,
    "parallel": 1,
    "p99_time": 0.010489890642929822,
    "mean_time": 0.007535596260940656,
    "mean_precisions": 0.9443790000000001,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 2425.2032582778484,
    "total_upload_time": 18502.08459948888,
    "p95_time": 0.09416574549395587,
    "rps": 1194.157246726137,
    "parallel": 100,
    "p99_time": 0.11318780258996419,
    "mean_time": 0.0809980880763149,
    "mean_precisions": 0.8905280000000001,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 2425.2032582778484,
    "total_upload_time": 18502.08459948888,
    "p95_time": 0.11924030937952917,
    "rps": 974.1163339693045,
    "parallel": 100,
    "p99_time": 0.15529208316933368,
    "mean_time": 0.1003446164607536,
    "mean_precisions": 0.9443790000000001,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 2425.2032582778484,
    "total_upload_time": 18502.08459948888,
    "p95_time": 0.16074017899809404,
    "rps": 724.5734021523666,
    "parallel": 100,
    "p99_time": 0.17760570100741463,
    "mean_time": 0.13556917203979102,
    "mean_precisions": 0.973267,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 2425.2032582778484,
    "total_upload_time": 18502.08459948888,
    "p95_time": 0.012261523643974214,
    "rps": 99.01808204048415,
    "parallel": 1,
    "p99_time": 0.013377968468703332,
    "mean_time": 0.009997568472777493,
    "mean_precisions": 0.973267,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 633.1172507370002,
    "total_upload_time": 3197.271678973,
    "p95_time": 0.014866457350262853,
    "rps": 91.65158392828637,
    "parallel": 1,
    "p99_time": 0.025736917890772013,
    "mean_time": 0.010765515562991823,
    "mean_precisions": 0.7275799999999999,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 633.1172507370002,
    "total_upload_time": 3197.271678973,
    "p95_time": 0.014381237099814825,
    "rps": 84.04457684854975,
    "parallel": 1,
    "p99_time": 0.01624086328954945,
    "mean_time": 0.011734184136005752,
    "mean_precisions": 0.8273199999999999,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 633.1172507370002,
    "total_upload_time": 3197.271678973,
    "p95_time": 0.15453352619947505,
    "rps": 711.807838493539,
    "parallel": 100,
    "p99_time": 0.20965827535982498,
    "mean_time": 0.1187133113770069,
    "mean_precisions": 0.7275799999999999,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 633.1172507370002,
    "total_upload_time": 3197.271678973,
    "p95_time": 0.20103751409942558,
    "rps": 552.8764743450033,
    "parallel": 100,
    "p99_time": 0.234226747440689,
    "mean_time": 0.15770676233801167,
    "mean_precisions": 0.82732,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 633.1172507370002,
    "total_upload_time": 3197.271678973,
    "p95_time": 0.3278236743002708,
    "rps": 378.24920678538257,
    "parallel": 100,
    "p99_time": 0.38728050407965375,
    "mean_time": 0.2398662840930074,
    "mean_precisions": 0.89703,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 633.1172507370002,
    "total_upload_time": 3197.271678973,
    "p95_time": 0.0197051053999985,
    "rps": 61.07666346437966,
    "parallel": 1,
    "p99_time": 0.021689443599852892,
    "mean_time": 0.016189784476996465,
    "mean_precisions": 0.89703,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 256.26150244699966,
    "total_upload_time": 1551.8028322830069,
    "p95_time": 0.00794782514203689,
    "rps": 158.39886459587856,
    "parallel": 1,
    "p99_time": 0.009753598200186394,
    "mean_time": 0.006241403037589043,
    "mean_precisions": 0.726397,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 256.26150244699966,
    "total_upload_time": 1551.8028322830069,
    "p95_time": 0.008305216301232576,
    "rps": 140.59381520153164,
    "parallel": 1,
    "p99_time": 0.009375394604867325,
    "mean_time": 0.007040036853149649,
    "mean_precisions": 0.79719,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 256.26150244699966,
    "total_upload_time": 1551.8028322830069,
    "p95_time": 0.07811501055257394,
    "rps": 1465.7110320442525,
    "parallel": 100,
    "p99_time": 0.13126777865720216,
    "mean_time": 0.06568219360790681,
    "mean_precisions": 0.7263970000000001,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 256.26150244699966,
    "total_upload_time": 1551.8028322830069,
    "p95_time": 0.10001112779791584,
    "rps": 1165.6284600095173,
    "parallel": 100,
    "p99_time": 0.15087921227677728,
    "mean_time": 0.08349930615938647,
    "mean_precisions": 0.79719,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 256.26150244699966,
    "total_upload_time": 1551.8028322830069,
    "p95_time": 0.14890940726108962,
    "rps": 834.5563419914222,
    "parallel": 100,
    "p99_time": 0.17533527947889527,
    "mean_time": 0.11751103328010212,
    "mean_precisions": 0.8534870000000001,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 256.26150244699966,
    "total_upload_time": 1551.8028322830069,
    "p95_time": 0.011469258851138874,
    "rps": 104.60200443820526,
    "parallel": 1,
    "p99_time": 0.012501014138251776,
    "mean_time": 0.009479008107894333,
    "mean_precisions": 0.8534870000000001,
    "engine_params": {
      "index_options": {
        "m": 16,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1150.9815927050076,
    "total_upload_time": 5023.614104792941,
    "p95_time": 0.01108675883151591,
    "rps": 83.37374991885824,
    "parallel": 1,
    "p99_time": 0.07198159035178896,
    "mean_time": 0.01132263448855374,
    "mean_precisions": 0.9845600000000002,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1150.9815927050076,
    "total_upload_time": 5023.614104792941,
    "p95_time": 0.01546007383731194,
    "rps": 84.26237597933988,
    "parallel": 1,
    "p99_time": 0.016677619131514804,
    "mean_time": 0.011177583474665881,
    "mean_precisions": 0.9913200000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1150.9815927050076,
    "total_upload_time": 5023.614104792941,
    "p95_time": 0.07253377526649281,
    "rps": 716.806215582217,
    "parallel": 100,
    "p99_time": 0.135680788747268,
    "mean_time": 0.022105432172934526,
    "mean_precisions": 0.98456,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1150.9815927050076,
    "total_upload_time": 5023.614104792941,
    "p95_time": 0.1790687370230444,
    "rps": 536.6457790939344,
    "parallel": 100,
    "p99_time": 0.20859449971816507,
    "mean_time": 0.1430724504160229,
    "mean_precisions": 0.9913200000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1150.9815927050076,
    "total_upload_time": 5023.614104792941,
    "p95_time": 0.3701563402311877,
    "rps": 348.7510583908793,
    "parallel": 100,
    "p99_time": 0.42005057535832757,
    "mean_time": 0.23658453582623043,
    "mean_precisions": 0.9954799999999999,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1150.9815927050076,
    "total_upload_time": 5023.614104792941,
    "p95_time": 0.024210043880157173,
    "rps": 56.54807627168174,
    "parallel": 1,
    "p99_time": 0.026253748417366298,
    "mean_time": 0.01693473806383554,
    "mean_precisions": 0.9954799999999999,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 2559.7831692490727,
    "total_upload_time": 19487.516070577083,
    "p95_time": 0.008868721744511275,
    "rps": 136.91229589804587,
    "parallel": 1,
    "p99_time": 0.011768629860598607,
    "mean_time": 0.007224706749152392,
    "mean_precisions": 0.930125,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 2559.7831692490727,
    "total_upload_time": 19487.516070577083,
    "p95_time": 0.010220156481955199,
    "rps": 118.82998897454544,
    "parallel": 1,
    "p99_time": 0.011280442911665887,
    "mean_time": 0.00832931117133703,
    "mean_precisions": 0.9698540000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 2559.7831692490727,
    "total_upload_time": 19487.516070577083,
    "p95_time": 0.10006914760451764,
    "rps": 1151.343584304409,
    "parallel": 100,
    "p99_time": 0.11511069691041495,
    "mean_time": 0.08458333641351201,
    "mean_precisions": 0.930125,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 2559.7831692490727,
    "total_upload_time": 19487.516070577083,
    "p95_time": 0.13073010161751877,
    "rps": 894.9683257369506,
    "parallel": 100,
    "p99_time": 0.15036409652093424,
    "mean_time": 0.10939158214328346,
    "mean_precisions": 0.9698540000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 2559.7831692490727,
    "total_upload_time": 19487.516070577083,
    "p95_time": 0.18571234341943632,
    "rps": 640.594022564242,
    "parallel": 100,
    "p99_time": 0.20829460784792903,
    "mean_time": 0.15369381133934948,
    "mean_precisions": 0.9880690000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 2559.7831692490727,
    "total_upload_time": 19487.516070577083,
    "p95_time": 0.014528208738192914,
    "rps": 87.29416328451083,
    "parallel": 1,
    "p99_time": 0.01569396123522893,
    "mean_time": 0.011365188645827584,
    "mean_precisions": 0.9880690000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 970.144391545,
    "total_upload_time": 3973.1910538440006,
    "p95_time": 0.013132082499214447,
    "rps": 96.78840858719957,
    "parallel": 1,
    "p99_time": 0.01906153301051745,
    "mean_time": 0.01018684906697672,
    "mean_precisions": 0.80344,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 970.144391545,
    "total_upload_time": 3973.1910538440006,
    "p95_time": 0.01658262120072322,
    "rps": 74.67101066048421,
    "parallel": 1,
    "p99_time": 0.018983866690596186,
    "mean_time": 0.013211647077034285,
    "mean_precisions": 0.8918100000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 970.144391545,
    "total_upload_time": 3973.1910538440006,
    "p95_time": 0.16763955819906184,
    "rps": 620.800489551817,
    "parallel": 100,
    "p99_time": 0.20298069523954837,
    "mean_time": 0.1392442400480086,
    "mean_precisions": 0.8034399999999999,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 970.144391545,
    "total_upload_time": 3973.1910538440006,
    "p95_time": 0.28352903224995313,
    "rps": 440.13179544167326,
    "parallel": 100,
    "p99_time": 0.3257548010184837,
    "mean_time": 0.20378787359800116,
    "mean_precisions": 0.8918100000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 970.144391545,
    "total_upload_time": 3973.1910538440006,
    "p95_time": 0.41175941844894626,
    "rps": 307.6314170226933,
    "parallel": 100,
    "p99_time": 0.4944528657487171,
    "mean_time": 0.3018437623660193,
    "mean_precisions": 0.9463199999999999,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 970.144391545,
    "total_upload_time": 3973.1910538440006,
    "p95_time": 0.024565063799127526,
    "rps": 51.45436772976396,
    "parallel": 1,
    "p99_time": 0.02675159557051302,
    "mean_time": 0.01924194044399701,
    "mean_precisions": 0.94632,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 304.02019559399923,
    "total_upload_time": 2220.0981862820045,
    "p95_time": 0.007096108755649766,
    "rps": 164.94284753209172,
    "parallel": 1,
    "p99_time": 0.008157314394047717,
    "mean_time": 0.005992331320577068,
    "mean_precisions": 0.785586,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 304.02019559399923,
    "total_upload_time": 2220.0981862820045,
    "p95_time": 0.009627567599818577,
    "rps": 125.92104225933008,
    "parallel": 1,
    "p99_time": 0.010602903418766801,
    "mean_time": 0.007869667861844936,
    "mean_precisions": 0.8525889999999999,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 304.02019559399923,
    "total_upload_time": 2220.0981862820045,
    "p95_time": 0.08370201814250322,
    "rps": 1406.5339991485612,
    "parallel": 100,
    "p99_time": 0.10751863954399597,
    "mean_time": 0.06805146279085311,
    "mean_precisions": 0.785586,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 304.02019559399923,
    "total_upload_time": 2220.0981862820045,
    "p95_time": 0.12058346974517911,
    "rps": 1033.6875297947192,
    "parallel": 100,
    "p99_time": 0.13964557587460155,
    "mean_time": 0.09382968176980502,
    "mean_precisions": 0.8525889999999999,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 304.02019559399923,
    "total_upload_time": 2220.0981862820045,
    "p95_time": 0.19296247134916483,
    "rps": 677.0060006547941,
    "parallel": 100,
    "p99_time": 0.2244198495904857,
    "mean_time": 0.1452589644088832,
    "mean_precisions": 0.905184,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 304.02019559399923,
    "total_upload_time": 2220.0981862820045,
    "p95_time": 0.014626675305044044,
    "rps": 85.68578593003059,
    "parallel": 1,
    "p99_time": 0.0158663870964665,
    "mean_time": 0.01158369797127816,
    "mean_precisions": 0.905184,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 128
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1400.049110705033,
    "total_upload_time": 10058.765229195007,
    "p95_time": 0.011595265578944237,
    "rps": 79.40909162217838,
    "parallel": 1,
    "p99_time": 0.05803877095226205,
    "mean_time": 0.011932483700383455,
    "mean_precisions": 0.99006,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1400.049110705033,
    "total_upload_time": 10058.765229195007,
    "p95_time": 0.016765173664316537,
    "rps": 76.15971903021641,
    "parallel": 1,
    "p99_time": 0.017807942901272328,
    "mean_time": 0.012434954623668455,
    "mean_precisions": 0.99582,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1400.049110705033,
    "total_upload_time": 10058.765229195007,
    "p95_time": 0.12137416162877344,
    "rps": 712.986780406697,
    "parallel": 100,
    "p99_time": 0.1297527443745639,
    "mean_time": 0.09075350076924078,
    "mean_precisions": 0.99006,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1400.049110705033,
    "total_upload_time": 10058.765229195007,
    "p95_time": 0.21659185422468,
    "rps": 470.58070516178697,
    "parallel": 100,
    "p99_time": 0.27022519676480444,
    "mean_time": 0.16641954399971293,
    "mean_precisions": 0.99582,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1400.049110705033,
    "total_upload_time": 10058.765229195007,
    "p95_time": 0.4919894267630298,
    "rps": 297.5703545701693,
    "parallel": 100,
    "p99_time": 0.5172454699198716,
    "mean_time": 0.2809415587874828,
    "mean_precisions": 0.9982800000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1400.049110705033,
    "total_upload_time": 10058.765229195007,
    "p95_time": 0.026937370450468734,
    "rps": 49.89164152567326,
    "parallel": 1,
    "p99_time": 0.0291247210535221,
    "mean_time": 0.019294925636565312,
    "mean_precisions": 0.99828,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 4024.3746634309646,
    "total_upload_time": 36517.66519238893,
    "p95_time": 0.009233571367803957,
    "rps": 124.53579405875736,
    "parallel": 1,
    "p99_time": 0.012808151384815591,
    "mean_time": 0.007950910034170375,
    "mean_precisions": 0.949465,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 4024.3746634309646,
    "total_upload_time": 36517.66519238893,
    "p95_time": 0.011167677887715399,
    "rps": 110.26786028997246,
    "parallel": 1,
    "p99_time": 0.012334696154575796,
    "mean_time": 0.008982286320021377,
    "mean_precisions": 0.980742,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 4024.3746634309646,
    "total_upload_time": 36517.66519238893,
    "p95_time": 0.10310496435267848,
    "rps": 1095.2361841793859,
    "parallel": 100,
    "p99_time": 0.11392656951444224,
    "mean_time": 0.08897757755783386,
    "mean_precisions": 0.949465,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 4024.3746634309646,
    "total_upload_time": 36517.66519238893,
    "p95_time": 0.1445387328392826,
    "rps": 827.183320059003,
    "parallel": 100,
    "p99_time": 0.17226245791884148,
    "mean_time": 0.11858266945162323,
    "mean_precisions": 0.980742,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 4024.3746634309646,
    "total_upload_time": 36517.66519238893,
    "p95_time": 0.21549845712725071,
    "rps": 574.7735762817307,
    "parallel": 100,
    "p99_time": 0.24194457350531595,
    "mean_time": 0.1715712742680218,
    "mean_precisions": 0.9934649999999999,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 4024.3746634309646,
    "total_upload_time": 36517.66519238893,
    "p95_time": 0.016293688945006577,
    "rps": 78.77265815867138,
    "parallel": 1,
    "p99_time": 0.01793423818424344,
    "mean_time": 0.012589114686776884,
    "mean_precisions": 0.9934649999999999,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 860.1360141739988,
    "total_upload_time": 7367.693119109001,
    "p95_time": 0.014517270299984368,
    "rps": 88.20391155763757,
    "parallel": 1,
    "p99_time": 0.03720128392909825,
    "mean_time": 0.011180406353985746,
    "mean_precisions": 0.85102,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 860.1360141739988,
    "total_upload_time": 7367.693119109001,
    "p95_time": 0.017752054700395092,
    "rps": 69.2112946439859,
    "parallel": 1,
    "p99_time": 0.020693652400550485,
    "mean_time": 0.0142602497620137,
    "mean_precisions": 0.92598,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 860.1360141739988,
    "total_upload_time": 7367.693119109001,
    "p95_time": 0.16899813444779282,
    "rps": 606.2409778157223,
    "parallel": 100,
    "p99_time": 0.19026202970992018,
    "mean_time": 0.14252680968094136,
    "mean_precisions": 0.85102,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 860.1360141739988,
    "total_upload_time": 7367.693119109001,
    "p95_time": 0.28938003170078447,
    "rps": 419.19420581596717,
    "parallel": 100,
    "p99_time": 0.3415100636425632,
    "mean_time": 0.21483038239098096,
    "mean_precisions": 0.92598,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 860.1360141739988,
    "total_upload_time": 7367.693119109001,
    "p95_time": 0.4784660441997401,
    "rps": 275.11968933512355,
    "parallel": 100,
    "p99_time": 0.5896169356521568,
    "mean_time": 0.33853344867004487,
    "mean_precisions": 0.9659099999999999,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 860.1360141739988,
    "total_upload_time": 7367.693119109001,
    "p95_time": 0.026269712399334823,
    "rps": 47.99816025816206,
    "parallel": 1,
    "p99_time": 0.02850178478864109,
    "mean_time": 0.020633671532053994,
    "mean_precisions": 0.96591,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 457.405857197009,
    "total_upload_time": 4475.3482212300005,
    "p95_time": 0.007581935098278332,
    "rps": 156.54220346254823,
    "parallel": 1,
    "p99_time": 0.008671501016651746,
    "mean_time": 0.006316210441064322,
    "mean_precisions": 0.814575,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 457.405857197009,
    "total_upload_time": 4475.3482212300005,
    "p95_time": 0.010649422597634838,
    "rps": 115.78112141425474,
    "parallel": 1,
    "p99_time": 0.011941632869129536,
    "mean_time": 0.008560619319483521,
    "mean_precisions": 0.8800030000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 457.405857197009,
    "total_upload_time": 4475.3482212300005,
    "p95_time": 0.08910700719570738,
    "rps": 1327.730478363642,
    "parallel": 100,
    "p99_time": 0.10276084301804077,
    "mean_time": 0.07232465959918045,
    "mean_precisions": 0.814575,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 457.405857197009,
    "total_upload_time": 4475.3482212300005,
    "p95_time": 0.13846140480018218,
    "rps": 923.7682823159864,
    "parallel": 100,
    "p99_time": 0.1786350290836709,
    "mean_time": 0.10575097742999497,
    "mean_precisions": 0.8800030000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 457.405857197009,
    "total_upload_time": 4475.3482212300005,
    "p95_time": 0.22386979424700254,
    "rps": 599.1588869977548,
    "parallel": 100,
    "p99_time": 0.2582596645600279,
    "mean_time": 0.1642550023003394,
    "mean_precisions": 0.9292299999999999,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 457.405857197009,
    "total_upload_time": 4475.3482212300005,
    "p95_time": 0.01615173149621114,
    "rps": 78.05474092936628,
    "parallel": 1,
    "p99_time": 0.017601609186531277,
    "mean_time": 0.01272182557151391,
    "mean_precisions": 0.9292300000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1982.689348487067,
    "total_upload_time": 19125.295860829065,
    "p95_time": 0.01179508623899892,
    "rps": 78.3070852653807,
    "parallel": 1,
    "p99_time": 0.049140950699802545,
    "mean_time": 0.012106586299021728,
    "mean_precisions": 0.9934199999999999,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1982.689348487067,
    "total_upload_time": 19125.295860829065,
    "p95_time": 0.017841921624494717,
    "rps": 69.0519935521126,
    "parallel": 1,
    "p99_time": 0.018948133238591253,
    "mean_time": 0.013767532027605922,
    "mean_precisions": 0.99734,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1982.689348487067,
    "total_upload_time": 19125.295860829065,
    "p95_time": 0.14286986053921286,
    "rps": 648.2051325669138,
    "parallel": 100,
    "p99_time": 0.20606871052528733,
    "mean_time": 0.11733824582151137,
    "mean_precisions": 0.9934199999999999,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1982.689348487067,
    "total_upload_time": 19125.295860829065,
    "p95_time": 0.27337484027375475,
    "rps": 422.34088287757817,
    "parallel": 100,
    "p99_time": 0.324275865778327,
    "mean_time": 0.1880261828172952,
    "mean_precisions": 0.99734,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1982.689348487067,
    "total_upload_time": 19125.295860829065,
    "p95_time": 0.5766871099185664,
    "rps": 257.8761365133282,
    "parallel": 100,
    "p99_time": 0.5955291455320548,
    "mean_time": 0.3279269294054247,
    "mean_precisions": 0.9989600000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1982.689348487067,
    "total_upload_time": 19125.295860829065,
    "p95_time": 0.029068448423640803,
    "rps": 44.47276998061625,
    "parallel": 1,
    "p99_time": 0.031149914212292063,
    "mean_time": 0.021742140268255026,
    "mean_precisions": 0.9989600000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1192.6988747629985,
    "total_upload_time": 13767.552721817,
    "p95_time": 0.015390284649947713,
    "rps": 79.70272110536568,
    "parallel": 1,
    "p99_time": 0.048873470221333176,
    "mean_time": 0.012383631943037472,
    "mean_precisions": 0.8810999999999999,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1192.6988747629985,
    "total_upload_time": 13767.552721817,
    "p95_time": 0.018847242848278257,
    "rps": 64.53134125512732,
    "parallel": 1,
    "p99_time": 0.021287532711976382,
    "mean_time": 0.01530830808292012,
    "mean_precisions": 0.9457900000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1192.6988747629985,
    "total_upload_time": 13767.552721817,
    "p95_time": 0.19182465264857454,
    "rps": 562.1505218428061,
    "parallel": 100,
    "p99_time": 0.22613916252179478,
    "mean_time": 0.15172420940592565,
    "mean_precisions": 0.8811,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1192.6988747629985,
    "total_upload_time": 13767.552721817,
    "p95_time": 0.31032231324934395,
    "rps": 382.69607680040735,
    "parallel": 100,
    "p99_time": 0.3613700280501143,
    "mean_time": 0.23576530685909894,
    "mean_precisions": 0.9457899999999999,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1192.6988747629985,
    "total_upload_time": 13767.552721817,
    "p95_time": 0.5153729434990962,
    "rps": 259.5158328747311,
    "parallel": 100,
    "p99_time": 0.6131504459488133,
    "mean_time": 0.36061166866692657,
    "mean_precisions": 0.9774700000000002,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1192.6988747629985,
    "total_upload_time": 13767.552721817,
    "p95_time": 0.028718242151262525,
    "rps": 43.50314445635678,
    "parallel": 1,
    "p99_time": 0.03158288291029748,
    "mean_time": 0.02278412222503175,
    "mean_precisions": 0.9774700000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 607.124571331995,
    "total_upload_time": 8953.12518215699,
    "p95_time": 0.0076509181380970395,
    "rps": 153.86715483799387,
    "parallel": 1,
    "p99_time": 0.008595291163364894,
    "mean_time": 0.006429960457231209,
    "mean_precisions": 0.830054,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 607.124571331995,
    "total_upload_time": 8953.12518215699,
    "p95_time": 0.010926363149337703,
    "rps": 110.96924215305319,
    "parallel": 1,
    "p99_time": 0.012221231930889193,
    "mean_time": 0.008938396449267747,
    "mean_precisions": 0.8951690000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 607.124571331995,
    "total_upload_time": 8953.12518215699,
    "p95_time": 0.09441653304238568,
    "rps": 1276.2008786264144,
    "parallel": 100,
    "p99_time": 0.11974362861263219,
    "mean_time": 0.07531136015000665,
    "mean_precisions": 0.8300540000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 607.124571331995,
    "total_upload_time": 8953.12518215699,
    "p95_time": 0.1429621811075776,
    "rps": 889.244100961821,
    "parallel": 100,
    "p99_time": 0.1644975398629322,
    "mean_time": 0.10948341080228566,
    "mean_precisions": 0.8951690000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 607.124571331995,
    "total_upload_time": 8953.12518215699,
    "p95_time": 0.2346289677567255,
    "rps": 567.3408266965548,
    "parallel": 100,
    "p99_time": 0.2709701713640243,
    "mean_time": 0.17371488141738228,
    "mean_precisions": 0.9425140000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 607.124571331995,
    "total_upload_time": 8953.12518215699,
    "p95_time": 0.016526212009193842,
    "rps": 74.84617026907715,
    "parallel": 1,
    "p99_time": 0.017972299789107637,
    "mean_time": 0.013274238179925305,
    "mean_precisions": 0.9425140000000001,
    "engine_params": {
      "index_options": {
        "m": 32,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1425.2530145939672,
    "total_upload_time": 11104.308376293979,
    "p95_time": 0.013904584536794575,
    "rps": 69.21640203953407,
    "parallel": 1,
    "p99_time": 0.06449694778886662,
    "mean_time": 0.013781106048217043,
    "mean_precisions": 0.9929,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1425.2530145939672,
    "total_upload_time": 11104.308376293979,
    "p95_time": 0.020504556311061607,
    "rps": 67.36176681514021,
    "parallel": 1,
    "p99_time": 0.02221789517789149,
    "mean_time": 0.014132639853749424,
    "mean_precisions": 0.99672,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1425.2530145939672,
    "total_upload_time": 11104.308376293979,
    "p95_time": 0.14837392189074308,
    "rps": 636.2893778891117,
    "parallel": 100,
    "p99_time": 0.1627355858543888,
    "mean_time": 0.12087500766923186,
    "mean_precisions": 0.9929,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1425.2530145939672,
    "total_upload_time": 11104.308376293979,
    "p95_time": 0.2810053933179007,
    "rps": 412.4404019323622,
    "parallel": 100,
    "p99_time": 0.34294281821115885,
    "mean_time": 0.19567979270997457,
    "mean_precisions": 0.99672,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1425.2530145939672,
    "total_upload_time": 11104.308376293979,
    "p95_time": 0.5857639882538933,
    "rps": 255.61482990972897,
    "parallel": 100,
    "p99_time": 0.6204265330149792,
    "mean_time": 0.3384062527755741,
    "mean_precisions": 0.99854,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1425.2530145939672,
    "total_upload_time": 11104.308376293979,
    "p95_time": 0.03282865136279725,
    "rps": 43.62271801498888,
    "parallel": 1,
    "p99_time": 0.03549764409777709,
    "mean_time": 0.022143378259497696,
    "mean_precisions": 0.99854,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 875.7830108460003,
    "total_upload_time": 8155.238315557002,
    "p95_time": 0.01823679315020852,
    "rps": 66.28668047599537,
    "parallel": 1,
    "p99_time": 0.10278804270361426,
    "mean_time": 0.014913538842134585,
    "mean_precisions": 0.87864,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 875.7830108460003,
    "total_upload_time": 8155.238315557002,
    "p95_time": 0.021256346003428916,
    "rps": 61.5630499418176,
    "parallel": 1,
    "p99_time": 0.023107050100370542,
    "mean_time": 0.016049100679134426,
    "mean_precisions": 0.94578,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 875.7830108460003,
    "total_upload_time": 8155.238315557002,
    "p95_time": 0.21404080010179308,
    "rps": 528.4948848676033,
    "parallel": 100,
    "p99_time": 0.25878101778609564,
    "mean_time": 0.16411360496307315,
    "mean_precisions": 0.87864,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 875.7830108460003,
    "total_upload_time": 8155.238315557002,
    "p95_time": 0.34506041520544384,
    "rps": 365.98838760956846,
    "parallel": 100,
    "p99_time": 0.39478664500762534,
    "mean_time": 0.24738745049502905,
    "mean_precisions": 0.94578,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 875.7830108460003,
    "total_upload_time": 8155.238315557002,
    "p95_time": 0.5939419434984301,
    "rps": 237.9129939093825,
    "parallel": 100,
    "p99_time": 0.6549277391100622,
    "mean_time": 0.39511401846419175,
    "mean_precisions": 0.97885,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 875.7830108460003,
    "total_upload_time": 8155.238315557002,
    "p95_time": 0.032263232599871114,
    "rps": 41.44900789210713,
    "parallel": 1,
    "p99_time": 0.034439582137129034,
    "mean_time": 0.02392064308802219,
    "mean_precisions": 0.9788500000000001,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 453.8465308110026,
    "total_upload_time": 5787.3111897909985,
    "p95_time": 0.008913194496562938,
    "rps": 139.54632545256496,
    "parallel": 1,
    "p99_time": 0.009967607799917464,
    "mean_time": 0.00709631112075731,
    "mean_precisions": 0.8477220000000001,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 453.8465308110026,
    "total_upload_time": 5787.3111897909985,
    "p95_time": 0.013053236305131576,
    "rps": 99.35092956381044,
    "parallel": 1,
    "p99_time": 0.014281826360529522,
    "mean_time": 0.009991573765639623,
    "mean_precisions": 0.910533,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 453.8465308110026,
    "total_upload_time": 5787.3111897909985,
    "p95_time": 0.10677433570526772,
    "rps": 1152.9927517602432,
    "parallel": 100,
    "p99_time": 0.12078952407886392,
    "mean_time": 0.08387398638283484,
    "mean_precisions": 0.8477220000000001,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 453.8465308110026,
    "total_upload_time": 5787.3111897909985,
    "p95_time": 0.1652573006627789,
    "rps": 782.7695415879707,
    "parallel": 100,
    "p99_time": 0.19011438938134234,
    "mean_time": 0.12513084370950672,
    "mean_precisions": 0.910533,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 453.8465308110026,
    "total_upload_time": 5787.3111897909985,
    "p95_time": 0.27833481965935786,
    "rps": 486.705932117694,
    "parallel": 100,
    "p99_time": 0.31939160743975664,
    "mean_time": 0.20267568551938167,
    "mean_precisions": 0.954212,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 453.8465308110026,
    "total_upload_time": 5787.3111897909985,
    "p95_time": 0.02000088774730102,
    "rps": 65.99023681363164,
    "parallel": 1,
    "p99_time": 0.021634649969200843,
    "mean_time": 0.0150693794130304,
    "mean_precisions": 0.9542120000000001,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 256
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1863.5589663529536,
    "total_upload_time": 22264.17694292497,
    "p95_time": 0.015285072318511084,
    "rps": 65.6465437035491,
    "parallel": 1,
    "p99_time": 0.046852740189060584,
    "mean_time": 0.014559031385392883,
    "mean_precisions": 0.99508,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1863.5589663529536,
    "total_upload_time": 22264.17694292497,
    "p95_time": 0.023432900063926357,
    "rps": 57.68447400233918,
    "parallel": 1,
    "p99_time": 0.025335660581476988,
    "mean_time": 0.016600885034701786,
    "mean_precisions": 0.9981,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1863.5589663529536,
    "total_upload_time": 22264.17694292497,
    "p95_time": 0.17825843887985685,
    "rps": 545.2528003337748,
    "parallel": 100,
    "p99_time": 0.2075027251942085,
    "mean_time": 0.14246995146342087,
    "mean_precisions": 0.99508,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1863.5589663529536,
    "total_upload_time": 22264.17694292497,
    "p95_time": 0.39202341322088635,
    "rps": 346.59439648694297,
    "parallel": 100,
    "p99_time": 0.4285061989387032,
    "mean_time": 0.23636582069024445,
    "mean_precisions": 0.9981,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1863.5589663529536,
    "total_upload_time": 22264.17694292497,
    "p95_time": 0.7312809652416036,
    "rps": 215.18841858827233,
    "parallel": 100,
    "p99_time": 0.7671952783979942,
    "mean_time": 0.41005969029606787,
    "mean_precisions": 0.9994,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1863.5589663529536,
    "total_upload_time": 22264.17694292497,
    "p95_time": 0.03812710763886571,
    "rps": 36.59493074730065,
    "parallel": 1,
    "p99_time": 0.04126721020205878,
    "mean_time": 0.026500729365856387,
    "mean_precisions": 0.9994,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 348.87877320701955,
    "total_upload_time": 3928.910908914986,
    "p95_time": 0.016917963413288814,
    "rps": 74.88602210792446,
    "parallel": 1,
    "p99_time": 0.020368739535915663,
    "mean_time": 0.013255434202437754,
    "mean_precisions": 0.32652,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 348.87877320701955,
    "total_upload_time": 3928.910908914986,
    "p95_time": 0.020570494045387022,
    "rps": 61.289159708148084,
    "parallel": 1,
    "p99_time": 0.02220026400638744,
    "mean_time": 0.01621339765324956,
    "mean_precisions": 0.33421000000000006,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 348.87877320701955,
    "total_upload_time": 3928.910908914986,
    "p95_time": 0.21240151294332463,
    "rps": 515.1996909805125,
    "parallel": 100,
    "p99_time": 0.23836903139017518,
    "mean_time": 0.17105373126716586,
    "mean_precisions": 0.32652000000000003,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 348.87877320701955,
    "total_upload_time": 3928.910908914986,
    "p95_time": 0.32098334916809107,
    "rps": 368.20521434120667,
    "parallel": 100,
    "p99_time": 0.38176895207900086,
    "mean_time": 0.24751158943877088,
    "mean_precisions": 0.33421,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 348.87877320701955,
    "total_upload_time": 3928.910908914986,
    "p95_time": 0.5195746125973528,
    "rps": 260.4724799494793,
    "parallel": 100,
    "p99_time": 0.5991017660690704,
    "mean_time": 0.3606434393493109,
    "mean_precisions": 0.33664,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 348.87877320701955,
    "total_upload_time": 3928.910908914986,
    "p95_time": 0.029134517518104985,
    "rps": 43.9607683106764,
    "parallel": 1,
    "p99_time": 0.031064645320875568,
    "mean_time": 0.02263594625511905,
    "mean_precisions": 0.33664,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 626.7961872549931,
    "total_upload_time": 12074.624013235996,
    "p95_time": 0.009743354099191493,
    "rps": 126.6936547365818,
    "parallel": 1,
    "p99_time": 0.010763504137285055,
    "mean_time": 0.007821093461250712,
    "mean_precisions": 0.874705,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 626.7961872549931,
    "total_upload_time": 12074.624013235996,
    "p95_time": 0.014495678357343422,
    "rps": 88.28828955685702,
    "parallel": 1,
    "p99_time": 0.015876051509840183,
    "mean_time": 0.011250459162132756,
    "mean_precisions": 0.933834,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 626.7961872549931,
    "total_upload_time": 12074.624013235996,
    "p95_time": 0.12298899810339207,
    "rps": 1015.4168034294848,
    "parallel": 100,
    "p99_time": 0.13986510397182428,
    "mean_time": 0.09589256144010869,
    "mean_precisions": 0.874705,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 626.7961872549931,
    "total_upload_time": 12074.624013235996,
    "p95_time": 0.19505000635472242,
    "rps": 671.8837397639264,
    "parallel": 100,
    "p99_time": 0.22465797006356297,
    "mean_time": 0.14621000217482796,
    "mean_precisions": 0.933834,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 626.7961872549931,
    "total_upload_time": 12074.624013235996,
    "p95_time": 0.3322367105924058,
    "rps": 417.45061957103275,
    "parallel": 100,
    "p99_time": 0.38070984922451323,
    "mean_time": 0.2369255954286753,
    "mean_precisions": 0.9709899999999999,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "elasticsearch",
    "setup_name": "elasticsearch-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 626.7961872549931,
    "total_upload_time": 12074.624013235996,
    "p95_time": 0.022720023092551854,
    "rps": 57.70266591373781,
    "parallel": 1,
    "p99_time": 0.024572266588802457,
    "mean_time": 0.017245928194544104,
    "mean_precisions": 0.9709900000000001,
    "engine_params": {
      "index_options": {
        "m": 64,
        "ef_construction": 512
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 16.44080770702567,
    "total_upload_time": 69.87649160204455,
    "p95_time": 0.020290032544289717,
    "rps": 68.4380647760098,
    "parallel": 1,
    "p99_time": 0.0275039308005944,
    "mean_time": 0.013842020893353037,
    "mean_precisions": 0.993,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 16.44080770702567,
    "total_upload_time": 69.87649160204455,
    "p95_time": 0.0310893306392245,
    "rps": 52.58191689930728,
    "parallel": 1,
    "p99_time": 0.03741540424176492,
    "mean_time": 0.018182585797435605,
    "mean_precisions": 0.99682,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 16.44080770702567,
    "total_upload_time": 69.87649160204455,
    "p95_time": 0.4413246157404501,
    "rps": 219.1164855675971,
    "parallel": 100,
    "p99_time": 0.5766513449500781,
    "mean_time": 0.39331543537132674,
    "mean_precisions": 0.99734,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 16.44080770702567,
    "total_upload_time": 69.87649160204455,
    "p95_time": 0.7568574528413592,
    "rps": 128.3694805826125,
    "parallel": 100,
    "p99_time": 1.1000995788665024,
    "mean_time": 0.7098438354038517,
    "mean_precisions": 0.9983200000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 16.44080770702567,
    "total_upload_time": 69.87649160204455,
    "p95_time": 1.3375194063992242,
    "rps": 76.66430211940148,
    "parallel": 100,
    "p99_time": 1.9238487879402237,
    "mean_time": 1.23703547862696,
    "mean_precisions": 0.9987800000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 16.44080770702567,
    "total_upload_time": 69.87649160204455,
    "p95_time": 0.023390320589533078,
    "rps": 51.28050713549892,
    "parallel": 1,
    "p99_time": 0.025001369887031614,
    "mean_time": 0.018683701451017987,
    "mean_precisions": 0.9987800000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 258.43017653599964,
    "total_upload_time": 908.4754672920008,
    "p95_time": 0.011969527349356208,
    "rps": 110.23200384033498,
    "parallel": 1,
    "p99_time": 0.016014418901140776,
    "mean_time": 0.008969986490699921,
    "mean_precisions": 0.99392,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 258.43017653599964,
    "total_upload_time": 908.4754672920008,
    "p95_time": 0.014619004149244571,
    "rps": 91.98971009328866,
    "parallel": 1,
    "p99_time": 0.018765603289466533,
    "mean_time": 0.010757044257708003,
    "mean_precisions": 0.9978049999999999,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 258.43017653599964,
    "total_upload_time": 908.4754672920008,
    "p95_time": 0.33359716344921236,
    "rps": 394.8216124821764,
    "parallel": 100,
    "p99_time": 0.37862255913940324,
    "mean_time": 0.2500239214016019,
    "mean_precisions": 0.9865229999999999,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 258.43017653599964,
    "total_upload_time": 908.4754672920008,
    "p95_time": 0.521910297850627,
    "rps": 260.7510358072426,
    "parallel": 100,
    "p99_time": 0.634425337129178,
    "mean_time": 0.3795201484150932,
    "mean_precisions": 0.9951979999999999,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 258.43017653599964,
    "total_upload_time": 908.4754672920008,
    "p95_time": 0.7959847926497787,
    "rps": 166.28680464589993,
    "parallel": 100,
    "p99_time": 0.9414332240708063,
    "mean_time": 0.5969147134650952,
    "mean_precisions": 0.998394,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 258.43017653599964,
    "total_upload_time": 908.4754672920008,
    "p95_time": 0.023571292349242854,
    "rps": 67.53235003793063,
    "parallel": 1,
    "p99_time": 0.030535250448810985,
    "mean_time": 0.014679130142308532,
    "mean_precisions": 0.999218,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.4749776619974,
    "total_upload_time": 476.3130891949986,
    "p95_time": 0.010123701900374727,
    "rps": 116.0965657905425,
    "parallel": 1,
    "p99_time": 0.011907591390408924,
    "mean_time": 0.008483400110009824,
    "mean_precisions": 0.94013,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.4749776619974,
    "total_upload_time": 476.3130891949986,
    "p95_time": 0.013175551298627396,
    "rps": 90.33828100711317,
    "parallel": 1,
    "p99_time": 0.01490723335140501,
    "mean_time": 0.01094937195796956,
    "mean_precisions": 0.9741100000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.4749776619974,
    "total_upload_time": 476.3130891949986,
    "p95_time": 0.38274144864953996,
    "rps": 316.03009187724166,
    "parallel": 100,
    "p99_time": 0.39112252148137483,
    "mean_time": 0.2859951995649753,
    "mean_precisions": 0.94229,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.4749776619974,
    "total_upload_time": 476.3130891949986,
    "p95_time": 0.5998544650015901,
    "rps": 200.7450982339373,
    "parallel": 100,
    "p99_time": 0.630661806851167,
    "mean_time": 0.4614150212170534,
    "mean_precisions": 0.9749500000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.4749776619974,
    "total_upload_time": 476.3130891949986,
    "p95_time": 0.9339719460009291,
    "rps": 122.36146124589882,
    "parallel": 100,
    "p99_time": 0.9506763562810363,
    "mean_time": 0.7711574566230774,
    "mean_precisions": 0.98921,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.4749776619974,
    "total_upload_time": 476.3130891949986,
    "p95_time": 0.01897811850030848,
    "rps": 64.25155061047674,
    "parallel": 1,
    "p99_time": 0.020479027100409438,
    "mean_time": 0.015433241247952537,
    "mean_precisions": 0.98921,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.517058006997104,
    "total_upload_time": 127.83506886698888,
    "p95_time": 0.008347840199712664,
    "rps": 166.59991623609704,
    "parallel": 1,
    "p99_time": 0.013393281239314098,
    "mean_time": 0.005883181939892165,
    "mean_precisions": 0.825209,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.517058006997104,
    "total_upload_time": 127.83506886698888,
    "p95_time": 0.009263888699751987,
    "rps": 137.8417646291365,
    "parallel": 1,
    "p99_time": 0.0128322677403412,
    "mean_time": 0.007149821202999283,
    "mean_precisions": 0.8854879999999999,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.517058006997104,
    "total_upload_time": 127.83506886698888,
    "p95_time": 0.06564809444962519,
    "rps": 2260.8531174914647,
    "parallel": 100,
    "p99_time": 0.0759827761305678,
    "mean_time": 0.03961063465489679,
    "mean_precisions": 0.7128950000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.517058006997104,
    "total_upload_time": 127.83506886698888,
    "p95_time": 0.07699133250052906,
    "rps": 1961.8413603899987,
    "parallel": 100,
    "p99_time": 0.09245948474985198,
    "mean_time": 0.04696427437989178,
    "mean_precisions": 0.790924,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.517058006997104,
    "total_upload_time": 127.83506886698888,
    "p95_time": 0.0916189424996446,
    "rps": 1501.669137607354,
    "parallel": 100,
    "p99_time": 0.10670514880032898,
    "mean_time": 0.0634730499991937,
    "mean_precisions": 0.8543280000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.517058006997104,
    "total_upload_time": 127.83506886698888,
    "p95_time": 0.012373737249708935,
    "rps": 115.40583533608353,
    "parallel": 1,
    "p99_time": 0.01633907393998017,
    "mean_time": 0.008548652315800518,
    "mean_precisions": 0.933541,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 16
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 176.65841434302274,
    "total_upload_time": 1062.8112723830272,
    "p95_time": 0.03227416866284329,
    "rps": 48.111511375071615,
    "parallel": 1,
    "p99_time": 0.039293009025277596,
    "mean_time": 0.019982510972383898,
    "mean_precisions": 0.9958,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 176.65841434302274,
    "total_upload_time": 1062.8112723830272,
    "p95_time": 0.04047074247791898,
    "rps": 43.58707211812903,
    "parallel": 1,
    "p99_time": 0.04721082920033951,
    "mean_time": 0.02211648977729492,
    "mean_precisions": 0.9981200000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 176.65841434302274,
    "total_upload_time": 1062.8112723830272,
    "p95_time": 0.6262575893779285,
    "rps": 154.06270277415646,
    "parallel": 100,
    "p99_time": 0.6484211655246327,
    "mean_time": 0.5825115745197982,
    "mean_precisions": 0.9981399999999999,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 176.65841434302274,
    "total_upload_time": 1062.8112723830272,
    "p95_time": 1.0663248277443926,
    "rps": 94.14517251639545,
    "parallel": 100,
    "p99_time": 1.4023403139010773,
    "mean_time": 0.9960199070878327,
    "mean_precisions": 0.99884,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 176.65841434302274,
    "total_upload_time": 1062.8112723830272,
    "p95_time": 1.8369350289111026,
    "rps": 55.45284724046135,
    "parallel": 100,
    "p99_time": 2.5230114806647186,
    "mean_time": 1.730878366412851,
    "mean_precisions": 0.9991800000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 176.65841434302274,
    "total_upload_time": 1062.8112723830272,
    "p95_time": 0.03228191633243114,
    "rps": 38.766441778378095,
    "parallel": 1,
    "p99_time": 0.03458953588851728,
    "mean_time": 0.0249424866696354,
    "mean_precisions": 0.9991800000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 272.3199094879674,
    "total_upload_time": 2247.4655076150084,
    "p95_time": 0.011680976790376007,
    "rps": 116.42860548986732,
    "parallel": 1,
    "p99_time": 0.014636582903331157,
    "mean_time": 0.008478434061643203,
    "mean_precisions": 0.9897290000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 272.3199094879674,
    "total_upload_time": 2247.4655076150084,
    "p95_time": 0.009253299055853858,
    "rps": 131.96467895648598,
    "parallel": 1,
    "p99_time": 0.011235479274764659,
    "mean_time": 0.007474864311062265,
    "mean_precisions": 0.996531,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 272.3199094879674,
    "total_upload_time": 2247.4655076150084,
    "p95_time": 0.2126469859620556,
    "rps": 580.7217391702638,
    "parallel": 100,
    "p99_time": 0.23794421044411143,
    "mean_time": 0.16882343932637014,
    "mean_precisions": 0.9896280000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 272.3199094879674,
    "total_upload_time": 2247.4655076150084,
    "p95_time": 0.31773491484345856,
    "rps": 388.9807446762083,
    "parallel": 100,
    "p99_time": 0.3649431368138176,
    "mean_time": 0.2538598900598474,
    "mean_precisions": 0.9966380000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 272.3199094879674,
    "total_upload_time": 2247.4655076150084,
    "p95_time": 0.5167733783484436,
    "rps": 241.10655832347464,
    "parallel": 100,
    "p99_time": 0.6103793797956316,
    "mean_time": 0.41077888933632056,
    "mean_precisions": 0.9988970000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 272.3199094879674,
    "total_upload_time": 2247.4655076150084,
    "p95_time": 0.013047331984853371,
    "rps": 98.32942368690311,
    "parallel": 1,
    "p99_time": 0.014484765991801396,
    "mean_time": 0.010042611890926492,
    "mean_precisions": 0.9988970000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.96849478299919,
    "total_upload_time": 572.0299993599983,
    "p95_time": 0.011034868101523898,
    "rps": 112.18583182222551,
    "parallel": 1,
    "p99_time": 0.012515965501297613,
    "mean_time": 0.008779466732870788,
    "mean_precisions": 0.96226,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.96849478299919,
    "total_upload_time": 572.0299993599983,
    "p95_time": 0.013919721648926497,
    "rps": 90.61317422217203,
    "parallel": 1,
    "p99_time": 0.015497392277575272,
    "mean_time": 0.010899620496002172,
    "mean_precisions": 0.9859600000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.96849478299919,
    "total_upload_time": 572.0299993599983,
    "p95_time": 0.4212264971512923,
    "rps": 281.5280399337747,
    "parallel": 100,
    "p99_time": 0.43687832194125803,
    "mean_time": 0.3226303301979024,
    "mean_precisions": 0.9633800000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.96849478299919,
    "total_upload_time": 572.0299993599983,
    "p95_time": 0.6127967846496176,
    "rps": 182.85465703689457,
    "parallel": 100,
    "p99_time": 0.8089335615813252,
    "mean_time": 0.5094148798070455,
    "mean_precisions": 0.9864,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.96849478299919,
    "total_upload_time": 572.0299993599983,
    "p95_time": 0.9946499836001749,
    "rps": 110.87764373189869,
    "parallel": 100,
    "p99_time": 1.0984080916777383,
    "mean_time": 0.8513385111439639,
    "mean_precisions": 0.99487,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.96849478299919,
    "total_upload_time": 572.0299993599983,
    "p95_time": 0.01998230165027053,
    "rps": 64.94986340295678,
    "parallel": 1,
    "p99_time": 0.02316058485830581,
    "mean_time": 0.015262728164052532,
    "mean_precisions": 0.99487,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 33.99336479900012,
    "total_upload_time": 222.02942449700004,
    "p95_time": 0.009059649499840807,
    "rps": 148.27596248911559,
    "parallel": 1,
    "p99_time": 0.013670126250353864,
    "mean_time": 0.0066278306940025684,
    "mean_precisions": 0.882182,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 33.99336479900012,
    "total_upload_time": 222.02942449700004,
    "p95_time": 0.011889312849552879,
    "rps": 115.63681575552404,
    "parallel": 1,
    "p99_time": 0.015025758700849113,
    "mean_time": 0.008531160203200943,
    "mean_precisions": 0.934486,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 33.99336479900012,
    "total_upload_time": 222.02942449700004,
    "p95_time": 0.07724877804989772,
    "rps": 2015.6901990272022,
    "parallel": 100,
    "p99_time": 0.0943515081102396,
    "mean_time": 0.04602207436040271,
    "mean_precisions": 0.775332,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 33.99336479900012,
    "total_upload_time": 222.02942449700004,
    "p95_time": 0.09001807904946872,
    "rps": 1640.0496352754762,
    "parallel": 100,
    "p99_time": 0.10657020865010967,
    "mean_time": 0.05753609927440311,
    "mean_precisions": 0.848159,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 33.99336479900012,
    "total_upload_time": 222.02942449700004,
    "p95_time": 0.10750191734928194,
    "rps": 1157.507666863126,
    "parallel": 100,
    "p99_time": 0.1265126749401407,
    "mean_time": 0.08367736184229525,
    "mean_precisions": 0.904582,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 33.99336479900012,
    "total_upload_time": 222.02942449700004,
    "p95_time": 0.01748902934982652,
    "rps": 84.97811436231132,
    "parallel": 1,
    "p99_time": 0.025247101699642387,
    "mean_time": 0.011634945086505376,
    "mean_precisions": 0.969842,
    "engine_params": {
      "index_params": {
        "efConstruction": 128,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 212.19189746800112,
    "total_upload_time": 1783.9065994640114,
    "p95_time": 0.03508374769880903,
    "rps": 43.33766235284997,
    "parallel": 1,
    "p99_time": 0.0404776348063024,
    "mean_time": 0.022176152804354206,
    "mean_precisions": 0.9979199999999999,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 212.19189746800112,
    "total_upload_time": 1783.9065994640114,
    "p95_time": 0.04572465558012482,
    "rps": 34.3690386083599,
    "parallel": 1,
    "p99_time": 0.0525079075433314,
    "mean_time": 0.028126089456107003,
    "mean_precisions": 0.9994,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 212.19189746800112,
    "total_upload_time": 1783.9065994640114,
    "p95_time": 0.7260412628354971,
    "rps": 134.33277983642634,
    "parallel": 100,
    "p99_time": 1.0363464294478764,
    "mean_time": 0.6749677295065368,
    "mean_precisions": 0.99926,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 212.19189746800112,
    "total_upload_time": 1783.9065994640114,
    "p95_time": 1.2591227708180668,
    "rps": 80.79447743247542,
    "parallel": 100,
    "p99_time": 1.526127090324309,
    "mean_time": 1.1671500574584002,
    "mean_precisions": 0.99974,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 212.19189746800112,
    "total_upload_time": 1783.9065994640114,
    "p95_time": 2.104764699502266,
    "rps": 48.14587557268658,
    "parallel": 100,
    "p99_time": 2.5667058676294983,
    "mean_time": 2.0038942780951854,
    "mean_precisions": 0.99984,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 212.19189746800112,
    "total_upload_time": 1783.9065994640114,
    "p95_time": 0.036022179876454175,
    "rps": 33.82339672721765,
    "parallel": 1,
    "p99_time": 0.038784970003762284,
    "mean_time": 0.028578869760152885,
    "mean_precisions": 0.99984,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 269.5519010690041,
    "total_upload_time": 4407.703182558995,
    "p95_time": 0.011958275950746609,
    "rps": 106.47673328700208,
    "parallel": 1,
    "p99_time": 0.015544630456715822,
    "mean_time": 0.009267930290999357,
    "mean_precisions": 0.9947450000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 269.5519010690041,
    "total_upload_time": 4407.703182558995,
    "p95_time": 0.015523226786172012,
    "rps": 84.85587839606026,
    "parallel": 1,
    "p99_time": 0.0190177490655333,
    "mean_time": 0.011643581183231435,
    "mean_precisions": 0.998552,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 269.5519010690041,
    "total_upload_time": 4407.703182558995,
    "p95_time": 0.23868132639327083,
    "rps": 538.4874625192699,
    "parallel": 100,
    "p99_time": 0.2773008225206286,
    "mean_time": 0.18234442798229866,
    "mean_precisions": 0.994475,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 269.5519010690041,
    "total_upload_time": 4407.703182558995,
    "p95_time": 0.3383619575179182,
    "rps": 353.4076442808558,
    "parallel": 100,
    "p99_time": 0.41989448509062643,
    "mean_time": 0.2792607893323642,
    "mean_precisions": 0.9985069999999999,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 269.5519010690041,
    "total_upload_time": 4407.703182558995,
    "p95_time": 0.5571133912075311,
    "rps": 217.36144903974218,
    "parallel": 100,
    "p99_time": 0.6714337956008968,
    "mean_time": 0.45578008938523706,
    "mean_precisions": 0.999607,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 269.5519010690041,
    "total_upload_time": 4407.703182558995,
    "p95_time": 0.02266855703783221,
    "rps": 63.97434953552702,
    "parallel": 1,
    "p99_time": 0.031121428037295118,
    "mean_time": 0.015466112217365298,
    "mean_precisions": 0.999627,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.02664345300218,
    "total_upload_time": 832.4888724680022,
    "p95_time": 0.011953335649741346,
    "rps": 104.78967320193244,
    "parallel": 1,
    "p99_time": 0.013821405767812392,
    "mean_time": 0.009419097384983616,
    "mean_precisions": 0.9769800000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.02664345300218,
    "total_upload_time": 832.4888724680022,
    "p95_time": 0.015575297497525748,
    "rps": 82.2512429315525,
    "parallel": 1,
    "p99_time": 0.017854464336887758,
    "mean_time": 0.01204780070992274,
    "mean_precisions": 0.9924200000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.02664345300218,
    "total_upload_time": 832.4888724680022,
    "p95_time": 0.483868644550239,
    "rps": 249.20745835437225,
    "parallel": 100,
    "p99_time": 0.5546777821805517,
    "mean_time": 0.36748726744101806,
    "mean_precisions": 0.97755,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.02664345300218,
    "total_upload_time": 832.4888724680022,
    "p95_time": 0.7692875032971642,
    "rps": 150.31632446315066,
    "parallel": 100,
    "p99_time": 0.7758437791117467,
    "mean_time": 0.6219584645870746,
    "mean_precisions": 0.99258,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.02664345300218,
    "total_upload_time": 832.4888724680022,
    "p95_time": 1.2218479353989096,
    "rps": 92.50645363227835,
    "parallel": 100,
    "p99_time": 1.265303313608929,
    "mean_time": 1.024034412738998,
    "mean_precisions": 0.99746,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.02664345300218,
    "total_upload_time": 832.4888724680022,
    "p95_time": 0.022688084102810535,
    "rps": 56.89470446186484,
    "parallel": 1,
    "p99_time": 0.02516449375165393,
    "mean_time": 0.017443095621936664,
    "mean_precisions": 0.99746,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.842366515999856,
    "total_upload_time": 742.9091456939996,
    "p95_time": 0.008578274049887114,
    "rps": 156.22135321935426,
    "parallel": 1,
    "p99_time": 0.012847405329939651,
    "mean_time": 0.006280608489790393,
    "mean_precisions": 0.8437180000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.842366515999856,
    "total_upload_time": 742.9091456939996,
    "p95_time": 0.010632538650042987,
    "rps": 122.15309307003224,
    "parallel": 1,
    "p99_time": 0.013811162089277788,
    "mean_time": 0.008078677385491938,
    "mean_precisions": 0.9066130000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.842366515999856,
    "total_upload_time": 742.9091456939996,
    "p95_time": 0.15839562989967812,
    "rps": 856.9924993024713,
    "parallel": 100,
    "p99_time": 0.2108519131804133,
    "mean_time": 0.11375444300758154,
    "mean_precisions": 0.843408,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.842366515999856,
    "total_upload_time": 742.9091456939996,
    "p95_time": 0.20518910590008088,
    "rps": 577.4946124574423,
    "parallel": 100,
    "p99_time": 0.2311372014091103,
    "mean_time": 0.17033208782880666,
    "mean_precisions": 0.9071540000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.842366515999856,
    "total_upload_time": 742.9091456939996,
    "p95_time": 0.24656144840082556,
    "rps": 536.5952287042737,
    "parallel": 100,
    "p99_time": 0.26744615025883833,
    "mean_time": 0.18360101266038728,
    "mean_precisions": 0.952408,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.842366515999856,
    "total_upload_time": 742.9091456939996,
    "p95_time": 0.017708931899051088,
    "rps": 85.47158759671062,
    "parallel": 1,
    "p99_time": 0.027643058059602484,
    "mean_time": 0.011573718987201392,
    "mean_precisions": 0.952407,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 225.8738528789836,
    "total_upload_time": 2819.5124523159466,
    "p95_time": 0.03722250974387862,
    "rps": 39.61649029550851,
    "parallel": 1,
    "p99_time": 0.04151531647134109,
    "mean_time": 0.024360068328503987,
    "mean_precisions": 0.9985,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 225.8738528789836,
    "total_upload_time": 2819.5124523159466,
    "p95_time": 0.05410327027493622,
    "rps": 25.02818563704536,
    "parallel": 1,
    "p99_time": 0.061320520389126616,
    "mean_time": 0.03897973559821257,
    "mean_precisions": 0.99956,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 225.8738528789836,
    "total_upload_time": 2819.5124523159466,
    "p95_time": 0.8085369415610331,
    "rps": 125.16995024467096,
    "parallel": 100,
    "p99_time": 1.203903211079305,
    "mean_time": 0.7616710828928742,
    "mean_precisions": 0.9993800000000002,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 225.8738528789836,
    "total_upload_time": 2819.5124523159466,
    "p95_time": 1.4074500956397968,
    "rps": 73.54934239047417,
    "parallel": 100,
    "p99_time": 1.9049084263970144,
    "mean_time": 1.319273378749669,
    "mean_precisions": 0.9996200000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 225.8738528789836,
    "total_upload_time": 2819.5124523159466,
    "p95_time": 2.3820976740127664,
    "rps": 43.13965698837132,
    "parallel": 100,
    "p99_time": 3.358554256554344,
    "mean_time": 2.2699432777081268,
    "mean_precisions": 0.9997799999999999,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 225.8738528789836,
    "total_upload_time": 2819.5124523159466,
    "p95_time": 0.0825594261783408,
    "rps": 17.25109240622256,
    "parallel": 1,
    "p99_time": 0.09290220665163361,
    "mean_time": 0.056967805082153065,
    "mean_precisions": 0.9998,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 254.53017482499126,
    "total_upload_time": 8048.384916940937,
    "p95_time": 0.01323094420949928,
    "rps": 97.53718498285214,
    "parallel": 1,
    "p99_time": 0.016384451002813882,
    "mean_time": 0.010122968998667783,
    "mean_precisions": 0.9959819999999999,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 254.53017482499126,
    "total_upload_time": 8048.384916940937,
    "p95_time": 0.01652293576626107,
    "rps": 79.37387769171285,
    "parallel": 1,
    "p99_time": 0.02080182998091914,
    "mean_time": 0.012451688419666608,
    "mean_precisions": 0.9991040000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 254.53017482499126,
    "total_upload_time": 8048.384916940937,
    "p95_time": 0.27058942201547315,
    "rps": 466.4705384857541,
    "parallel": 100,
    "p99_time": 0.3112210066290572,
    "mean_time": 0.21089050717380597,
    "mean_precisions": 0.9957289999999999,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 254.53017482499126,
    "total_upload_time": 8048.384916940937,
    "p95_time": 0.43409935175441194,
    "rps": 298.5125942076022,
    "parallel": 100,
    "p99_time": 0.47859681367524903,
    "mean_time": 0.3309164611062035,
    "mean_precisions": 0.999037,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 254.53017482499126,
    "total_upload_time": 8048.384916940937,
    "p95_time": 0.6480932687991299,
    "rps": 181.71853204048892,
    "parallel": 100,
    "p99_time": 0.8023144157009688,
    "mean_time": 0.5456103388736141,
    "mean_precisions": 0.9997440000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 254.53017482499126,
    "total_upload_time": 8048.384916940937,
    "p95_time": 0.02984506117063574,
    "rps": 55.69912224482779,
    "parallel": 1,
    "p99_time": 0.03592655458371155,
    "mean_time": 0.017786421072715893,
    "mean_precisions": 0.999758,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 100.18390694499976,
    "total_upload_time": 1825.8781604409996,
    "p95_time": 0.01188274935084337,
    "rps": 105.0969071439513,
    "parallel": 1,
    "p99_time": 0.013407686090795323,
    "mean_time": 0.00938378102297429,
    "mean_precisions": 0.9828500000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 100.18390694499976,
    "total_upload_time": 1825.8781604409996,
    "p95_time": 0.015547169900128211,
    "rps": 80.5400891771081,
    "parallel": 1,
    "p99_time": 0.01776844570897083,
    "mean_time": 0.01228693896583718,
    "mean_precisions": 0.99528,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 100.18390694499976,
    "total_upload_time": 1825.8781604409996,
    "p95_time": 0.48039184200042656,
    "rps": 243.9040523010698,
    "parallel": 100,
    "p99_time": 0.4915113505805857,
    "mean_time": 0.377470913941921,
    "mean_precisions": 0.98316,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 100.18390694499976,
    "total_upload_time": 1825.8781604409996,
    "p95_time": 0.7639285995504906,
    "rps": 152.72992355780414,
    "parallel": 100,
    "p99_time": 0.7765473536286663,
    "mean_time": 0.6130324604259877,
    "mean_precisions": 0.99539,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 100.18390694499976,
    "total_upload_time": 1825.8781604409996,
    "p95_time": 1.3298442689007062,
    "rps": 91.03840429177446,
    "parallel": 100,
    "p99_time": 1.3469974336079757,
    "mean_time": 1.045244576186018,
    "mean_precisions": 0.99873,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 100.18390694499976,
    "total_upload_time": 1825.8781604409996,
    "p95_time": 0.022174150851969894,
    "rps": 56.76019352113345,
    "parallel": 1,
    "p99_time": 0.024631456251372582,
    "mean_time": 0.017484605346988247,
    "mean_precisions": 0.99873,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 33.27338609099934,
    "total_upload_time": 1352.3380144330004,
    "p95_time": 0.007430410500364807,
    "rps": 186.68208224178093,
    "parallel": 1,
    "p99_time": 0.010519147900922697,
    "mean_time": 0.005250885339889283,
    "mean_precisions": 0.849817,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 33.27338609099934,
    "total_upload_time": 1352.3380144330004,
    "p95_time": 0.012113768649942357,
    "rps": 114.53661305904181,
    "parallel": 1,
    "p99_time": 0.014989221649721015,
    "mean_time": 0.00860510897861368,
    "mean_precisions": 0.913483,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 33.27338609099934,
    "total_upload_time": 1352.3380144330004,
    "p95_time": 0.1487097949488998,
    "rps": 849.2318145897202,
    "parallel": 100,
    "p99_time": 0.1780865557598918,
    "mean_time": 0.11494529357269821,
    "mean_precisions": 0.849493,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 33.27338609099934,
    "total_upload_time": 1352.3380144330004,
    "p95_time": 0.21797790270111359,
    "rps": 539.0007329777283,
    "parallel": 100,
    "p99_time": 0.24799694345982068,
    "mean_time": 0.18278351134879867,
    "mean_precisions": 0.9139120000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 33.27338609099934,
    "total_upload_time": 1352.3380144330004,
    "p95_time": 0.36937242939993664,
    "rps": 306.9673004683988,
    "parallel": 100,
    "p99_time": 0.40120882518953294,
    "mean_time": 0.3219694937140119,
    "mean_precisions": 0.958068,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 33.27338609099934,
    "total_upload_time": 1352.3380144330004,
    "p95_time": 0.020855732850213825,
    "rps": 77.56701057492658,
    "parallel": 1,
    "p99_time": 0.033729261250246056,
    "mean_time": 0.012773442607618927,
    "mean_precisions": 0.9580710000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 32
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 213.4419205459999,
    "total_upload_time": 2015.693305675988,
    "p95_time": 0.038392800732981416,
    "rps": 38.74735315872078,
    "parallel": 1,
    "p99_time": 0.04379686872533059,
    "mean_time": 0.024931044344755356,
    "mean_precisions": 0.9985,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 213.4419205459999,
    "total_upload_time": 2015.693305675988,
    "p95_time": 0.034916487694135884,
    "rps": 41.80165997201831,
    "parallel": 1,
    "p99_time": 0.04556277088297066,
    "mean_time": 0.023035359144501853,
    "mean_precisions": 0.99936,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 213.4419205459999,
    "total_upload_time": 2015.693305675988,
    "p95_time": 0.8814881186379353,
    "rps": 116.57649360668285,
    "parallel": 100,
    "p99_time": 1.1743695757468235,
    "mean_time": 0.8221378217227175,
    "mean_precisions": 0.9994200000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 213.4419205459999,
    "total_upload_time": 2015.693305675988,
    "p95_time": 1.4973409175669077,
    "rps": 68.83154158355153,
    "parallel": 100,
    "p99_time": 2.1569170526572274,
    "mean_time": 1.4115881968702422,
    "mean_precisions": 0.9996,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 213.4419205459999,
    "total_upload_time": 2015.693305675988,
    "p95_time": 2.511677393227001,
    "rps": 40.77349600907682,
    "parallel": 100,
    "p99_time": 2.582542409867747,
    "mean_time": 2.4069097627784126,
    "mean_precisions": 0.99982,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 213.4419205459999,
    "total_upload_time": 2015.693305675988,
    "p95_time": 0.04402944531757385,
    "rps": 28.319501927883895,
    "parallel": 1,
    "p99_time": 0.04744122008618435,
    "mean_time": 0.034333355193934406,
    "mean_precisions": 0.99982,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 263.43693214305677,
    "total_upload_time": 4247.68300470314,
    "p95_time": 0.012637663213536144,
    "rps": 102.89921366824188,
    "parallel": 1,
    "p99_time": 0.015442547618877147,
    "mean_time": 0.009591119416058063,
    "mean_precisions": 0.995917,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 263.43693214305677,
    "total_upload_time": 4247.68300470314,
    "p95_time": 0.016150938696227968,
    "rps": 83.43331666479921,
    "parallel": 1,
    "p99_time": 0.01971400716574863,
    "mean_time": 0.011856405646330677,
    "mean_precisions": 0.998869,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 263.43693214305677,
    "total_upload_time": 4247.68300470314,
    "p95_time": 0.269636683317367,
    "rps": 471.1701102260313,
    "parallel": 100,
    "p99_time": 0.3120435256068595,
    "mean_time": 0.2084694609761471,
    "mean_precisions": 0.9957470000000002,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 263.43693214305677,
    "total_upload_time": 4247.68300470314,
    "p95_time": 0.39985015932470536,
    "rps": 303.1669685511518,
    "parallel": 100,
    "p99_time": 0.487771794188302,
    "mean_time": 0.3259346979250433,
    "mean_precisions": 0.998827,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 263.43693214305677,
    "total_upload_time": 4247.68300470314,
    "p95_time": 0.6266207387670875,
    "rps": 185.43689589178217,
    "parallel": 100,
    "p99_time": 0.7546518495515921,
    "mean_time": 0.5345095665523549,
    "mean_precisions": 0.9996789999999999,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 263.43693214305677,
    "total_upload_time": 4247.68300470314,
    "p95_time": 0.0294521914096549,
    "rps": 58.9232599688508,
    "parallel": 1,
    "p99_time": 0.035890216436237105,
    "mean_time": 0.01684026211653836,
    "mean_precisions": 0.9997090000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 85.63918870999987,
    "total_upload_time": 989.5106064499996,
    "p95_time": 0.01238827974812011,
    "rps": 96.3519352916101,
    "parallel": 1,
    "p99_time": 0.013970358829974426,
    "mean_time": 0.01024897459296335,
    "mean_precisions": 0.98039,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 85.63918870999987,
    "total_upload_time": 989.5106064499996,
    "p95_time": 0.01570868064827664,
    "rps": 80.69506361224227,
    "parallel": 1,
    "p99_time": 0.01783025120101229,
    "mean_time": 0.012251555866962008,
    "mean_precisions": 0.9936300000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 85.63918870999987,
    "total_upload_time": 989.5106064499996,
    "p95_time": 0.5348843336501886,
    "rps": 239.8257905074596,
    "parallel": 100,
    "p99_time": 0.5414976235408904,
    "mean_time": 0.38367406812601984,
    "mean_precisions": 0.98087,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 85.63918870999987,
    "total_upload_time": 989.5106064499996,
    "p95_time": 0.8802775180502067,
    "rps": 150.18749837588203,
    "parallel": 100,
    "p99_time": 0.902720963879874,
    "mean_time": 0.6231299272670076,
    "mean_precisions": 0.9938200000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 85.63918870999987,
    "total_upload_time": 989.5106064499996,
    "p95_time": 1.3517514944007416,
    "rps": 92.22844870796456,
    "parallel": 100,
    "p99_time": 1.3646794861404123,
    "mean_time": 1.033570561923083,
    "mean_precisions": 0.9979300000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 85.63918870999987,
    "total_upload_time": 989.5106064499996,
    "p95_time": 0.022862045198598933,
    "rps": 57.150042225776,
    "parallel": 1,
    "p99_time": 0.026241945222027423,
    "mean_time": 0.017368884521973087,
    "mean_precisions": 0.9979300000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 38.14195053200092,
    "total_upload_time": 897.7870773560007,
    "p95_time": 0.011710926948762789,
    "rps": 117.63649227230916,
    "parallel": 1,
    "p99_time": 0.015143455589732185,
    "mean_time": 0.008385420120806703,
    "mean_precisions": 0.926032,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 38.14195053200092,
    "total_upload_time": 897.7870773560007,
    "p95_time": 0.015954278949266154,
    "rps": 91.37673482924697,
    "parallel": 1,
    "p99_time": 0.019789699170105455,
    "mean_time": 0.010823419665197617,
    "mean_precisions": 0.967433,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 38.14195053200092,
    "total_upload_time": 897.7870773560007,
    "p95_time": 0.17023369165044638,
    "rps": 760.6643734312115,
    "parallel": 100,
    "p99_time": 0.21554721190934306,
    "mean_time": 0.12880510866160585,
    "mean_precisions": 0.8584219999999999,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 38.14195053200092,
    "total_upload_time": 897.7870773560007,
    "p95_time": 0.24346796939944396,
    "rps": 480.063129453664,
    "parallel": 100,
    "p99_time": 0.2638844263697684,
    "mean_time": 0.2052159714906089,
    "mean_precisions": 0.9188290000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 38.14195053200092,
    "total_upload_time": 897.7870773560007,
    "p95_time": 0.40115854149962615,
    "rps": 275.0970780016979,
    "parallel": 100,
    "p99_time": 0.4188634145397919,
    "mean_time": 0.3599368658091991,
    "mean_precisions": 0.9601280000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 38.14195053200092,
    "total_upload_time": 897.7870773560007,
    "p95_time": 0.033815070451601016,
    "rps": 55.97535422407312,
    "parallel": 1,
    "p99_time": 0.04023383581859889,
    "mean_time": 0.017736736822690183,
    "mean_precisions": 0.9891049999999999,
    "engine_params": {
      "index_params": {
        "efConstruction": 256,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 181.94533036695793,
    "total_upload_time": 3080.033233964001,
    "p95_time": 0.046580393385374924,
    "rps": 28.870429140590463,
    "parallel": 1,
    "p99_time": 0.05224586854979863,
    "mean_time": 0.03368589113453636,
    "mean_precisions": 0.9990600000000002,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 181.94533036695793,
    "total_upload_time": 3080.033233964001,
    "p95_time": 0.048966990975895915,
    "rps": 33.61058900387245,
    "parallel": 1,
    "p99_time": 0.061639176505268574,
    "mean_time": 0.02881517920787446,
    "mean_precisions": 0.99982,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 181.94533036695793,
    "total_upload_time": 3080.033233964001,
    "p95_time": 1.1228435003577033,
    "rps": 91.1510083369234,
    "parallel": 100,
    "p99_time": 1.6849440273130314,
    "mean_time": 1.055182751451456,
    "mean_precisions": 0.9997399999999997,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 181.94533036695793,
    "total_upload_time": 3080.033233964001,
    "p95_time": 1.9074816893873503,
    "rps": 53.49520767309054,
    "parallel": 100,
    "p99_time": 1.9399091217969544,
    "mean_time": 1.827115242284222,
    "mean_precisions": 0.99992,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 181.94533036695793,
    "total_upload_time": 3080.033233964001,
    "p95_time": 3.227562866840162,
    "rps": 31.77510758303607,
    "parallel": 100,
    "p99_time": 3.851102164224722,
    "mean_time": 3.093414354176121,
    "mean_precisions": 0.9999400000000002,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 181.94533036695793,
    "total_upload_time": 3080.033233964001,
    "p95_time": 0.051072504921467046,
    "rps": 23.50244215524408,
    "parallel": 1,
    "p99_time": 0.05477411155356095,
    "mean_time": 0.04153671111073345,
    "mean_precisions": 0.9999400000000002,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 259.05464479885995,
    "total_upload_time": 8574.305167488055,
    "p95_time": 0.014673934516031294,
    "rps": 90.51050193401346,
    "parallel": 1,
    "p99_time": 0.01843819948844612,
    "mean_time": 0.01091963901228737,
    "mean_precisions": 0.9974930000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 259.05464479885995,
    "total_upload_time": 8574.305167488055,
    "p95_time": 0.02061780932126566,
    "rps": 70.11339608728935,
    "parallel": 1,
    "p99_time": 0.029588060786481952,
    "mean_time": 0.01413330964425113,
    "mean_precisions": 0.999423,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 259.05464479885995,
    "total_upload_time": 8574.305167488055,
    "p95_time": 0.315764607489109,
    "rps": 381.8254130635449,
    "parallel": 100,
    "p99_time": 0.3959117712546141,
    "mean_time": 0.2583643818900222,
    "mean_precisions": 0.9973860000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 259.05464479885995,
    "total_upload_time": 8574.305167488055,
    "p95_time": 0.5136898616794493,
    "rps": 238.24016784842394,
    "parallel": 100,
    "p99_time": 0.6489034180901945,
    "mean_time": 0.41528543825198433,
    "mean_precisions": 0.999402,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 259.05464479885995,
    "total_upload_time": 8574.305167488055,
    "p95_time": 0.8303686390398067,
    "rps": 144.2175925748924,
    "parallel": 100,
    "p99_time": 1.0310982758062892,
    "mean_time": 0.6894007428043755,
    "mean_precisions": 0.9998239999999999,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 259.05464479885995,
    "total_upload_time": 8574.305167488055,
    "p95_time": 0.03893176576821133,
    "rps": 44.16558412268347,
    "parallel": 1,
    "p99_time": 0.04552466108463705,
    "mean_time": 0.022502499479963443,
    "mean_precisions": 0.9998370000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.19080577799832,
    "total_upload_time": 1579.959836471,
    "p95_time": 0.026486532649505533,
    "rps": 53.79708385866931,
    "parallel": 1,
    "p99_time": 0.032461471657952636,
    "mean_time": 0.018464296401038156,
    "mean_precisions": 0.9879600000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.19080577799832,
    "total_upload_time": 1579.959836471,
    "p95_time": 0.03970930824962124,
    "rps": 37.47092814527127,
    "parallel": 1,
    "p99_time": 0.045802128560753774,
    "mean_time": 0.026552290400988568,
    "mean_precisions": 0.9966200000000002,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.19080577799832,
    "total_upload_time": 1579.959836471,
    "p95_time": 1.2429380413490434,
    "rps": 96.39283341548874,
    "parallel": 100,
    "p99_time": 1.3651247665522532,
    "mean_time": 0.9923526608100001,
    "mean_precisions": 0.98833,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.19080577799832,
    "total_upload_time": 1579.959836471,
    "p95_time": 1.7670524733001003,
    "rps": 70.76450701367101,
    "parallel": 100,
    "p99_time": 1.901101919988796,
    "mean_time": 1.3600009725609634,
    "mean_precisions": 0.9966900000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.19080577799832,
    "total_upload_time": 1579.959836471,
    "p95_time": 1.5278229122013727,
    "rps": 75.64111520678601,
    "parallel": 100,
    "p99_time": 1.806952729172699,
    "mean_time": 1.262165114607971,
    "mean_precisions": 0.99897,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 84.19080577799832,
    "total_upload_time": 1579.959836471,
    "p95_time": 0.0582753758490071,
    "rps": 24.658164282803828,
    "parallel": 1,
    "p99_time": 0.06861510400023689,
    "mean_time": 0.040396342833075326,
    "mean_precisions": 0.99899,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 37.73656263399971,
    "total_upload_time": 1603.6864030320012,
    "p95_time": 0.008183389399619044,
    "rps": 160.52968920252337,
    "parallel": 1,
    "p99_time": 0.0117694974184451,
    "mean_time": 0.0061121400336969604,
    "mean_precisions": 0.931012,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 37.73656263399971,
    "total_upload_time": 1603.6864030320012,
    "p95_time": 0.017749045750770145,
    "rps": 86.3111807806699,
    "parallel": 1,
    "p99_time": 0.02547192687970892,
    "mean_time": 0.011463584514306421,
    "mean_precisions": 0.972922,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 37.73656263399971,
    "total_upload_time": 1603.6864030320012,
    "p95_time": 0.29112774804916597,
    "rps": 425.90748132494633,
    "parallel": 100,
    "p99_time": 0.3303961167604757,
    "mean_time": 0.23183805783909667,
    "mean_precisions": 0.9308650000000002,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 37.73656263399971,
    "total_upload_time": 1603.6864030320012,
    "p95_time": 0.4817617239497848,
    "rps": 246.20468137527806,
    "parallel": 100,
    "p99_time": 0.565005122310431,
    "mean_time": 0.4020597437276925,
    "mean_precisions": 0.9730880000000001,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 37.73656263399971,
    "total_upload_time": 1603.6864030320012,
    "p95_time": 0.8752394896007899,
    "rps": 139.9027951051027,
    "parallel": 100,
    "p99_time": 1.0014568364904153,
    "mean_time": 0.7094184602841016,
    "mean_precisions": 0.992608,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "milvus",
    "setup_name": "milvus-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 37.73656263399971,
    "total_upload_time": 1603.6864030320012,
    "p95_time": 0.036574195699176915,
    "rps": 48.03323479045597,
    "parallel": 1,
    "p99_time": 0.04363378071893749,
    "mean_time": 0.020681911872406998,
    "mean_precisions": 0.992608,
    "engine_params": {
      "index_params": {
        "efConstruction": 512,
        "M": 64
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 170.79145554397837,
    "total_upload_time": 787.4732924849959,
    "p95_time": 0.003753595001762733,
    "rps": 263.9178487660236,
    "parallel": 1,
    "p99_time": 0.00394780756061664,
    "mean_time": 0.003191390408150619,
    "mean_precisions": 0.94978,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 170.79145554397837,
    "total_upload_time": 787.4732924849959,
    "p95_time": 0.005548784797429107,
    "rps": 193.04339238484351,
    "parallel": 1,
    "p99_time": 0.005835152337967884,
    "mean_time": 0.004538932709948858,
    "mean_precisions": 0.9608200000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 170.79145554397837,
    "total_upload_time": 787.4732924849959,
    "p95_time": 0.16508748536143686,
    "rps": 612.5382257897662,
    "parallel": 100,
    "p99_time": 0.16644011736789252,
    "mean_time": 0.1550471999337664,
    "mean_precisions": 0.94978,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 170.79145554397837,
    "total_upload_time": 787.4732924849959,
    "p95_time": 0.2762160241865786,
    "rps": 371.2130114498419,
    "parallel": 100,
    "p99_time": 0.28102599976875353,
    "mean_time": 0.2612141632417857,
    "mean_precisions": 0.9608200000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 170.79145554397837,
    "total_upload_time": 787.4732924849959,
    "p95_time": 0.4709699284037924,
    "rps": 218.13515549945532,
    "parallel": 100,
    "p99_time": 0.4773386136197951,
    "mean_time": 0.4497493864105199,
    "mean_precisions": 0.9664,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 170.79145554397837,
    "total_upload_time": 787.4732924849959,
    "p95_time": 0.817961457707861,
    "rps": 126.18328421774443,
    "parallel": 100,
    "p99_time": 0.8278185858947109,
    "mean_time": 0.780613935025828,
    "mean_precisions": 0.9690200000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 170.79145554397837,
    "total_upload_time": 787.4732924849959,
    "p95_time": 0.008764602744486183,
    "rps": 132.3278712821631,
    "parallel": 1,
    "p99_time": 0.00934756153670606,
    "mean_time": 0.00689600105167483,
    "mean_precisions": 0.9664,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 170.79145554397837,
    "total_upload_time": 787.4732924849959,
    "p95_time": 0.014704899540811313,
    "rps": 82.58797428183273,
    "parallel": 1,
    "p99_time": 0.01566631530877203,
    "mean_time": 0.011391201966954395,
    "mean_precisions": 0.9690200000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1749.064867038,
    "total_upload_time": 2501.5592498,
    "p95_time": 0.005095112312119453,
    "rps": 235.26380328062953,
    "parallel": 1,
    "p99_time": 0.006473039493430409,
    "mean_time": 0.0041847370975650845,
    "mean_precisions": 0.912696,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1749.064867038,
    "total_upload_time": 2501.5592498,
    "p95_time": 0.006464095425326376,
    "rps": 183.67345125565112,
    "parallel": 1,
    "p99_time": 0.007846663324162367,
    "mean_time": 0.005374823157885112,
    "mean_precisions": 0.9589170000000002,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1749.064867038,
    "total_upload_time": 2501.5592498,
    "p95_time": 0,
    "rps": 0,
    "parallel": 100,
    "p99_time": 0,
    "mean_time": 0,
    "mean_precisions": 0,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1749.064867038,
    "total_upload_time": 2501.5592498,
    "p95_time": 0,
    "rps": 0,
    "parallel": 100,
    "p99_time": 0,
    "mean_time": 0,
    "mean_precisions": 0,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1749.064867038,
    "total_upload_time": 2501.5592498,
    "p95_time": 0,
    "rps": 0,
    "parallel": 100,
    "p99_time": 0,
    "mean_time": 0,
    "mean_precisions": 0,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1749.064867038,
    "total_upload_time": 2501.5592498,
    "p95_time": 0,
    "rps": 0,
    "parallel": 100,
    "p99_time": 0,
    "mean_time": 0,
    "mean_precisions": 0,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1749.064867038,
    "total_upload_time": 2501.5592498,
    "p95_time": 0.007364304934162645,
    "rps": 162.81403011332512,
    "parallel": 1,
    "p99_time": 0.008551314396318049,
    "mean_time": 0.006071963520324789,
    "mean_precisions": 0.9826520000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1749.064867038,
    "total_upload_time": 2501.5592498,
    "p95_time": 0.009207469597458839,
    "rps": 132.94700423093434,
    "parallel": 1,
    "p99_time": 0.0105999395926483,
    "mean_time": 0.007451963961916044,
    "mean_precisions": 0.992466,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 110.55960359200253,
    "total_upload_time": 531.0140923040017,
    "p95_time": 0.005222286955904564,
    "rps": 233.81947308140857,
    "parallel": 1,
    "p99_time": 0.006302726971698575,
    "mean_time": 0.004196053406936699,
    "mean_precisions": 0.77924,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 110.55960359200253,
    "total_upload_time": 531.0140923040017,
    "p95_time": 0.006762893097038613,
    "rps": 184.02349336512495,
    "parallel": 1,
    "p99_time": 0.008297505295777226,
    "mean_time": 0.005348147579927172,
    "mean_precisions": 0.87229,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 110.55960359200253,
    "total_upload_time": 531.0140923040017,
    "p95_time": 0.009187854801712091,
    "rps": 137.8473313206122,
    "parallel": 1,
    "p99_time": 0.009991885794370318,
    "mean_time": 0.00716508019779576,
    "mean_precisions": 0.92968,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 110.55960359200253,
    "total_upload_time": 531.0140923040017,
    "p95_time": 0.013342021295829908,
    "rps": 97.74503229014154,
    "parallel": 1,
    "p99_time": 0.014216061751139932,
    "mean_time": 0.010131806000012148,
    "mean_precisions": 0.9588300000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 50.55554709600983,
    "total_upload_time": 271.94820965701365,
    "p95_time": 0.003722286543052178,
    "rps": 330.48910633126957,
    "parallel": 1,
    "p99_time": 0.004792188518040349,
    "mean_time": 0.0029682083801075352,
    "mean_precisions": 0.755603,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 50.55554709600983,
    "total_upload_time": 271.94820965701365,
    "p95_time": 0.0044984218897297975,
    "rps": 268.67996038166746,
    "parallel": 1,
    "p99_time": 0.005786714691494127,
    "mean_time": 0.0036613552793918645,
    "mean_precisions": 0.8306680000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 50.55554709600983,
    "total_upload_time": 271.94820965701365,
    "p95_time": 0.00551684900856344,
    "rps": 218.39947473781876,
    "parallel": 1,
    "p99_time": 0.006726889189158101,
    "mean_time": 0.0045147955198946875,
    "mean_precisions": 0.8895790000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 50.55554709600983,
    "total_upload_time": 271.94820965701365,
    "p95_time": 0.007490885064180474,
    "rps": 163.60141846023308,
    "parallel": 1,
    "p99_time": 0.008544066699687393,
    "mean_time": 0.006046875435096444,
    "mean_precisions": 0.9347770000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 178.2390039980237,
    "total_upload_time": 884.2723836730001,
    "p95_time": 0.0047161975206108766,
    "rps": 230.21304973010305,
    "parallel": 1,
    "p99_time": 0.004995673897210509,
    "mean_time": 0.0037297625494364184,
    "mean_precisions": 0.98362,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 178.2390039980237,
    "total_upload_time": 884.2723836730001,
    "p95_time": 0.007111857064592187,
    "rps": 165.3574049045924,
    "parallel": 1,
    "p99_time": 0.00765135616529733,
    "mean_time": 0.005398247175873257,
    "mean_precisions": 0.9926799999999999,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 178.2390039980237,
    "total_upload_time": 884.2723836730001,
    "p95_time": 0.1796941278196755,
    "rps": 569.9143013131649,
    "parallel": 100,
    "p99_time": 0.18255943836789812,
    "mean_time": 0.1674060499308107,
    "mean_precisions": 0.98362,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 178.2390039980237,
    "total_upload_time": 884.2723836730001,
    "p95_time": 0.30042826459539357,
    "rps": 342.98512979302996,
    "parallel": 100,
    "p99_time": 0.30550503102946097,
    "mean_time": 0.2837924346808577,
    "mean_precisions": 0.9926799999999999,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 178.2390039980237,
    "total_upload_time": 884.2723836730001,
    "p95_time": 0.512715710196062,
    "rps": 201.48397955806962,
    "parallel": 100,
    "p99_time": 0.5207591778444476,
    "mean_time": 0.4874842981149035,
    "mean_precisions": 0.9965200000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 178.2390039980237,
    "total_upload_time": 884.2723836730001,
    "p95_time": 0.8843060537197743,
    "rps": 117.37117737951895,
    "parallel": 100,
    "p99_time": 0.8994663568434771,
    "mean_time": 0.8397146557343076,
    "mean_precisions": 0.99824,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 178.2390039980237,
    "total_upload_time": 884.2723836730001,
    "p95_time": 0.01162010554689914,
    "rps": 109.16019160132757,
    "parallel": 1,
    "p99_time": 0.012510481640347283,
    "mean_time": 0.008488545644917758,
    "mean_precisions": 0.9965200000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 178.2390039980237,
    "total_upload_time": 884.2723836730001,
    "p95_time": 0.019164052790438292,
    "rps": 67.7611197643453,
    "parallel": 1,
    "p99_time": 0.020757956984743944,
    "mean_time": 0.014033698238176294,
    "mean_precisions": 0.99824,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 611.9262975760003,
    "total_upload_time": 2321.4704917189997,
    "p95_time": 0.0048391244499725854,
    "rps": 246.19084944753624,
    "parallel": 1,
    "p99_time": 0.005671166800557332,
    "mean_time": 0.003996905441702347,
    "mean_precisions": 0.9382860000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 611.9262975760003,
    "total_upload_time": 2321.4704917189997,
    "p95_time": 0.006353793349990154,
    "rps": 191.08988892886464,
    "parallel": 1,
    "p99_time": 0.007461690379604989,
    "mean_time": 0.005166350420202525,
    "mean_precisions": 0.9756189999999999,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 611.9262975760003,
    "total_upload_time": 2321.4704917189997,
    "p95_time": 0.0076107656502244925,
    "rps": 163.5699945662313,
    "parallel": 1,
    "p99_time": 0.008970925039993746,
    "mean_time": 0.006038711037500616,
    "mean_precisions": 0.991291,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 611.9262975760003,
    "total_upload_time": 2321.4704917189997,
    "p95_time": 0.010041388450281375,
    "rps": 130.38745304262144,
    "parallel": 1,
    "p99_time": 0.01138270294023642,
    "mean_time": 0.007591004857595181,
    "mean_precisions": 0.997101,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 107.90830921399174,
    "total_upload_time": 630.2643945640302,
    "p95_time": 0.004874830148764885,
    "rps": 240.12054593134175,
    "parallel": 1,
    "p99_time": 0.005667010731340268,
    "mean_time": 0.004081673442065949,
    "mean_precisions": 0.77924,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 107.90830921399174,
    "total_upload_time": 630.2643945640302,
    "p95_time": 0.006404520146679714,
    "rps": 183.48296657630985,
    "parallel": 1,
    "p99_time": 0.00788228600169532,
    "mean_time": 0.005355720103958447,
    "mean_precisions": 0.87229,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 107.90830921399174,
    "total_upload_time": 630.2643945640302,
    "p95_time": 0.009037740750864031,
    "rps": 132.67991792527238,
    "parallel": 1,
    "p99_time": 0.010313708889152621,
    "mean_time": 0.007441713914966386,
    "mean_precisions": 0.92968,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 107.90830921399174,
    "total_upload_time": 630.2643945640302,
    "p95_time": 0.013627552947218645,
    "rps": 91.49205370552184,
    "parallel": 1,
    "p99_time": 0.01497797837218968,
    "mean_time": 0.01082919978186692,
    "mean_precisions": 0.9588300000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 64.32560223501059,
    "total_upload_time": 311.23861210700125,
    "p95_time": 0.0035566422578995113,
    "rps": 339.2559846675914,
    "parallel": 1,
    "p99_time": 0.004164591706648935,
    "mean_time": 0.002889824107082677,
    "mean_precisions": 0.755603,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 64.32560223501059,
    "total_upload_time": 311.23861210700125,
    "p95_time": 0.004430337945814243,
    "rps": 269.6760780405784,
    "parallel": 1,
    "p99_time": 0.0054685204298584806,
    "mean_time": 0.0036450360942690166,
    "mean_precisions": 0.8306680000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 64.32560223501059,
    "total_upload_time": 311.23861210700125,
    "p95_time": 0.005407122039468958,
    "rps": 221.1684221030914,
    "parallel": 1,
    "p99_time": 0.006305491994717159,
    "mean_time": 0.004456657296020421,
    "mean_precisions": 0.8895790000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 64.32560223501059,
    "total_upload_time": 311.23861210700125,
    "p95_time": 0.007315549021586774,
    "rps": 167.95953931879254,
    "parallel": 1,
    "p99_time": 0.008446925299358555,
    "mean_time": 0.005886160932347412,
    "mean_precisions": 0.9347770000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 336.81916415999876,
    "total_upload_time": 1712.3196264930011,
    "p95_time": 0.005130014990572818,
    "rps": 209.18795101744738,
    "parallel": 1,
    "p99_time": 0.0054259412392275415,
    "mean_time": 0.004157402288314188,
    "mean_precisions": 0.98846,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 336.81916415999876,
    "total_upload_time": 1712.3196264930011,
    "p95_time": 0.007987399504054337,
    "rps": 144.22440919493297,
    "parallel": 1,
    "p99_time": 0.0084674672872643,
    "mean_time": 0.0062706781182729175,
    "mean_precisions": 0.9952799999999999,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 336.81916415999876,
    "total_upload_time": 1712.3196264930011,
    "p95_time": 0.2119449452875415,
    "rps": 482.9337707167375,
    "parallel": 100,
    "p99_time": 0.21585874649113976,
    "mean_time": 0.19980698488602647,
    "mean_precisions": 0.98846,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 336.81916415999876,
    "total_upload_time": 1712.3196264930011,
    "p95_time": 0.35892835094127806,
    "rps": 286.2738494379441,
    "parallel": 100,
    "p99_time": 0.36349587760341817,
    "mean_time": 0.3415132500600244,
    "mean_precisions": 0.9952799999999999,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 336.81916415999876,
    "total_upload_time": 1712.3196264930011,
    "p95_time": 0.6171365019064978,
    "rps": 167.01855608620878,
    "parallel": 100,
    "p99_time": 0.6254179462124011,
    "mean_time": 0.588843408653338,
    "mean_precisions": 0.9978800000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 336.81916415999876,
    "total_upload_time": 1712.3196264930011,
    "p95_time": 1.0589758918416918,
    "rps": 97.43330242664854,
    "parallel": 100,
    "p99_time": 1.0751843567661126,
    "mean_time": 1.0124064784424671,
    "mean_precisions": 0.99876,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 336.81916415999876,
    "total_upload_time": 1712.3196264930011,
    "p95_time": 0.013166172048659063,
    "rps": 93.28034190810031,
    "parallel": 1,
    "p99_time": 0.013946948080265432,
    "mean_time": 0.01002965659147012,
    "mean_precisions": 0.9978800000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 336.81916415999876,
    "total_upload_time": 1712.3196264930011,
    "p95_time": 0.021842940741044006,
    "rps": 57.81908235757009,
    "parallel": 1,
    "p99_time": 0.023348154644190804,
    "mean_time": 0.016539902316633378,
    "mean_precisions": 0.99876,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 565.2247771119,
    "total_upload_time": 3836.6452654149616,
    "p95_time": 0.0052380254957824935,
    "rps": 228.2727714572749,
    "parallel": 1,
    "p99_time": 0.0064526953839231325,
    "mean_time": 0.0043149613655172284,
    "mean_precisions": 0.9512980000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 565.2247771119,
    "total_upload_time": 3836.6452654149616,
    "p95_time": 0.006944288907106966,
    "rps": 176.00309156217443,
    "parallel": 1,
    "p99_time": 0.007929234087932856,
    "mean_time": 0.005612496895494405,
    "mean_precisions": 0.983032,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 565.2247771119,
    "total_upload_time": 3836.6452654149616,
    "p95_time": 0.14017966903047635,
    "rps": 716.3567658582014,
    "parallel": 100,
    "p99_time": 0.262502774222578,
    "mean_time": 0.13535321514693788,
    "mean_precisions": 0.9512980000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 565.2247771119,
    "total_upload_time": 3836.6452654149616,
    "p95_time": 0.22627154601505026,
    "rps": 478.386085191182,
    "parallel": 100,
    "p99_time": 0.2420534832251724,
    "mean_time": 0.2063914375422406,
    "mean_precisions": 0.983032,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 565.2247771119,
    "total_upload_time": 3836.6452654149616,
    "p95_time": 0.276521856081672,
    "rps": 379.48851682151115,
    "parallel": 100,
    "p99_time": 0.28978243910358287,
    "mean_time": 0.2605848106650985,
    "mean_precisions": 0.994707,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 565.2247771119,
    "total_upload_time": 3836.6452654149616,
    "p95_time": 0.379529765114421,
    "rps": 276.66888466907824,
    "parallel": 100,
    "p99_time": 0.3935713658318855,
    "mean_time": 0.3580087543906411,
    "mean_precisions": 0.9982639999999999,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 565.2247771119,
    "total_upload_time": 3836.6452654149616,
    "p95_time": 0.008426631940528749,
    "rps": 149.01267043485112,
    "parallel": 1,
    "p99_time": 0.00951043301727623,
    "mean_time": 0.006641166872065514,
    "mean_precisions": 0.994707,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 565.2247771119,
    "total_upload_time": 3836.6452654149616,
    "p95_time": 0.01133645263616927,
    "rps": 116.70355477264117,
    "parallel": 1,
    "p99_time": 0.012593600210966543,
    "mean_time": 0.008492673383268994,
    "mean_precisions": 0.9982639999999999,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 106.55064394196961,
    "total_upload_time": 979.1283855779911,
    "p95_time": 0.005016487351531396,
    "rps": 237.25008072047552,
    "parallel": 1,
    "p99_time": 0.005775450543005717,
    "mean_time": 0.004133293334954942,
    "mean_precisions": 0.77924,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 106.55064394196961,
    "total_upload_time": 979.1283855779911,
    "p95_time": 0.006417532100385869,
    "rps": 181.9473610703572,
    "parallel": 1,
    "p99_time": 0.006966091087742825,
    "mean_time": 0.00540950941596384,
    "mean_precisions": 0.87229,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 106.55064394196961,
    "total_upload_time": 979.1283855779911,
    "p95_time": 0.009242277005614596,
    "rps": 131.06729684026607,
    "parallel": 1,
    "p99_time": 0.010137068212425219,
    "mean_time": 0.00754075694680796,
    "mean_precisions": 0.92968,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 106.55064394196961,
    "total_upload_time": 979.1283855779911,
    "p95_time": 0.013503034702443984,
    "rps": 91.51183479028333,
    "parallel": 1,
    "p99_time": 0.014083297610923182,
    "mean_time": 0.010828931419069704,
    "mean_precisions": 0.9588300000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 32.84080829099912,
    "total_upload_time": 419.253565676001,
    "p95_time": 0.0034829042371711688,
    "rps": 344.0759104744191,
    "parallel": 1,
    "p99_time": 0.004194049557263499,
    "mean_time": 0.0028472546654840698,
    "mean_precisions": 0.755603,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 32.84080829099912,
    "total_upload_time": 419.253565676001,
    "p95_time": 0.0042709672517958095,
    "rps": 277.5706760124808,
    "parallel": 1,
    "p99_time": 0.005037371485086629,
    "mean_time": 0.0035406672969722423,
    "mean_precisions": 0.8306680000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 32.84080829099912,
    "total_upload_time": 419.253565676001,
    "p95_time": 0.005289006208477076,
    "rps": 225.39915840989732,
    "parallel": 1,
    "p99_time": 0.006083509372547272,
    "mean_time": 0.0043724317223910476,
    "mean_precisions": 0.8895790000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 32.84080829099912,
    "total_upload_time": 419.253565676001,
    "p95_time": 0.007200799482234287,
    "rps": 169.36061497306963,
    "parallel": 1,
    "p99_time": 0.008281398268009072,
    "mean_time": 0.005836673626222182,
    "mean_precisions": 0.9347770000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 159.88063041499117,
    "total_upload_time": 2631.392147230974,
    "p95_time": 0.005375580352847464,
    "rps": 194.92383310040677,
    "parallel": 1,
    "p99_time": 0.005659113910514862,
    "mean_time": 0.004500088445097208,
    "mean_precisions": 0.9912799999999999,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 159.88063041499117,
    "total_upload_time": 2631.392147230974,
    "p95_time": 0.00852186293050181,
    "rps": 131.68213161556557,
    "parallel": 1,
    "p99_time": 0.00897120832290966,
    "mean_time": 0.006933868916658685,
    "mean_precisions": 0.9966200000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 159.88063041499117,
    "total_upload_time": 2631.392147230974,
    "p95_time": 0.23780069585191085,
    "rps": 428.46485205391645,
    "parallel": 100,
    "p99_time": 0.2402955084334826,
    "mean_time": 0.2252066746023367,
    "mean_precisions": 0.9912799999999999,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 159.88063041499117,
    "total_upload_time": 2631.392147230974,
    "p95_time": 0.41278432151302696,
    "rps": 249.08922144070942,
    "parallel": 100,
    "p99_time": 0.4188118422141997,
    "mean_time": 0.39291723482650703,
    "mean_precisions": 0.9966200000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 159.88063041499117,
    "total_upload_time": 2631.392147230974,
    "p95_time": 0.7084042388800299,
    "rps": 144.6495766032998,
    "parallel": 100,
    "p99_time": 0.7170497284352314,
    "mean_time": 0.6804555252311868,
    "mean_precisions": 0.9988,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 159.88063041499117,
    "total_upload_time": 2631.392147230974,
    "p95_time": 1.2235780444927513,
    "rps": 84.09595292864552,
    "parallel": 100,
    "p99_time": 1.2415090582729318,
    "mean_time": 1.173367665463814,
    "mean_precisions": 0.9995,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 159.88063041499117,
    "total_upload_time": 2631.392147230974,
    "p95_time": 0.014354341197758913,
    "rps": 82.35625217859861,
    "parallel": 1,
    "p99_time": 0.01516696646809578,
    "mean_time": 0.011431896126607898,
    "mean_precisions": 0.9988,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 159.88063041499117,
    "total_upload_time": 2631.392147230974,
    "p95_time": 0.024204320996068417,
    "rps": 50.568962626348956,
    "parallel": 1,
    "p99_time": 0.025934246683027594,
    "mean_time": 0.01896872672345489,
    "mean_precisions": 0.9995,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.8765118400333,
    "total_upload_time": 6868.83220406808,
    "p95_time": 0.005225329333916306,
    "rps": 230.9081663037645,
    "parallel": 1,
    "p99_time": 0.006247391572687775,
    "mean_time": 0.004266609806707129,
    "mean_precisions": 0.960089,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.8765118400333,
    "total_upload_time": 6868.83220406808,
    "p95_time": 0.0071389571879990395,
    "rps": 172.4425301129493,
    "parallel": 1,
    "p99_time": 0.00820557900471613,
    "mean_time": 0.005728344186907634,
    "mean_precisions": 0.988123,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.8765118400333,
    "total_upload_time": 6868.83220406808,
    "p95_time": 0.14415782678988756,
    "rps": 695.6595978972545,
    "parallel": 100,
    "p99_time": 0.2703855965042158,
    "mean_time": 0.1397918814124656,
    "mean_precisions": 0.960089,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.8765118400333,
    "total_upload_time": 6868.83220406808,
    "p95_time": 0.22157707042060792,
    "rps": 481.60831542805136,
    "parallel": 100,
    "p99_time": 0.2373325641488191,
    "mean_time": 0.205015870734246,
    "mean_precisions": 0.988123,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.8765118400333,
    "total_upload_time": 6868.83220406808,
    "p95_time": 0.2769390617497265,
    "rps": 382.0461347773635,
    "parallel": 100,
    "p99_time": 0.294829653755296,
    "mean_time": 0.2588576819723938,
    "mean_precisions": 0.997049,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.8765118400333,
    "total_upload_time": 6868.83220406808,
    "p95_time": 0.37009529856150036,
    "rps": 286.15599504577693,
    "parallel": 100,
    "p99_time": 0.3823559874959756,
    "mean_time": 0.34618375271882396,
    "mean_precisions": 0.9993349999999999,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.8765118400333,
    "total_upload_time": 6868.83220406808,
    "p95_time": 0.008585460431640967,
    "rps": 146.92694873216482,
    "parallel": 1,
    "p99_time": 0.009647181774489581,
    "mean_time": 0.006735102048411499,
    "mean_precisions": 0.997049,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.8765118400333,
    "total_upload_time": 6868.83220406808,
    "p95_time": 0.011551541625522074,
    "rps": 114.11539113042542,
    "parallel": 1,
    "p99_time": 0.012758012358099223,
    "mean_time": 0.008686835707561113,
    "mean_precisions": 0.9993349999999999,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 106.61461189005058,
    "total_upload_time": 1668.7367734460277,
    "p95_time": 0.0048449775447807035,
    "rps": 236.0088403773891,
    "parallel": 1,
    "p99_time": 0.00568782228314376,
    "mean_time": 0.004158483817896922,
    "mean_precisions": 0.77924,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 106.61461189005058,
    "total_upload_time": 1668.7367734460277,
    "p95_time": 0.006583522599612479,
    "rps": 180.437117108073,
    "parallel": 1,
    "p99_time": 0.007448279164600535,
    "mean_time": 0.005456783129069663,
    "mean_precisions": 0.87229,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 106.61461189005058,
    "total_upload_time": 1668.7367734460277,
    "p95_time": 0.00912349084901507,
    "rps": 131.9996299807025,
    "parallel": 1,
    "p99_time": 0.009790048551003565,
    "mean_time": 0.007483785310207168,
    "mean_precisions": 0.92968,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 106.61461189005058,
    "total_upload_time": 1668.7367734460277,
    "p95_time": 0.013669977745666983,
    "rps": 91.37771893222468,
    "parallel": 1,
    "p99_time": 0.014566839562830863,
    "mean_time": 0.010842111114012369,
    "mean_precisions": 0.9588300000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 32.83693141399999,
    "total_upload_time": 829.5889840630007,
    "p95_time": 0.0035979224921902637,
    "rps": 338.74609612755154,
    "parallel": 1,
    "p99_time": 0.00436186529666884,
    "mean_time": 0.002892857326354715,
    "mean_precisions": 0.755603,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 32.83693141399999,
    "total_upload_time": 829.5889840630007,
    "p95_time": 0.00434298005857272,
    "rps": 274.60321460746843,
    "parallel": 1,
    "p99_time": 0.005185962331597696,
    "mean_time": 0.0035770189467759336,
    "mean_precisions": 0.8306680000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 32.83693141399999,
    "total_upload_time": 829.5889840630007,
    "p95_time": 0.0054885902791284025,
    "rps": 221.51775904052366,
    "parallel": 1,
    "p99_time": 0.0066570586850866675,
    "mean_time": 0.0044505249217676466,
    "mean_precisions": 0.8895790000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 32.83693141399999,
    "total_upload_time": 829.5889840630007,
    "p95_time": 0.007365611739805899,
    "rps": 167.9500658054599,
    "parallel": 1,
    "p99_time": 0.008567355705890805,
    "mean_time": 0.0058877154970308765,
    "mean_precisions": 0.9347770000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 162.1254526989651,
    "total_upload_time": 1819.841061529005,
    "p95_time": 0.006095247689518146,
    "rps": 186.05928927276983,
    "parallel": 1,
    "p99_time": 0.006587603756343017,
    "mean_time": 0.004741563095885795,
    "mean_precisions": 0.99082,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 162.1254526989651,
    "total_upload_time": 1819.841061529005,
    "p95_time": 0.009740858562872745,
    "rps": 125.63056197692386,
    "parallel": 1,
    "p99_time": 0.010536638813209721,
    "mean_time": 0.007288231400039513,
    "mean_precisions": 0.99624,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 162.1254526989651,
    "total_upload_time": 1819.841061529005,
    "p95_time": 0.2573479713028064,
    "rps": 399.1859529240765,
    "parallel": 100,
    "p99_time": 0.2614492987591075,
    "mean_time": 0.2432782397023635,
    "mean_precisions": 0.99082,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 162.1254526989651,
    "total_upload_time": 1819.841061529005,
    "p95_time": 0.43477864942688027,
    "rps": 237.88035332961172,
    "parallel": 100,
    "p99_time": 0.44070080610224976,
    "mean_time": 0.4118107320001815,
    "mean_precisions": 0.99624,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 162.1254526989651,
    "total_upload_time": 1819.841061529005,
    "p95_time": 0.7397271865513175,
    "rps": 139.89706537932332,
    "parallel": 100,
    "p99_time": 0.7491781046165852,
    "mean_time": 0.7038585753312684,
    "mean_precisions": 0.9982800000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 162.1254526989651,
    "total_upload_time": 1819.841061529005,
    "p95_time": 1.2585212296049577,
    "rps": 82.26599574936677,
    "parallel": 100,
    "p99_time": 1.2744099288305732,
    "mean_time": 1.199820989187155,
    "mean_precisions": 0.9990400000000002,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 162.1254526989651,
    "total_upload_time": 1819.841061529005,
    "p95_time": 0.015918264666106553,
    "rps": 79.54669148963599,
    "parallel": 1,
    "p99_time": 0.017177003481192523,
    "mean_time": 0.011839985420368612,
    "mean_precisions": 0.9982800000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 162.1254526989651,
    "total_upload_time": 1819.841061529005,
    "p95_time": 0.02588133746467065,
    "rps": 49.70272866131123,
    "parallel": 1,
    "p99_time": 0.02803436575399246,
    "mean_time": 0.01930058597534662,
    "mean_precisions": 0.9990400000000002,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 574.7115747239441,
    "total_upload_time": 4177.995847588987,
    "p95_time": 0.005396199348615482,
    "rps": 224.48693400198252,
    "parallel": 1,
    "p99_time": 0.006606117152841766,
    "mean_time": 0.004387352883559651,
    "mean_precisions": 0.9614130000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 574.7115747239441,
    "total_upload_time": 4177.995847588987,
    "p95_time": 0.007247697369894013,
    "rps": 169.98775760411948,
    "parallel": 1,
    "p99_time": 0.008404146442189814,
    "mean_time": 0.005811233231518418,
    "mean_precisions": 0.9869450000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 574.7115747239441,
    "total_upload_time": 4177.995847588987,
    "p95_time": 0.14766349934507159,
    "rps": 679.0369747686246,
    "parallel": 100,
    "p99_time": 0.2809466661920895,
    "mean_time": 0.14312682529899756,
    "mean_precisions": 0.9614130000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 574.7115747239441,
    "total_upload_time": 4177.995847588987,
    "p95_time": 0.2363931139349006,
    "rps": 454.8895412663129,
    "parallel": 100,
    "p99_time": 0.24930941385915506,
    "mean_time": 0.21700522064914693,
    "mean_precisions": 0.9869450000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 574.7115747239441,
    "total_upload_time": 4177.995847588987,
    "p95_time": 0.2967013081477489,
    "rps": 355.25727385627755,
    "parallel": 100,
    "p99_time": 0.30946324614807963,
    "mean_time": 0.27840337634069146,
    "mean_precisions": 0.995992,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 574.7115747239441,
    "total_upload_time": 4177.995847588987,
    "p95_time": 0.4160227152693551,
    "rps": 254.62879514287357,
    "parallel": 100,
    "p99_time": 0.4352501993335319,
    "mean_time": 0.38919005385865457,
    "mean_precisions": 0.998699,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 574.7115747239441,
    "total_upload_time": 4177.995847588987,
    "p95_time": 0.009063458448508753,
    "rps": 141.69577974926216,
    "parallel": 1,
    "p99_time": 0.010437513211509215,
    "mean_time": 0.006982239664380904,
    "mean_precisions": 0.995992,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 574.7115747239441,
    "total_upload_time": 4177.995847588987,
    "p95_time": 0.012646786053664982,
    "rps": 107.50196970637538,
    "parallel": 1,
    "p99_time": 0.014000293036224323,
    "mean_time": 0.009215069890127051,
    "mean_precisions": 0.998699,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 109.55810492101591,
    "total_upload_time": 1040.166135238018,
    "p95_time": 0.004941357751886244,
    "rps": 236.8291162019236,
    "parallel": 1,
    "p99_time": 0.006017788161479984,
    "mean_time": 0.0041424998759466685,
    "mean_precisions": 0.77924,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 109.55810492101591,
    "total_upload_time": 1040.166135238018,
    "p95_time": 0.006853721449078874,
    "rps": 175.2812693437805,
    "parallel": 1,
    "p99_time": 0.007880572056019445,
    "mean_time": 0.005619037556993135,
    "mean_precisions": 0.87229,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 109.55810492101591,
    "total_upload_time": 1040.166135238018,
    "p95_time": 0.009288214096523006,
    "rps": 129.0794222364776,
    "parallel": 1,
    "p99_time": 0.010524519387545297,
    "mean_time": 0.007653663155062531,
    "mean_precisions": 0.92968,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 109.55810492101591,
    "total_upload_time": 1040.166135238018,
    "p95_time": 0.013761356196846463,
    "rps": 90.73743080195008,
    "parallel": 1,
    "p99_time": 0.015348364361416315,
    "mean_time": 0.010922576491037034,
    "mean_precisions": 0.9588300000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.406029968999064,
    "total_upload_time": 432.5092441259985,
    "p95_time": 0.0035393722951994272,
    "rps": 340.7723656203129,
    "parallel": 1,
    "p99_time": 0.004082796689472162,
    "mean_time": 0.002875790364659042,
    "mean_precisions": 0.755603,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.406029968999064,
    "total_upload_time": 432.5092441259985,
    "p95_time": 0.0043040489370469006,
    "rps": 277.36174329115903,
    "parallel": 1,
    "p99_time": 0.005237202714488377,
    "mean_time": 0.003538966392024304,
    "mean_precisions": 0.8306680000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.406029968999064,
    "total_upload_time": 432.5092441259985,
    "p95_time": 0.005330350287840699,
    "rps": 224.83621319387464,
    "parallel": 1,
    "p99_time": 0.006674372267734728,
    "mean_time": 0.004383300857146969,
    "mean_precisions": 0.8895790000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.406029968999064,
    "total_upload_time": 432.5092441259985,
    "p95_time": 0.007320070134301203,
    "rps": 168.17002649483948,
    "parallel": 1,
    "p99_time": 0.008662070856662468,
    "mean_time": 0.005880366990700713,
    "mean_precisions": 0.9347770000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 167.71123526402516,
    "total_upload_time": 2972.241888266988,
    "p95_time": 0.006954891083296388,
    "rps": 162.91790081507165,
    "parallel": 1,
    "p99_time": 0.007366689677583054,
    "mean_time": 0.0055006650031544264,
    "mean_precisions": 0.9933200000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 167.71123526402516,
    "total_upload_time": 2972.241888266988,
    "p95_time": 0.011586319122579881,
    "rps": 104.51290980223747,
    "parallel": 1,
    "p99_time": 0.012362217159825379,
    "mean_time": 0.008863212639384437,
    "mean_precisions": 0.9977600000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 167.71123526402516,
    "total_upload_time": 2972.241888266988,
    "p95_time": 0.30496158443856985,
    "rps": 337.5075195247038,
    "parallel": 100,
    "p99_time": 0.3087530011322815,
    "mean_time": 0.2891135820414289,
    "mean_precisions": 0.9933200000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 167.71123526402516,
    "total_upload_time": 2972.241888266988,
    "p95_time": 0.5203146451385692,
    "rps": 197.6376086506115,
    "parallel": 100,
    "p99_time": 0.5331432236946421,
    "mean_time": 0.4970064436558401,
    "mean_precisions": 0.9977600000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 167.71123526402516,
    "total_upload_time": 2972.241888266988,
    "p95_time": 0.8936030203767586,
    "rps": 115.49711542719787,
    "parallel": 100,
    "p99_time": 0.9033825106458971,
    "mean_time": 0.8535612061309512,
    "mean_precisions": 0.9990800000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 167.71123526402516,
    "total_upload_time": 2972.241888266988,
    "p95_time": 1.5235832352540455,
    "rps": 67.83619738105737,
    "parallel": 100,
    "p99_time": 1.5393403382442195,
    "mean_time": 1.4558054275739123,
    "mean_precisions": 0.9995,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 167.71123526402516,
    "total_upload_time": 2972.241888266988,
    "p95_time": 0.01898339183535427,
    "rps": 65.42828098790812,
    "parallel": 1,
    "p99_time": 0.020513463688548655,
    "mean_time": 0.014513985235861037,
    "mean_precisions": 0.9990800000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 167.71123526402516,
    "total_upload_time": 2972.241888266988,
    "p95_time": 0.031214848093804905,
    "rps": 40.62620165621441,
    "parallel": 1,
    "p99_time": 0.03341348478628788,
    "mean_time": 0.023754658815660513,
    "mean_precisions": 0.9995,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.6571407259908,
    "total_upload_time": 7455.924749655998,
    "p95_time": 0.005326789867831394,
    "rps": 226.36598049353756,
    "parallel": 1,
    "p99_time": 0.00656115851481446,
    "mean_time": 0.0043516048922552725,
    "mean_precisions": 0.9715380000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.6571407259908,
    "total_upload_time": 7455.924749655998,
    "p95_time": 0.007260273641441016,
    "rps": 170.9518662804313,
    "parallel": 1,
    "p99_time": 0.008579596963245423,
    "mean_time": 0.005777093329653144,
    "mean_precisions": 0.991898,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.6571407259908,
    "total_upload_time": 7455.924749655998,
    "p95_time": 0.15261546254041602,
    "rps": 649.8096357661898,
    "parallel": 100,
    "p99_time": 0.2855816435907628,
    "mean_time": 0.14987177200838925,
    "mean_precisions": 0.9715380000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.6571407259908,
    "total_upload_time": 7455.924749655998,
    "p95_time": 0.2404131524963304,
    "rps": 434.78678217658586,
    "parallel": 100,
    "p99_time": 0.25816154037369415,
    "mean_time": 0.22723139223098987,
    "mean_precisions": 0.991898,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.6571407259908,
    "total_upload_time": 7455.924749655998,
    "p95_time": 0.3190524772624485,
    "rps": 331.39688276806095,
    "parallel": 100,
    "p99_time": 0.33552716936334037,
    "mean_time": 0.29860102251522475,
    "mean_precisions": 0.9979469999999999,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.6571407259908,
    "total_upload_time": 7455.924749655998,
    "p95_time": 0.45202750656171703,
    "rps": 234.84531647691773,
    "parallel": 100,
    "p99_time": 0.4704970739479177,
    "mean_time": 0.4221152276265551,
    "mean_precisions": 0.999531,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.6571407259908,
    "total_upload_time": 7455.924749655998,
    "p95_time": 0.009224903065478426,
    "rps": 141.2264886055763,
    "parallel": 1,
    "p99_time": 0.010717873267130926,
    "mean_time": 0.007008552533318288,
    "mean_precisions": 0.9979469999999999,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 588.6571407259908,
    "total_upload_time": 7455.924749655998,
    "p95_time": 0.013167370751034458,
    "rps": 104.69577787474692,
    "parallel": 1,
    "p99_time": 0.01472056202706881,
    "mean_time": 0.009458679927897173,
    "mean_precisions": 0.999531,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 115.17745286098216,
    "total_upload_time": 1789.7089886539616,
    "p95_time": 0.005019533003724063,
    "rps": 235.73107709167618,
    "parallel": 1,
    "p99_time": 0.005679682069821865,
    "mean_time": 0.004162965709117998,
    "mean_precisions": 0.77924,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 115.17745286098216,
    "total_upload_time": 1789.7089886539616,
    "p95_time": 0.006520982249639928,
    "rps": 179.81019691956328,
    "parallel": 1,
    "p99_time": 0.0075943592855037415,
    "mean_time": 0.00547649341973738,
    "mean_precisions": 0.87229,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 115.17745286098216,
    "total_upload_time": 1789.7089886539616,
    "p95_time": 0.009259890503744827,
    "rps": 130.868153352027,
    "parallel": 1,
    "p99_time": 0.010261482859277749,
    "mean_time": 0.007549966155071161,
    "mean_precisions": 0.92968,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 115.17745286098216,
    "total_upload_time": 1789.7089886539616,
    "p95_time": 0.013609099895620601,
    "rps": 91.24688236332594,
    "parallel": 1,
    "p99_time": 0.014564739721827208,
    "mean_time": 0.01085820238609449,
    "mean_precisions": 0.9588300000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 29.297624336999434,
    "total_upload_time": 866.2354264290007,
    "p95_time": 0.0034802868045517243,
    "rps": 344.2533647570864,
    "parallel": 1,
    "p99_time": 0.004222080004692545,
    "mean_time": 0.0028441999555710936,
    "mean_precisions": 0.755603,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 29.297624336999434,
    "total_upload_time": 866.2354264290007,
    "p95_time": 0.004447042306128423,
    "rps": 272.9397544253975,
    "parallel": 1,
    "p99_time": 0.005223351368622395,
    "mean_time": 0.003600467896129703,
    "mean_precisions": 0.8306680000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 29.297624336999434,
    "total_upload_time": 866.2354264290007,
    "p95_time": 0.005471287635737098,
    "rps": 223.3404888689413,
    "parallel": 1,
    "p99_time": 0.006408017941867003,
    "mean_time": 0.004411435728843207,
    "mean_precisions": 0.8895790000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 29.297624336999434,
    "total_upload_time": 866.2354264290007,
    "p95_time": 0.007562183648406062,
    "rps": 166.37475981294966,
    "parallel": 1,
    "p99_time": 0.008710003982123456,
    "mean_time": 0.005943461981794098,
    "mean_precisions": 0.9347770000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.0017044486303348094,
    "rps": 489.95933565356233,
    "parallel": 1,
    "p99_time": 0.0018631831044331195,
    "mean_time": 0.0015170191435609013,
    "mean_precisions": 0.8193,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.0017142802884336562,
    "rps": 493.177004350638,
    "parallel": 1,
    "p99_time": 0.0019347642094362538,
    "mean_time": 0.0015120042925467715,
    "mean_precisions": 0.9034400000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.002778795995982364,
    "rps": 345.9163842452213,
    "parallel": 1,
    "p99_time": 0.0029720230633392933,
    "mean_time": 0.0023519449250074104,
    "mean_precisions": 0.9682799999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.002833074436057359,
    "rps": 336.33543637601286,
    "parallel": 1,
    "p99_time": 0.0030395711900200713,
    "mean_time": 0.0024259883279679345,
    "mean_precisions": 0.9832200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.004069770738715306,
    "rps": 251.30766749820341,
    "parallel": 1,
    "p99_time": 0.004356864580186086,
    "mean_time": 0.0033733323458349333,
    "mean_precisions": 0.8404200000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.004104277800070122,
    "rps": 250.52629557129356,
    "parallel": 1,
    "p99_time": 0.004463614213746042,
    "mean_time": 0.0033843422304140405,
    "mean_precisions": 0.9312600000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.004092581133591011,
    "rps": 251.13931174512547,
    "parallel": 1,
    "p99_time": 0.00451648571761325,
    "mean_time": 0.0033742431106511504,
    "mean_precisions": 0.973,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.0041363473923411226,
    "rps": 247.79984768533888,
    "parallel": 1,
    "p99_time": 0.004530091530177744,
    "mean_time": 0.0034245176908094437,
    "mean_precisions": 0.9884,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.00201110823545605,
    "rps": 1214.0409095279429,
    "parallel": 100,
    "p99_time": 0.01366264395299374,
    "mean_time": 0.002046145990374498,
    "mean_precisions": 0.8193,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.00199805170414038,
    "rps": 1221.5007712825197,
    "parallel": 100,
    "p99_time": 0.012175936592975637,
    "mean_time": 0.0018177298220107333,
    "mean_precisions": 0.9034400000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.002017689181957394,
    "rps": 1228.5017582396983,
    "parallel": 100,
    "p99_time": 0.013868511157343189,
    "mean_time": 0.0018740794400451705,
    "mean_precisions": 0.93874,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.002191494940780103,
    "rps": 1222.5547734454715,
    "parallel": 100,
    "p99_time": 0.013085738833760865,
    "mean_time": 0.0019936231608735397,
    "mean_precisions": 0.9594800000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.0017350183159578591,
    "rps": 488.62319934777304,
    "parallel": 1,
    "p99_time": 0.0019364624039735667,
    "mean_time": 0.0015264635547529905,
    "mean_precisions": 0.93874,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.0023849327932111922,
    "rps": 1215.4169165697012,
    "parallel": 100,
    "p99_time": 0.012531123664230108,
    "mean_time": 0.002145726456330158,
    "mean_precisions": 0.83236,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.002414167916867882,
    "rps": 1221.5608396373668,
    "parallel": 100,
    "p99_time": 0.01243549529230224,
    "mean_time": 0.002142950082407333,
    "mean_precisions": 0.92,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.0025478267227299527,
    "rps": 1208.8244863377759,
    "parallel": 100,
    "p99_time": 0.01361409046221525,
    "mean_time": 0.0022525985533604397,
    "mean_precisions": 0.9588,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.002564129972597584,
    "rps": 1196.9836462445664,
    "parallel": 100,
    "p99_time": 0.013451962878461952,
    "mean_time": 0.0022883646889822556,
    "mean_precisions": 0.97246,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.004061184416059405,
    "rps": 1211.247658870995,
    "parallel": 100,
    "p99_time": 0.015619826667243653,
    "mean_time": 0.0031735014637000857,
    "mean_precisions": 0.83852,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.004205219971481711,
    "rps": 1223.3119892118148,
    "parallel": 100,
    "p99_time": 0.01578738733194778,
    "mean_time": 0.0031688117381418125,
    "mean_precisions": 0.9277200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.005298579094232994,
    "rps": 1195.8842506896444,
    "parallel": 100,
    "p99_time": 0.015522967533906957,
    "mean_time": 0.0033391895991982893,
    "mean_precisions": 0.9682799999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.004729870753362776,
    "rps": 1211.6749981701078,
    "parallel": 100,
    "p99_time": 0.014658991408068695,
    "mean_time": 0.003346469705691561,
    "mean_precisions": 0.9832200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.118748222355498,
    "rps": 850.2999716782898,
    "parallel": 100,
    "p99_time": 0.1272944285662379,
    "mean_time": 0.10804997621334624,
    "mean_precisions": 0.8404200000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.11779004415730014,
    "rps": 850.6046936387712,
    "parallel": 100,
    "p99_time": 0.12080729019478896,
    "mean_time": 0.10814447093047201,
    "mean_precisions": 0.9312600000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.0018557752831839026,
    "rps": 463.5346504613408,
    "parallel": 1,
    "p99_time": 0.0020076363196130844,
    "mean_time": 0.0016393120571272447,
    "mean_precisions": 0.9594800000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.11972652792464941,
    "rps": 836.6875200343588,
    "parallel": 100,
    "p99_time": 0.12087132258107887,
    "mean_time": 0.10932728564878925,
    "mean_precisions": 0.973,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.12247168106259779,
    "rps": 822.8759691966428,
    "parallel": 100,
    "p99_time": 0.12626620389521123,
    "mean_time": 0.11192594913502689,
    "mean_precisions": 0.9884,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.0020534428360406308,
    "rps": 432.4254175105746,
    "parallel": 1,
    "p99_time": 0.0022132883209269516,
    "mean_time": 0.0017903466458432376,
    "mean_precisions": 0.83236,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.0020869645872153343,
    "rps": 424.02333279742874,
    "parallel": 1,
    "p99_time": 0.0023254579131025822,
    "mean_time": 0.0018372738923877478,
    "mean_precisions": 0.92,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.002093658474041149,
    "rps": 422.2996659217851,
    "parallel": 1,
    "p99_time": 0.002304247189313174,
    "mean_time": 0.001848176378500648,
    "mean_precisions": 0.9588,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.0021565470146015287,
    "rps": 413.47670723793306,
    "parallel": 1,
    "p99_time": 0.0023436618503183144,
    "mean_time": 0.001895686239283532,
    "mean_precisions": 0.9724599999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.002760276768822223,
    "rps": 347.54613749155675,
    "parallel": 1,
    "p99_time": 0.0029912788572255527,
    "mean_time": 0.0023304845854407175,
    "mean_precisions": 0.83852,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 230.58331176894717,
    "total_upload_time": 452.07155711296946,
    "p95_time": 0.002779979165643454,
    "rps": 346.2627612460471,
    "parallel": 1,
    "p99_time": 0.0030113539902959026,
    "mean_time": 0.0023479513589991256,
    "mean_precisions": 0.9277200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.00430845280008043,
    "rps": 281.28712083547356,
    "parallel": 1,
    "p99_time": 0.006193175669986887,
    "mean_time": 0.0034938307110001687,
    "mean_precisions": 0.156711,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.00497854120007446,
    "rps": 250.7857281189308,
    "parallel": 1,
    "p99_time": 0.0067555014900040075,
    "mean_time": 0.003927820864499858,
    "mean_precisions": 0.225444,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.006031726850096665,
    "rps": 209.19600017452697,
    "parallel": 1,
    "p99_time": 0.007863499900101942,
    "mean_time": 0.004718215008600555,
    "mean_precisions": 0.303345,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.008275914549938078,
    "rps": 155.8499691038666,
    "parallel": 1,
    "p99_time": 0.01038139934003539,
    "mean_time": 0.0063511618592002154,
    "mean_precisions": 0.389569,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.0064821444500353185,
    "rps": 194.0751755076812,
    "parallel": 1,
    "p99_time": 0.008185042590027935,
    "mean_time": 0.005091100036300781,
    "mean_precisions": 0.15243099999999998,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.006550575400171962,
    "rps": 194.18738992916468,
    "parallel": 1,
    "p99_time": 0.008356158540148045,
    "mean_time": 0.005087555093500168,
    "mean_precisions": 0.218926,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.006735920149867523,
    "rps": 192.88413678073954,
    "parallel": 1,
    "p99_time": 0.008344688739864523,
    "mean_time": 0.005118276650300663,
    "mean_precisions": 0.298378,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.008092571250153922,
    "rps": 158.7996629883808,
    "parallel": 1,
    "p99_time": 0.009723432860073445,
    "mean_time": 0.006231965154599902,
    "mean_precisions": 0.389569,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.4069278989500731,
    "rps": 601.089115797319,
    "parallel": 100,
    "p99_time": 1.0072086040700652,
    "mean_time": 0.15677005388259957,
    "mean_precisions": 0.156711,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.055371203099900866,
    "rps": 1959.8089387203913,
    "parallel": 100,
    "p99_time": 0.06105398859986509,
    "mean_time": 0.048184486185698754,
    "mean_precisions": 0.225444,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.0711237913500213,
    "rps": 1501.7974872956468,
    "parallel": 100,
    "p99_time": 0.07955250088004732,
    "mean_time": 0.06412502476729925,
    "mean_precisions": 0.303345,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.10279283920004899,
    "rps": 1042.6984104441603,
    "parallel": 100,
    "p99_time": 0.10641602996010079,
    "mean_time": 0.09371460455920028,
    "mean_precisions": 0.38956899999999994,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.006220895550018212,
    "rps": 206.7459220862884,
    "parallel": 1,
    "p99_time": 0.007990264230047615,
    "mean_time": 0.0047746359181998176,
    "mean_precisions": 0.303345,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.0524085985001534,
    "rps": 2196.9812424057377,
    "parallel": 100,
    "p99_time": 0.06103868150005156,
    "mean_time": 0.043064448421698674,
    "mean_precisions": 0.15548,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.058348345250180955,
    "rps": 1899.1689913548314,
    "parallel": 100,
    "p99_time": 0.0642147397299664,
    "mean_time": 0.04986610580700121,
    "mean_precisions": 0.225444,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.07144870584999125,
    "rps": 1498.4976823473676,
    "parallel": 100,
    "p99_time": 0.0747955959399178,
    "mean_time": 0.06444729203029995,
    "mean_precisions": 0.303345,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.10147091700018791,
    "rps": 1052.0174118467633,
    "parallel": 100,
    "p99_time": 0.1059628649100523,
    "mean_time": 0.0927160282824002,
    "mean_precisions": 0.389569,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.059164265900039925,
    "rps": 1851.327201150791,
    "parallel": 100,
    "p99_time": 0.06638184074000719,
    "mean_time": 0.05175459638249995,
    "mean_precisions": 0.154752,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.05845450855003945,
    "rps": 1851.3799707535477,
    "parallel": 100,
    "p99_time": 0.0641490782699384,
    "mean_time": 0.05136816972929919,
    "mean_precisions": 0.22185500000000002,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.07043662990009805,
    "rps": 1517.1162993701098,
    "parallel": 100,
    "p99_time": 0.07492023178999489,
    "mean_time": 0.06326732169120107,
    "mean_precisions": 0.303345,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.10160011905011287,
    "rps": 1048.4423960228526,
    "parallel": 100,
    "p99_time": 0.10814480941989134,
    "mean_time": 0.09287749565760012,
    "mean_precisions": 0.389569,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.07663288834989998,
    "rps": 1394.7032087897041,
    "parallel": 100,
    "p99_time": 0.08093751783993867,
    "mean_time": 0.06931740543939911,
    "mean_precisions": 0.15243099999999998,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.0783725280499766,
    "rps": 1370.1550549285803,
    "parallel": 100,
    "p99_time": 0.08209869732998186,
    "mean_time": 0.0705969164256999,
    "mean_precisions": 0.218926,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.008501002249988687,
    "rps": 155.3502222247577,
    "parallel": 1,
    "p99_time": 0.01017281140010028,
    "mean_time": 0.006370875174700245,
    "mean_precisions": 0.389569,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.07884295920015347,
    "rps": 1355.0290661363522,
    "parallel": 100,
    "p99_time": 0.08339783757015085,
    "mean_time": 0.07141082434099938,
    "mean_precisions": 0.298378,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.10276214369998796,
    "rps": 1044.0498266552902,
    "parallel": 100,
    "p99_time": 0.10686552823974581,
    "mean_time": 0.09338974412189996,
    "mean_precisions": 0.389569,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.004657320949820584,
    "rps": 270.7618122228233,
    "parallel": 1,
    "p99_time": 0.006350061820028264,
    "mean_time": 0.0036348929764986222,
    "mean_precisions": 0.15548,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.005148886999870676,
    "rps": 249.156090991007,
    "parallel": 1,
    "p99_time": 0.007204276990059955,
    "mean_time": 0.003953876665398752,
    "mean_precisions": 0.225444,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.006176455650108891,
    "rps": 207.13116002103976,
    "parallel": 1,
    "p99_time": 0.007752120750160431,
    "mean_time": 0.0047659577123006554,
    "mean_precisions": 0.303345,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.008139814499941167,
    "rps": 157.19947171493322,
    "parallel": 1,
    "p99_time": 0.009723514940105815,
    "mean_time": 0.006292979611400278,
    "mean_precisions": 0.389569,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.005373448400098365,
    "rps": 237.39464877486728,
    "parallel": 1,
    "p99_time": 0.007203504790027182,
    "mean_time": 0.004152466135098985,
    "mean_precisions": 0.154752,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 47.40695791400003,
    "total_upload_time": 290.142142864,
    "p95_time": 0.005403146650110097,
    "rps": 235.78056141089803,
    "parallel": 1,
    "p99_time": 0.007114973820189335,
    "mean_time": 0.004180776022098508,
    "mean_precisions": 0.22185500000000002,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0019130002357997,
    "rps": 469.3087012744812,
    "parallel": 1,
    "p99_time": 0.0020927002979442486,
    "mean_time": 0.0016232581085525452,
    "mean_precisions": 0.7883399999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0018757490033749493,
    "rps": 468.0902618962408,
    "parallel": 1,
    "p99_time": 0.0020475935051217677,
    "mean_time": 0.0016199690477689728,
    "mean_precisions": 0.8869599999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0031039479945320636,
    "rps": 322.76037971439035,
    "parallel": 1,
    "p99_time": 0.0035053593385964634,
    "mean_time": 0.0025367692960426213,
    "mean_precisions": 0.95134,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.003146859584376216,
    "rps": 319.675115254463,
    "parallel": 1,
    "p99_time": 0.0036336307658348236,
    "mean_time": 0.0025657939791446554,
    "mean_precisions": 0.973,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.004441524588037283,
    "rps": 240.46670249800925,
    "parallel": 1,
    "p99_time": 0.005049087994266302,
    "mean_time": 0.003527853345731273,
    "mean_precisions": 0.8013,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.004506826034048572,
    "rps": 237.80235348107647,
    "parallel": 1,
    "p99_time": 0.005124340265756473,
    "mean_time": 0.0035708520288113507,
    "mean_precisions": 0.9036799999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.004522070521488786,
    "rps": 237.50399569396515,
    "parallel": 1,
    "p99_time": 0.005153258123900741,
    "mean_time": 0.0035768597818911074,
    "mean_precisions": 0.9536800000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.004647362401010469,
    "rps": 236.60373084346824,
    "parallel": 1,
    "p99_time": 0.00529893517959863,
    "mean_time": 0.003605069069797173,
    "mean_precisions": 0.97546,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.002161440596682951,
    "rps": 1217.041411679204,
    "parallel": 100,
    "p99_time": 0.013078436887590288,
    "mean_time": 0.002093925333232619,
    "mean_precisions": 0.7883399999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0022343332413583997,
    "rps": 1203.6189682519887,
    "parallel": 100,
    "p99_time": 0.012974485838785774,
    "mean_time": 0.0019749842964112757,
    "mean_precisions": 0.8869599999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0022465206857305024,
    "rps": 1212.213687688523,
    "parallel": 100,
    "p99_time": 0.013803985440172258,
    "mean_time": 0.002015392330335453,
    "mean_precisions": 0.9324,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.002397013857262209,
    "rps": 1211.4234979513926,
    "parallel": 100,
    "p99_time": 0.0130270521657076,
    "mean_time": 0.002139842806663364,
    "mean_precisions": 0.9578399999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0018750649178400636,
    "rps": 469.9568758102701,
    "parallel": 1,
    "p99_time": 0.0020373936404939753,
    "mean_time": 0.0016149766695220022,
    "mean_precisions": 0.9324,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.002715455938596279,
    "rps": 1210.9071261273086,
    "parallel": 100,
    "p99_time": 0.014165416397154343,
    "mean_time": 0.0023900486905360594,
    "mean_precisions": 0.79582,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0027899915992747994,
    "rps": 1222.1487398962004,
    "parallel": 100,
    "p99_time": 0.013862464788835517,
    "mean_time": 0.0024160255615599453,
    "mean_precisions": 0.8977200000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0027447390311863273,
    "rps": 1222.218579935692,
    "parallel": 100,
    "p99_time": 0.012815917531261238,
    "mean_time": 0.0023859955636318774,
    "mean_precisions": 0.9459200000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0028743336442857985,
    "rps": 1213.1399181906725,
    "parallel": 100,
    "p99_time": 0.013775433569680905,
    "mean_time": 0.0024849063602043315,
    "mean_precisions": 0.9664800000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.004745718277990819,
    "rps": 1210.5835514955882,
    "parallel": 100,
    "p99_time": 0.0148049657966476,
    "mean_time": 0.003577859088801779,
    "mean_precisions": 0.79952,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.004933182231616229,
    "rps": 1219.2478000662613,
    "parallel": 100,
    "p99_time": 0.014903108802391245,
    "mean_time": 0.0036551890650065614,
    "mean_precisions": 0.9018,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0047662884695455435,
    "rps": 1230.9568122111227,
    "parallel": 100,
    "p99_time": 0.014804356732638581,
    "mean_time": 0.0036553123992634938,
    "mean_precisions": 0.95134,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.005277316638967024,
    "rps": 1215.757589347745,
    "parallel": 100,
    "p99_time": 0.014652248062193424,
    "mean_time": 0.003834084107191302,
    "mean_precisions": 0.973,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.12152132422779686,
    "rps": 835.5264430501659,
    "parallel": 100,
    "p99_time": 0.12361628069076687,
    "mean_time": 0.11095812072402332,
    "mean_precisions": 0.8013,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.12258803013828583,
    "rps": 832.2940647867831,
    "parallel": 100,
    "p99_time": 0.12540603469824418,
    "mean_time": 0.11034030226462055,
    "mean_precisions": 0.9036799999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0019951725902501495,
    "rps": 448.51067946427855,
    "parallel": 1,
    "p99_time": 0.0021935743920039395,
    "mean_time": 0.0017159389528445899,
    "mean_precisions": 0.9578399999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.12081888292450457,
    "rps": 836.6595573490074,
    "parallel": 100,
    "p99_time": 0.1222010339028202,
    "mean_time": 0.11073449614364654,
    "mean_precisions": 0.9536800000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.12307321364060045,
    "rps": 825.4723032150139,
    "parallel": 100,
    "p99_time": 0.12491327383904718,
    "mean_time": 0.11235740706697106,
    "mean_precisions": 0.97546,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0022609336534515022,
    "rps": 418.85669712766423,
    "parallel": 1,
    "p99_time": 0.0025257602264173334,
    "mean_time": 0.0018715633335523306,
    "mean_precisions": 0.79582,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0022507681569550186,
    "rps": 416.8058513388829,
    "parallel": 1,
    "p99_time": 0.0025478383817244344,
    "mean_time": 0.0018788624699693174,
    "mean_precisions": 0.8977200000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0023241567076183857,
    "rps": 405.05651139389647,
    "parallel": 1,
    "p99_time": 0.0025838522671256226,
    "mean_time": 0.0019442597184097395,
    "mean_precisions": 0.9459200000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0023059112369082867,
    "rps": 406.64928164750046,
    "parallel": 1,
    "p99_time": 0.0025852304592262963,
    "mean_time": 0.001939322987664491,
    "mean_precisions": 0.9664800000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.003031830850522966,
    "rps": 335.458287211903,
    "parallel": 1,
    "p99_time": 0.0034388027398381403,
    "mean_time": 0.002434980022837408,
    "mean_precisions": 0.7995200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 214.01004187599756,
    "total_upload_time": 467.94193929294124,
    "p95_time": 0.0030693960434291516,
    "rps": 329.5096829183669,
    "parallel": 1,
    "p99_time": 0.003561095979530365,
    "mean_time": 0.002488756543607451,
    "mean_precisions": 0.9018,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.004762017950133664,
    "rps": 257.1319706806652,
    "parallel": 1,
    "p99_time": 0.00671865504012203,
    "mean_time": 0.003829829127899575,
    "mean_precisions": 0.156606,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.005656279899903887,
    "rps": 220.29454592057115,
    "parallel": 1,
    "p99_time": 0.007572630889771979,
    "mean_time": 0.00447787409430357,
    "mean_precisions": 0.22244699999999998,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.0077169866499161785,
    "rps": 170.38179256078112,
    "parallel": 1,
    "p99_time": 0.009595471749798894,
    "mean_time": 0.005804385448302174,
    "mean_precisions": 0.29897,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.010778510949694462,
    "rps": 121.66307556388412,
    "parallel": 1,
    "p99_time": 0.012642755069960003,
    "mean_time": 0.008147860120500354,
    "mean_precisions": 0.38492000000000004,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.008448784849906585,
    "rps": 154.80031722369475,
    "parallel": 1,
    "p99_time": 0.010292842099988778,
    "mean_time": 0.006395506205298307,
    "mean_precisions": 0.14986799999999997,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.008483749150150285,
    "rps": 153.66312676913714,
    "parallel": 1,
    "p99_time": 0.01053924123012166,
    "mean_time": 0.006442056798201065,
    "mean_precisions": 0.21465600000000004,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.008364934350220206,
    "rps": 154.38299270056962,
    "parallel": 1,
    "p99_time": 0.010361348469632506,
    "mean_time": 0.006408915841301496,
    "mean_precisions": 0.293141,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.010637649800105462,
    "rps": 122.04375707755864,
    "parallel": 1,
    "p99_time": 0.012677521089945005,
    "mean_time": 0.008123261119500376,
    "mean_precisions": 0.38492000000000004,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.05495605120022445,
    "rps": 2003.3349344365693,
    "parallel": 100,
    "p99_time": 0.061259381190102435,
    "mean_time": 0.046847936488199,
    "mean_precisions": 0.15660600000000002,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.0698086934498633,
    "rps": 1559.7330216777464,
    "parallel": 100,
    "p99_time": 0.07610195348979233,
    "mean_time": 0.061598203350100224,
    "mean_precisions": 0.22244700000000003,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.09241256390014314,
    "rps": 1146.008664195187,
    "parallel": 100,
    "p99_time": 0.09820388458977504,
    "mean_time": 0.08478490603750324,
    "mean_precisions": 0.29896999999999996,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.14311534315038443,
    "rps": 746.2420683342791,
    "parallel": 100,
    "p99_time": 0.14875903035987448,
    "mean_time": 0.13143624524379874,
    "mean_precisions": 0.38492000000000004,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.00754456999973172,
    "rps": 171.78210303201803,
    "parallel": 1,
    "p99_time": 0.009113273909915736,
    "mean_time": 0.005757095408797477,
    "mean_precisions": 0.29897,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.05871634110026207,
    "rps": 1863.789220589455,
    "parallel": 100,
    "p99_time": 0.0640388170999404,
    "mean_time": 0.05058004638670268,
    "mean_precisions": 0.15410300000000002,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.06758441635004146,
    "rps": 1594.001393511416,
    "parallel": 100,
    "p99_time": 0.07463985257995773,
    "mean_time": 0.06032359150080183,
    "mean_precisions": 0.22244699999999998,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.09323135939991971,
    "rps": 1149.9227238360418,
    "parallel": 100,
    "p99_time": 0.09721026207007072,
    "mean_time": 0.08468083823590178,
    "mean_precisions": 0.29896999999999996,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.14312074969986952,
    "rps": 746.0999501547204,
    "parallel": 100,
    "p99_time": 0.14801126049998403,
    "mean_time": 0.13157061410210136,
    "mean_precisions": 0.38492000000000004,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.07447662720019252,
    "rps": 1445.2407411325257,
    "parallel": 100,
    "p99_time": 0.07953400856028113,
    "mean_time": 0.06666881729639935,
    "mean_precisions": 0.152317,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.07643360849986035,
    "rps": 1425.3803658115942,
    "parallel": 100,
    "p99_time": 0.08107681330024208,
    "mean_time": 0.0678564604510007,
    "mean_precisions": 0.21824700000000002,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.09401898690009602,
    "rps": 1133.3986059781623,
    "parallel": 100,
    "p99_time": 0.09812062263007648,
    "mean_time": 0.08584634481889743,
    "mean_precisions": 0.29897,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.14246748619973457,
    "rps": 752.4133445092157,
    "parallel": 100,
    "p99_time": 0.14947701003993188,
    "mean_time": 0.13024755728799856,
    "mean_precisions": 0.38492,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.10397663969981749,
    "rps": 1018.1968759140595,
    "parallel": 100,
    "p99_time": 0.10868807962964638,
    "mean_time": 0.09565928433390154,
    "mean_precisions": 0.14986799999999997,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.1053358520999609,
    "rps": 1020.3785240804094,
    "parallel": 100,
    "p99_time": 0.11120912391988443,
    "mean_time": 0.0954678329431993,
    "mean_precisions": 0.21465599999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.010594629799675202,
    "rps": 122.39817692708641,
    "parallel": 1,
    "p99_time": 0.012382504039637752,
    "mean_time": 0.008098279715899253,
    "mean_precisions": 0.38492000000000004,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.10609465434990853,
    "rps": 998.5062933970696,
    "parallel": 100,
    "p99_time": 0.11298124600984011,
    "mean_time": 0.09759699087299982,
    "mean_precisions": 0.293141,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.1412281858996721,
    "rps": 746.8871664084724,
    "parallel": 100,
    "p99_time": 0.14599774434007942,
    "mean_time": 0.13137100507619967,
    "mean_precisions": 0.38492,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.005046281300087684,
    "rps": 244.67637942755806,
    "parallel": 1,
    "p99_time": 0.0068489107099821925,
    "mean_time": 0.004027540519999684,
    "mean_precisions": 0.15410300000000002,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.005890363500316196,
    "rps": 217.50041703024382,
    "parallel": 1,
    "p99_time": 0.00769512135982041,
    "mean_time": 0.004537470298600602,
    "mean_precisions": 0.22244699999999998,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.00752958289997423,
    "rps": 170.98723152499804,
    "parallel": 1,
    "p99_time": 0.009337131940123986,
    "mean_time": 0.005782505657798401,
    "mean_precisions": 0.29897,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.010808095099946513,
    "rps": 120.39368149941001,
    "parallel": 1,
    "p99_time": 0.012667974160008273,
    "mean_time": 0.008230084992002276,
    "mean_precisions": 0.38492000000000004,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.006270162800046816,
    "rps": 202.26685990158867,
    "parallel": 1,
    "p99_time": 0.008099061009875187,
    "mean_time": 0.004883395637402373,
    "mean_precisions": 0.152317,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 51.96304804200008,
    "total_upload_time": 477.269728879,
    "p95_time": 0.006497017399897229,
    "rps": 201.2084113966486,
    "parallel": 1,
    "p99_time": 0.008347769629854156,
    "mean_time": 0.0049069427736000305,
    "mean_precisions": 0.21824700000000002,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.0019746828998904674,
    "rps": 448.50166083408476,
    "parallel": 1,
    "p99_time": 0.0022587003069929777,
    "mean_time": 0.0017016215321142226,
    "mean_precisions": 0.77332,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.001915630925213918,
    "rps": 460.47500232412295,
    "parallel": 1,
    "p99_time": 0.0020838068041484806,
    "mean_time": 0.0016561131218681112,
    "mean_precisions": 0.88792,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.003739969979505986,
    "rps": 287.83901161629143,
    "parallel": 1,
    "p99_time": 0.0041117438871879144,
    "mean_time": 0.002898996530706063,
    "mean_precisions": 0.9583,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.0037277590134181084,
    "rps": 287.6210855932437,
    "parallel": 1,
    "p99_time": 0.004106640944955872,
    "mean_time": 0.00290241947916802,
    "mean_precisions": 0.9833799999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.005640384083380924,
    "rps": 208.92243236820866,
    "parallel": 1,
    "p99_time": 0.006263307025656107,
    "mean_time": 0.004157628198247403,
    "mean_precisions": 0.78328,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.00559596783714369,
    "rps": 208.23064399213388,
    "parallel": 1,
    "p99_time": 0.006204254038166259,
    "mean_time": 0.004172159066936001,
    "mean_precisions": 0.9016799999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.005678577214712278,
    "rps": 205.93343924478924,
    "parallel": 1,
    "p99_time": 0.006323945370968431,
    "mean_time": 0.004223884125659242,
    "mean_precisions": 0.9601800000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.005757754953810946,
    "rps": 203.15856673806817,
    "parallel": 1,
    "p99_time": 0.00639819218660705,
    "mean_time": 0.004290286207129248,
    "mean_precisions": 0.98562,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.0022457945917267355,
    "rps": 1204.313925516098,
    "parallel": 100,
    "p99_time": 0.012813901103800231,
    "mean_time": 0.002176380843552761,
    "mean_precisions": 0.77332,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.0022438392392359675,
    "rps": 1206.9445319064762,
    "parallel": 100,
    "p99_time": 0.013155039146076896,
    "mean_time": 0.002037727839150466,
    "mean_precisions": 0.88792,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.002279132086550817,
    "rps": 1201.7877400361428,
    "parallel": 100,
    "p99_time": 0.013238709664437923,
    "mean_time": 0.0020768906472716482,
    "mean_precisions": 0.9420800000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.0024739686166867616,
    "rps": 1214.6988646476952,
    "parallel": 100,
    "p99_time": 0.013660687707597395,
    "mean_time": 0.0022719138771062717,
    "mean_precisions": 0.9700200000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.0019366583495866508,
    "rps": 459.0635821081023,
    "parallel": 1,
    "p99_time": 0.0021961213834583776,
    "mean_time": 0.0016634237886872143,
    "mean_precisions": 0.9420800000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.002903370041167364,
    "rps": 1208.7147588321627,
    "parallel": 100,
    "p99_time": 0.013700616019777977,
    "mean_time": 0.002556087975949049,
    "mean_precisions": 0.7799800000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.002945833100238815,
    "rps": 1213.305393197062,
    "parallel": 100,
    "p99_time": 0.014494439720874693,
    "mean_time": 0.002612447069399059,
    "mean_precisions": 0.8973800000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.0029830041341483596,
    "rps": 1206.8356115167385,
    "parallel": 100,
    "p99_time": 0.01509624756523412,
    "mean_time": 0.0026553371701855213,
    "mean_precisions": 0.9541,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.003017218771856278,
    "rps": 1199.9078731713234,
    "parallel": 100,
    "p99_time": 0.013903905309271068,
    "mean_time": 0.0026492686100769787,
    "mean_precisions": 0.9786000000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.013849627680610868,
    "rps": 1206.1371234486194,
    "parallel": 100,
    "p99_time": 0.016975561619037762,
    "mean_time": 0.0064598003016551955,
    "mean_precisions": 0.7824,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.01643864262732677,
    "rps": 1196.1241334265974,
    "parallel": 100,
    "p99_time": 0.01908947283518502,
    "mean_time": 0.009706612720200791,
    "mean_precisions": 0.90038,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.027464071894064548,
    "rps": 1205.4724968105822,
    "parallel": 100,
    "p99_time": 0.029280059995362536,
    "mean_time": 0.016990932931099087,
    "mean_precisions": 0.9583,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.08199042301275768,
    "rps": 1178.2875669746202,
    "parallel": 100,
    "p99_time": 0.08389948533615098,
    "mean_time": 0.05074680896115023,
    "mean_precisions": 0.9833799999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.13936172419344076,
    "rps": 725.9927633924724,
    "parallel": 100,
    "p99_time": 0.14074440547148698,
    "mean_time": 0.1284339896848658,
    "mean_precisions": 0.78328,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.13830357846454716,
    "rps": 729.7791044093528,
    "parallel": 100,
    "p99_time": 0.13987251685117372,
    "mean_time": 0.12849711159886792,
    "mean_precisions": 0.9016800000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.0021423857950139793,
    "rps": 421.94753778595776,
    "parallel": 1,
    "p99_time": 0.002450532512739303,
    "mean_time": 0.001850149910687469,
    "mean_precisions": 0.9700200000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.14180179208051413,
    "rps": 719.9637849940254,
    "parallel": 100,
    "p99_time": 0.14346018233569338,
    "mean_time": 0.13026457230059896,
    "mean_precisions": 0.9601800000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.14246125005302018,
    "rps": 717.2114986763843,
    "parallel": 100,
    "p99_time": 0.14460190741228873,
    "mean_time": 0.13046773780388757,
    "mean_precisions": 0.98562,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.0024434535705950113,
    "rps": 389.2010427953219,
    "parallel": 1,
    "p99_time": 0.002735460017574952,
    "mean_time": 0.002043463142751716,
    "mean_precisions": 0.7799800000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.0024327679595444354,
    "rps": 391.11995509306826,
    "parallel": 1,
    "p99_time": 0.002708501624874771,
    "mean_time": 0.002031973882485181,
    "mean_precisions": 0.8973800000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.0024261176062282176,
    "rps": 385.127516432379,
    "parallel": 1,
    "p99_time": 0.0026857541338540613,
    "mean_time": 0.0020715467680245637,
    "mean_precisions": 0.9541,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.002523902448592708,
    "rps": 378.1778248379456,
    "parallel": 1,
    "p99_time": 0.0027570445067249243,
    "mean_time": 0.002118282137811184,
    "mean_precisions": 0.9786000000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.00334870177321136,
    "rps": 304.00323284032226,
    "parallel": 1,
    "p99_time": 0.0038322003895882545,
    "mean_time": 0.002725560328690335,
    "mean_precisions": 0.7824,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 235.41115621000063,
    "total_upload_time": 665.5782463320065,
    "p95_time": 0.003437631711130962,
    "rps": 298.7909754011836,
    "parallel": 1,
    "p99_time": 0.003967645957600327,
    "mean_time": 0.002775529770576395,
    "mean_precisions": 0.90038,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.0048774936503832534,
    "rps": 247.48536060407986,
    "parallel": 1,
    "p99_time": 0.006760363729308666,
    "mean_time": 0.003980192494396033,
    "mean_precisions": 0.155034,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.005974067050192381,
    "rps": 208.42232914682518,
    "parallel": 1,
    "p99_time": 0.007847489599998883,
    "mean_time": 0.004735439877794033,
    "mean_precisions": 0.22032200000000002,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.007618788550371391,
    "rps": 170.42186380574728,
    "parallel": 1,
    "p99_time": 0.009422671010042905,
    "mean_time": 0.005803951730796871,
    "mean_precisions": 0.296164,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.010864974700234597,
    "rps": 120.44422932007676,
    "parallel": 1,
    "p99_time": 0.012922351480474395,
    "mean_time": 0.008231522536506237,
    "mean_precisions": 0.38251900000000005,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.008316053849648597,
    "rps": 154.4493087616013,
    "parallel": 1,
    "p99_time": 0.010122540529309849,
    "mean_time": 0.006410297282799365,
    "mean_precisions": 0.148933,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.008335378700257934,
    "rps": 154.39280875393277,
    "parallel": 1,
    "p99_time": 0.010275892469971959,
    "mean_time": 0.0064134703606039695,
    "mean_precisions": 0.21309100000000003,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.00858590849975371,
    "rps": 152.52935591599032,
    "parallel": 1,
    "p99_time": 0.010411717209735799,
    "mean_time": 0.006488607909298389,
    "mean_precisions": 0.290429,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.010628051550565941,
    "rps": 121.53645478751223,
    "parallel": 1,
    "p99_time": 0.012600283619894985,
    "mean_time": 0.008157985900804215,
    "mean_precisions": 0.38251900000000005,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.056180573650135554,
    "rps": 1978.3345661449714,
    "parallel": 100,
    "p99_time": 0.06457517686973915,
    "mean_time": 0.047612361108599996,
    "mean_precisions": 0.155034,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.06961960044927763,
    "rps": 1576.1283672729328,
    "parallel": 100,
    "p99_time": 0.07554569795993304,
    "mean_time": 0.061181836844599005,
    "mean_precisions": 0.22032200000000002,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.09616151444997739,
    "rps": 1115.6942726053014,
    "parallel": 100,
    "p99_time": 0.10090489942025671,
    "mean_time": 0.08749703995399923,
    "mean_precisions": 0.296164,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.14776475254957402,
    "rps": 722.241522441681,
    "parallel": 100,
    "p99_time": 0.15261890087052962,
    "mean_time": 0.13593679327579966,
    "mean_precisions": 0.382519,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.008078901300041252,
    "rps": 157.147347547495,
    "parallel": 1,
    "p99_time": 0.009881316709806928,
    "mean_time": 0.006297534553003879,
    "mean_precisions": 0.296164,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.059518256399542224,
    "rps": 1827.8080283173686,
    "parallel": 100,
    "p99_time": 0.0656423794199327,
    "mean_time": 0.05168237134339506,
    "mean_precisions": 0.152599,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.06954340295023939,
    "rps": 1547.4793666231587,
    "parallel": 100,
    "p99_time": 0.07446718582965332,
    "mean_time": 0.06242615497980278,
    "mean_precisions": 0.22032200000000002,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.09555333764956231,
    "rps": 1112.0159923788326,
    "parallel": 100,
    "p99_time": 0.10006225794011699,
    "mean_time": 0.08761559074699944,
    "mean_precisions": 0.29616400000000004,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.14756555744934302,
    "rps": 722.0130823003071,
    "parallel": 100,
    "p99_time": 0.15389991954974902,
    "mean_time": 0.13613837046240643,
    "mean_precisions": 0.38251900000000005,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.07611164929976438,
    "rps": 1406.4685348392813,
    "parallel": 100,
    "p99_time": 0.08141060089961684,
    "mean_time": 0.06852755740900211,
    "mean_precisions": 0.15101900000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.07709316040049999,
    "rps": 1401.9304288721924,
    "parallel": 100,
    "p99_time": 0.08412848596955882,
    "mean_time": 0.06910556593849587,
    "mean_precisions": 0.21588200000000002,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.09598812475010163,
    "rps": 1110.3026438709228,
    "parallel": 100,
    "p99_time": 0.10116138535959185,
    "mean_time": 0.08703908983399879,
    "mean_precisions": 0.296164,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.14863031144977867,
    "rps": 712.7681014775255,
    "parallel": 100,
    "p99_time": 0.15383714982009225,
    "mean_time": 0.1378354444272991,
    "mean_precisions": 0.382519,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.10941755620019648,
    "rps": 980.7726327016467,
    "parallel": 100,
    "p99_time": 0.11681189578943306,
    "mean_time": 0.09967437633219214,
    "mean_precisions": 0.148933,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.11134712679986478,
    "rps": 975.294424284969,
    "parallel": 100,
    "p99_time": 0.11656822950990318,
    "mean_time": 0.10038472563640553,
    "mean_precisions": 0.21309099999999997,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.011886736750238922,
    "rps": 107.3331496705219,
    "parallel": 1,
    "p99_time": 0.013812680470500716,
    "mean_time": 0.00924189003090296,
    "mean_precisions": 0.38251900000000005,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.11101997234995906,
    "rps": 968.8415355609409,
    "parallel": 100,
    "p99_time": 0.11596095369006434,
    "mean_time": 0.10072220574370358,
    "mean_precisions": 0.290429,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.1458880978495017,
    "rps": 724.7342494248308,
    "parallel": 100,
    "p99_time": 0.15128107925979747,
    "mean_time": 0.13534798046290106,
    "mean_precisions": 0.38251900000000005,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.005299112850116214,
    "rps": 236.2153790180047,
    "parallel": 1,
    "p99_time": 0.007211991500162185,
    "mean_time": 0.004173801462800111,
    "mean_precisions": 0.152599,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.006027134199894135,
    "rps": 205.69794910088945,
    "parallel": 1,
    "p99_time": 0.007897474930150567,
    "mean_time": 0.004799759609803459,
    "mean_precisions": 0.22032200000000002,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.008153008049748675,
    "rps": 156.28667595541722,
    "parallel": 1,
    "p99_time": 0.009747800890663716,
    "mean_time": 0.006333803826191069,
    "mean_precisions": 0.296164,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.01181264254983034,
    "rps": 109.20197880476553,
    "parallel": 1,
    "p99_time": 0.013799360989451096,
    "mean_time": 0.009081026991399085,
    "mean_precisions": 0.38251900000000005,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.006477090749967827,
    "rps": 196.55832877119823,
    "parallel": 1,
    "p99_time": 0.0083064550405652,
    "mean_time": 0.005026877414698174,
    "mean_precisions": 0.15101900000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.620201680000264,
    "total_upload_time": 956.7574452830004,
    "p95_time": 0.006293458049913167,
    "rps": 198.966825652858,
    "parallel": 1,
    "p99_time": 0.00809497252984329,
    "mean_time": 0.00496468406399872,
    "mean_precisions": 0.21588200000000002,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.0021245405485387893,
    "rps": 421.4514821892171,
    "parallel": 1,
    "p99_time": 0.0023087931121699512,
    "mean_time": 0.0018438972363481298,
    "mean_precisions": 0.80156,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.0021294677688274534,
    "rps": 425.62631725456555,
    "parallel": 1,
    "p99_time": 0.0023107564914971596,
    "mean_time": 0.0018263849151786418,
    "mean_precisions": 0.9045799999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.004024570144247264,
    "rps": 258.77570888186193,
    "parallel": 1,
    "p99_time": 0.004345616864738986,
    "mean_time": 0.0032633645313093437,
    "mean_precisions": 0.96362,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.0040924834029283375,
    "rps": 258.1109720284869,
    "parallel": 1,
    "p99_time": 0.0043880129558965565,
    "mean_time": 0.0032756043435074387,
    "mean_precisions": 0.9856,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.006123119074618444,
    "rps": 182.85337239469183,
    "parallel": 1,
    "p99_time": 0.00673318856745027,
    "mean_time": 0.004823221598775126,
    "mean_precisions": 0.80896,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.006153765262570232,
    "rps": 183.93407727464148,
    "parallel": 1,
    "p99_time": 0.00674216427956708,
    "mean_time": 0.004791740199876949,
    "mean_precisions": 0.91476,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.006293249351438135,
    "rps": 181.46906746220884,
    "parallel": 1,
    "p99_time": 0.006828216060530395,
    "mean_time": 0.004861936918529682,
    "mean_precisions": 0.9653,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.006216671300353483,
    "rps": 182.81386817787507,
    "parallel": 1,
    "p99_time": 0.006737784148426735,
    "mean_time": 0.004827109792130068,
    "mean_precisions": 0.98716,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.0024118816130794586,
    "rps": 1223.7893289743342,
    "parallel": 100,
    "p99_time": 0.01241144747938965,
    "mean_time": 0.0023015621561324226,
    "mean_precisions": 0.80156,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.0024134345701895656,
    "rps": 1216.914451402595,
    "parallel": 100,
    "p99_time": 0.0123323006532155,
    "mean_time": 0.0021479261591332032,
    "mean_precisions": 0.9045799999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.002472835982916877,
    "rps": 1223.0209862687755,
    "parallel": 100,
    "p99_time": 0.012724488382227735,
    "mean_time": 0.0022094099477864802,
    "mean_precisions": 0.9509799999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.0027093359793070705,
    "rps": 1220.5684521410878,
    "parallel": 100,
    "p99_time": 0.013218537695938767,
    "mean_time": 0.0024388725742930544,
    "mean_precisions": 0.9739400000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.0021512581908609716,
    "rps": 424.3230400768803,
    "parallel": 1,
    "p99_time": 0.0023703537590336068,
    "mean_time": 0.0018285042747855187,
    "mean_precisions": 0.9509799999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.004300999460974709,
    "rps": 1222.7773282100918,
    "parallel": 100,
    "p99_time": 0.014971949496539311,
    "mean_time": 0.003208981146197766,
    "mean_precisions": 0.8063600000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.004467779753031212,
    "rps": 1212.8745012769061,
    "parallel": 100,
    "p99_time": 0.013941685791360235,
    "mean_time": 0.0032113068462815138,
    "mean_precisions": 0.911,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.005312169785611332,
    "rps": 1215.516756846469,
    "parallel": 100,
    "p99_time": 0.015147648160345868,
    "mean_time": 0.003327744435193017,
    "mean_precisions": 0.95962,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.004144118609838188,
    "rps": 1220.4413194777558,
    "parallel": 100,
    "p99_time": 0.014659922870341697,
    "mean_time": 0.003297557980217971,
    "mean_precisions": 0.9805799999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.11606459296308458,
    "rps": 866.3736431875543,
    "parallel": 100,
    "p99_time": 0.11724370328942314,
    "mean_time": 0.10617585489044432,
    "mean_precisions": 0.8081800000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.11647837690543383,
    "rps": 868.2700797586641,
    "parallel": 100,
    "p99_time": 0.1179040969349444,
    "mean_time": 0.10573497378285975,
    "mean_precisions": 0.91396,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.11601458366494626,
    "rps": 864.8998815601353,
    "parallel": 100,
    "p99_time": 0.11942531271022747,
    "mean_time": 0.10622792608968448,
    "mean_precisions": 0.96362,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.11915737393428572,
    "rps": 839.2982571032471,
    "parallel": 100,
    "p99_time": 0.12057196920271965,
    "mean_time": 0.10987870143263136,
    "mean_precisions": 0.9856,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.19504331114003434,
    "rps": 523.3659711614434,
    "parallel": 100,
    "p99_time": 0.1972644902614411,
    "mean_time": 0.18336747008922977,
    "mean_precisions": 0.80896,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.2015505847230088,
    "rps": 510.51312273413896,
    "parallel": 100,
    "p99_time": 0.20478189848130568,
    "mean_time": 0.18807477140056436,
    "mean_precisions": 0.91476,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.0023879000451415776,
    "rps": 389.97611898158254,
    "parallel": 1,
    "p99_time": 0.002628227206878364,
    "mean_time": 0.002040580477332696,
    "mean_precisions": 0.9739400000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.1966640660073608,
    "rps": 516.5007334848374,
    "parallel": 100,
    "p99_time": 0.198813338765176,
    "mean_time": 0.18622575967521407,
    "mean_precisions": 0.9653,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.20315888353507033,
    "rps": 503.7284101528477,
    "parallel": 100,
    "p99_time": 0.20513632577261887,
    "mean_time": 0.191354981525545,
    "mean_precisions": 0.98716,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.002801827376242727,
    "rps": 344.60095000485455,
    "parallel": 1,
    "p99_time": 0.0030370221449993588,
    "mean_time": 0.002361693112156354,
    "mean_precisions": 0.8063600000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.0027961908897850664,
    "rps": 348.3260340420462,
    "parallel": 1,
    "p99_time": 0.0030134394555352633,
    "mean_time": 0.0023344346918165683,
    "mean_precisions": 0.911,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.0028651325032114983,
    "rps": 338.44962221080294,
    "parallel": 1,
    "p99_time": 0.0031109515251591803,
    "mean_time": 0.0024117228517076,
    "mean_precisions": 0.95962,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.0028804873116314413,
    "rps": 338.7458786207307,
    "parallel": 1,
    "p99_time": 0.0031335256353486334,
    "mean_time": 0.0024114808002952486,
    "mean_precisions": 0.9805800000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.003953591466415674,
    "rps": 265.81223323231745,
    "parallel": 1,
    "p99_time": 0.0042684141546487815,
    "mean_time": 0.003176147459121421,
    "mean_precisions": 0.80818,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 215.32705093803816,
    "total_upload_time": 805.0102241019486,
    "p95_time": 0.004061102366540581,
    "rps": 259.45741595072786,
    "parallel": 1,
    "p99_time": 0.004386295075528324,
    "mean_time": 0.003256340873474255,
    "mean_precisions": 0.9139600000000002,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.004995797149786083,
    "rps": 248.84156469115965,
    "parallel": 1,
    "p99_time": 0.006983275329630489,
    "mean_time": 0.0039586560997986455,
    "mean_precisions": 0.154342,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.006018408650379567,
    "rps": 211.4298438900908,
    "parallel": 1,
    "p99_time": 0.007762690820227363,
    "mean_time": 0.00466660682440197,
    "mean_precisions": 0.21954400000000002,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.007996084199385217,
    "rps": 162.19860376347324,
    "parallel": 1,
    "p99_time": 0.009744899518573227,
    "mean_time": 0.006099846817202706,
    "mean_precisions": 0.295594,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.011312479601474476,
    "rps": 114.2946419512268,
    "parallel": 1,
    "p99_time": 0.013205226768877766,
    "mean_time": 0.008675343416502073,
    "mean_precisions": 0.381401,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.008816189300341648,
    "rps": 147.99224603665908,
    "parallel": 1,
    "p99_time": 0.01074758337936146,
    "mean_time": 0.006691364026805786,
    "mean_precisions": 0.148499,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.008607356801712736,
    "rps": 148.06691540062852,
    "parallel": 1,
    "p99_time": 0.010752142239489334,
    "mean_time": 0.006687655994095622,
    "mean_precisions": 0.21255900000000003,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.008848822701020253,
    "rps": 145.2252628674146,
    "parallel": 1,
    "p99_time": 0.010694042979303051,
    "mean_time": 0.00681559104109092,
    "mean_precisions": 0.29003799999999996,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.01133891239896911,
    "rps": 114.71454941510147,
    "parallel": 1,
    "p99_time": 0.013456594580457023,
    "mean_time": 0.008644852281200838,
    "mean_precisions": 0.381401,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.05411950944990167,
    "rps": 1973.1892048581587,
    "parallel": 100,
    "p99_time": 0.06212974880871116,
    "mean_time": 0.047496116431602425,
    "mean_precisions": 0.154342,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.0712854409504871,
    "rps": 1536.5388062282393,
    "parallel": 100,
    "p99_time": 0.07565682921069312,
    "mean_time": 0.06274728625170246,
    "mean_precisions": 0.21954400000000002,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.10040946035078377,
    "rps": 1067.995141209019,
    "parallel": 100,
    "p99_time": 0.1053974974095945,
    "mean_time": 0.09139564930810448,
    "mean_precisions": 0.295594,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.15168594775086602,
    "rps": 697.5796425143674,
    "parallel": 100,
    "p99_time": 0.15988143581951592,
    "mean_time": 0.14103290641739458,
    "mean_precisions": 0.38140100000000005,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.007895515900327148,
    "rps": 163.00563320668542,
    "parallel": 1,
    "p99_time": 0.010025680609760458,
    "mean_time": 0.006068149501799325,
    "mean_precisions": 0.295594,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.06000069484862251,
    "rps": 1787.8696158531295,
    "parallel": 100,
    "p99_time": 0.06394808912926238,
    "mean_time": 0.05286630775020312,
    "mean_precisions": 0.15203599999999998,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.06997706105030374,
    "rps": 1522.5158465606573,
    "parallel": 100,
    "p99_time": 0.07608194925960561,
    "mean_time": 0.06311843973767864,
    "mean_precisions": 0.21954400000000002,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.10246795309967635,
    "rps": 1065.058073161501,
    "parallel": 100,
    "p99_time": 0.10886269516009635,
    "mean_time": 0.09158119936670919,
    "mean_precisions": 0.295594,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.15263545059897296,
    "rps": 698.1760640167565,
    "parallel": 100,
    "p99_time": 0.15907925104123935,
    "mean_time": 0.14084957926358693,
    "mean_precisions": 0.381401,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.07690844315002322,
    "rps": 1384.9549169456018,
    "parallel": 100,
    "p99_time": 0.08219429936909367,
    "mean_time": 0.0696892923656038,
    "mean_precisions": 0.15059,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.0789486838499215,
    "rps": 1356.5068732257648,
    "parallel": 100,
    "p99_time": 0.08412024156001281,
    "mean_time": 0.07141853925690575,
    "mean_precisions": 0.21545800000000004,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.09834232359980888,
    "rps": 1082.5201806003743,
    "parallel": 100,
    "p99_time": 0.10309428435082736,
    "mean_time": 0.08984351903439074,
    "mean_precisions": 0.295594,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.15283358499973473,
    "rps": 691.5952920949364,
    "parallel": 100,
    "p99_time": 0.15785308775975865,
    "mean_time": 0.14218190556919763,
    "mean_precisions": 0.38140100000000005,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.1141765173000749,
    "rps": 953.5113625314514,
    "parallel": 100,
    "p99_time": 0.11987280357972852,
    "mean_time": 0.10252178038369766,
    "mean_precisions": 0.148499,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.11457245475021409,
    "rps": 946.59284724195,
    "parallel": 100,
    "p99_time": 0.11958947627039379,
    "mean_time": 0.1033639763186884,
    "mean_precisions": 0.21255900000000003,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.011262332450132816,
    "rps": 114.83276517444132,
    "parallel": 1,
    "p99_time": 0.01327185730986458,
    "mean_time": 0.008632498190995647,
    "mean_precisions": 0.381401,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.11308956835036951,
    "rps": 936.3830134880027,
    "parallel": 100,
    "p99_time": 0.11968464154884716,
    "mean_time": 0.10445228501189867,
    "mean_precisions": 0.29003799999999996,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.15464150704910934,
    "rps": 688.624495972874,
    "parallel": 100,
    "p99_time": 0.1597367050912544,
    "mean_time": 0.14275074536880275,
    "mean_precisions": 0.381401,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.005320201950235057,
    "rps": 235.86822140855583,
    "parallel": 1,
    "p99_time": 0.007203962099738419,
    "mean_time": 0.004177861473404391,
    "mean_precisions": 0.152036,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.006026604999669871,
    "rps": 210.38516600756986,
    "parallel": 1,
    "p99_time": 0.007818486499663777,
    "mean_time": 0.0046917363326079795,
    "mean_precisions": 0.21954400000000002,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.007817982699998538,
    "rps": 164.8331661243427,
    "parallel": 1,
    "p99_time": 0.009611478340066251,
    "mean_time": 0.006001261075897856,
    "mean_precisions": 0.295594,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.011202104299400162,
    "rps": 115.43112842618424,
    "parallel": 1,
    "p99_time": 0.013316210259490618,
    "mean_time": 0.008587069532102578,
    "mean_precisions": 0.381401,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.0065923869495236416,
    "rps": 195.6310288789693,
    "parallel": 1,
    "p99_time": 0.008262142239636892,
    "mean_time": 0.005049882524692111,
    "mean_precisions": 0.15059,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.07842074000018,
    "total_upload_time": 1364.4860596670005,
    "p95_time": 0.006484602101045304,
    "rps": 195.04119583760274,
    "parallel": 1,
    "p99_time": 0.008302533010264597,
    "mean_time": 0.00506484742170669,
    "mean_precisions": 0.21545799999999998,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.0022048306302167478,
    "rps": 433.01381972775624,
    "parallel": 1,
    "p99_time": 0.0024715764308348306,
    "mean_time": 0.0017823987716576084,
    "mean_precisions": 0.79762,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.0020833124406635763,
    "rps": 444.33168980615324,
    "parallel": 1,
    "p99_time": 0.002289698170498014,
    "mean_time": 0.001737328635342419,
    "mean_precisions": 0.90236,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.004016958049032837,
    "rps": 268.06175303009303,
    "parallel": 1,
    "p99_time": 0.00455220093368553,
    "mean_time": 0.0031413413498550652,
    "mean_precisions": 0.9623,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.0040253422863315794,
    "rps": 267.13631610301917,
    "parallel": 1,
    "p99_time": 0.00453704540617764,
    "mean_time": 0.0031549757460830733,
    "mean_precisions": 0.9853200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.005968790175393224,
    "rps": 191.49442358434823,
    "parallel": 1,
    "p99_time": 0.006627913668053226,
    "mean_time": 0.004580799783859402,
    "mean_precisions": 0.80364,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.006103364849695936,
    "rps": 190.1317930252266,
    "parallel": 1,
    "p99_time": 0.0071735057525802405,
    "mean_time": 0.004622393899736926,
    "mean_precisions": 0.9105200000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.005992887169122696,
    "rps": 191.02556381329683,
    "parallel": 1,
    "p99_time": 0.006535331587074327,
    "mean_time": 0.00459410256522242,
    "mean_precisions": 0.9635400000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.006037796789314598,
    "rps": 189.8349531929998,
    "parallel": 1,
    "p99_time": 0.006840181814040999,
    "mean_time": 0.004631101936288178,
    "mean_precisions": 0.9868400000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.0024312932044267656,
    "rps": 1214.2227199091262,
    "parallel": 100,
    "p99_time": 0.015517191069666317,
    "mean_time": 0.0023771694131195543,
    "mean_precisions": 0.79762,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.002430766489123926,
    "rps": 1213.3655407093866,
    "parallel": 100,
    "p99_time": 0.012828104717191311,
    "mean_time": 0.0021511095330584793,
    "mean_precisions": 0.90236,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.0025094749056734146,
    "rps": 1230.5984500596446,
    "parallel": 100,
    "p99_time": 0.014029250466264838,
    "mean_time": 0.00227582405093126,
    "mean_precisions": 0.95258,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.002842792129376903,
    "rps": 1217.9585193901135,
    "parallel": 100,
    "p99_time": 0.01335057862568648,
    "mean_time": 0.0024640080466866495,
    "mean_precisions": 0.9770400000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.0021388170251157137,
    "rps": 431.91688978061535,
    "parallel": 1,
    "p99_time": 0.0023530330439098185,
    "mean_time": 0.0018007891281042248,
    "mean_precisions": 0.95258,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.0036658446653746067,
    "rps": 1209.3803112714852,
    "parallel": 100,
    "p99_time": 0.014919592725345876,
    "mean_time": 0.0030157698339782655,
    "mean_precisions": 0.80202,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.0037771340750623497,
    "rps": 1212.4074208068828,
    "parallel": 100,
    "p99_time": 0.01452532451832668,
    "mean_time": 0.0030528649087063968,
    "mean_precisions": 0.9072,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.0038543041679076863,
    "rps": 1211.3346917772883,
    "parallel": 100,
    "p99_time": 0.013877871982986125,
    "mean_time": 0.0030707520253956317,
    "mean_precisions": 0.9593400000000002,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.004054916743189097,
    "rps": 1217.808418178508,
    "parallel": 100,
    "p99_time": 0.014675423944136137,
    "mean_time": 0.003187448575347662,
    "mean_precisions": 0.9820199999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.104740036878502,
    "rps": 962.8425716202548,
    "parallel": 100,
    "p99_time": 0.1061587701085955,
    "mean_time": 0.09340448773980606,
    "mean_precisions": 0.8030200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.10317701644380577,
    "rps": 973.4227304995667,
    "parallel": 100,
    "p99_time": 0.10493237912538461,
    "mean_time": 0.09223188531619962,
    "mean_precisions": 0.90912,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.10424515443737618,
    "rps": 962.6005399885358,
    "parallel": 100,
    "p99_time": 0.1054807490471285,
    "mean_time": 0.092415565943392,
    "mean_precisions": 0.9623,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.10819760422455146,
    "rps": 931.0938445475651,
    "parallel": 100,
    "p99_time": 0.11046924067661168,
    "mean_time": 0.09678524026956875,
    "mean_precisions": 0.9853200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.17564240511273965,
    "rps": 580.6744492026357,
    "parallel": 100,
    "p99_time": 0.17748006388428622,
    "mean_time": 0.16358406227813102,
    "mean_precisions": 0.8036399999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.17628489302587697,
    "rps": 580.4466443025559,
    "parallel": 100,
    "p99_time": 0.1791295749694109,
    "mean_time": 0.16373892816232982,
    "mean_precisions": 0.9105200000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.002286330203060061,
    "rps": 414.9209735619509,
    "parallel": 1,
    "p99_time": 0.0025778387370519345,
    "mean_time": 0.001894945809827186,
    "mean_precisions": 0.9770399999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.1785675212100614,
    "rps": 574.7172248352372,
    "parallel": 100,
    "p99_time": 0.18108285788446665,
    "mean_time": 0.16563238232943694,
    "mean_precisions": 0.9635400000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.1792757430812344,
    "rps": 572.1231769567178,
    "parallel": 100,
    "p99_time": 0.18348059412208387,
    "mean_time": 0.1671890308333561,
    "mean_precisions": 0.9868400000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.0026985987031366678,
    "rps": 366.2523681371561,
    "parallel": 1,
    "p99_time": 0.0029809768556151553,
    "mean_time": 0.0022082160839345306,
    "mean_precisions": 0.8020200000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.0027785696671344343,
    "rps": 362.7127210480121,
    "parallel": 1,
    "p99_time": 0.0031052831769920915,
    "mean_time": 0.002229825541959144,
    "mean_precisions": 0.9072,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.0027947894064709543,
    "rps": 358.555727161457,
    "parallel": 1,
    "p99_time": 0.0031782766233664013,
    "mean_time": 0.0022542915344703944,
    "mean_precisions": 0.9593400000000002,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.002815181581536308,
    "rps": 353.7725335320679,
    "parallel": 1,
    "p99_time": 0.0031862863560672863,
    "mean_time": 0.002293184841889888,
    "mean_precisions": 0.9820199999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.004007823718711734,
    "rps": 268.73394181242793,
    "parallel": 1,
    "p99_time": 0.004526472602738069,
    "mean_time": 0.003132257702993229,
    "mean_precisions": 0.80302,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 222.45490989403334,
    "total_upload_time": 593.0384756129934,
    "p95_time": 0.003966469952138141,
    "rps": 269.87466157225845,
    "parallel": 1,
    "p99_time": 0.004412904541241006,
    "mean_time": 0.003119837749097496,
    "mean_precisions": 0.90912,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.005568687600498373,
    "rps": 222.9897963613241,
    "parallel": 1,
    "p99_time": 0.007436706601038173,
    "mean_time": 0.004422202736891268,
    "mean_precisions": 0.15338200000000002,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.007268607899732158,
    "rps": 176.90806950032066,
    "parallel": 1,
    "p99_time": 0.00898696369094978,
    "mean_time": 0.00558813417370493,
    "mean_precisions": 0.21733200000000003,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.009729377450639728,
    "rps": 132.79520500813044,
    "parallel": 1,
    "p99_time": 0.011663079070531242,
    "mean_time": 0.007447711427499053,
    "mean_precisions": 0.292529,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.014681976149950059,
    "rps": 87.45857404821963,
    "parallel": 1,
    "p99_time": 0.016874247931045833,
    "mean_time": 0.0113318627133076,
    "mean_precisions": 0.378045,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.011129353651358542,
    "rps": 119.33518546084709,
    "parallel": 1,
    "p99_time": 0.013181536690481159,
    "mean_time": 0.008298850848398433,
    "mean_precisions": 0.147598,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.011395410600835015,
    "rps": 115.99633586088007,
    "parallel": 1,
    "p99_time": 0.013322178418675324,
    "mean_time": 0.00853892026859703,
    "mean_precisions": 0.210612,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.011166345849687787,
    "rps": 117.63479034387404,
    "parallel": 1,
    "p99_time": 0.012955952128504578,
    "mean_time": 0.00841232220310758,
    "mean_precisions": 0.286369,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.014564992550640454,
    "rps": 88.55146457527654,
    "parallel": 1,
    "p99_time": 0.016695034530057457,
    "mean_time": 0.01118843516248835,
    "mean_precisions": 0.378045,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.06407658399994035,
    "rps": 1658.8667974649447,
    "parallel": 100,
    "p99_time": 0.07098885064970091,
    "mean_time": 0.057229602454793714,
    "mean_precisions": 0.15338200000000002,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.08793117545010318,
    "rps": 1211.8539732017423,
    "parallel": 100,
    "p99_time": 0.09317730250046226,
    "mean_time": 0.08002476033121383,
    "mean_precisions": 0.21733200000000003,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.12927569375015083,
    "rps": 819.2628791207036,
    "parallel": 100,
    "p99_time": 0.1351644041297186,
    "mean_time": 0.11950917601541715,
    "mean_precisions": 0.292529,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.21301938570004494,
    "rps": 502.65796610297934,
    "parallel": 100,
    "p99_time": 0.21889273867895098,
    "mean_time": 0.19632021282339573,
    "mean_precisions": 0.37804499999999996,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.010408586999437829,
    "rps": 127.63643083462851,
    "parallel": 1,
    "p99_time": 0.01238083864995133,
    "mean_time": 0.0077539580295055205,
    "mean_precisions": 0.292529,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.0714953746498395,
    "rps": 1493.5869265181989,
    "parallel": 100,
    "p99_time": 0.07562864583094779,
    "mean_time": 0.06381332804439935,
    "mean_precisions": 0.150617,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.08783231005081689,
    "rps": 1230.9341509481192,
    "parallel": 100,
    "p99_time": 0.09310306522980683,
    "mean_time": 0.07876790679470869,
    "mean_precisions": 0.21733199999999997,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.12933937464849804,
    "rps": 818.5416187616047,
    "parallel": 100,
    "p99_time": 0.1355609683793591,
    "mean_time": 0.11955584090249194,
    "mean_precisions": 0.29252900000000004,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.21450322500040783,
    "rps": 499.84895149510356,
    "parallel": 100,
    "p99_time": 0.22276636406098987,
    "mean_time": 0.197405829845627,
    "mean_precisions": 0.37804499999999996,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.1011020659487258,
    "rps": 1070.0012664352691,
    "parallel": 100,
    "p99_time": 0.10619035078067102,
    "mean_time": 0.09094239365351386,
    "mean_precisions": 0.14888300000000002,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.10162016234990005,
    "rps": 1059.0038817596712,
    "parallel": 100,
    "p99_time": 0.1082018112413607,
    "mean_time": 0.09202856597470035,
    "mean_precisions": 0.212733,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.1342877917994883,
    "rps": 798.3901162057687,
    "parallel": 100,
    "p99_time": 0.13975451101039654,
    "mean_time": 0.12213693484119739,
    "mean_precisions": 0.292529,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.21522220875103812,
    "rps": 500.29361581931164,
    "parallel": 100,
    "p99_time": 0.22409512149972216,
    "mean_time": 0.19726906626870533,
    "mean_precisions": 0.37804499999999996,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.1579049730005863,
    "rps": 679.31042354117,
    "parallel": 100,
    "p99_time": 0.16657521581968468,
    "mean_time": 0.1447056304315951,
    "mean_precisions": 0.147598,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.15216331069968872,
    "rps": 699.4770029684875,
    "parallel": 100,
    "p99_time": 0.15781552267997542,
    "mean_time": 0.14043210606870216,
    "mean_precisions": 0.21061200000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.01563730794978255,
    "rps": 81.98692659639553,
    "parallel": 1,
    "p99_time": 0.017984986160099657,
    "mean_time": 0.012088612643002488,
    "mean_precisions": 0.378045,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.15628711505078172,
    "rps": 687.8647184272747,
    "parallel": 100,
    "p99_time": 0.16325039553050374,
    "mean_time": 0.14266294799630141,
    "mean_precisions": 0.286369,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.21151018539976574,
    "rps": 500.7248246455445,
    "parallel": 100,
    "p99_time": 0.21913478854976348,
    "mean_time": 0.19707455205550833,
    "mean_precisions": 0.378045,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.006125666000025375,
    "rps": 206.27792648881064,
    "parallel": 1,
    "p99_time": 0.008001009089330184,
    "mean_time": 0.004778041320505144,
    "mean_precisions": 0.15061700000000003,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.0074802435506171544,
    "rps": 174.71150590671343,
    "parallel": 1,
    "p99_time": 0.009127616940186272,
    "mean_time": 0.005650155934103713,
    "mean_precisions": 0.21733200000000003,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.010271643699161358,
    "rps": 127.04399152292063,
    "parallel": 1,
    "p99_time": 0.012332950440395509,
    "mean_time": 0.007781317699097235,
    "mean_precisions": 0.292529,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.014946286899430545,
    "rps": 86.21484157119514,
    "parallel": 1,
    "p99_time": 0.016944464578919,
    "mean_time": 0.01147984240480091,
    "mean_precisions": 0.378045,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.007837382650268407,
    "rps": 165.60608861001788,
    "parallel": 1,
    "p99_time": 0.009721931818803577,
    "mean_time": 0.00596364173010279,
    "mean_precisions": 0.14888300000000002,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 58.02326682400053,
    "total_upload_time": 1094.4807313769998,
    "p95_time": 0.007934538799327125,
    "rps": 163.91267718572848,
    "parallel": 1,
    "p99_time": 0.00967145927024831,
    "mean_time": 0.00602860275490475,
    "mean_precisions": 0.212733,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.0022503482119645923,
    "rps": 415.01572281050665,
    "parallel": 1,
    "p99_time": 0.0025117331999354067,
    "mean_time": 0.0018990931698586791,
    "mean_precisions": 0.75592,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.002244560362305492,
    "rps": 414.03140068757506,
    "parallel": 1,
    "p99_time": 0.0024698590056505057,
    "mean_time": 0.001896595684904605,
    "mean_precisions": 0.88002,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.004980189073830844,
    "rps": 224.04126279330796,
    "parallel": 1,
    "p99_time": 0.005691870644222947,
    "mean_time": 0.003840422384161502,
    "mean_precisions": 0.95242,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.005014099337859079,
    "rps": 222.07556144872336,
    "parallel": 1,
    "p99_time": 0.005621405469719324,
    "mean_time": 0.0038783426202367993,
    "mean_precisions": 0.98198,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.00749306856887415,
    "rps": 157.04026043730644,
    "parallel": 1,
    "p99_time": 0.008658398741390556,
    "mean_time": 0.005709140631207265,
    "mean_precisions": 0.76072,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.0075699340959545225,
    "rps": 156.00491857419675,
    "parallel": 1,
    "p99_time": 0.008862754347501329,
    "mean_time": 0.0057574849186232315,
    "mean_precisions": 0.8869400000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.00767363613122143,
    "rps": 155.51101904356878,
    "parallel": 1,
    "p99_time": 0.008792836687061935,
    "mean_time": 0.005773469379846938,
    "mean_precisions": 0.9532799999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.007738578453427181,
    "rps": 155.13634640711211,
    "parallel": 1,
    "p99_time": 0.00879849111661315,
    "mean_time": 0.0057914603221928705,
    "mean_precisions": 0.98306,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.00268841166398488,
    "rps": 1223.7750402719316,
    "parallel": 100,
    "p99_time": 0.01441460887901486,
    "mean_time": 0.002542047438072041,
    "mean_precisions": 0.75592,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.0027567945828195664,
    "rps": 1213.2818063325435,
    "parallel": 100,
    "p99_time": 0.013704456241102893,
    "mean_time": 0.002409552138019353,
    "mean_precisions": 0.88002,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.002717933157691732,
    "rps": 1228.1926660729941,
    "parallel": 100,
    "p99_time": 0.013768670983845373,
    "mean_time": 0.0024090952354017645,
    "mean_precisions": 0.94386,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.003187974367756398,
    "rps": 1226.7356337424587,
    "parallel": 100,
    "p99_time": 0.013284452632069597,
    "mean_time": 0.002703955432283692,
    "mean_precisions": 0.9747,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.002274182450491935,
    "rps": 412.00809783611265,
    "parallel": 1,
    "p99_time": 0.0024891742249019467,
    "mean_time": 0.0019087991386884824,
    "mean_precisions": 0.94386,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.004575779353035614,
    "rps": 1225.3251105666995,
    "parallel": 100,
    "p99_time": 0.015383316746447242,
    "mean_time": 0.003593485086620785,
    "mean_precisions": 0.75912,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.005007970996666701,
    "rps": 1227.0189510110156,
    "parallel": 100,
    "p99_time": 0.015283621582202615,
    "mean_time": 0.003638314202823676,
    "mean_precisions": 0.8847800000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.0050986969086807225,
    "rps": 1224.8441331416348,
    "parallel": 100,
    "p99_time": 0.015056060742354023,
    "mean_time": 0.0037018268988234923,
    "mean_precisions": 0.9501799999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.004852698929607869,
    "rps": 1216.1745964477457,
    "parallel": 100,
    "p99_time": 0.014574580831686062,
    "mean_time": 0.0036594888299005105,
    "mean_precisions": 0.9793200000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.11462482594652101,
    "rps": 880.8019963111104,
    "parallel": 100,
    "p99_time": 0.11594447560957634,
    "mean_time": 0.1039163375377655,
    "mean_precisions": 0.76046,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.11543408578727395,
    "rps": 881.4170546202821,
    "parallel": 100,
    "p99_time": 0.1172601990425028,
    "mean_time": 0.10448508531041444,
    "mean_precisions": 0.8860800000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.1148380767146591,
    "rps": 876.7655560090909,
    "parallel": 100,
    "p99_time": 0.11774035312584602,
    "mean_time": 0.10442023815724533,
    "mean_precisions": 0.95242,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.11631571293110028,
    "rps": 865.4979939507242,
    "parallel": 100,
    "p99_time": 0.11798673412995413,
    "mean_time": 0.10648929068562575,
    "mean_precisions": 0.98198,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.19638560996972956,
    "rps": 523.7120136831784,
    "parallel": 100,
    "p99_time": 0.19968595063081013,
    "mean_time": 0.18308127035452054,
    "mean_precisions": 0.76072,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.20014767559478058,
    "rps": 515.3066121579195,
    "parallel": 100,
    "p99_time": 0.20296373039484025,
    "mean_time": 0.18632185551906005,
    "mean_precisions": 0.88694,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.0025777433940675112,
    "rps": 377.9153030990962,
    "parallel": 1,
    "p99_time": 0.0028733986464794742,
    "mean_time": 0.0021198349373647944,
    "mean_precisions": 0.9747,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.19868381900014356,
    "rps": 519.5769351991892,
    "parallel": 100,
    "p99_time": 0.201945985914208,
    "mean_time": 0.18543568438328803,
    "mean_precisions": 0.9532799999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.19752884021145292,
    "rps": 519.954087990623,
    "parallel": 100,
    "p99_time": 0.20113577464711854,
    "mean_time": 0.18465703264067415,
    "mean_precisions": 0.9830600000000003,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.0031387946044560524,
    "rps": 322.5983770834678,
    "parallel": 1,
    "p99_time": 0.0035355377115774923,
    "mean_time": 0.0025490725103067234,
    "mean_precisions": 0.75912,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.003062958922237158,
    "rps": 322.5988290166309,
    "parallel": 1,
    "p99_time": 0.0033987351239193235,
    "mean_time": 0.00254508411353454,
    "mean_precisions": 0.8847800000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.0031135363737121225,
    "rps": 319.8999095726588,
    "parallel": 1,
    "p99_time": 0.00340904810349457,
    "mean_time": 0.0025669612352969126,
    "mean_precisions": 0.9501799999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.0031593527819495652,
    "rps": 315.44520818669025,
    "parallel": 1,
    "p99_time": 0.003485763014759871,
    "mean_time": 0.002615294300764799,
    "mean_precisions": 0.9793200000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.004906398913590238,
    "rps": 225.50739174623126,
    "parallel": 1,
    "p99_time": 0.005606873921351508,
    "mean_time": 0.0038152491593500598,
    "mean_precisions": 0.76046,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 224.44683034694754,
    "total_upload_time": 1103.0889565509278,
    "p95_time": 0.004946194979129359,
    "rps": 223.71405401180203,
    "parallel": 1,
    "p99_time": 0.005555029965471478,
    "mean_time": 0.0038471245975000784,
    "mean_precisions": 0.8860800000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.005754249749952578,
    "rps": 219.08345404809825,
    "parallel": 1,
    "p99_time": 0.0075128233194664065,
    "mean_time": 0.004500754479599891,
    "mean_precisions": 0.15217599999999998,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.0076274931990155835,
    "rps": 168.24903058354712,
    "parallel": 1,
    "p99_time": 0.009228122049098604,
    "mean_time": 0.005869887730089613,
    "mean_precisions": 0.21578500000000003,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.010764504199050859,
    "rps": 121.62864098175837,
    "parallel": 1,
    "p99_time": 0.012527871159418285,
    "mean_time": 0.008140566407002007,
    "mean_precisions": 0.290968,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.015879289300755772,
    "rps": 79.69754337767232,
    "parallel": 1,
    "p99_time": 0.01808094073974644,
    "mean_time": 0.012436585395309886,
    "mean_precisions": 0.37678899999999993,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.012208386499969493,
    "rps": 106.06161997176912,
    "parallel": 1,
    "p99_time": 0.013978789799966763,
    "mean_time": 0.009335026444805408,
    "mean_precisions": 0.146947,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.01209713590042156,
    "rps": 106.10389141496012,
    "parallel": 1,
    "p99_time": 0.013881889931089976,
    "mean_time": 0.009334400376592566,
    "mean_precisions": 0.209657,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.011801228749936853,
    "rps": 107.96284931042551,
    "parallel": 1,
    "p99_time": 0.013733791279864824,
    "mean_time": 0.009168099301613074,
    "mean_precisions": 0.285059,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.015490437750304406,
    "rps": 81.16778579560994,
    "parallel": 1,
    "p99_time": 0.017701614300713122,
    "mean_time": 0.012215285867415696,
    "mean_precisions": 0.37678899999999993,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.06794876709973323,
    "rps": 1572.4935552689421,
    "parallel": 100,
    "p99_time": 0.07209148842935974,
    "mean_time": 0.06034028376179704,
    "mean_precisions": 0.152176,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.09067838339915396,
    "rps": 1166.6105538074075,
    "parallel": 100,
    "p99_time": 0.09623842538003373,
    "mean_time": 0.08311632529879753,
    "mean_precisions": 0.215785,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.13984030159908795,
    "rps": 763.419541576526,
    "parallel": 100,
    "p99_time": 0.14667043045088576,
    "mean_time": 0.12840925486579471,
    "mean_precisions": 0.290968,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.2341827487987757,
    "rps": 456.07607913986874,
    "parallel": 100,
    "p99_time": 0.24502383077926423,
    "mean_time": 0.21651481559609964,
    "mean_precisions": 0.37678900000000004,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.010948762150474066,
    "rps": 118.37597571031816,
    "parallel": 1,
    "p99_time": 0.01271307608987627,
    "mean_time": 0.008362177810290814,
    "mean_precisions": 0.290968,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.07491807734804751,
    "rps": 1422.0701255898846,
    "parallel": 100,
    "p99_time": 0.07887201425168314,
    "mean_time": 0.06706654691138829,
    "mean_precisions": 0.149647,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.09256227729765669,
    "rps": 1159.7117019425275,
    "parallel": 100,
    "p99_time": 0.09794801856183767,
    "mean_time": 0.0838435152641403,
    "mean_precisions": 0.215785,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.13920595919971673,
    "rps": 767.0395875380902,
    "parallel": 100,
    "p99_time": 0.1442555274805636,
    "mean_time": 0.12781929515641824,
    "mean_precisions": 0.290968,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.23286746670073624,
    "rps": 458.05596760224444,
    "parallel": 100,
    "p99_time": 0.24096264197218262,
    "mean_time": 0.21565529934419356,
    "mean_precisions": 0.376789,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.10711605545093335,
    "rps": 1019.9284759163971,
    "parallel": 100,
    "p99_time": 0.1138420982829848,
    "mean_time": 0.09555829328321852,
    "mean_precisions": 0.148171,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.10704761889974179,
    "rps": 1006.6565813722815,
    "parallel": 100,
    "p99_time": 0.1128454964701814,
    "mean_time": 0.09693528132609536,
    "mean_precisions": 0.21120999999999998,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.14099973354932444,
    "rps": 762.2635355102587,
    "parallel": 100,
    "p99_time": 0.14874040156304547,
    "mean_time": 0.12864885881849622,
    "mean_precisions": 0.290968,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.23057355634937265,
    "rps": 466.59170961372905,
    "parallel": 100,
    "p99_time": 0.24224625795053725,
    "mean_time": 0.21156524074019797,
    "mean_precisions": 0.37678900000000004,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.1634508930512311,
    "rps": 653.3540951511222,
    "parallel": 100,
    "p99_time": 0.17074583917034034,
    "mean_time": 0.15057165140571632,
    "mean_precisions": 0.146947,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.16461044915231468,
    "rps": 650.4943970487643,
    "parallel": 100,
    "p99_time": 0.1727369104412355,
    "mean_time": 0.15116754430250548,
    "mean_precisions": 0.209657,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.0164084211489353,
    "rps": 77.22330269669911,
    "parallel": 1,
    "p99_time": 0.01860339805069089,
    "mean_time": 0.01283550956000381,
    "mean_precisions": 0.37678899999999993,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.16757561444810562,
    "rps": 641.8837466864032,
    "parallel": 100,
    "p99_time": 0.17572477102083212,
    "mean_time": 0.15317389346984964,
    "mean_precisions": 0.285059,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.23108241429927148,
    "rps": 462.9592435998669,
    "parallel": 100,
    "p99_time": 0.24140198234887067,
    "mean_time": 0.2132287888025945,
    "mean_precisions": 0.376789,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.006225205549617382,
    "rps": 202.4597595328744,
    "parallel": 1,
    "p99_time": 0.008074725989954465,
    "mean_time": 0.004866112156302188,
    "mean_precisions": 0.14964699999999997,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.007560223499240234,
    "rps": 171.07806843770243,
    "parallel": 1,
    "p99_time": 0.00924916677988222,
    "mean_time": 0.005774598315408548,
    "mean_precisions": 0.21578500000000003,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.01071230004854442,
    "rps": 120.2528831324137,
    "parallel": 1,
    "p99_time": 0.012541597369290685,
    "mean_time": 0.00823011383019748,
    "mean_precisions": 0.290968,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.016888618550274258,
    "rps": 75.85155808888511,
    "parallel": 1,
    "p99_time": 0.01959560561119361,
    "mean_time": 0.013065032109803906,
    "mean_precisions": 0.37678899999999993,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.008612179000192554,
    "rps": 152.68062347640807,
    "parallel": 1,
    "p99_time": 0.010674762449962147,
    "mean_time": 0.0064703520173943615,
    "mean_precisions": 0.148171,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-bq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 59.116963147000206,
    "total_upload_time": 2729.5538194969995,
    "p95_time": 0.008361382800012505,
    "rps": 152.54760164328437,
    "parallel": 1,
    "p99_time": 0.010020831771216763,
    "mean_time": 0.006483734548305256,
    "mean_precisions": 0.21121000000000004,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 238.42200625600526,
    "total_upload_time": 910.2488787590119,
    "p95_time": 0.0029313841499060806,
    "rps": 346.2080238720009,
    "parallel": 1,
    "p99_time": 0.003288380369951938,
    "mean_time": 0.002327026510199539,
    "mean_precisions": 0.9665799999999999,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 238.42200625600526,
    "total_upload_time": 910.2488787590119,
    "p95_time": 0.004177707049996117,
    "rps": 261.5076837239442,
    "parallel": 1,
    "p99_time": 0.004798319469944094,
    "mean_time": 0.003199097125999106,
    "mean_precisions": 0.9836800000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 238.42200625600526,
    "total_upload_time": 910.2488787590119,
    "p95_time": 0.005223112099895389,
    "rps": 1260.5282889991831,
    "parallel": 100,
    "p99_time": 0.008068365889898824,
    "mean_time": 0.003263794908599175,
    "mean_precisions": 0.9665799999999999,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 238.42200625600526,
    "total_upload_time": 910.2488787590119,
    "p95_time": 0.11050786064981821,
    "rps": 920.5136432254327,
    "parallel": 100,
    "p99_time": 0.11177302519988644,
    "mean_time": 0.1016133293905998,
    "mean_precisions": 0.9836799999999999,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 238.42200625600526,
    "total_upload_time": 910.2488787590119,
    "p95_time": 0.18823315499993215,
    "rps": 541.8998921433692,
    "parallel": 100,
    "p99_time": 0.19100036953992458,
    "mean_time": 0.1784472670251996,
    "mean_precisions": 0.9914,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 238.42200625600526,
    "total_upload_time": 910.2488787590119,
    "p95_time": 0.32914919420009026,
    "rps": 312.85779398911956,
    "parallel": 100,
    "p99_time": 0.333565036669861,
    "mean_time": 0.31388763648740015,
    "mean_precisions": 0.9955,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 238.42200625600526,
    "total_upload_time": 910.2488787590119,
    "p95_time": 0.00558018295008651,
    "rps": 196.474650798234,
    "parallel": 1,
    "p99_time": 0.006211642810060312,
    "mean_time": 0.0044395907161982,
    "mean_precisions": 0.9914,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 238.42200625600526,
    "total_upload_time": 910.2488787590119,
    "p95_time": 0.009755059050064574,
    "rps": 129.68928230254153,
    "parallel": 1,
    "p99_time": 0.011872956359927685,
    "mean_time": 0.007044820040400327,
    "mean_precisions": 0.9955,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1464.936949934,
    "total_upload_time": 1936.95878214,
    "p95_time": 0.003432763600721955,
    "rps": 321.3463543329688,
    "parallel": 1,
    "p99_time": 0.003825631989166142,
    "mean_time": 0.003050727408286184,
    "mean_precisions": 0.8941459999999999,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1464.936949934,
    "total_upload_time": 1936.95878214,
    "p95_time": 0.003605476720258593,
    "rps": 305.17394608693974,
    "parallel": 1,
    "p99_time": 0.0039226973801851275,
    "mean_time": 0.003213082034140825,
    "mean_precisions": 0.926127,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1464.936949934,
    "total_upload_time": 1936.95878214,
    "p95_time": 0.06266824272461236,
    "rps": 1613.9061073402293,
    "parallel": 100,
    "p99_time": 0.06436275746673345,
    "mean_time": 0.05986746261715889,
    "mean_precisions": 0.8941459999999999,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1464.936949934,
    "total_upload_time": 1936.95878214,
    "p95_time": 0.077494016289711,
    "rps": 1288.3976491750248,
    "parallel": 100,
    "p99_time": 0.0787774110864848,
    "mean_time": 0.07498231315482408,
    "mean_precisions": 0.926127,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1464.936949934,
    "total_upload_time": 1936.95878214,
    "p95_time": 0.09595144633203745,
    "rps": 1059.4288173599527,
    "parallel": 100,
    "p99_time": 0.09824380089528859,
    "mean_time": 0.0922344725864008,
    "mean_precisions": 0.9679260000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1464.936949934,
    "total_upload_time": 1936.95878214,
    "p95_time": 0.13034787494689226,
    "rps": 785.1994472192704,
    "parallel": 100,
    "p99_time": 0.1340391770657152,
    "mean_time": 0.1252096754369326,
    "mean_precisions": 0.987043,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1464.936949934,
    "total_upload_time": 1936.95878214,
    "p95_time": 0.0042120733764022585,
    "rps": 260.59572876168045,
    "parallel": 1,
    "p99_time": 0.004605777375400067,
    "mean_time": 0.0037712595774792136,
    "mean_precisions": 0.9679260000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 1464.936949934,
    "total_upload_time": 1936.95878214,
    "p95_time": 0.005462657893076539,
    "rps": 207.5777054234448,
    "parallel": 1,
    "p99_time": 0.005979722440242767,
    "mean_time": 0.004747379661444575,
    "mean_precisions": 0.987043,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 162.90116923197638,
    "total_upload_time": 662.2031776579679,
    "p95_time": 0.004761035292176529,
    "rps": 245.22489170710102,
    "parallel": 1,
    "p99_time": 0.006716843114700166,
    "mean_time": 0.003994918125565163,
    "mean_precisions": 0.73861,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 162.90116923197638,
    "total_upload_time": 662.2031776579679,
    "p95_time": 0.005516869918210432,
    "rps": 223.68658791304995,
    "parallel": 1,
    "p99_time": 0.0067508854321204105,
    "mean_time": 0.004384029640583322,
    "mean_precisions": 0.79011,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 162.90116923197638,
    "total_upload_time": 662.2031776579679,
    "p95_time": 0.072279235010501,
    "rps": 1283.7553339001836,
    "parallel": 100,
    "p99_time": 0.07426636104588397,
    "mean_time": 0.056817075302358716,
    "mean_precisions": 0.7386099999999999,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 162.90116923197638,
    "total_upload_time": 662.2031776579679,
    "p95_time": 0.09615494584431872,
    "rps": 1017.2008511224242,
    "parallel": 100,
    "p99_time": 0.09825160655076616,
    "mean_time": 0.07674532864964567,
    "mean_precisions": 0.79011,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 162.90116923197638,
    "total_upload_time": 662.2031776579679,
    "p95_time": 0.15474128689384087,
    "rps": 657.69523798573,
    "parallel": 100,
    "p99_time": 0.15686275582062081,
    "mean_time": 0.13190773885080126,
    "mean_precisions": 0.87919,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 162.90116923197638,
    "total_upload_time": 662.2031776579679,
    "p95_time": 0.2560046433005482,
    "rps": 408.10779878423267,
    "parallel": 100,
    "p99_time": 0.25984877929207867,
    "mean_time": 0.22249870683532208,
    "mean_precisions": 0.9365899999999999,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 162.90116923197638,
    "total_upload_time": 662.2031776579679,
    "p95_time": 0.007620009157108138,
    "rps": 160.7186795503382,
    "parallel": 1,
    "p99_time": 0.00955379270366393,
    "mean_time": 0.006131253018858842,
    "mean_precisions": 0.87919,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 162.90116923197638,
    "total_upload_time": 662.2031776579679,
    "p95_time": 0.012177355313906445,
    "rps": 106.5093029830546,
    "parallel": 1,
    "p99_time": 0.01355179367121309,
    "mean_time": 0.009292680775979533,
    "mean_precisions": 0.93659,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.486052633001236,
    "total_upload_time": 322.12088411999866,
    "p95_time": 0.0030491131008602676,
    "rps": 365.30928417857154,
    "parallel": 1,
    "p99_time": 0.0041066526039503564,
    "mean_time": 0.0026797526543494315,
    "mean_precisions": 0.6941620000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.486052633001236,
    "total_upload_time": 322.12088411999866,
    "p95_time": 0.003177879052236676,
    "rps": 349.6225216653747,
    "parallel": 1,
    "p99_time": 0.003715443904511631,
    "mean_time": 0.00279940714975819,
    "mean_precisions": 0.726136,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.486052633001236,
    "total_upload_time": 322.12088411999866,
    "p95_time": 0.037889149133116,
    "rps": 3029.196166782227,
    "parallel": 100,
    "p99_time": 0.0443061170121655,
    "mean_time": 0.030677990901004523,
    "mean_precisions": 0.694162,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.486052633001236,
    "total_upload_time": 322.12088411999866,
    "p95_time": 0.04039279280696063,
    "rps": 2777.698836348256,
    "parallel": 100,
    "p99_time": 0.046481808475218725,
    "mean_time": 0.03336424119032454,
    "mean_precisions": 0.726136,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.486052633001236,
    "total_upload_time": 322.12088411999866,
    "p95_time": 0.0480691772303544,
    "rps": 2232.687731164946,
    "parallel": 100,
    "p99_time": 0.05343608367256821,
    "mean_time": 0.04272332464356441,
    "mean_precisions": 0.80291,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.486052633001236,
    "total_upload_time": 322.12088411999866,
    "p95_time": 0.06535199607023968,
    "rps": 1603.1050107699052,
    "parallel": 100,
    "p99_time": 0.06990242686122657,
    "mean_time": 0.06042917914856225,
    "mean_precisions": 0.8636650000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.486052633001236,
    "total_upload_time": 322.12088411999866,
    "p95_time": 0.0038855136022903024,
    "rps": 290.07275390480913,
    "parallel": 1,
    "p99_time": 0.004838651688769462,
    "mean_time": 0.003383973466604948,
    "mean_precisions": 0.80291,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.486052633001236,
    "total_upload_time": 322.12088411999866,
    "p95_time": 0.005073237349279225,
    "rps": 226.69853557268635,
    "parallel": 1,
    "p99_time": 0.006872109121177346,
    "mean_time": 0.004344028668082319,
    "mean_precisions": 0.863665,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 232.63992904900806,
    "total_upload_time": 976.3964438080147,
    "p95_time": 0.003619733200184783,
    "rps": 294.911621536127,
    "parallel": 1,
    "p99_time": 0.004194097040035559,
    "mean_time": 0.0027982483578006395,
    "mean_precisions": 0.9759400000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 232.63992904900806,
    "total_upload_time": 976.3964438080147,
    "p95_time": 0.005056583199984743,
    "rps": 223.41924288756877,
    "parallel": 1,
    "p99_time": 0.005988737339698679,
    "mean_time": 0.0038312007036006433,
    "mean_precisions": 0.9877,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 232.63992904900806,
    "total_upload_time": 976.3964438080147,
    "p95_time": 0.08612562119997165,
    "rps": 1166.6739385064623,
    "parallel": 100,
    "p99_time": 0.08916189207010579,
    "mean_time": 0.07232519235579803,
    "mean_precisions": 0.9759400000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 232.63992904900806,
    "total_upload_time": 976.3964438080147,
    "p95_time": 0.1447148766497321,
    "rps": 711.7812077793762,
    "parallel": 100,
    "p99_time": 0.1464633267300178,
    "mean_time": 0.13470317042779945,
    "mean_precisions": 0.9877,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 232.63992904900806,
    "total_upload_time": 976.3964438080147,
    "p95_time": 0.24457380240025942,
    "rps": 421.87684183123,
    "parallel": 100,
    "p99_time": 0.24839107811993474,
    "mean_time": 0.23187833085399717,
    "mean_precisions": 0.9935799999999999,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 232.63992904900806,
    "total_upload_time": 976.3964438080147,
    "p95_time": 0.4200033868998162,
    "rps": 245.7369931498206,
    "parallel": 100,
    "p99_time": 0.4280663790900917,
    "mean_time": 0.3990280582043999,
    "mean_precisions": 0.99674,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 232.63992904900806,
    "total_upload_time": 976.3964438080147,
    "p95_time": 0.00764277720015798,
    "rps": 160.73331730139094,
    "parallel": 1,
    "p99_time": 0.008815381549875384,
    "mean_time": 0.005573312640999484,
    "mean_precisions": 0.9935799999999999,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 232.63992904900806,
    "total_upload_time": 976.3964438080147,
    "p95_time": 0.012310930399962672,
    "rps": 106.23903215854091,
    "parallel": 1,
    "p99_time": 0.014421750579922454,
    "mean_time": 0.008753874341197116,
    "mean_precisions": 0.99674,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 595.7114245319972,
    "total_upload_time": 2080.965743687004,
    "p95_time": 0.003866372024640441,
    "rps": 296.24638405773266,
    "parallel": 1,
    "p99_time": 0.006343749370425945,
    "mean_time": 0.003314221282955259,
    "mean_precisions": 0.924491,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 595.7114245319972,
    "total_upload_time": 2080.965743687004,
    "p95_time": 0.0038468218408524986,
    "rps": 290.8386908453719,
    "parallel": 1,
    "p99_time": 0.004450153196230531,
    "mean_time": 0.0033763263376429676,
    "mean_precisions": 0.946839,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 595.7114245319972,
    "total_upload_time": 2080.965743687004,
    "p95_time": 0.06449793758802116,
    "rps": 1573.3332089095081,
    "parallel": 100,
    "p99_time": 0.06670877463184298,
    "mean_time": 0.06118561698887497,
    "mean_precisions": 0.924491,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 595.7114245319972,
    "total_upload_time": 2080.965743687004,
    "p95_time": 0.0796124794986099,
    "rps": 1274.0105539890126,
    "parallel": 100,
    "p99_time": 0.08304492541588843,
    "mean_time": 0.07621860861824825,
    "mean_precisions": 0.946839,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 595.7114245319972,
    "total_upload_time": 2080.965743687004,
    "p95_time": 0.1305953104048967,
    "rps": 984.900893864654,
    "parallel": 100,
    "p99_time": 0.14849094603210689,
    "mean_time": 0.09926712450273335,
    "mean_precisions": 0.9785280000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 595.7114245319972,
    "total_upload_time": 2080.965743687004,
    "p95_time": 0.1396208037622273,
    "rps": 738.3064166784529,
    "parallel": 100,
    "p99_time": 0.14227696876972915,
    "mean_time": 0.13306286735069006,
    "mean_precisions": 0.991965,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 595.7114245319972,
    "total_upload_time": 2080.965743687004,
    "p95_time": 0.004647806286811829,
    "rps": 243.12818605169392,
    "parallel": 1,
    "p99_time": 0.005105723375454546,
    "mean_time": 0.004040738967619836,
    "mean_precisions": 0.9785280000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 595.7114245319972,
    "total_upload_time": 2080.965743687004,
    "p95_time": 0.006169995944947003,
    "rps": 190.89606994130145,
    "parallel": 1,
    "p99_time": 0.006611850950866939,
    "mean_time": 0.005166572865098715,
    "mean_precisions": 0.991965,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 148.5530198829947,
    "total_upload_time": 647.2861472649965,
    "p95_time": 0.005416395101929083,
    "rps": 232.777535337662,
    "parallel": 1,
    "p99_time": 0.006721187463263049,
    "mean_time": 0.004214877348393202,
    "mean_precisions": 0.829,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 148.5530198829947,
    "total_upload_time": 647.2861472649965,
    "p95_time": 0.005963531840825453,
    "rps": 201.40393182574914,
    "parallel": 1,
    "p99_time": 0.007173237530514597,
    "mean_time": 0.004879452961497009,
    "mean_precisions": 0.8912100000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 148.5530198829947,
    "total_upload_time": 647.2861472649965,
    "p95_time": 0.1102744102186989,
    "rps": 906.8902047870002,
    "parallel": 100,
    "p99_time": 0.11240949708037078,
    "mean_time": 0.09038239588798024,
    "mean_precisions": 0.829,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 148.5530198829947,
    "total_upload_time": 647.2861472649965,
    "p95_time": 0.16495275772758758,
    "rps": 624.594964632148,
    "parallel": 100,
    "p99_time": 0.16822183526237494,
    "mean_time": 0.13856040014093743,
    "mean_precisions": 0.8912100000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 148.5530198829947,
    "total_upload_time": 647.2861472649965,
    "p95_time": 0.2720008747302927,
    "rps": 390.9390618232577,
    "parallel": 100,
    "p99_time": 0.27761930790147743,
    "mean_time": 0.23245563338894862,
    "mean_precisions": 0.94978,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 148.5530198829947,
    "total_upload_time": 647.2861472649965,
    "p95_time": 0.45272507324116307,
    "rps": 237.80023948039562,
    "parallel": 100,
    "p99_time": 0.46339316191850227,
    "mean_time": 0.3903204154353589,
    "mean_precisions": 0.9794,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 148.5530198829947,
    "total_upload_time": 647.2861472649965,
    "p95_time": 0.009619638801086693,
    "rps": 136.3367123481661,
    "parallel": 1,
    "p99_time": 0.010429681164678186,
    "mean_time": 0.007243214334477671,
    "mean_precisions": 0.94978,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 148.5530198829947,
    "total_upload_time": 647.2861472649965,
    "p95_time": 0.014511867536930368,
    "rps": 92.09337129283011,
    "parallel": 1,
    "p99_time": 0.01625598353683017,
    "mean_time": 0.010762147759203798,
    "mean_precisions": 0.9794,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 63.99415807600599,
    "total_upload_time": 385.87576489901403,
    "p95_time": 0.003233875858131796,
    "rps": 345.58314263909983,
    "parallel": 1,
    "p99_time": 0.0036162509024143235,
    "mean_time": 0.0028338772267801687,
    "mean_precisions": 0.748418,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 63.99415807600599,
    "total_upload_time": 385.87576489901403,
    "p95_time": 0.0035045876982621846,
    "rps": 322.3039927223977,
    "parallel": 1,
    "p99_time": 0.0038319551828317347,
    "mean_time": 0.0030383065642323346,
    "mean_precisions": 0.778266,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 63.99415807600599,
    "total_upload_time": 385.87576489901403,
    "p95_time": 0.04234530073590576,
    "rps": 2650.6631697685034,
    "parallel": 100,
    "p99_time": 0.048642504957970255,
    "mean_time": 0.034860896968073214,
    "mean_precisions": 0.7484179999999999,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 63.99415807600599,
    "total_upload_time": 385.87576489901403,
    "p95_time": 0.04447329676477238,
    "rps": 2505.6607706606815,
    "parallel": 100,
    "p99_time": 0.050756044923327866,
    "mean_time": 0.03755958657669835,
    "mean_precisions": 0.778266,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 63.99415807600599,
    "total_upload_time": 385.87576489901403,
    "p95_time": 0.0573718536295928,
    "rps": 1852.6611124497404,
    "parallel": 100,
    "p99_time": 0.06243435068521649,
    "mean_time": 0.05188427007347345,
    "mean_precisions": 0.849908,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 63.99415807600599,
    "total_upload_time": 385.87576489901403,
    "p95_time": 0.08604702898301184,
    "rps": 1233.066523414409,
    "parallel": 100,
    "p99_time": 0.08969426712486893,
    "mean_time": 0.07883982370540034,
    "mean_precisions": 0.905983,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 63.99415807600599,
    "total_upload_time": 385.87576489901403,
    "p95_time": 0.004613978241104632,
    "rps": 252.5466997222076,
    "parallel": 1,
    "p99_time": 0.005313679766841234,
    "mean_time": 0.0038889596468070524,
    "mean_precisions": 0.849908,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 63.99415807600599,
    "total_upload_time": 385.87576489901403,
    "p95_time": 0.006438321247696876,
    "rps": 188.07487940124983,
    "parallel": 1,
    "p99_time": 0.006981009168084713,
    "mean_time": 0.005239305862318725,
    "mean_precisions": 0.905983,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 240.50372104198323,
    "total_upload_time": 1574.094076620997,
    "p95_time": 0.0036487832000148047,
    "rps": 281.66571868172747,
    "parallel": 1,
    "p99_time": 0.004185443050700997,
    "mean_time": 0.002951470735001385,
    "mean_precisions": 0.98424,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 240.50372104198323,
    "total_upload_time": 1574.094076620997,
    "p95_time": 0.00527097650065116,
    "rps": 208.46544252261816,
    "parallel": 1,
    "p99_time": 0.0059919517993694184,
    "mean_time": 0.0041542233926020345,
    "mean_precisions": 0.9938799999999999,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 240.50372104198323,
    "total_upload_time": 1574.094076620997,
    "p95_time": 0.10123151134989712,
    "rps": 1001.1308249206421,
    "parallel": 100,
    "p99_time": 0.10276059209932101,
    "mean_time": 0.09164273359839717,
    "mean_precisions": 0.98424,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 240.50372104198323,
    "total_upload_time": 1574.094076620997,
    "p95_time": 0.17076743830016314,
    "rps": 601.2768609836063,
    "parallel": 100,
    "p99_time": 0.17482922633982526,
    "mean_time": 0.1609985772448128,
    "mean_precisions": 0.9938799999999999,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 240.50372104198323,
    "total_upload_time": 1574.094076620997,
    "p95_time": 0.29186705140068625,
    "rps": 351.8713124818412,
    "parallel": 100,
    "p99_time": 0.2952057140101988,
    "mean_time": 0.27761640682519645,
    "mean_precisions": 0.9970600000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 240.50372104198323,
    "total_upload_time": 1574.094076620997,
    "p95_time": 0.5040100622499267,
    "rps": 204.88695380394975,
    "parallel": 100,
    "p99_time": 0.5107075620999422,
    "mean_time": 0.48050084470320037,
    "mean_precisions": 0.99866,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 240.50372104198323,
    "total_upload_time": 1574.094076620997,
    "p95_time": 0.008591761450088598,
    "rps": 142.92710828200282,
    "parallel": 1,
    "p99_time": 0.010019119059925294,
    "mean_time": 0.0063433363292089776,
    "mean_precisions": 0.9970600000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 240.50372104198323,
    "total_upload_time": 1574.094076620997,
    "p95_time": 0.014959656799555887,
    "rps": 89.86126320185278,
    "parallel": 1,
    "p99_time": 0.01728583442998571,
    "mean_time": 0.010461787393808299,
    "mean_precisions": 0.99866,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 627.7186440769583,
    "total_upload_time": 4414.400991358911,
    "p95_time": 0.0038509813137352464,
    "rps": 291.58173438089153,
    "parallel": 1,
    "p99_time": 0.006692649181932213,
    "mean_time": 0.0033683212071657182,
    "mean_precisions": 0.947161,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 627.7186440769583,
    "total_upload_time": 4414.400991358911,
    "p95_time": 0.004192829364910721,
    "rps": 276.3754482495746,
    "parallel": 1,
    "p99_time": 0.004643324473872782,
    "mean_time": 0.0035519533031620086,
    "mean_precisions": 0.9704790000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 627.7186440769583,
    "total_upload_time": 4414.400991358911,
    "p95_time": 0.0801780228037387,
    "rps": 1284.936442599179,
    "parallel": 100,
    "p99_time": 0.08443146518431605,
    "mean_time": 0.0757140115221031,
    "mean_precisions": 0.947161,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 627.7186440769583,
    "total_upload_time": 4414.400991358911,
    "p95_time": 0.10520868357270956,
    "rps": 969.0992135754107,
    "parallel": 100,
    "p99_time": 0.11180624491535128,
    "mean_time": 0.10096136395549402,
    "mean_precisions": 0.9704790000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 627.7186440769583,
    "total_upload_time": 4414.400991358911,
    "p95_time": 0.1393495569936931,
    "rps": 733.0714728658778,
    "parallel": 100,
    "p99_time": 0.1415280966926366,
    "mean_time": 0.13421046615997329,
    "mean_precisions": 0.9904470000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 627.7186440769583,
    "total_upload_time": 4414.400991358911,
    "p95_time": 0.20331145604141057,
    "rps": 508.01076537602177,
    "parallel": 100,
    "p99_time": 0.20655682428739966,
    "mean_time": 0.19434574462538584,
    "mean_precisions": 0.9971770000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 627.7186440769583,
    "total_upload_time": 4414.400991358911,
    "p95_time": 0.005432577384635806,
    "rps": 223.13006226997504,
    "parallel": 1,
    "p99_time": 0.006014557527378202,
    "mean_time": 0.004414193203207105,
    "mean_precisions": 0.9904470000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 627.7186440769583,
    "total_upload_time": 4414.400991358911,
    "p95_time": 0.007352391583845019,
    "rps": 173.30695857545277,
    "parallel": 1,
    "p99_time": 0.008211999675258996,
    "mean_time": 0.005698734320607036,
    "mean_precisions": 0.9971770000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 142.06457075697836,
    "total_upload_time": 1236.4171061979723,
    "p95_time": 0.005995115381665528,
    "rps": 193.8200359439814,
    "parallel": 1,
    "p99_time": 0.008014058000408112,
    "mean_time": 0.005074141374207102,
    "mean_precisions": 0.83764,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 142.06457075697836,
    "total_upload_time": 1236.4171061979723,
    "p95_time": 0.006702053884509951,
    "rps": 176.7380146202128,
    "parallel": 1,
    "p99_time": 0.0074023549840785555,
    "mean_time": 0.005568845953326672,
    "mean_precisions": 0.8756100000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 142.06457075697836,
    "total_upload_time": 1236.4171061979723,
    "p95_time": 0.10142062834347598,
    "rps": 982.6847681756525,
    "parallel": 100,
    "p99_time": 0.10432271703844889,
    "mean_time": 0.08049111556378193,
    "mean_precisions": 0.8376399999999999,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 142.06457075697836,
    "total_upload_time": 1236.4171061979723,
    "p95_time": 0.13358977129682897,
    "rps": 753.6472599282068,
    "parallel": 100,
    "p99_time": 0.1353864594991319,
    "mean_time": 0.11146397606597748,
    "mean_precisions": 0.87561,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 142.06457075697836,
    "total_upload_time": 1236.4171061979723,
    "p95_time": 0.21937823864282108,
    "rps": 476.1640495364931,
    "parallel": 100,
    "p99_time": 0.22349535061628556,
    "mean_time": 0.1880506471118424,
    "mean_precisions": 0.9424100000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 142.06457075697836,
    "total_upload_time": 1236.4171061979723,
    "p95_time": 0.3639622142713051,
    "rps": 292.61298855385525,
    "parallel": 100,
    "p99_time": 0.3718079211714212,
    "mean_time": 0.31476882911520077,
    "mean_precisions": 0.9772000000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 142.06457075697836,
    "total_upload_time": 1236.4171061979723,
    "p95_time": 0.010167213797103614,
    "rps": 120.35351645474825,
    "parallel": 1,
    "p99_time": 0.010755812623538077,
    "mean_time": 0.008213517914526165,
    "mean_precisions": 0.9424100000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 142.06457075697836,
    "total_upload_time": 1236.4171061979723,
    "p95_time": 0.01621157998451963,
    "rps": 78.84293212287164,
    "parallel": 1,
    "p99_time": 0.018400587021606043,
    "mean_time": 0.012581340287462809,
    "mean_precisions": 0.9772000000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.632560038007796,
    "total_upload_time": 754.4723812700249,
    "p95_time": 0.003547081688884645,
    "rps": 320.21159351476786,
    "parallel": 1,
    "p99_time": 0.00444527052808553,
    "mean_time": 0.0030638952519744635,
    "mean_precisions": 0.7733619999999999,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.632560038007796,
    "total_upload_time": 754.4723812700249,
    "p95_time": 0.0037706472678109997,
    "rps": 299.48118460720144,
    "parallel": 1,
    "p99_time": 0.004238993646577001,
    "mean_time": 0.0032769586871843784,
    "mean_precisions": 0.80461,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.632560038007796,
    "total_upload_time": 754.4723812700249,
    "p95_time": 0.04505237233825027,
    "rps": 2444.9872011499588,
    "parallel": 100,
    "p99_time": 0.05094331298256293,
    "mean_time": 0.037960522650298666,
    "mean_precisions": 0.7733620000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.632560038007796,
    "total_upload_time": 754.4723812700249,
    "p95_time": 0.04754764786921441,
    "rps": 2263.66633390606,
    "parallel": 100,
    "p99_time": 0.052598043705802414,
    "mean_time": 0.04191297342225444,
    "mean_precisions": 0.8046100000000002,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.632560038007796,
    "total_upload_time": 754.4723812700249,
    "p95_time": 0.06413507726974785,
    "rps": 1639.016990884796,
    "parallel": 100,
    "p99_time": 0.06961720832623543,
    "mean_time": 0.05884745837154332,
    "mean_precisions": 0.8774930000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.632560038007796,
    "total_upload_time": 754.4723812700249,
    "p95_time": 0.09928009994328021,
    "rps": 1050.3136530108738,
    "parallel": 100,
    "p99_time": 0.1025438743759878,
    "mean_time": 0.09303388653923757,
    "mean_precisions": 0.9316650000000002,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.632560038007796,
    "total_upload_time": 754.4723812700249,
    "p95_time": 0.0050724779022857545,
    "rps": 229.80424144735426,
    "parallel": 1,
    "p99_time": 0.005646102894097567,
    "mean_time": 0.0042824475147528575,
    "mean_precisions": 0.8774930000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 60.632560038007796,
    "total_upload_time": 754.4723812700249,
    "p95_time": 0.007443511253222823,
    "rps": 163.2202950117109,
    "parallel": 1,
    "p99_time": 0.007947391772177074,
    "mean_time": 0.006045119918882847,
    "mean_precisions": 0.931665,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.41448086799937,
    "total_upload_time": 3131.9855859989766,
    "p95_time": 0.00397656510053821,
    "rps": 261.1873235894333,
    "parallel": 1,
    "p99_time": 0.004511522289813002,
    "mean_time": 0.003217788850598117,
    "mean_precisions": 0.9835200000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.41448086799937,
    "total_upload_time": 3131.9855859989766,
    "p95_time": 0.006055341149976812,
    "rps": 185.52882260492532,
    "parallel": 1,
    "p99_time": 0.007222612349951308,
    "mean_time": 0.004734539201597181,
    "mean_precisions": 0.9941,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.41448086799937,
    "total_upload_time": 3131.9855859989766,
    "p95_time": 0.11226695244954499,
    "rps": 903.8028820027992,
    "parallel": 100,
    "p99_time": 0.11544536740998411,
    "mean_time": 0.10373296666160732,
    "mean_precisions": 0.9835200000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.41448086799937,
    "total_upload_time": 3131.9855859989766,
    "p95_time": 0.1911926593001681,
    "rps": 534.273488663875,
    "parallel": 100,
    "p99_time": 0.1946560540899827,
    "mean_time": 0.1815973763094069,
    "mean_precisions": 0.9941,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.41448086799937,
    "total_upload_time": 3131.9855859989766,
    "p95_time": 0.325589153549754,
    "rps": 315.48638188555384,
    "parallel": 100,
    "p99_time": 0.32870946258985895,
    "mean_time": 0.31092909928740026,
    "mean_precisions": 0.9976,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.41448086799937,
    "total_upload_time": 3131.9855859989766,
    "p95_time": 0.5573308718005137,
    "rps": 183.88846908377587,
    "parallel": 100,
    "p99_time": 0.5636811844999738,
    "mean_time": 0.5347915641810099,
    "mean_precisions": 0.9992200000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.41448086799937,
    "total_upload_time": 3131.9855859989766,
    "p95_time": 0.010429040549843194,
    "rps": 122.77141484114209,
    "parallel": 1,
    "p99_time": 0.012014101810073044,
    "mean_time": 0.007488495844601311,
    "mean_precisions": 0.9976,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.41448086799937,
    "total_upload_time": 3131.9855859989766,
    "p95_time": 0.0162310005001018,
    "rps": 79.27436073993344,
    "parallel": 1,
    "p99_time": 0.0194064456104843,
    "mean_time": 0.011945160562401906,
    "mean_precisions": 0.9992200000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 590.1877605599584,
    "total_upload_time": 7142.509499358013,
    "p95_time": 0.00397347486577928,
    "rps": 288.79907555512165,
    "parallel": 1,
    "p99_time": 0.0059021417517215015,
    "mean_time": 0.0033980204336345196,
    "mean_precisions": 0.950385,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 590.1877605599584,
    "total_upload_time": 7142.509499358013,
    "p95_time": 0.004060539603233338,
    "rps": 276.8807915598099,
    "parallel": 1,
    "p99_time": 0.004505950380116702,
    "mean_time": 0.003546308580506593,
    "mean_precisions": 0.96925,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 590.1877605599584,
    "total_upload_time": 7142.509499358013,
    "p95_time": 0.06792924548499286,
    "rps": 1501.752762036984,
    "parallel": 100,
    "p99_time": 0.07155143318697813,
    "mean_time": 0.06442692568749189,
    "mean_precisions": 0.9503849999999998,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 590.1877605599584,
    "total_upload_time": 7142.509499358013,
    "p95_time": 0.08422888009808957,
    "rps": 1202.021904295535,
    "parallel": 100,
    "p99_time": 0.08862926363945012,
    "mean_time": 0.08033827413581311,
    "mean_precisions": 0.96925,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 590.1877605599584,
    "total_upload_time": 7142.509499358013,
    "p95_time": 0.10848395409993827,
    "rps": 943.0130468417454,
    "parallel": 100,
    "p99_time": 0.11108452709391713,
    "mean_time": 0.10406105041885748,
    "mean_precisions": 0.9910310000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 590.1877605599584,
    "total_upload_time": 7142.509499358013,
    "p95_time": 0.1542342378757894,
    "rps": 669.2497360587028,
    "parallel": 100,
    "p99_time": 0.1566277450788766,
    "mean_time": 0.14733061116253957,
    "mean_precisions": 0.9976440000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 590.1877605599584,
    "total_upload_time": 7142.509499358013,
    "p95_time": 0.005034842249006032,
    "rps": 227.48524389644015,
    "parallel": 1,
    "p99_time": 0.005780199468135836,
    "mean_time": 0.0043260312399826945,
    "mean_precisions": 0.9910310000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 590.1877605599584,
    "total_upload_time": 7142.509499358013,
    "p95_time": 0.0070096014998853205,
    "rps": 172.24558642305928,
    "parallel": 1,
    "p99_time": 0.007882188400253653,
    "mean_time": 0.005732370066270232,
    "mean_precisions": 0.9976440000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 146.28566276002675,
    "total_upload_time": 2161.0912810770096,
    "p95_time": 0.006962971453322097,
    "rps": 174.74900381312713,
    "parallel": 1,
    "p99_time": 0.008671602314570918,
    "mean_time": 0.005638627551612444,
    "mean_precisions": 0.86565,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 146.28566276002675,
    "total_upload_time": 2161.0912810770096,
    "p95_time": 0.007578972436022013,
    "rps": 157.0311715839325,
    "parallel": 1,
    "p99_time": 0.008671717008110131,
    "mean_time": 0.0062783294732216745,
    "mean_precisions": 0.9017800000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 146.28566276002675,
    "total_upload_time": 2161.0912810770096,
    "p95_time": 0.11343736837734468,
    "rps": 889.780980171397,
    "parallel": 100,
    "p99_time": 0.11572579833329655,
    "mean_time": 0.08968947567709255,
    "mean_precisions": 0.8656500000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 146.28566276002675,
    "total_upload_time": 2161.0912810770096,
    "p95_time": 0.15100387065322138,
    "rps": 670.8533236266424,
    "parallel": 100,
    "p99_time": 0.15462983316974716,
    "mean_time": 0.12724414299649653,
    "mean_precisions": 0.90178,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 146.28566276002675,
    "total_upload_time": 2161.0912810770096,
    "p95_time": 0.24167466786457226,
    "rps": 433.9498278502696,
    "parallel": 100,
    "p99_time": 0.24529060054454022,
    "mean_time": 0.20728443163924384,
    "mean_precisions": 0.95985,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 146.28566276002675,
    "total_upload_time": 2161.0912810770096,
    "p95_time": 0.40847341134794984,
    "rps": 263.3893661647915,
    "parallel": 100,
    "p99_time": 0.41689270472968926,
    "mean_time": 0.35103450901946054,
    "mean_precisions": 0.98592,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 146.28566276002675,
    "total_upload_time": 2161.0912810770096,
    "p95_time": 0.01196677667903714,
    "rps": 106.10846877696844,
    "parallel": 1,
    "p99_time": 0.013713203889783471,
    "mean_time": 0.009328807535814122,
    "mean_precisions": 0.9598500000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 146.28566276002675,
    "total_upload_time": 2161.0912810770096,
    "p95_time": 0.018382134957937522,
    "rps": 70.30043783138184,
    "parallel": 1,
    "p99_time": 0.02044106303830631,
    "mean_time": 0.014121853595832363,
    "mean_precisions": 0.98592,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.595890484000847,
    "total_upload_time": 1079.5629729800003,
    "p95_time": 0.00357719943858683,
    "rps": 311.9320676438909,
    "parallel": 1,
    "p99_time": 0.004947609314695003,
    "mean_time": 0.0031451909713912755,
    "mean_precisions": 0.7826789999999999,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.595890484000847,
    "total_upload_time": 1079.5629729800003,
    "p95_time": 0.003872235945891589,
    "rps": 291.5112396812869,
    "parallel": 1,
    "p99_time": 0.0048432690999470765,
    "mean_time": 0.0033690028346842157,
    "mean_precisions": 0.8158740000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.595890484000847,
    "total_upload_time": 1079.5629729800003,
    "p95_time": 0.04610313563607633,
    "rps": 2368.9909081029573,
    "parallel": 100,
    "p99_time": 0.05207971935160459,
    "mean_time": 0.03982297289213166,
    "mean_precisions": 0.782679,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.595890484000847,
    "total_upload_time": 1079.5629729800003,
    "p95_time": 0.049294413765892386,
    "rps": 2163.162293840321,
    "parallel": 100,
    "p99_time": 0.053103195126168436,
    "mean_time": 0.043785061059030704,
    "mean_precisions": 0.815874,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.595890484000847,
    "total_upload_time": 1079.5629729800003,
    "p95_time": 0.06793999098008499,
    "rps": 1531.3582505367774,
    "parallel": 100,
    "p99_time": 0.07281672674231232,
    "mean_time": 0.06302427139845676,
    "mean_precisions": 0.8914920000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.595890484000847,
    "total_upload_time": 1079.5629729800003,
    "p95_time": 0.10877766608027742,
    "rps": 967.3223174429163,
    "parallel": 100,
    "p99_time": 0.11421940565574915,
    "mean_time": 0.10092411645662505,
    "mean_precisions": 0.9449619999999999,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.595890484000847,
    "total_upload_time": 1079.5629729800003,
    "p95_time": 0.005248585052322596,
    "rps": 219.53021083437386,
    "parallel": 1,
    "p99_time": 0.00627833014354111,
    "mean_time": 0.004477008607145399,
    "mean_precisions": 0.8914920000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.595890484000847,
    "total_upload_time": 1079.5629729800003,
    "p95_time": 0.007913747965358197,
    "rps": 152.6208173807525,
    "parallel": 1,
    "p99_time": 0.00932075117481873,
    "mean_time": 0.0064696193346986544,
    "mean_precisions": 0.9449619999999999,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 229.78320517099928,
    "total_upload_time": 1748.192219228018,
    "p95_time": 0.004539325350378931,
    "rps": 245.04862174965382,
    "parallel": 1,
    "p99_time": 0.005249126230137344,
    "mean_time": 0.0034661916987981387,
    "mean_precisions": 0.9869,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 229.78320517099928,
    "total_upload_time": 1748.192219228018,
    "p95_time": 0.0067088098511703725,
    "rps": 179.71963549308222,
    "parallel": 1,
    "p99_time": 0.008193377130392037,
    "mean_time": 0.0049120532583885506,
    "mean_precisions": 0.9944400000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 229.78320517099928,
    "total_upload_time": 1748.192219228018,
    "p95_time": 0.12248038994976014,
    "rps": 839.0269298058073,
    "parallel": 100,
    "p99_time": 0.1250487917809187,
    "mean_time": 0.11249352208457239,
    "mean_precisions": 0.9869,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 229.78320517099928,
    "total_upload_time": 1748.192219228018,
    "p95_time": 0.20306450440020854,
    "rps": 506.98289503835525,
    "parallel": 100,
    "p99_time": 0.2066746170412989,
    "mean_time": 0.19209165963119812,
    "mean_precisions": 0.9944400000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 229.78320517099928,
    "total_upload_time": 1748.192219228018,
    "p95_time": 0.3466691078999247,
    "rps": 298.0578745197191,
    "parallel": 100,
    "p99_time": 0.3541799862907283,
    "mean_time": 0.32939390148780257,
    "mean_precisions": 0.9975799999999999,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 229.78320517099928,
    "total_upload_time": 1748.192219228018,
    "p95_time": 0.5885578880005596,
    "rps": 176.0669720703053,
    "parallel": 100,
    "p99_time": 0.5971916816207523,
    "mean_time": 0.5599046329720091,
    "mean_precisions": 0.9990599999999998,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 229.78320517099928,
    "total_upload_time": 1748.192219228018,
    "p95_time": 0.010604416300066078,
    "rps": 122.10961255761713,
    "parallel": 1,
    "p99_time": 0.012393074549927415,
    "mean_time": 0.007529392087988526,
    "mean_precisions": 0.9975799999999999,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 229.78320517099928,
    "total_upload_time": 1748.192219228018,
    "p95_time": 0.01681874365067415,
    "rps": 79.65357496667572,
    "parallel": 1,
    "p99_time": 0.018706942371354673,
    "mean_time": 0.011885988970801191,
    "mean_precisions": 0.9990599999999998,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 658.2578205890022,
    "total_upload_time": 4875.703027451993,
    "p95_time": 0.004168789554387331,
    "rps": 281.39911398130045,
    "parallel": 1,
    "p99_time": 0.006532817361876387,
    "mean_time": 0.0034891014934517444,
    "mean_precisions": 0.9595980000000002,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 658.2578205890022,
    "total_upload_time": 4875.703027451993,
    "p95_time": 0.004530607722699641,
    "rps": 268.51331100490455,
    "parallel": 1,
    "p99_time": 0.005063237408176065,
    "mean_time": 0.003660304521303624,
    "mean_precisions": 0.977411,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 658.2578205890022,
    "total_upload_time": 4875.703027451993,
    "p95_time": 0.08079627840779721,
    "rps": 1245.3827330061881,
    "parallel": 100,
    "p99_time": 0.08337406229227784,
    "mean_time": 0.07744656158043071,
    "mean_precisions": 0.959598,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 658.2578205890022,
    "total_upload_time": 4875.703027451993,
    "p95_time": 0.10901322020217775,
    "rps": 939.6294762092058,
    "parallel": 100,
    "p99_time": 0.11175790827721357,
    "mean_time": 0.1042766677312553,
    "mean_precisions": 0.977411,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 658.2578205890022,
    "total_upload_time": 4875.703027451993,
    "p95_time": 0.1429049323312938,
    "rps": 720.8167697555758,
    "parallel": 100,
    "p99_time": 0.1467130949255079,
    "mean_time": 0.13652016876526177,
    "mean_precisions": 0.9928110000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 658.2578205890022,
    "total_upload_time": 4875.703027451993,
    "p95_time": 0.20518410834483802,
    "rps": 504.4998073079617,
    "parallel": 100,
    "p99_time": 0.2091970584448427,
    "mean_time": 0.19577132142009213,
    "mean_precisions": 0.9979009999999998,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 658.2578205890022,
    "total_upload_time": 4875.703027451993,
    "p95_time": 0.005510656302794813,
    "rps": 223.4230961370189,
    "parallel": 1,
    "p99_time": 0.006334863277152181,
    "mean_time": 0.004406087694689632,
    "mean_precisions": 0.9928110000000001,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 658.2578205890022,
    "total_upload_time": 4875.703027451993,
    "p95_time": 0.007058924110606311,
    "rps": 178.32194221937397,
    "parallel": 1,
    "p99_time": 0.007953926399350168,
    "mean_time": 0.0055340485676191745,
    "mean_precisions": 0.9979009999999998,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.3222759690252,
    "total_upload_time": 1350.3348185530049,
    "p95_time": 0.007387157599441707,
    "rps": 171.12795479100637,
    "parallel": 1,
    "p99_time": 0.00868840308859944,
    "mean_time": 0.005756442243116908,
    "mean_precisions": 0.86914,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.3222759690252,
    "total_upload_time": 1350.3348185530049,
    "p95_time": 0.008873117540497332,
    "rps": 150.17654187457651,
    "parallel": 1,
    "p99_time": 0.010584388244897127,
    "mean_time": 0.006569258873001672,
    "mean_precisions": 0.9024300000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.3222759690252,
    "total_upload_time": 1350.3348185530049,
    "p95_time": 0.11995341243455186,
    "rps": 845.9942041273791,
    "parallel": 100,
    "p99_time": 0.12245871674036607,
    "mean_time": 0.09648096230684314,
    "mean_precisions": 0.8691400000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.3222759690252,
    "total_upload_time": 1350.3348185530049,
    "p95_time": 0.1623661987367086,
    "rps": 642.4659595472816,
    "parallel": 100,
    "p99_time": 0.16514915104140526,
    "mean_time": 0.13379883465031162,
    "mean_precisions": 0.9024300000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.3222759690252,
    "total_upload_time": 1350.3348185530049,
    "p95_time": 0.2629470948129892,
    "rps": 405.9592774340774,
    "parallel": 100,
    "p99_time": 0.26943062601960266,
    "mean_time": 0.22281209839973598,
    "mean_precisions": 0.9593,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.3222759690252,
    "total_upload_time": 1350.3348185530049,
    "p95_time": 0.4331726893491577,
    "rps": 251.98238637932792,
    "parallel": 100,
    "p99_time": 0.44146887343842534,
    "mean_time": 0.36728828243725004,
    "mean_precisions": 0.98492,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.3222759690252,
    "total_upload_time": 1350.3348185530049,
    "p95_time": 0.01249332358711399,
    "rps": 105.52986675984624,
    "parallel": 1,
    "p99_time": 0.013749522777507074,
    "mean_time": 0.009380377891939134,
    "mean_precisions": 0.9592999999999999,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.3222759690252,
    "total_upload_time": 1350.3348185530049,
    "p95_time": 0.019619786302791906,
    "rps": 69.39331137055842,
    "parallel": 1,
    "p99_time": 0.02183356848428957,
    "mean_time": 0.014307867472642101,
    "mean_precisions": 0.98492,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 35.20023968699752,
    "total_upload_time": 571.3659372429975,
    "p95_time": 0.004096905782353132,
    "rps": 288.7694911800922,
    "parallel": 1,
    "p99_time": 0.0060047414316795784,
    "mean_time": 0.0033986689410870894,
    "mean_precisions": 0.8119240000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 35.20023968699752,
    "total_upload_time": 571.3659372429975,
    "p95_time": 0.004407735704444349,
    "rps": 268.8707324386084,
    "parallel": 1,
    "p99_time": 0.005857725022360704,
    "mean_time": 0.0036493591560283678,
    "mean_precisions": 0.8402390000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 35.20023968699752,
    "total_upload_time": 571.3659372429975,
    "p95_time": 0.048167318804189556,
    "rps": 2219.823086236756,
    "parallel": 100,
    "p99_time": 0.05295934904599563,
    "mean_time": 0.04279326590495184,
    "mean_precisions": 0.811924,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 35.20023968699752,
    "total_upload_time": 571.3659372429975,
    "p95_time": 0.05284184387419373,
    "rps": 1999.6628484102405,
    "parallel": 100,
    "p99_time": 0.05631118125049398,
    "mean_time": 0.04756942935290281,
    "mean_precisions": 0.840239,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 35.20023968699752,
    "total_upload_time": 571.3659372429975,
    "p95_time": 0.07583757906686514,
    "rps": 1395.8860084835358,
    "parallel": 100,
    "p99_time": 0.08103977092541755,
    "mean_time": 0.06970103207700885,
    "mean_precisions": 0.9062349999999999,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 35.20023968699752,
    "total_upload_time": 571.3659372429975,
    "p95_time": 0.1216048605623655,
    "rps": 872.9505993036962,
    "parallel": 100,
    "p99_time": 0.1262835781159811,
    "mean_time": 0.11231370696593077,
    "mean_precisions": 0.952909,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 35.20023968699752,
    "total_upload_time": 571.3659372429975,
    "p95_time": 0.0060440373141318554,
    "rps": 204.17597304007285,
    "parallel": 1,
    "p99_time": 0.006583038545213641,
    "mean_time": 0.00482631151296664,
    "mean_precisions": 0.906235,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 35.20023968699752,
    "total_upload_time": 571.3659372429975,
    "p95_time": 0.009263926465064286,
    "rps": 138.93001225562526,
    "parallel": 1,
    "p99_time": 0.010221464463975283,
    "mean_time": 0.007119640224659815,
    "mean_precisions": 0.952909,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.36927255798946,
    "total_upload_time": 3523.891227562999,
    "p95_time": 0.00506596744999115,
    "rps": 222.6608831822921,
    "parallel": 1,
    "p99_time": 0.005843512988612929,
    "mean_time": 0.0038581752963789766,
    "mean_precisions": 0.9904,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.36927255798946,
    "total_upload_time": 3523.891227562999,
    "p95_time": 0.007876653100174736,
    "rps": 156.7740762921631,
    "parallel": 1,
    "p99_time": 0.009136599139364989,
    "mean_time": 0.005712553774390108,
    "mean_precisions": 0.9969600000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.36927255798946,
    "total_upload_time": 3523.891227562999,
    "p95_time": 0.14198134984899297,
    "rps": 719.012278521698,
    "parallel": 100,
    "p99_time": 0.14382499820962039,
    "mean_time": 0.1333806612776134,
    "mean_precisions": 0.9904,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.36927255798946,
    "total_upload_time": 3523.891227562999,
    "p95_time": 0.2420458842510925,
    "rps": 424.61766085086305,
    "parallel": 100,
    "p99_time": 0.2451358433092537,
    "mean_time": 0.23002237717220234,
    "mean_precisions": 0.9969600000000001,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.36927255798946,
    "total_upload_time": 3523.891227562999,
    "p95_time": 0.4156881176494608,
    "rps": 247.74480191027538,
    "parallel": 100,
    "p99_time": 0.42071122373938125,
    "mean_time": 0.397038830383218,
    "mean_precisions": 0.9987400000000002,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.36927255798946,
    "total_upload_time": 3523.891227562999,
    "p95_time": 0.7037186263503827,
    "rps": 146.55333626632265,
    "parallel": 100,
    "p99_time": 0.7164776047113446,
    "mean_time": 0.6729908856251986,
    "mean_precisions": 0.9995800000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.36927255798946,
    "total_upload_time": 3523.891227562999,
    "p95_time": 0.012483827448613738,
    "rps": 104.31599763169567,
    "parallel": 1,
    "p99_time": 0.014378148920768587,
    "mean_time": 0.008921861631806678,
    "mean_precisions": 0.9987400000000002,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 205.36927255798946,
    "total_upload_time": 3523.891227562999,
    "p95_time": 0.020348951900086832,
    "rps": 65.96510147394557,
    "parallel": 1,
    "p99_time": 0.0235861215701334,
    "mean_time": 0.0144855231442074,
    "mean_precisions": 0.9995800000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 610.7908542869845,
    "total_upload_time": 7552.622853319976,
    "p95_time": 0.0038536155130714173,
    "rps": 291.49452553405104,
    "parallel": 1,
    "p99_time": 0.004394795205444098,
    "mean_time": 0.0033656967408023774,
    "mean_precisions": 0.965627,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 610.7908542869845,
    "total_upload_time": 7552.622853319976,
    "p95_time": 0.004188936809077859,
    "rps": 275.458220999569,
    "parallel": 1,
    "p99_time": 0.00491626998409629,
    "mean_time": 0.003564986782707274,
    "mean_precisions": 0.979815,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 610.7908542869845,
    "total_upload_time": 7552.622853319976,
    "p95_time": 0.07182977041229605,
    "rps": 1414.3862072412733,
    "parallel": 100,
    "p99_time": 0.07376482060179115,
    "mean_time": 0.06844549506669864,
    "mean_precisions": 0.965627,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 610.7908542869845,
    "total_upload_time": 7552.622853319976,
    "p95_time": 0.09078228990547357,
    "rps": 1119.9113236166165,
    "parallel": 100,
    "p99_time": 0.0930767931882292,
    "mean_time": 0.0864167289569974,
    "mean_precisions": 0.979815,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 610.7908542869845,
    "total_upload_time": 7552.622853319976,
    "p95_time": 0.12020923043601214,
    "rps": 857.9392621448959,
    "parallel": 100,
    "p99_time": 0.12235563118010759,
    "mean_time": 0.11426980204181746,
    "mean_precisions": 0.9943209999999999,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 610.7908542869845,
    "total_upload_time": 7552.622853319976,
    "p95_time": 0.1706919060088694,
    "rps": 604.6124235685569,
    "parallel": 100,
    "p99_time": 0.17381335310637952,
    "mean_time": 0.1630153571761213,
    "mean_precisions": 0.9984850000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 610.7908542869845,
    "total_upload_time": 7552.622853319976,
    "p95_time": 0.005249867914244533,
    "rps": 225.8067189129743,
    "parallel": 1,
    "p99_time": 0.0062733401451259855,
    "mean_time": 0.004357024220284075,
    "mean_precisions": 0.9943209999999999,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 610.7908542869845,
    "total_upload_time": 7552.622853319976,
    "p95_time": 0.007510303100571036,
    "rps": 169.74616811740862,
    "parallel": 1,
    "p99_time": 0.009200143525376916,
    "mean_time": 0.00581582218715921,
    "mean_precisions": 0.9984850000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.69707310502417,
    "total_upload_time": 2364.802643018018,
    "p95_time": 0.0080074853671249,
    "rps": 155.09486507650368,
    "parallel": 1,
    "p99_time": 0.009487725512590257,
    "mean_time": 0.006361524675390683,
    "mean_precisions": 0.9018200000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.69707310502417,
    "total_upload_time": 2364.802643018018,
    "p95_time": 0.010395461053121833,
    "rps": 131.79382474922383,
    "parallel": 1,
    "p99_time": 0.011938255886780097,
    "mean_time": 0.007495332236867398,
    "mean_precisions": 0.9313899999999999,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.69707310502417,
    "total_upload_time": 2364.802643018018,
    "p95_time": 0.1399580724129919,
    "rps": 729.214625310552,
    "parallel": 100,
    "p99_time": 0.14287128292489795,
    "mean_time": 0.11510886761476286,
    "mean_precisions": 0.9018200000000001,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.69707310502417,
    "total_upload_time": 2364.802643018018,
    "p95_time": 0.18740981505252421,
    "rps": 561.8973222621535,
    "parallel": 100,
    "p99_time": 0.1912158062052913,
    "mean_time": 0.1555795830563875,
    "mean_precisions": 0.93139,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.69707310502417,
    "total_upload_time": 2364.802643018018,
    "p95_time": 0.3088960084714927,
    "rps": 350.30673223979477,
    "parallel": 100,
    "p99_time": 0.3164072857273277,
    "mean_time": 0.26122571229189634,
    "mean_precisions": 0.97404,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.69707310502417,
    "total_upload_time": 2364.802643018018,
    "p95_time": 0.523466447845567,
    "rps": 214.97473761644096,
    "parallel": 100,
    "p99_time": 0.538687527909642,
    "mean_time": 0.43338107334880627,
    "mean_precisions": 0.9918300000000001,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.69707310502417,
    "total_upload_time": 2364.802643018018,
    "p95_time": 0.014826432144036514,
    "rps": 90.04081664903111,
    "parallel": 1,
    "p99_time": 0.016884276433847843,
    "mean_time": 0.011008509338251316,
    "mean_precisions": 0.97404,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 145.69707310502417,
    "total_upload_time": 2364.802643018018,
    "p95_time": 0.02275504971621558,
    "rps": 59.45214916596298,
    "parallel": 1,
    "p99_time": 0.025698925761971622,
    "mean_time": 0.016711517963209188,
    "mean_precisions": 0.99183,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.822619411999767,
    "total_upload_time": 1193.9337070209986,
    "p95_time": 0.004302926477976143,
    "rps": 272.7629833085153,
    "parallel": 1,
    "p99_time": 0.005594117152504626,
    "mean_time": 0.003598985007731244,
    "mean_precisions": 0.8322390000000002,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.822619411999767,
    "total_upload_time": 1193.9337070209986,
    "p95_time": 0.004755928681697696,
    "rps": 248.9151761187308,
    "parallel": 1,
    "p99_time": 0.005802809582091869,
    "mean_time": 0.003950425573345274,
    "mean_precisions": 0.861801,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.822619411999767,
    "total_upload_time": 1193.9337070209986,
    "p95_time": 0.05460754738887772,
    "rps": 1951.534708833909,
    "parallel": 100,
    "p99_time": 0.059327378089074095,
    "mean_time": 0.04896540082017891,
    "mean_precisions": 0.8322390000000002,
    "engine_params": {
      "hnsw_ef": 64
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.822619411999767,
    "total_upload_time": 1193.9337070209986,
    "p95_time": 0.06130774414632469,
    "rps": 1719.1325609914604,
    "parallel": 100,
    "p99_time": 0.06439099236857146,
    "mean_time": 0.05593643722315319,
    "mean_precisions": 0.861801,
    "engine_params": {
      "hnsw_ef": 128
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.822619411999767,
    "total_upload_time": 1193.9337070209986,
    "p95_time": 0.09155707899481058,
    "rps": 1148.46775842845,
    "parallel": 100,
    "p99_time": 0.09587176654720679,
    "mean_time": 0.08478953643660062,
    "mean_precisions": 0.927426,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.822619411999767,
    "total_upload_time": 1193.9337070209986,
    "p95_time": 0.15101493319962173,
    "rps": 697.7368413791231,
    "parallel": 100,
    "p99_time": 0.15431551849236713,
    "mean_time": 0.14095176355934236,
    "mean_precisions": 0.969015,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.822619411999767,
    "total_upload_time": 1193.9337070209986,
    "p95_time": 0.006904253829270601,
    "rps": 179.05921130821505,
    "parallel": 1,
    "p99_time": 0.008354835987556727,
    "mean_time": 0.00550945347098168,
    "mean_precisions": 0.927426,
    "engine_params": {
      "hnsw_ef": 256
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 31.822619411999767,
    "total_upload_time": 1193.9337070209986,
    "p95_time": 0.010783416754566132,
    "rps": 119.93280437821848,
    "parallel": 1,
    "p99_time": 0.011769030431751173,
    "mean_time": 0.008255400147358887,
    "mean_precisions": 0.969015,
    "engine_params": {
      "hnsw_ef": 512
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.0021743263521784685,
    "rps": 428.7571487729666,
    "parallel": 1,
    "p99_time": 0.002410263949641377,
    "mean_time": 0.001789452538806654,
    "mean_precisions": 0.94752,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.0022619323506660296,
    "rps": 409.6476742157381,
    "parallel": 1,
    "p99_time": 0.002537380520880106,
    "mean_time": 0.0018867303562379676,
    "mean_precisions": 0.96546,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.0038730950487661175,
    "rps": 264.8523752927213,
    "parallel": 1,
    "p99_time": 0.004190005513155484,
    "mean_time": 0.003165680373790383,
    "mean_precisions": 0.99106,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.003919369051436661,
    "rps": 263.01778387602883,
    "parallel": 1,
    "p99_time": 0.004313637981322247,
    "mean_time": 0.003198499602229276,
    "mean_precisions": 0.99106,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.005890520396496868,
    "rps": 189.1812038117435,
    "parallel": 1,
    "p99_time": 0.006498962883051718,
    "mean_time": 0.004635557724829414,
    "mean_precisions": 0.9746800000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.005817088396725012,
    "rps": 190.67256448446082,
    "parallel": 1,
    "p99_time": 0.006382675411150566,
    "mean_time": 0.004594010074016114,
    "mean_precisions": 0.99534,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.005915033498604317,
    "rps": 188.19317798284303,
    "parallel": 1,
    "p99_time": 0.006642273796023802,
    "mean_time": 0.004664045457934844,
    "mean_precisions": 0.9955799999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.005903646348087932,
    "rps": 187.6455648858659,
    "parallel": 1,
    "p99_time": 0.0063026133576931905,
    "mean_time": 0.004677435091897496,
    "mean_precisions": 0.9955799999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.002464613750271383,
    "rps": 1221.3843028941415,
    "parallel": 100,
    "p99_time": 0.005922101340329403,
    "mean_time": 0.0020571046033786844,
    "mean_precisions": 0.94752,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.002489679949576385,
    "rps": 1217.9738525555636,
    "parallel": 100,
    "p99_time": 0.005777316301391709,
    "mean_time": 0.0020477798619773237,
    "mean_precisions": 0.96546,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.0025020386445248734,
    "rps": 1227.200570178276,
    "parallel": 100,
    "p99_time": 0.006158970650503762,
    "mean_time": 0.0020601326965581394,
    "mean_precisions": 0.9657,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.0028674185010459045,
    "rps": 1233.6097811907093,
    "parallel": 100,
    "p99_time": 0.006214178507216281,
    "mean_time": 0.0023082371518321453,
    "mean_precisions": 0.9724200000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.0023269196473847844,
    "rps": 398.93457586423625,
    "parallel": 1,
    "p99_time": 0.0026048698929662354,
    "mean_time": 0.0019541004102124134,
    "mean_precisions": 0.9657,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.003621175749140093,
    "rps": 1192.9000315523506,
    "parallel": 100,
    "p99_time": 0.006892381968864378,
    "mean_time": 0.002816482376526983,
    "mean_precisions": 0.9635,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.0038472496547910856,
    "rps": 1234.258235595264,
    "parallel": 100,
    "p99_time": 0.007310592608191663,
    "mean_time": 0.0028838288087936234,
    "mean_precisions": 0.9828600000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.003732793747985853,
    "rps": 1111.2010188782617,
    "parallel": 100,
    "p99_time": 0.0072778401226241945,
    "mean_time": 0.002867942919986672,
    "mean_precisions": 0.9831,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.0038166096052009387,
    "rps": 1115.533576298925,
    "parallel": 100,
    "p99_time": 0.0069959850343730276,
    "mean_time": 0.0029470516184621374,
    "mean_precisions": 0.9831,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.09902519680290425,
    "rps": 1005.9013338285151,
    "parallel": 100,
    "p99_time": 0.10007536881341367,
    "mean_time": 0.08936919643480797,
    "mean_precisions": 0.9708200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.0995587110028282,
    "rps": 1015.1757811323015,
    "parallel": 100,
    "p99_time": 0.10143904816766736,
    "mean_time": 0.08944050624876254,
    "mean_precisions": 0.99082,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.09992371709886357,
    "rps": 1004.8169901597008,
    "parallel": 100,
    "p99_time": 0.10174046097323299,
    "mean_time": 0.09104518730830169,
    "mean_precisions": 0.99106,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.10229116584960138,
    "rps": 988.6502875804314,
    "parallel": 100,
    "p99_time": 0.10376751186886395,
    "mean_time": 0.09193394303341337,
    "mean_precisions": 0.99106,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.17079485604772343,
    "rps": 597.8922465408978,
    "parallel": 100,
    "p99_time": 0.17220278431239422,
    "mean_time": 0.161447608467791,
    "mean_precisions": 0.9746800000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.17152237880472967,
    "rps": 596.3548018362737,
    "parallel": 100,
    "p99_time": 0.17373176025350404,
    "mean_time": 0.16222780616815727,
    "mean_precisions": 0.99534,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.0024399897010880522,
    "rps": 387.9913002313724,
    "parallel": 1,
    "p99_time": 0.0026641284521610946,
    "mean_time": 0.0020341889705276115,
    "mean_precisions": 0.9724200000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.17281390280149936,
    "rps": 590.0544041477523,
    "parallel": 100,
    "p99_time": 0.17465892460517352,
    "mean_time": 0.16386939857298857,
    "mean_precisions": 0.9955799999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.17568557929553208,
    "rps": 581.6763984371614,
    "parallel": 100,
    "p99_time": 0.17845839475950925,
    "mean_time": 0.1661753004863771,
    "mean_precisions": 0.9955799999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.002773947850801051,
    "rps": 347.0489792760588,
    "parallel": 1,
    "p99_time": 0.003049226219809498,
    "mean_time": 0.0023163377723671146,
    "mean_precisions": 0.9635,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.002800756149008521,
    "rps": 346.53426694597505,
    "parallel": 1,
    "p99_time": 0.0030822175694629555,
    "mean_time": 0.002324847709016467,
    "mean_precisions": 0.9828600000000002,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.002788235747357248,
    "rps": 343.9715162547285,
    "parallel": 1,
    "p99_time": 0.002986572441222961,
    "mean_time": 0.0023441958013776455,
    "mean_precisions": 0.9831,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.002898801747505786,
    "rps": 333.24439127175543,
    "parallel": 1,
    "p99_time": 0.0032219907882972626,
    "mean_time": 0.0024220020988053874,
    "mean_precisions": 0.9831,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.0038823188977403335,
    "rps": 266.0581232731711,
    "parallel": 1,
    "p99_time": 0.0042722458512434985,
    "mean_time": 0.0031490941040145117,
    "mean_precisions": 0.9708200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 220.5908488649875,
    "total_upload_time": 535.2270815119846,
    "p95_time": 0.0038918688507692425,
    "rps": 264.03895313145443,
    "parallel": 1,
    "p99_time": 0.004339582333122962,
    "mean_time": 0.003177543871990929,
    "mean_precisions": 0.99082,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.003351649362593889,
    "rps": 347.401253066795,
    "parallel": 1,
    "p99_time": 0.0037125636171549564,
    "mean_time": 0.002821155866701156,
    "mean_precisions": 0.897452,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.0037679739762097593,
    "rps": 314.46906998496655,
    "parallel": 1,
    "p99_time": 0.004177009910345078,
    "mean_time": 0.003116243740171194,
    "mean_precisions": 0.9543710000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.005420817714184523,
    "rps": 235.11437935569717,
    "parallel": 1,
    "p99_time": 0.005791534688323737,
    "mean_time": 0.0041860510617494585,
    "mean_precisions": 0.98592,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.0071772795170545545,
    "rps": 186.36625683367023,
    "parallel": 1,
    "p99_time": 0.007767414348199964,
    "mean_time": 0.005297201055288315,
    "mean_precisions": 0.994333,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.005781902652233835,
    "rps": 225.53128526120213,
    "parallel": 1,
    "p99_time": 0.006259075766429306,
    "mean_time": 0.0043676994415000085,
    "mean_precisions": 0.9884060000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.005815081344917416,
    "rps": 223.5595561924783,
    "parallel": 1,
    "p99_time": 0.006273632049560547,
    "mean_time": 0.0044067751775495705,
    "mean_precisions": 0.989597,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.005860072979703545,
    "rps": 222.0772669803511,
    "parallel": 1,
    "p99_time": 0.0063178726565092805,
    "mean_time": 0.004437317317258566,
    "mean_precisions": 0.9897890000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.007128610461950301,
    "rps": 185.6191365114944,
    "parallel": 1,
    "p99_time": 0.007814352111890912,
    "mean_time": 0.005316238358709961,
    "mean_precisions": 0.994333,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.07146405442617834,
    "rps": 1405.6037595055707,
    "parallel": 100,
    "p99_time": 0.12409824324771765,
    "mean_time": 0.06898433465147391,
    "mean_precisions": 0.897452,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.0821666153613478,
    "rps": 1241.7856530058,
    "parallel": 100,
    "p99_time": 0.08488730012439191,
    "mean_time": 0.07862973663723097,
    "mean_precisions": 0.9543710000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.10512688420712946,
    "rps": 977.9836553959088,
    "parallel": 100,
    "p99_time": 0.11379389511421326,
    "mean_time": 0.10028277420401573,
    "mean_precisions": 0.9812460000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.1461788324639201,
    "rps": 701.288576631178,
    "parallel": 100,
    "p99_time": 0.14864741188473998,
    "mean_time": 0.1405237974206917,
    "mean_precisions": 0.992624,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.004656400438398122,
    "rps": 262.05741740649995,
    "parallel": 1,
    "p99_time": 0.005078905662521721,
    "mean_time": 0.003752712832111865,
    "mean_precisions": 0.9812460000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.09285639207810163,
    "rps": 1092.3166511761847,
    "parallel": 100,
    "p99_time": 0.09503846980631352,
    "mean_time": 0.08962603414738551,
    "mean_precisions": 0.939292,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.10481735426001251,
    "rps": 973.2575664484973,
    "parallel": 100,
    "p99_time": 0.10655723994597793,
    "mean_time": 0.10076517527885735,
    "mean_precisions": 0.9650900000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.13290437371470035,
    "rps": 764.4989974501677,
    "parallel": 100,
    "p99_time": 0.1348000156786293,
    "mean_time": 0.12858927519731222,
    "mean_precisions": 0.98592,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.1885117965284735,
    "rps": 543.1276296763576,
    "parallel": 100,
    "p99_time": 0.1908516894094646,
    "mean_time": 0.1818768152677454,
    "mean_precisions": 0.994333,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.11094387206248939,
    "rps": 916.5344484418526,
    "parallel": 100,
    "p99_time": 0.11254924172535538,
    "mean_time": 0.10702304680822416,
    "mean_precisions": 0.9733149999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.11201257249340416,
    "rps": 911.1764716579196,
    "parallel": 100,
    "p99_time": 0.11486167781054973,
    "mean_time": 0.10775012027360499,
    "mean_precisions": 0.9744490000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.13344890465959908,
    "rps": 762.1099626110235,
    "parallel": 100,
    "p99_time": 0.1366673015523702,
    "mean_time": 0.12939384345039726,
    "mean_precisions": 0.98592,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.1895120413508266,
    "rps": 539.3850333219506,
    "parallel": 100,
    "p99_time": 0.1947809184342623,
    "mean_time": 0.1825490416311659,
    "mean_precisions": 0.994333,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.14648675792850555,
    "rps": 698.7240202835999,
    "parallel": 100,
    "p99_time": 0.14849731440655886,
    "mean_time": 0.14102101447721943,
    "mean_precisions": 0.9884060000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.14682503505609928,
    "rps": 695.7262656671606,
    "parallel": 100,
    "p99_time": 0.14981103646568955,
    "mean_time": 0.14158537374353036,
    "mean_precisions": 0.989597,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.0059417578857392074,
    "rps": 206.814317489259,
    "parallel": 1,
    "p99_time": 0.006608948493376374,
    "mean_time": 0.004767893817741424,
    "mean_precisions": 0.9926240000000002,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.14970600460655986,
    "rps": 682.3589229936946,
    "parallel": 100,
    "p99_time": 0.15148319381289185,
    "mean_time": 0.14447856874410064,
    "mean_precisions": 0.9897890000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.18968938239850103,
    "rps": 540.4741789820262,
    "parallel": 100,
    "p99_time": 0.1926238969527185,
    "mean_time": 0.1827306871620938,
    "mean_precisions": 0.994333,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.004095187271013856,
    "rps": 301.05181873460344,
    "parallel": 1,
    "p99_time": 0.004281714763492346,
    "mean_time": 0.0032598020338453354,
    "mean_precisions": 0.939292,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.0045083207078278065,
    "rps": 279.2537373805864,
    "parallel": 1,
    "p99_time": 0.004795186314731837,
    "mean_time": 0.0035180672985501587,
    "mean_precisions": 0.9650900000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.005434377677738666,
    "rps": 235.80558361280694,
    "parallel": 1,
    "p99_time": 0.005853544315323234,
    "mean_time": 0.004173342963773757,
    "mean_precisions": 0.98592,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.007171262521296739,
    "rps": 185.66930079846415,
    "parallel": 1,
    "p99_time": 0.007775109224021436,
    "mean_time": 0.005314566845819354,
    "mean_precisions": 0.994333,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.004772665025666356,
    "rps": 262.84170456476716,
    "parallel": 1,
    "p99_time": 0.005098629444837571,
    "mean_time": 0.0037397511430084704,
    "mean_precisions": 0.9733149999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 284.7286567820047,
    "total_upload_time": 1419.7107531639995,
    "p95_time": 0.004732216242700815,
    "rps": 267.4294496308108,
    "parallel": 1,
    "p99_time": 0.005112352799624205,
    "mean_time": 0.0036719317828305064,
    "mean_precisions": 0.9744490000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.0037210702779702843,
    "rps": 305.95473332697975,
    "parallel": 1,
    "p99_time": 0.00646191594423726,
    "mean_time": 0.0031875824353192,
    "mean_precisions": 0.7662100000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.004752501437906175,
    "rps": 242.1925016057626,
    "parallel": 1,
    "p99_time": 0.0058919867221266025,
    "mean_time": 0.004037543546175584,
    "mean_precisions": 0.8663,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.008038850058801473,
    "rps": 152.23003172551645,
    "parallel": 1,
    "p99_time": 0.01063378087012097,
    "mean_time": 0.006444869074039161,
    "mean_precisions": 0.9433899999999998,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.011910369002725926,
    "rps": 104.01015588913518,
    "parallel": 1,
    "p99_time": 0.014031558784190564,
    "mean_time": 0.009483845323091373,
    "mean_precisions": 0.97184,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.00845933296950534,
    "rps": 144.4639713622786,
    "parallel": 1,
    "p99_time": 0.009432124756276606,
    "mean_time": 0.006803306520683691,
    "mean_precisions": 0.95535,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.008893809863366185,
    "rps": 139.75919224512322,
    "parallel": 1,
    "p99_time": 0.011194870120380073,
    "mean_time": 0.007039952196879313,
    "mean_precisions": 0.95537,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.008944106416311114,
    "rps": 136.18134568885972,
    "parallel": 1,
    "p99_time": 0.009829544632229952,
    "mean_time": 0.007225035201758146,
    "mean_precisions": 0.95537,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.012181933142710476,
    "rps": 102.12386414004507,
    "parallel": 1,
    "p99_time": 0.014239962096326051,
    "mean_time": 0.009654104900546372,
    "mean_precisions": 0.97184,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.061986781819723544,
    "rps": 1310.127583080633,
    "parallel": 100,
    "p99_time": 0.06324820462614297,
    "mean_time": 0.048039818292716516,
    "mean_precisions": 0.7662100000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.0973354843677953,
    "rps": 1000.3041325018263,
    "parallel": 100,
    "p99_time": 0.09816710919607431,
    "mean_time": 0.0798343603934627,
    "mean_precisions": 0.8663,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.1707119073253125,
    "rps": 624.957290009921,
    "parallel": 100,
    "p99_time": 0.17599524703109637,
    "mean_time": 0.1395113264892716,
    "mean_precisions": 0.93069,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.26598239636514337,
    "rps": 383.3033734337955,
    "parallel": 100,
    "p99_time": 0.26910772200673816,
    "mean_time": 0.2369297504534479,
    "mean_precisions": 0.96504,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.0068477272405289115,
    "rps": 169.76858885477776,
    "parallel": 1,
    "p99_time": 0.007519960170611739,
    "mean_time": 0.005781408128095791,
    "mean_precisions": 0.93069,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.09053281696978957,
    "rps": 1046.2378171002858,
    "parallel": 100,
    "p99_time": 0.09854330432368441,
    "mean_time": 0.07362214892287738,
    "mean_precisions": 0.8376800000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.11993537185480818,
    "rps": 805.5334541739618,
    "parallel": 100,
    "p99_time": 0.12126029026228935,
    "mean_time": 0.1032453303958755,
    "mean_precisions": 0.8896700000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.20072668635984883,
    "rps": 508.34162920147804,
    "parallel": 100,
    "p99_time": 0.20398222625488416,
    "mean_time": 0.1748318641439546,
    "mean_precisions": 0.9433900000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.3312608174746856,
    "rps": 310.9951886355814,
    "parallel": 100,
    "p99_time": 0.3355312579264864,
    "mean_time": 0.29397778695565646,
    "mean_precisions": 0.97184,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.13639530120417476,
    "rps": 730.7868923089837,
    "parallel": 100,
    "p99_time": 0.13782793548190966,
    "mean_time": 0.11571435227268376,
    "mean_precisions": 0.91272,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.14051800422603264,
    "rps": 700.1646534734247,
    "parallel": 100,
    "p99_time": 0.14259885387960822,
    "mean_time": 0.12279702698881738,
    "mean_precisions": 0.91274,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.20328394756652415,
    "rps": 501.8979055649101,
    "parallel": 100,
    "p99_time": 0.2053109538485296,
    "mean_time": 0.17699591067433357,
    "mean_precisions": 0.9433900000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.3299066515523009,
    "rps": 314.63300341209424,
    "parallel": 100,
    "p99_time": 0.33383320478955286,
    "mean_time": 0.2902850987620186,
    "mean_precisions": 0.97184,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.21782200082670897,
    "rps": 469.4430518593542,
    "parallel": 100,
    "p99_time": 0.220354187740013,
    "mean_time": 0.1898325384678319,
    "mean_precisions": 0.95535,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.2249828948173672,
    "rps": 452.9113676159978,
    "parallel": 100,
    "p99_time": 0.2266108184005134,
    "mean_time": 0.1974162524836138,
    "mean_precisions": 0.95537,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.010779138980433344,
    "rps": 111.77004474138708,
    "parallel": 1,
    "p99_time": 0.012831114581786096,
    "mean_time": 0.008823483601212502,
    "mean_precisions": 0.96504,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.23185600796714423,
    "rps": 437.4625979935433,
    "parallel": 100,
    "p99_time": 0.23425948915304615,
    "mean_time": 0.20478346916730517,
    "mean_precisions": 0.9553700000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.3426365124294534,
    "rps": 313.8673987224041,
    "parallel": 100,
    "p99_time": 0.3491236001276411,
    "mean_time": 0.2918761910609901,
    "mean_precisions": 0.97184,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.0042510377010330554,
    "rps": 273.49732179997045,
    "parallel": 1,
    "p99_time": 0.00639117007376626,
    "mean_time": 0.0035709076204802842,
    "mean_precisions": 0.8376800000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.005258453346323221,
    "rps": 222.58855980654616,
    "parallel": 1,
    "p99_time": 0.006603490179404616,
    "mean_time": 0.004398762864759192,
    "mean_precisions": 0.88967,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.007663986214902252,
    "rps": 156.6553322335814,
    "parallel": 1,
    "p99_time": 0.008549717983696609,
    "mean_time": 0.006276695069856942,
    "mean_precisions": 0.9433899999999998,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.011975769628770649,
    "rps": 103.5970820863916,
    "parallel": 1,
    "p99_time": 0.013202030574902893,
    "mean_time": 0.00952516605798155,
    "mean_precisions": 0.97184,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.005688174930401146,
    "rps": 207.5968096976926,
    "parallel": 1,
    "p99_time": 0.006257835754659027,
    "mean_time": 0.004716051843715831,
    "mean_precisions": 0.91272,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 123.9285245860001,
    "total_upload_time": 375.7546836970005,
    "p95_time": 0.006045043584890663,
    "rps": 193.62076927914308,
    "parallel": 1,
    "p99_time": 0.0077960700076073405,
    "mean_time": 0.005042452444322407,
    "mean_precisions": 0.91274,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.004265623551145835,
    "rps": 283.9265135665757,
    "parallel": 1,
    "p99_time": 0.006116280540918525,
    "mean_time": 0.003455726924801638,
    "mean_precisions": 0.683384,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.005004463999830478,
    "rps": 250.17167060231046,
    "parallel": 1,
    "p99_time": 0.006918951141087747,
    "mean_time": 0.003925444494123076,
    "mean_precisions": 0.7760990000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.006088198050201753,
    "rps": 205.40498824875135,
    "parallel": 1,
    "p99_time": 0.008001678140281002,
    "mean_time": 0.004799921888027165,
    "mean_precisions": 0.842894,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.008224034848535665,
    "rps": 154.46608074759342,
    "parallel": 1,
    "p99_time": 0.009860488200356485,
    "mean_time": 0.006399300141795538,
    "mean_precisions": 0.8958,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.006603284050106592,
    "rps": 193.77855398145502,
    "parallel": 1,
    "p99_time": 0.00835561824089383,
    "mean_time": 0.005091124404605216,
    "mean_precisions": 0.83909,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.006502062549225227,
    "rps": 193.1941860663666,
    "parallel": 1,
    "p99_time": 0.008341088351044168,
    "mean_time": 0.00510687663348217,
    "mean_precisions": 0.861982,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.006659724950441159,
    "rps": 190.78777065784266,
    "parallel": 1,
    "p99_time": 0.008226759489552933,
    "mean_time": 0.0051682215619075576,
    "mean_precisions": 0.862883,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.008252737597467783,
    "rps": 155.87089662846088,
    "parallel": 1,
    "p99_time": 0.010077162470261107,
    "mean_time": 0.006337902552991727,
    "mean_precisions": 0.8958,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.04969444900125379,
    "rps": 2273.464199096453,
    "parallel": 100,
    "p99_time": 0.058082701998064305,
    "mean_time": 0.04085083068763488,
    "mean_precisions": 0.683384,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.0567900706984801,
    "rps": 1928.9699317827465,
    "parallel": 100,
    "p99_time": 0.06306579420921482,
    "mean_time": 0.04917763825599432,
    "mean_precisions": 0.776099,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.07368630254932212,
    "rps": 1474.9885673856777,
    "parallel": 100,
    "p99_time": 0.07804236370979198,
    "mean_time": 0.06531995025408177,
    "mean_precisions": 0.842894,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.1027289733505313,
    "rps": 1032.3603140637617,
    "parallel": 100,
    "p99_time": 0.10755821693852341,
    "mean_time": 0.09444838003211116,
    "mean_precisions": 0.8958,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.006042197948954707,
    "rps": 204.5179921618371,
    "parallel": 1,
    "p99_time": 0.007879456198497793,
    "mean_time": 0.0048088971446049985,
    "mean_precisions": 0.842894,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.050808662600138624,
    "rps": 2160.79743660809,
    "parallel": 100,
    "p99_time": 0.05621620463844011,
    "mean_time": 0.042858544672392966,
    "mean_precisions": 0.7140550000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.057486702050482556,
    "rps": 1952.5749203637872,
    "parallel": 100,
    "p99_time": 0.06432409897017352,
    "mean_time": 0.04881080684070912,
    "mean_precisions": 0.776099,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.07262990435156098,
    "rps": 1482.729012549318,
    "parallel": 100,
    "p99_time": 0.07651101496740012,
    "mean_time": 0.06483286652930255,
    "mean_precisions": 0.8428939999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.10284703365232417,
    "rps": 1032.6897441796878,
    "parallel": 100,
    "p99_time": 0.10720332452761795,
    "mean_time": 0.09423398043089729,
    "mean_precisions": 0.8958,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.0601547077010764,
    "rps": 1819.0825024861779,
    "parallel": 100,
    "p99_time": 0.06586548319752183,
    "mean_time": 0.052392077326687284,
    "mean_precisions": 0.7849389999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.05748297859809099,
    "rps": 1835.3477253474966,
    "parallel": 100,
    "p99_time": 0.06241548312820672,
    "mean_time": 0.05184373331551251,
    "mean_precisions": 0.801416,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.07191015484968374,
    "rps": 1491.0194353962743,
    "parallel": 100,
    "p99_time": 0.07694095978025874,
    "mean_time": 0.06465014625020522,
    "mean_precisions": 0.842894,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.104998094300754,
    "rps": 1031.3185305138272,
    "parallel": 100,
    "p99_time": 0.11052834918784356,
    "mean_time": 0.09423785287538194,
    "mean_precisions": 0.8958,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.07893642189883394,
    "rps": 1359.5615565598746,
    "parallel": 100,
    "p99_time": 0.08484676744286847,
    "mean_time": 0.07090693322631268,
    "mean_precisions": 0.83909,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.07672574974985763,
    "rps": 1369.093068390118,
    "parallel": 100,
    "p99_time": 0.08265637976044672,
    "mean_time": 0.07070128117719178,
    "mean_precisions": 0.861982,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.008252249751603812,
    "rps": 152.8794329703579,
    "parallel": 1,
    "p99_time": 0.009926844911533408,
    "mean_time": 0.006448459778824326,
    "mean_precisions": 0.8958,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.07840816585066931,
    "rps": 1346.2837898012924,
    "parallel": 100,
    "p99_time": 0.08213724381079374,
    "mean_time": 0.07178768754860393,
    "mean_precisions": 0.862883,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.1007890115486589,
    "rps": 1043.8451065985278,
    "parallel": 100,
    "p99_time": 0.10392536050825583,
    "mean_time": 0.09312466978488483,
    "mean_precisions": 0.8958,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.0046235827003329125,
    "rps": 272.16315006887436,
    "parallel": 1,
    "p99_time": 0.006450542820530245,
    "mean_time": 0.0036114770078838772,
    "mean_precisions": 0.714055,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.005013253049401101,
    "rps": 248.30316117126628,
    "parallel": 1,
    "p99_time": 0.006920831179268135,
    "mean_time": 0.003962383822189076,
    "mean_precisions": 0.7760990000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.006056148649804525,
    "rps": 207.37459626576293,
    "parallel": 1,
    "p99_time": 0.007746501900073781,
    "mean_time": 0.004754355050909726,
    "mean_precisions": 0.842894,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.008192679949206645,
    "rps": 155.82737957046075,
    "parallel": 1,
    "p99_time": 0.00996836859103496,
    "mean_time": 0.006338558642513453,
    "mean_precisions": 0.8958,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.005108449349791043,
    "rps": 240.3730948973125,
    "parallel": 1,
    "p99_time": 0.007105876802816057,
    "mean_time": 0.004095617212825892,
    "mean_precisions": 0.784939,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 43.32211580600051,
    "total_upload_time": 282.12565566099875,
    "p95_time": 0.0051483379496858085,
    "rps": 241.08645316960477,
    "parallel": 1,
    "p99_time": 0.007094232157542138,
    "mean_time": 0.00408371865449335,
    "mean_precisions": 0.801416,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.0025400087961315876,
    "rps": 382.2976016263397,
    "parallel": 1,
    "p99_time": 0.002806816203155906,
    "mean_time": 0.0020742852099996526,
    "mean_precisions": 0.9581400000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.0025441691013838863,
    "rps": 377.20943880420987,
    "parallel": 1,
    "p99_time": 0.0028121798689244317,
    "mean_time": 0.002093995172221912,
    "mean_precisions": 0.97662,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.004944225597500918,
    "rps": 226.5158147727349,
    "parallel": 1,
    "p99_time": 0.005334584262600404,
    "mean_time": 0.003779166123594041,
    "mean_precisions": 0.99416,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.005002150850123144,
    "rps": 223.86266632035293,
    "parallel": 1,
    "p99_time": 0.00548517876843107,
    "mean_time": 0.003829695969840395,
    "mean_precisions": 0.9942,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.007712682698183926,
    "rps": 158.12018120269707,
    "parallel": 1,
    "p99_time": 0.008513309699847016,
    "mean_time": 0.00565352476236003,
    "mean_precisions": 0.97604,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.007635787851904752,
    "rps": 159.61602521251365,
    "parallel": 1,
    "p99_time": 0.0083636582530744,
    "mean_time": 0.005602879309022682,
    "mean_precisions": 0.99698,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.007544933304234292,
    "rps": 160.83833040339275,
    "parallel": 1,
    "p99_time": 0.0082743640847184,
    "mean_time": 0.005562407923139108,
    "mean_precisions": 0.9971399999999998,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.007693027952700505,
    "rps": 157.3889129629688,
    "parallel": 1,
    "p99_time": 0.00860778479196597,
    "mean_time": 0.005688414518052014,
    "mean_precisions": 0.99718,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.0029066861512546897,
    "rps": 1224.904594710898,
    "parallel": 100,
    "p99_time": 0.007772666152013704,
    "mean_time": 0.00238059663198801,
    "mean_precisions": 0.9581400000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.002972533803404076,
    "rps": 1175.9571166604471,
    "parallel": 100,
    "p99_time": 0.012273741470417042,
    "mean_time": 0.0029248201676338793,
    "mean_precisions": 0.97662,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.0029628800024511293,
    "rps": 1228.676942888891,
    "parallel": 100,
    "p99_time": 0.0067330176996620176,
    "mean_time": 0.0023652109750473757,
    "mean_precisions": 0.9767600000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.003599852499974077,
    "rps": 1234.0359942447458,
    "parallel": 100,
    "p99_time": 0.007116066344533498,
    "mean_time": 0.0027645579633914165,
    "mean_precisions": 0.9812200000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.00258930095260439,
    "rps": 371.6463351159335,
    "parallel": 1,
    "p99_time": 0.002911139247371469,
    "mean_time": 0.002133311603416223,
    "mean_precisions": 0.9767600000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.00591532349935733,
    "rps": 1222.1893418525485,
    "parallel": 100,
    "p99_time": 0.009200749559458939,
    "mean_time": 0.0038297574362164597,
    "mean_precisions": 0.9683599999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.00595885590009857,
    "rps": 1233.8435860011775,
    "parallel": 100,
    "p99_time": 0.008616187910447498,
    "mean_time": 0.00391675833624904,
    "mean_precisions": 0.98806,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.009418201904190938,
    "rps": 1216.5465981159946,
    "parallel": 100,
    "p99_time": 0.012115052541557817,
    "mean_time": 0.004926550327542646,
    "mean_precisions": 0.9882,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.00865918790586875,
    "rps": 1230.0250376146037,
    "parallel": 100,
    "p99_time": 0.01544916945786099,
    "mean_time": 0.004976310582802398,
    "mean_precisions": 0.98824,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.1269604902503488,
    "rps": 803.9896822512771,
    "parallel": 100,
    "p99_time": 0.12919402360093954,
    "mean_time": 0.11740608792578423,
    "mean_precisions": 0.9736,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.12854825074718973,
    "rps": 797.2004137815361,
    "parallel": 100,
    "p99_time": 0.13071985397247773,
    "mean_time": 0.1185908245984363,
    "mean_precisions": 0.9940200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.12841363255247415,
    "rps": 794.6938951083993,
    "parallel": 100,
    "p99_time": 0.13073464947825414,
    "mean_time": 0.11889844866499334,
    "mean_precisions": 0.99416,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.13039364559881506,
    "rps": 784.1609855679989,
    "parallel": 100,
    "p99_time": 0.1329303135988448,
    "mean_time": 0.12089625321163912,
    "mean_precisions": 0.9942,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.21767573734723555,
    "rps": 472.95523276736816,
    "parallel": 100,
    "p99_time": 0.22097828099358593,
    "mean_time": 0.20573783038144028,
    "mean_precisions": 0.97604,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.21885890640223807,
    "rps": 467.99103656004615,
    "parallel": 100,
    "p99_time": 0.22237172685214318,
    "mean_time": 0.2069846798281651,
    "mean_precisions": 0.99698,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.002819019500384457,
    "rps": 346.0729355367348,
    "parallel": 1,
    "p99_time": 0.0030999960919143635,
    "mean_time": 0.0023215145671420033,
    "mean_precisions": 0.9812200000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.21939895599643933,
    "rps": 468.08134176600726,
    "parallel": 100,
    "p99_time": 0.22222285432835634,
    "mean_time": 0.20788683398680877,
    "mean_precisions": 0.9971399999999998,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.22181295759983186,
    "rps": 463.8438147794067,
    "parallel": 100,
    "p99_time": 0.2247919328371063,
    "mean_time": 0.20983636033401126,
    "mean_precisions": 0.99718,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.003391250547792879,
    "rps": 301.59296897402555,
    "parallel": 1,
    "p99_time": 0.0037023075199249444,
    "mean_time": 0.0027127771587416648,
    "mean_precisions": 0.96836,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.0033393079993402353,
    "rps": 305.3404452729514,
    "parallel": 1,
    "p99_time": 0.003638052392052489,
    "mean_time": 0.0026852445955839357,
    "mean_precisions": 0.98806,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.0033676338509394553,
    "rps": 304.3358344082265,
    "parallel": 1,
    "p99_time": 0.003725862101855455,
    "mean_time": 0.0026995962705594137,
    "mean_precisions": 0.9882,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.0033831430486316095,
    "rps": 302.58573259206776,
    "parallel": 1,
    "p99_time": 0.003702919151910465,
    "mean_time": 0.0027180805011856137,
    "mean_precisions": 0.9882400000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.004941019952457282,
    "rps": 226.1292247159146,
    "parallel": 1,
    "p99_time": 0.0054620213353337044,
    "mean_time": 0.0037845293918493555,
    "mean_precisions": 0.9736,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 228.3728278389899,
    "total_upload_time": 584.1704095680034,
    "p95_time": 0.00495764604784199,
    "rps": 225.7328696732991,
    "parallel": 1,
    "p99_time": 0.005451302610381394,
    "mean_time": 0.0037892990405816816,
    "mean_precisions": 0.9940200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.003578892908990383,
    "rps": 325.1994978677146,
    "parallel": 1,
    "p99_time": 0.004057152485474945,
    "mean_time": 0.003014236361067742,
    "mean_precisions": 0.928478,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.004094042675569653,
    "rps": 286.0922939543392,
    "parallel": 1,
    "p99_time": 0.004504729490727186,
    "mean_time": 0.003432258109841496,
    "mean_precisions": 0.971419,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.00597987612709403,
    "rps": 215.18127872313545,
    "parallel": 1,
    "p99_time": 0.006529228882864118,
    "mean_time": 0.004578397462330758,
    "mean_precisions": 0.992243,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.008209502091631293,
    "rps": 163.44790021674214,
    "parallel": 1,
    "p99_time": 0.009125979086384177,
    "mean_time": 0.006040607302077115,
    "mean_precisions": 0.997303,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.0065880820620805025,
    "rps": 197.86385779467315,
    "parallel": 1,
    "p99_time": 0.0072026540059596305,
    "mean_time": 0.004984978382661939,
    "mean_precisions": 0.993159,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.0064878821372985835,
    "rps": 199.44594090123613,
    "parallel": 1,
    "p99_time": 0.0071486792806535965,
    "mean_time": 0.004943665190786123,
    "mean_precisions": 0.9944200000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.006596355885267258,
    "rps": 198.42498299007892,
    "parallel": 1,
    "p99_time": 0.0072476040106266735,
    "mean_time": 0.004971139814145863,
    "mean_precisions": 0.9946390000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.008130336971953511,
    "rps": 164.20310698627424,
    "parallel": 1,
    "p99_time": 0.00895986787043512,
    "mean_time": 0.006016857735160738,
    "mean_precisions": 0.997303,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.07587850126437842,
    "rps": 1359.689197140256,
    "parallel": 100,
    "p99_time": 0.1273927347362042,
    "mean_time": 0.07190578255848959,
    "mean_precisions": 0.9284779999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.0876611927524209,
    "rps": 1163.3391268684165,
    "parallel": 100,
    "p99_time": 0.08948679485358298,
    "mean_time": 0.08374938143454493,
    "mean_precisions": 0.971419,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.11522664930671453,
    "rps": 889.9840018042619,
    "parallel": 100,
    "p99_time": 0.11829269059002401,
    "mean_time": 0.11010876778541133,
    "mean_precisions": 0.98939,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.16754212393425405,
    "rps": 615.6777938575445,
    "parallel": 100,
    "p99_time": 0.17083094591274858,
    "mean_time": 0.16008117851335554,
    "mean_precisions": 0.9963190000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.004977833013981581,
    "rps": 241.35572242037603,
    "parallel": 1,
    "p99_time": 0.005599447824060917,
    "mean_time": 0.004077794419135899,
    "mean_precisions": 0.9893900000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.09743566680699586,
    "rps": 1043.83049296081,
    "parallel": 100,
    "p99_time": 0.10017272510565818,
    "mean_time": 0.0936710195209831,
    "mean_precisions": 0.9599859999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.11252619363367557,
    "rps": 907.8364941335984,
    "parallel": 100,
    "p99_time": 0.11536034955643118,
    "mean_time": 0.10800397670939564,
    "mean_precisions": 0.9787859999999998,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.1477020127698779,
    "rps": 691.0586545798318,
    "parallel": 100,
    "p99_time": 0.14985016269609333,
    "mean_time": 0.14251730669718235,
    "mean_precisions": 0.992243,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.21526695019565523,
    "rps": 479.6677923595984,
    "parallel": 100,
    "p99_time": 0.21900672879070043,
    "mean_time": 0.20596697238488124,
    "mean_precisions": 0.997303,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.12142158797942101,
    "rps": 844.6485848380038,
    "parallel": 100,
    "p99_time": 0.12451514009386301,
    "mean_time": 0.1162006926253438,
    "mean_precisions": 0.9837230000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.12222847123630345,
    "rps": 837.4671531143255,
    "parallel": 100,
    "p99_time": 0.12592695170082152,
    "mean_time": 0.1172028483367525,
    "mean_precisions": 0.9849420000000002,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.14701385828666388,
    "rps": 695.3718539807987,
    "parallel": 100,
    "p99_time": 0.1487186193931848,
    "mean_time": 0.14154982991870493,
    "mean_precisions": 0.992243,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.21588037810288369,
    "rps": 478.4842847718043,
    "parallel": 100,
    "p99_time": 0.22122054846957329,
    "mean_time": 0.20645214739125223,
    "mean_precisions": 0.997303,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.16292546060867608,
    "rps": 626.1672230435594,
    "parallel": 100,
    "p99_time": 0.16542420197278263,
    "mean_time": 0.15680545121468603,
    "mean_precisions": 0.993159,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.16488261185586453,
    "rps": 622.1379558462696,
    "parallel": 100,
    "p99_time": 0.16973979730159044,
    "mean_time": 0.15833328851507977,
    "mean_precisions": 0.9944200000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.006767591042444109,
    "rps": 183.3461249749111,
    "parallel": 1,
    "p99_time": 0.007700025839731097,
    "mean_time": 0.005385532464273274,
    "mean_precisions": 0.9963190000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.1657480512280017,
    "rps": 617.0031712823657,
    "parallel": 100,
    "p99_time": 0.16797872923314572,
    "mean_time": 0.15977131039667875,
    "mean_precisions": 0.9946390000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.21577359433285892,
    "rps": 478.7404138765225,
    "parallel": 100,
    "p99_time": 0.22057069801725449,
    "mean_time": 0.2063652462963946,
    "mean_precisions": 0.997303,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.004086786182597279,
    "rps": 293.93819373391716,
    "parallel": 1,
    "p99_time": 0.004518534280359745,
    "mean_time": 0.0033409632024355234,
    "mean_precisions": 0.959986,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.0047557591926306484,
    "rps": 262.1356724117528,
    "parallel": 1,
    "p99_time": 0.005132793309167027,
    "mean_time": 0.003752158835437149,
    "mean_precisions": 0.978786,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.0059851313475519415,
    "rps": 215.52954241042335,
    "parallel": 1,
    "p99_time": 0.006520419614389539,
    "mean_time": 0.004573126643523574,
    "mean_precisions": 0.992243,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.008196221757680177,
    "rps": 163.2872896267247,
    "parallel": 1,
    "p99_time": 0.00900029075331986,
    "mean_time": 0.006052106024604291,
    "mean_precisions": 0.997303,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.005041081411764025,
    "rps": 247.87714208872134,
    "parallel": 1,
    "p99_time": 0.005468047168105841,
    "mean_time": 0.003969681956991553,
    "mean_precisions": 0.9837230000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 264.7458306080007,
    "total_upload_time": 1501.8586345220028,
    "p95_time": 0.0050909737125039095,
    "rps": 245.28434823247287,
    "parallel": 1,
    "p99_time": 0.005503600146621466,
    "mean_time": 0.004009803928155452,
    "mean_precisions": 0.984942,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.004062391037587076,
    "rps": 281.52888110379064,
    "parallel": 1,
    "p99_time": 0.005468939652200786,
    "mean_time": 0.0034699256364256145,
    "mean_precisions": 0.82827,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.0055295226862654085,
    "rps": 213.33258450029223,
    "parallel": 1,
    "p99_time": 0.006462002417538314,
    "mean_time": 0.004585979338735342,
    "mean_precisions": 0.9144,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.009594983083661645,
    "rps": 134.13410094624183,
    "parallel": 1,
    "p99_time": 0.011532045160420239,
    "mean_time": 0.007348557185614482,
    "mean_precisions": 0.9741700000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.013964885275345295,
    "rps": 91.09020078488066,
    "parallel": 1,
    "p99_time": 0.0157836093660444,
    "mean_time": 0.010845442411256954,
    "mean_precisions": 0.9894400000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.010216670273803175,
    "rps": 124.65064949238923,
    "parallel": 1,
    "p99_time": 0.01146857016487047,
    "mean_time": 0.007907999638700858,
    "mean_precisions": 0.98122,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.009841678955126554,
    "rps": 125.75526532531576,
    "parallel": 1,
    "p99_time": 0.0113238479453139,
    "mean_time": 0.007842157877748833,
    "mean_precisions": 0.98121,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.010420020716264843,
    "rps": 120.90628848973151,
    "parallel": 1,
    "p99_time": 0.012401713910512625,
    "mean_time": 0.008153220052365214,
    "mean_precisions": 0.98122,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.013987977209035305,
    "rps": 91.52953662090508,
    "parallel": 1,
    "p99_time": 0.01649241401348263,
    "mean_time": 0.010783446083776653,
    "mean_precisions": 0.9894400000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.07600001114187761,
    "rps": 1211.7036446578807,
    "parallel": 100,
    "p99_time": 0.07728003651602193,
    "mean_time": 0.06516986659751274,
    "mean_precisions": 0.82827,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.12010004421463236,
    "rps": 830.6730703524007,
    "parallel": 100,
    "p99_time": 0.12192192852497101,
    "mean_time": 0.09752427429915406,
    "mean_precisions": 0.9144000000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.20009731678292156,
    "rps": 517.292218651752,
    "parallel": 100,
    "p99_time": 0.20233327853493394,
    "mean_time": 0.16887849815073422,
    "mean_precisions": 0.9632999999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.327278359583579,
    "rps": 324.51500570886424,
    "parallel": 100,
    "p99_time": 0.3305245877779089,
    "mean_time": 0.28005885197222236,
    "mean_precisions": 0.98494,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.008145199797581881,
    "rps": 149.51882487463186,
    "parallel": 1,
    "p99_time": 0.009392952418420463,
    "mean_time": 0.0065661912155337634,
    "mean_precisions": 0.9632999999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.10827122437767685,
    "rps": 898.3273676314626,
    "parallel": 100,
    "p99_time": 0.10904438771307469,
    "mean_time": 0.08852411112957634,
    "mean_precisions": 0.89713,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.1516645956900902,
    "rps": 662.8579063447434,
    "parallel": 100,
    "p99_time": 0.15392332784831525,
    "mean_time": 0.12777657681703566,
    "mean_precisions": 0.93852,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.2654009576886892,
    "rps": 412.8147553412919,
    "parallel": 100,
    "p99_time": 0.2705225909268483,
    "mean_time": 0.21676113371388056,
    "mean_precisions": 0.9741700000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.4183916187728755,
    "rps": 256.63531341139327,
    "parallel": 100,
    "p99_time": 0.42447785632451995,
    "mean_time": 0.35862694708770143,
    "mean_precisions": 0.9894400000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.1742285206913948,
    "rps": 584.8311063926769,
    "parallel": 100,
    "p99_time": 0.1763939567725174,
    "mean_time": 0.14673052079812623,
    "mean_precisions": 0.95452,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.17617664920398965,
    "rps": 577.8904272777354,
    "parallel": 100,
    "p99_time": 0.17932578804669902,
    "mean_time": 0.14933831570413894,
    "mean_precisions": 0.95451,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.24443189698504283,
    "rps": 424.52300940400556,
    "parallel": 100,
    "p99_time": 0.24880636020563543,
    "mean_time": 0.210530937705189,
    "mean_precisions": 0.9741700000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.40634114025160667,
    "rps": 261.2858825252251,
    "parallel": 100,
    "p99_time": 0.4148426111065783,
    "mean_time": 0.35214882960147226,
    "mean_precisions": 0.9894400000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.2740434653824195,
    "rps": 385.1066991375817,
    "parallel": 100,
    "p99_time": 0.2790068061812781,
    "mean_time": 0.2333778487795498,
    "mean_precisions": 0.98122,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.28115463455906137,
    "rps": 371.354643226056,
    "parallel": 100,
    "p99_time": 0.28551282388390975,
    "mean_time": 0.24339406502223573,
    "mean_precisions": 0.98121,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.012535514961928129,
    "rps": 100.68743185272541,
    "parallel": 1,
    "p99_time": 0.014159726651851084,
    "mean_time": 0.009795640668598934,
    "mean_precisions": 0.98494,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.30123474179999904,
    "rps": 359.56517608713,
    "parallel": 100,
    "p99_time": 0.30468698154203594,
    "mean_time": 0.2509887514957227,
    "mean_precisions": 0.98122,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.40999065468786283,
    "rps": 258.8783827333865,
    "parallel": 100,
    "p99_time": 0.41498736632755023,
    "mean_time": 0.355112239522161,
    "mean_precisions": 0.9894400000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.004795396130066365,
    "rps": 247.80385396041092,
    "parallel": 1,
    "p99_time": 0.005203701092395931,
    "mean_time": 0.003943958366056904,
    "mean_precisions": 0.89713,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.0063963548047468064,
    "rps": 192.82287817762096,
    "parallel": 1,
    "p99_time": 0.00840476869838312,
    "mean_time": 0.005091125892242416,
    "mean_precisions": 0.93852,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.00926837840816006,
    "rps": 136.4779431487573,
    "parallel": 1,
    "p99_time": 0.01100431782659143,
    "mean_time": 0.007217390358215198,
    "mean_precisions": 0.9741700000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.014630669099278747,
    "rps": 89.36529066317577,
    "parallel": 1,
    "p99_time": 0.01687581358011812,
    "mean_time": 0.011051362443482503,
    "mean_precisions": 0.9894400000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.006811540108174086,
    "rps": 178.67438301465273,
    "parallel": 1,
    "p99_time": 0.008228774208109824,
    "mean_time": 0.005496799184009433,
    "mean_precisions": 0.95452,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 125.10763692799992,
    "total_upload_time": 390.88685319700016,
    "p95_time": 0.007192118349485099,
    "rps": 171.8252982107776,
    "parallel": 1,
    "p99_time": 0.008778142845258116,
    "mean_time": 0.005715069920057431,
    "mean_precisions": 0.95451,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.004672924951410094,
    "rps": 268.36568831508936,
    "parallel": 1,
    "p99_time": 0.006548522710072576,
    "mean_time": 0.0036635260644048684,
    "mean_precisions": 0.7360260000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.005486685149480762,
    "rps": 230.02013774896255,
    "parallel": 1,
    "p99_time": 0.0073716214108935675,
    "mean_time": 0.004283072652907867,
    "mean_precisions": 0.824924,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.007104785800765964,
    "rps": 181.61405266194933,
    "parallel": 1,
    "p99_time": 0.008864230199324084,
    "mean_time": 0.005437555653019444,
    "mean_precisions": 0.886984,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.010372078501313803,
    "rps": 129.8382871768991,
    "parallel": 1,
    "p99_time": 0.01227587049117574,
    "mean_time": 0.007623616932397272,
    "mean_precisions": 0.934307,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.007736532697890647,
    "rps": 166.62547642400082,
    "parallel": 1,
    "p99_time": 0.009584454939649734,
    "mean_time": 0.005930737893216065,
    "mean_precisions": 0.8760550000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.00777154485003848,
    "rps": 166.7372764740223,
    "parallel": 1,
    "p99_time": 0.00957470996800112,
    "mean_time": 0.005926993217616109,
    "mean_precisions": 0.904216,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.007887724101237835,
    "rps": 164.15974584966528,
    "parallel": 1,
    "p99_time": 0.009792429608532986,
    "mean_time": 0.006018300612505482,
    "mean_precisions": 0.905115,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.010247087651987383,
    "rps": 130.8327823416813,
    "parallel": 1,
    "p99_time": 0.012058043481229106,
    "mean_time": 0.007567193930495341,
    "mean_precisions": 0.934307,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.05247380350192543,
    "rps": 2095.5001793260717,
    "parallel": 100,
    "p99_time": 0.0588490494724465,
    "mean_time": 0.044579093994102,
    "mean_precisions": 0.7360260000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.06352990044888429,
    "rps": 1721.0688199276044,
    "parallel": 100,
    "p99_time": 0.06905330447934831,
    "mean_time": 0.0557655441537001,
    "mean_precisions": 0.824924,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.08383184809790692,
    "rps": 1275.1959325320358,
    "parallel": 100,
    "p99_time": 0.08831307749234839,
    "mean_time": 0.07599058794368248,
    "mean_precisions": 0.886984,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.13035679979730047,
    "rps": 825.1436641956077,
    "parallel": 100,
    "p99_time": 0.1355861248688234,
    "mean_time": 0.11871137920850561,
    "mean_precisions": 0.934307,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.007122595851978985,
    "rps": 181.11363123675218,
    "parallel": 1,
    "p99_time": 0.008761838029058711,
    "mean_time": 0.005450891043792581,
    "mean_precisions": 0.886984,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.0552844477999315,
    "rps": 1966.5575741992545,
    "parallel": 100,
    "p99_time": 0.060160224079008916,
    "mean_time": 0.04767031070817539,
    "mean_precisions": 0.763383,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.06353470614994876,
    "rps": 1718.203642840594,
    "parallel": 100,
    "p99_time": 0.06950799665031811,
    "mean_time": 0.055642322546590364,
    "mean_precisions": 0.824924,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.08411759954906302,
    "rps": 1259.1477337837919,
    "parallel": 100,
    "p99_time": 0.08966310829000577,
    "mean_time": 0.07702241617100408,
    "mean_precisions": 0.886984,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.12429947890086623,
    "rps": 843.5066641350978,
    "parallel": 100,
    "p99_time": 0.12841094015078852,
    "mean_time": 0.11617112731670096,
    "mean_precisions": 0.934307,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.06878038840113732,
    "rps": 1573.5936030424034,
    "parallel": 100,
    "p99_time": 0.0727775952520824,
    "mean_time": 0.06117474455619631,
    "mean_precisions": 0.8274960000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.06778963390006539,
    "rps": 1586.4077553141635,
    "parallel": 100,
    "p99_time": 0.07417670572918723,
    "mean_time": 0.060727124177589575,
    "mean_precisions": 0.8482790000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.08390178804984316,
    "rps": 1265.059668470625,
    "parallel": 100,
    "p99_time": 0.08746501755929786,
    "mean_time": 0.07655845605518626,
    "mean_precisions": 0.886984,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.12954803590127995,
    "rps": 826.4610380341646,
    "parallel": 100,
    "p99_time": 0.136633504180827,
    "mean_time": 0.11838169067140225,
    "mean_precisions": 0.934307,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.09583789589760272,
    "rps": 1124.7405433050276,
    "parallel": 100,
    "p99_time": 0.10000763478219597,
    "mean_time": 0.0864903877366014,
    "mean_precisions": 0.8760549999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.09700059265069284,
    "rps": 1111.231894733521,
    "parallel": 100,
    "p99_time": 0.10399927963990195,
    "mean_time": 0.08759497140510757,
    "mean_precisions": 0.904216,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.010232145549525735,
    "rps": 128.58704417619748,
    "parallel": 1,
    "p99_time": 0.012001560039061592,
    "mean_time": 0.007695836162700653,
    "mean_precisions": 0.934307,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.0956669231514752,
    "rps": 1114.674613640289,
    "parallel": 100,
    "p99_time": 0.09946023167973181,
    "mean_time": 0.0872303119878903,
    "mean_precisions": 0.905115,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.1276506833015446,
    "rps": 836.9019509015314,
    "parallel": 100,
    "p99_time": 0.13290045161869785,
    "mean_time": 0.11695127419727178,
    "mean_precisions": 0.934307,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.0047951295511666076,
    "rps": 257.48696011942087,
    "parallel": 1,
    "p99_time": 0.006562322389363544,
    "mean_time": 0.0038209719293045056,
    "mean_precisions": 0.763383,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.005478596649663812,
    "rps": 229.47930349308558,
    "parallel": 1,
    "p99_time": 0.007455591667785488,
    "mean_time": 0.004290210731792468,
    "mean_precisions": 0.824924,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.007092799351448773,
    "rps": 181.57909438293282,
    "parallel": 1,
    "p99_time": 0.008652090462528579,
    "mean_time": 0.005436710934907387,
    "mean_precisions": 0.886984,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.010371224551090562,
    "rps": 128.85231970884143,
    "parallel": 1,
    "p99_time": 0.012374055357686303,
    "mean_time": 0.007676015573110999,
    "mean_precisions": 0.934307,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.005859128947486168,
    "rps": 215.73598698095483,
    "parallel": 1,
    "p99_time": 0.007713716910475342,
    "mean_time": 0.004568737027280804,
    "mean_precisions": 0.8274959999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 45.797179175002384,
    "total_upload_time": 319.09494570600145,
    "p95_time": 0.0060285574991212326,
    "rps": 214.39594087753912,
    "parallel": 1,
    "p99_time": 0.007770499910548097,
    "mean_time": 0.004598493717794918,
    "mean_precisions": 0.8482790000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.0026429555473441724,
    "rps": 366.52741368052574,
    "parallel": 1,
    "p99_time": 0.0029462209260964303,
    "mean_time": 0.00217757411399798,
    "mean_precisions": 0.97052,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.0026147773049160607,
    "rps": 366.9136184378059,
    "parallel": 1,
    "p99_time": 0.0029033027110563128,
    "mean_time": 0.0021760936021615633,
    "mean_precisions": 0.9834400000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.005522208596812562,
    "rps": 202.7761696708173,
    "parallel": 1,
    "p99_time": 0.006146678593722756,
    "mean_time": 0.0042776017205629615,
    "mean_precisions": 0.99708,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.0057393455543206075,
    "rps": 196.5021252864866,
    "parallel": 1,
    "p99_time": 0.0064056752883334496,
    "mean_time": 0.004427705826389137,
    "mean_precisions": 0.9971,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.008800701595464488,
    "rps": 138.41501442519845,
    "parallel": 1,
    "p99_time": 0.009903659778792645,
    "mean_time": 0.00655725685665966,
    "mean_precisions": 0.9847400000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.008737676746022771,
    "rps": 138.70698129848358,
    "parallel": 1,
    "p99_time": 0.009881631608441242,
    "mean_time": 0.0065470924925772125,
    "mean_precisions": 0.9984800000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.008786584649351427,
    "rps": 138.08960683907094,
    "parallel": 1,
    "p99_time": 0.010009534106284267,
    "mean_time": 0.006578874719791929,
    "mean_precisions": 0.99866,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.008778558703852468,
    "rps": 138.72981121019555,
    "parallel": 1,
    "p99_time": 0.009953318306288567,
    "mean_time": 0.00654560920556396,
    "mean_precisions": 0.9986799999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.0031815757956792368,
    "rps": 1236.411871552735,
    "parallel": 100,
    "p99_time": 0.007367042283367486,
    "mean_time": 0.002569117962378368,
    "mean_precisions": 0.97052,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.003272561251287698,
    "rps": 1234.940217108062,
    "parallel": 100,
    "p99_time": 0.007428688046711633,
    "mean_time": 0.0025886142164454214,
    "mean_precisions": 0.9834400000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.003226992304553278,
    "rps": 1225.9197481416452,
    "parallel": 100,
    "p99_time": 0.006750047291643571,
    "mean_time": 0.002585521270999743,
    "mean_precisions": 0.98364,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.004290488597325748,
    "rps": 1233.987460345812,
    "parallel": 100,
    "p99_time": 0.007957538720074833,
    "mean_time": 0.003142724534252193,
    "mean_precisions": 0.98806,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.00270116540377785,
    "rps": 361.6631749365758,
    "parallel": 1,
    "p99_time": 0.0029515244499634732,
    "mean_time": 0.0022098053305759095,
    "mean_precisions": 0.98364,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.08597350470408856,
    "rps": 1153.1120439566444,
    "parallel": 100,
    "p99_time": 0.08726810921893048,
    "mean_time": 0.0685700369315935,
    "mean_precisions": 0.9794200000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.08697308845075895,
    "rps": 1151.1523326213282,
    "parallel": 100,
    "p99_time": 0.08899911758620875,
    "mean_time": 0.06888058337838593,
    "mean_precisions": 0.993,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.08844431010293193,
    "rps": 1131.0925294975323,
    "parallel": 100,
    "p99_time": 0.09119763518545372,
    "mean_time": 0.07706620720918726,
    "mean_precisions": 0.99318,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.08964319270489796,
    "rps": 1117.5149962786588,
    "parallel": 100,
    "p99_time": 0.09065332610851329,
    "mean_time": 0.07730890367941029,
    "mean_precisions": 0.9932,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.14776864064697293,
    "rps": 691.3263434272978,
    "parallel": 100,
    "p99_time": 0.15012423780106474,
    "mean_time": 0.13835408535882016,
    "mean_precisions": 0.9832400000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.1487627727470681,
    "rps": 688.3718051570465,
    "parallel": 100,
    "p99_time": 0.15240317829069683,
    "mean_time": 0.1394650868236742,
    "mean_precisions": 0.9969,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.1494738347013481,
    "rps": 684.1184349939828,
    "parallel": 100,
    "p99_time": 0.15201176084046894,
    "mean_time": 0.13984071987316565,
    "mean_precisions": 0.99708,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.15176577430138422,
    "rps": 672.7263853840014,
    "parallel": 100,
    "p99_time": 0.15419325335955364,
    "mean_time": 0.14229420799319342,
    "mean_precisions": 0.9971,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.25432222439885666,
    "rps": 404.06670471778364,
    "parallel": 100,
    "p99_time": 0.2577670570006012,
    "mean_time": 0.2416464882887696,
    "mean_precisions": 0.9847400000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.25451778779934103,
    "rps": 402.62731176502314,
    "parallel": 100,
    "p99_time": 0.2577030191080121,
    "mean_time": 0.24218391442808787,
    "mean_precisions": 0.9984800000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.002945968051426462,
    "rps": 335.1913881351392,
    "parallel": 1,
    "p99_time": 0.003262463945793571,
    "mean_time": 0.002406816498702392,
    "mean_precisions": 0.9880599999999998,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.2558677974509919,
    "rps": 400.7110442127018,
    "parallel": 100,
    "p99_time": 0.25967874686139114,
    "mean_time": 0.24370761750758974,
    "mean_precisions": 0.99866,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.2569337407498097,
    "rps": 398.38996629547484,
    "parallel": 100,
    "p99_time": 0.2597442363422306,
    "mean_time": 0.24495819881579373,
    "mean_precisions": 0.9986799999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.003611167650524294,
    "rps": 286.85930512069655,
    "parallel": 1,
    "p99_time": 0.003977323052895372,
    "mean_time": 0.0028870411491574485,
    "mean_precisions": 0.9794199999999998,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.0036099485958402512,
    "rps": 283.86846237682903,
    "parallel": 1,
    "p99_time": 0.00401429121477122,
    "mean_time": 0.0029242360010292034,
    "mean_precisions": 0.993,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.003722741199089796,
    "rps": 279.97957245972077,
    "parallel": 1,
    "p99_time": 0.004156782820209629,
    "mean_time": 0.002970446384655952,
    "mean_precisions": 0.99318,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.0036776729037228508,
    "rps": 280.61482160767923,
    "parallel": 1,
    "p99_time": 0.004082904362367118,
    "mean_time": 0.00296313887660217,
    "mean_precisions": 0.9932,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.005253004348196555,
    "rps": 209.4294012939643,
    "parallel": 1,
    "p99_time": 0.005934225886157949,
    "mean_time": 0.004124301539355656,
    "mean_precisions": 0.9832400000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 217.79812404001132,
    "total_upload_time": 895.9800113510573,
    "p95_time": 0.005333231347321998,
    "rps": 207.43105722274646,
    "parallel": 1,
    "p99_time": 0.0059635180424083955,
    "mean_time": 0.004172321884734265,
    "mean_precisions": 0.9969,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.0035654310602694747,
    "rps": 319.29348665275074,
    "parallel": 1,
    "p99_time": 0.003938073320314288,
    "mean_time": 0.003072468310780823,
    "mean_precisions": 0.9245439999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.004225826729089021,
    "rps": 275.0268293622099,
    "parallel": 1,
    "p99_time": 0.004656152492389083,
    "mean_time": 0.0035736856879666446,
    "mean_precisions": 0.9749300000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.00519990026950836,
    "rps": 223.28257187001154,
    "parallel": 1,
    "p99_time": 0.006185321332886815,
    "mean_time": 0.00441250373404473,
    "mean_precisions": 0.991926,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.007331896992400287,
    "rps": 165.82962773233044,
    "parallel": 1,
    "p99_time": 0.008758817771449687,
    "mean_time": 0.005958522044867277,
    "mean_precisions": 0.997393,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.005654987180605531,
    "rps": 207.28365865750973,
    "parallel": 1,
    "p99_time": 0.006695641949772837,
    "mean_time": 0.004753137428686023,
    "mean_precisions": 0.9780260000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.005770077183842659,
    "rps": 204.82066204139105,
    "parallel": 1,
    "p99_time": 0.006852897163480521,
    "mean_time": 0.004814575376920402,
    "mean_precisions": 0.9937790000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.006289710104465483,
    "rps": 198.53273352119948,
    "parallel": 1,
    "p99_time": 0.007384851267561316,
    "mean_time": 0.004968142510391771,
    "mean_precisions": 0.994504,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.008184225531294938,
    "rps": 160.9679925758667,
    "parallel": 1,
    "p99_time": 0.009429055424407124,
    "mean_time": 0.0061409401074051856,
    "mean_precisions": 0.997393,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.06442998056299983,
    "rps": 1608.6495012193939,
    "parallel": 100,
    "p99_time": 0.12457847309298821,
    "mean_time": 0.06051835605911911,
    "mean_precisions": 0.9245439999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.075370225450024,
    "rps": 1366.6090135445102,
    "parallel": 100,
    "p99_time": 0.07761250225827097,
    "mean_time": 0.07101898188916966,
    "mean_precisions": 0.9749300000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.10087533420883119,
    "rps": 1010.2767150833798,
    "parallel": 100,
    "p99_time": 0.10662163247354331,
    "mean_time": 0.09624594940794631,
    "mean_precisions": 0.9917959999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.14927342175506056,
    "rps": 692.0868931687806,
    "parallel": 100,
    "p99_time": 0.15214476542547348,
    "mean_time": 0.14226690858192742,
    "mean_precisions": 0.997359,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.005360149638727307,
    "rps": 217.12731183708405,
    "parallel": 1,
    "p99_time": 0.006027651857584716,
    "mean_time": 0.004537957986071706,
    "mean_precisions": 0.9917959999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.07443831264972686,
    "rps": 1372.4407954502767,
    "parallel": 100,
    "p99_time": 0.08183944733813413,
    "mean_time": 0.07075741206519305,
    "mean_precisions": 0.9428129999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.08683861684985458,
    "rps": 1190.144812500048,
    "parallel": 100,
    "p99_time": 0.08971747242845594,
    "mean_time": 0.08183640723545105,
    "mean_precisions": 0.9754710000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.1155269625596702,
    "rps": 888.0984246075903,
    "parallel": 100,
    "p99_time": 0.12101453584618867,
    "mean_time": 0.11044629455171526,
    "mean_precisions": 0.991926,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.17255939026363193,
    "rps": 598.1742992749105,
    "parallel": 100,
    "p99_time": 0.17530101928859948,
    "mean_time": 0.1648188245243393,
    "mean_precisions": 0.997393,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.09406195958144963,
    "rps": 1091.7944904276865,
    "parallel": 100,
    "p99_time": 0.09581464740447701,
    "mean_time": 0.08940852055745199,
    "mean_precisions": 0.9690880000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.09599315063096582,
    "rps": 1065.1783354477898,
    "parallel": 100,
    "p99_time": 0.09942095754668118,
    "mean_time": 0.09099370451308787,
    "mean_precisions": 0.9831409999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.11622393787838518,
    "rps": 884.5067973713763,
    "parallel": 100,
    "p99_time": 0.11835706111043692,
    "mean_time": 0.11091003062510862,
    "mean_precisions": 0.991926,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.1730513744056225,
    "rps": 596.8829805755666,
    "parallel": 100,
    "p99_time": 0.17568924339488148,
    "mean_time": 0.16515611667977645,
    "mean_precisions": 0.997393,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.13071174118667842,
    "rps": 790.9590917856319,
    "parallel": 100,
    "p99_time": 0.13393814970739185,
    "mean_time": 0.12421687286728993,
    "mean_precisions": 0.9780260000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.13074186621233821,
    "rps": 785.2745121941656,
    "parallel": 100,
    "p99_time": 0.13296782663092016,
    "mean_time": 0.12502134237401188,
    "mean_precisions": 0.9937790000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.007204993348568678,
    "rps": 166.45780515470392,
    "parallel": 1,
    "p99_time": 0.008085536966100336,
    "mean_time": 0.005937481832783669,
    "mean_precisions": 0.997359,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.1313476799055934,
    "rps": 782.4707440550993,
    "parallel": 100,
    "p99_time": 0.13431333027780057,
    "mean_time": 0.12562320995433257,
    "mean_precisions": 0.994504,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.1718995571602136,
    "rps": 595.7150285460884,
    "parallel": 100,
    "p99_time": 0.17610064681619406,
    "mean_time": 0.16370944452201946,
    "mean_precisions": 0.997393,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.0037633722182363262,
    "rps": 299.3161973970022,
    "parallel": 1,
    "p99_time": 0.004227512031793595,
    "mean_time": 0.0032767544421367346,
    "mean_precisions": 0.9428130000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.004283202532678842,
    "rps": 266.8526209265104,
    "parallel": 1,
    "p99_time": 0.00499576329253614,
    "mean_time": 0.0036835292499512434,
    "mean_precisions": 0.9754710000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.005314685311168432,
    "rps": 220.02349332462748,
    "parallel": 1,
    "p99_time": 0.006540986625477673,
    "mean_time": 0.004478715351969004,
    "mean_precisions": 0.991926,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.007224834198132157,
    "rps": 167.5348137278132,
    "parallel": 1,
    "p99_time": 0.008413725122809416,
    "mean_time": 0.005898798809573055,
    "mean_precisions": 0.997393,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.004336392041295767,
    "rps": 260.7786463537188,
    "parallel": 1,
    "p99_time": 0.004861603640019894,
    "mean_time": 0.0037692985996603968,
    "mean_precisions": 0.9690880000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 296.6749817439995,
    "total_upload_time": 2629.118173392002,
    "p95_time": 0.004434378305450082,
    "rps": 255.7613850387002,
    "parallel": 1,
    "p99_time": 0.005264985021203758,
    "mean_time": 0.0038430912358686327,
    "mean_precisions": 0.9831409999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.004720262798946351,
    "rps": 253.96630718344784,
    "parallel": 1,
    "p99_time": 0.006825934422668068,
    "mean_time": 0.003855561401695013,
    "mean_precisions": 0.8718199999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.006603498326148837,
    "rps": 183.36156662596804,
    "parallel": 1,
    "p99_time": 0.00868857114110142,
    "mean_time": 0.005357977236388251,
    "mean_precisions": 0.9447900000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.010414199798833576,
    "rps": 120.68820417918232,
    "parallel": 1,
    "p99_time": 0.012316015961114316,
    "mean_time": 0.008173433359246701,
    "mean_precisions": 0.9830099999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.016254513314925133,
    "rps": 78.50255115146652,
    "parallel": 1,
    "p99_time": 0.018153928311076015,
    "mean_time": 0.012611206690315157,
    "mean_precisions": 0.9936500000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.011423539405222982,
    "rps": 110.21698213837311,
    "parallel": 1,
    "p99_time": 0.012477804308291525,
    "mean_time": 0.008949409642489628,
    "mean_precisions": 0.9880399999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.011644742835778743,
    "rps": 109.49978180573353,
    "parallel": 1,
    "p99_time": 0.013358886805362999,
    "mean_time": 0.009021727844141424,
    "mean_precisions": 0.9880500000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.011496983468532562,
    "rps": 108.20948990481753,
    "parallel": 1,
    "p99_time": 0.012795042535290123,
    "mean_time": 0.00912217179336585,
    "mean_precisions": 0.9880500000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.015972793544642625,
    "rps": 80.82173509626969,
    "parallel": 1,
    "p99_time": 0.01734456842765212,
    "mean_time": 0.012252968129469083,
    "mean_precisions": 0.9936500000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.08447176107438281,
    "rps": 1114.870640551216,
    "parallel": 100,
    "p99_time": 0.08772519514663145,
    "mean_time": 0.0684697625709232,
    "mean_precisions": 0.8718199999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.13048066905466837,
    "rps": 762.8320646294263,
    "parallel": 100,
    "p99_time": 0.1334578563971445,
    "mean_time": 0.1098867916550953,
    "mean_precisions": 0.9447900000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.21693824087269603,
    "rps": 479.84679678920855,
    "parallel": 100,
    "p99_time": 0.22042749202111736,
    "mean_time": 0.1847383015193045,
    "mean_precisions": 0.97972,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.36017890410730613,
    "rps": 290.50268800159546,
    "parallel": 100,
    "p99_time": 0.3650189866614528,
    "mean_time": 0.31547710777213794,
    "mean_precisions": 0.99227,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.00962016750127077,
    "rps": 126.82723785881443,
    "parallel": 1,
    "p99_time": 0.010419292850419879,
    "mean_time": 0.0077836983248125765,
    "mean_precisions": 0.97972,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.11976926162606105,
    "rps": 826.0547562632787,
    "parallel": 100,
    "p99_time": 0.12188839422538876,
    "mean_time": 0.09944356520916335,
    "mean_precisions": 0.91952,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.16562850786140187,
    "rps": 616.8419959080803,
    "parallel": 100,
    "p99_time": 0.16820811369689181,
    "mean_time": 0.13916732245613822,
    "mean_precisions": 0.95509,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.265281406766735,
    "rps": 389.77540621776035,
    "parallel": 100,
    "p99_time": 0.26891557455761356,
    "mean_time": 0.23043301770533436,
    "mean_precisions": 0.9830099999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.4413094239076599,
    "rps": 238.55814483785522,
    "parallel": 100,
    "p99_time": 0.45010747484862806,
    "mean_time": 0.38715587215684355,
    "mean_precisions": 0.9936500000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.19163112057140097,
    "rps": 544.5275563062395,
    "parallel": 100,
    "p99_time": 0.19408112411620096,
    "mean_time": 0.16024780040537007,
    "mean_precisions": 0.9681000000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.19729421579977496,
    "rps": 522.4304702751598,
    "parallel": 100,
    "p99_time": 0.20023498704656958,
    "mean_time": 0.16694642772898077,
    "mean_precisions": 0.96811,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.28077446115203203,
    "rps": 376.8533564572805,
    "parallel": 100,
    "p99_time": 0.2846172846900299,
    "mean_time": 0.24040536584006622,
    "mean_precisions": 0.9830099999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.44558306490071115,
    "rps": 237.9807722874666,
    "parallel": 100,
    "p99_time": 0.45269915585406123,
    "mean_time": 0.3880124056278728,
    "mean_precisions": 0.9936499999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.30790914678946135,
    "rps": 341.22643629286455,
    "parallel": 100,
    "p99_time": 0.31252307111164557,
    "mean_time": 0.26626409831340425,
    "mean_precisions": 0.98804,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.3137755052186549,
    "rps": 336.51017956207556,
    "parallel": 100,
    "p99_time": 0.3179993469431065,
    "mean_time": 0.2702553837832529,
    "mean_precisions": 0.9880500000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.015060708008240909,
    "rps": 82.61294317423359,
    "parallel": 1,
    "p99_time": 0.01653100869152695,
    "mean_time": 0.01197317444998771,
    "mean_precisions": 0.99227,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.31858236400876194,
    "rps": 328.0099798866239,
    "parallel": 100,
    "p99_time": 0.3229329121857881,
    "mean_time": 0.2776725703838747,
    "mean_precisions": 0.9880500000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.45776229734765367,
    "rps": 232.81844446085296,
    "parallel": 100,
    "p99_time": 0.4644112538616173,
    "mean_time": 0.39647669504326766,
    "mean_precisions": 0.9936500000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.005299826664850116,
    "rps": 220.79166421588624,
    "parallel": 1,
    "p99_time": 0.006462744374293833,
    "mean_time": 0.004436775987502187,
    "mean_precisions": 0.91952,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.006875167076941579,
    "rps": 178.63669542890273,
    "parallel": 1,
    "p99_time": 0.008142214359249916,
    "mean_time": 0.005502578557701782,
    "mean_precisions": 0.95509,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.01051343660801649,
    "rps": 120.69964812020044,
    "parallel": 1,
    "p99_time": 0.011801741989329456,
    "mean_time": 0.008175943374168129,
    "mean_precisions": 0.9830099999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.015924804587848482,
    "rps": 79.83339302235642,
    "parallel": 1,
    "p99_time": 0.017557207772042602,
    "mean_time": 0.012404059156775475,
    "mean_precisions": 0.9936500000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.007796420727390795,
    "rps": 160.51504320934305,
    "parallel": 1,
    "p99_time": 0.009145036046393214,
    "mean_time": 0.006130610328167677,
    "mean_precisions": 0.9681000000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.71100308399946,
    "total_upload_time": 539.4887163499998,
    "p95_time": 0.008119064336642622,
    "rps": 156.028958114439,
    "parallel": 1,
    "p99_time": 0.009603052616585044,
    "mean_time": 0.006307320485590026,
    "mean_precisions": 0.96811,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.004902030899393139,
    "rps": 255.89386241218727,
    "parallel": 1,
    "p99_time": 0.006790535019645179,
    "mean_time": 0.0038428438075839948,
    "mean_precisions": 0.7588280000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.005796787751023655,
    "rps": 215.9935147135,
    "parallel": 1,
    "p99_time": 0.007691380567739544,
    "mean_time": 0.004561164114412532,
    "mean_precisions": 0.852086,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.007667015449624159,
    "rps": 167.8026897548295,
    "parallel": 1,
    "p99_time": 0.009611576689421784,
    "mean_time": 0.005886694826405438,
    "mean_precisions": 0.9134740000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.011401144798401219,
    "rps": 114.7681590469467,
    "parallel": 1,
    "p99_time": 0.013312498620325642,
    "mean_time": 0.008612033851187152,
    "mean_precisions": 0.9561129999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.008541037050963495,
    "rps": 150.73243556218532,
    "parallel": 1,
    "p99_time": 0.010661440860203583,
    "mean_time": 0.006554436722197715,
    "mean_precisions": 0.8970879999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.008747064400085944,
    "rps": 152.35062085695893,
    "parallel": 1,
    "p99_time": 0.010975617389049149,
    "mean_time": 0.006489382972308522,
    "mean_precisions": 0.9296699999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.008244818200182632,
    "rps": 153.06926266518803,
    "parallel": 1,
    "p99_time": 0.010008005541349122,
    "mean_time": 0.006453477819227919,
    "mean_precisions": 0.930587,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.0110407234986269,
    "rps": 119.48985220544432,
    "parallel": 1,
    "p99_time": 0.012921154710529665,
    "mean_time": 0.008284309061792373,
    "mean_precisions": 0.9561129999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.053511298999910646,
    "rps": 2006.8555103363508,
    "parallel": 100,
    "p99_time": 0.06106538189917049,
    "mean_time": 0.04675011777090112,
    "mean_precisions": 0.7588280000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.0670901606008556,
    "rps": 1598.6483952170797,
    "parallel": 100,
    "p99_time": 0.07063598682667362,
    "mean_time": 0.06023991567861085,
    "mean_precisions": 0.8520859999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.09635124139786057,
    "rps": 1125.662284685588,
    "parallel": 100,
    "p99_time": 0.10027241101834079,
    "mean_time": 0.08644910409229524,
    "mean_precisions": 0.913474,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.14581755945018812,
    "rps": 727.9932636087926,
    "parallel": 100,
    "p99_time": 0.1517904100674423,
    "mean_time": 0.13483283344949887,
    "mean_precisions": 0.9561130000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.007774669051104862,
    "rps": 165.38157257485852,
    "parallel": 1,
    "p99_time": 0.009552777019198403,
    "mean_time": 0.005972247150390831,
    "mean_precisions": 0.9134740000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.05602152390165429,
    "rps": 1891.4288570719348,
    "parallel": 100,
    "p99_time": 0.06186392514147884,
    "mean_time": 0.049530029847517656,
    "mean_precisions": 0.787109,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.06883989725047286,
    "rps": 1582.4082715409522,
    "parallel": 100,
    "p99_time": 0.07542847440101469,
    "mean_time": 0.060803324036486084,
    "mean_precisions": 0.852086,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.09254844585084356,
    "rps": 1145.5502268354398,
    "parallel": 100,
    "p99_time": 0.09760333606154746,
    "mean_time": 0.08474406382712768,
    "mean_precisions": 0.913474,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.14655890479807565,
    "rps": 731.3762403703479,
    "parallel": 100,
    "p99_time": 0.15270968377066313,
    "mean_time": 0.1341765974148122,
    "mean_precisions": 0.9561130000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.07527711394814104,
    "rps": 1438.8913480757737,
    "parallel": 100,
    "p99_time": 0.0788531673779653,
    "mean_time": 0.06691579668208869,
    "mean_precisions": 0.852089,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.07517965230217669,
    "rps": 1431.6110144420854,
    "parallel": 100,
    "p99_time": 0.07887542591000965,
    "mean_time": 0.06719398410809117,
    "mean_precisions": 0.875785,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.09580342105073214,
    "rps": 1116.1376591339383,
    "parallel": 100,
    "p99_time": 0.10021272040801706,
    "mean_time": 0.08638747578850416,
    "mean_precisions": 0.913474,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.1454524306980602,
    "rps": 728.1622733422819,
    "parallel": 100,
    "p99_time": 0.15419671028095763,
    "mean_time": 0.1347693705894024,
    "mean_precisions": 0.9561130000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.10555859314918052,
    "rps": 1001.744982459704,
    "parallel": 100,
    "p99_time": 0.10991941325923109,
    "mean_time": 0.09719452100466078,
    "mean_precisions": 0.8970879999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.10529612345035275,
    "rps": 1007.0537240227179,
    "parallel": 100,
    "p99_time": 0.11005141329875187,
    "mean_time": 0.0967155704933888,
    "mean_precisions": 0.9296700000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.011593649650785664,
    "rps": 113.8286396980862,
    "parallel": 1,
    "p99_time": 0.013645933042098485,
    "mean_time": 0.008696964122003192,
    "mean_precisions": 0.9561129999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.1067160790989874,
    "rps": 993.2196353883512,
    "parallel": 100,
    "p99_time": 0.11098349774936651,
    "mean_time": 0.09812368382257991,
    "mean_precisions": 0.930587,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.14527141190246767,
    "rps": 729.031403714044,
    "parallel": 100,
    "p99_time": 0.15015932705955493,
    "mean_time": 0.13483012804428654,
    "mean_precisions": 0.9561130000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.005184835502768692,
    "rps": 244.5973534570085,
    "parallel": 1,
    "p99_time": 0.007023189391293274,
    "mean_time": 0.004025208921403828,
    "mean_precisions": 0.7871090000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.00574171819971525,
    "rps": 218.4921622880417,
    "parallel": 1,
    "p99_time": 0.007642380421493726,
    "mean_time": 0.004509790896186314,
    "mean_precisions": 0.852086,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.007658126797650765,
    "rps": 166.76391059966244,
    "parallel": 1,
    "p99_time": 0.009462363269340137,
    "mean_time": 0.005924638306794804,
    "mean_precisions": 0.9134740000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.011429611099993053,
    "rps": 113.96561614863047,
    "parallel": 1,
    "p99_time": 0.013280538530816562,
    "mean_time": 0.008677736550897316,
    "mean_precisions": 0.9561129999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.006217451697921204,
    "rps": 202.3960882449696,
    "parallel": 1,
    "p99_time": 0.008014581991301385,
    "mean_time": 0.004872432530770311,
    "mean_precisions": 0.852089,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 53.307377715002076,
    "total_upload_time": 638.963331539002,
    "p95_time": 0.006390998250390105,
    "rps": 197.65135358709364,
    "parallel": 1,
    "p99_time": 0.008124859522795307,
    "mean_time": 0.0049900130842794165,
    "mean_precisions": 0.875785,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.002953189750405727,
    "rps": 329.9803986745982,
    "parallel": 1,
    "p99_time": 0.0031981047173758287,
    "mean_time": 0.002469538642191037,
    "mean_precisions": 0.9714599999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.0030445189033343925,
    "rps": 323.1978433842412,
    "parallel": 1,
    "p99_time": 0.0033540776883455694,
    "mean_time": 0.002518941939029901,
    "mean_precisions": 0.98674,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.006604497200532933,
    "rps": 170.7178352862593,
    "parallel": 1,
    "p99_time": 0.0072865425502095646,
    "mean_time": 0.005186568422819255,
    "mean_precisions": 0.9982200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.006596764255300513,
    "rps": 171.2616067794554,
    "parallel": 1,
    "p99_time": 0.007109658438421321,
    "mean_time": 0.0051856881440049615,
    "mean_precisions": 0.9982200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.010423688895025407,
    "rps": 116.24605246333792,
    "parallel": 1,
    "p99_time": 0.011457593960585658,
    "mean_time": 0.007942725318735756,
    "mean_precisions": 0.98288,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.010701050901479903,
    "rps": 113.7288459617293,
    "parallel": 1,
    "p99_time": 0.012077721302630384,
    "mean_time": 0.008120336515536473,
    "mean_precisions": 0.9992400000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.010497459851103487,
    "rps": 115.51886037385796,
    "parallel": 1,
    "p99_time": 0.01153710572456476,
    "mean_time": 0.00798869747514982,
    "mean_precisions": 0.9994599999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.010697589648043505,
    "rps": 113.59985674749981,
    "parallel": 1,
    "p99_time": 0.01208460176414519,
    "mean_time": 0.00812071916397399,
    "mean_precisions": 0.9994799999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.004027590850091656,
    "rps": 1218.544628781139,
    "parallel": 100,
    "p99_time": 0.0091287174819445,
    "mean_time": 0.0031567874117885367,
    "mean_precisions": 0.9714599999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.004083716949025984,
    "rps": 1225.7618378219229,
    "parallel": 100,
    "p99_time": 0.008187137877321225,
    "mean_time": 0.0031233741834803368,
    "mean_precisions": 0.98674,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.004058958154200809,
    "rps": 1208.5258781022674,
    "parallel": 100,
    "p99_time": 0.007885778148556713,
    "mean_time": 0.0031482813775757677,
    "mean_precisions": 0.9869,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.005978156602941454,
    "rps": 1215.2283997144734,
    "parallel": 100,
    "p99_time": 0.008658046019845645,
    "mean_time": 0.004025346374075161,
    "mean_precisions": 0.99034,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.0031211436995363328,
    "rps": 314.42631792114923,
    "parallel": 1,
    "p99_time": 0.003417189211759252,
    "mean_time": 0.002586651864608575,
    "mean_precisions": 0.9869,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.10399506209905666,
    "rps": 968.890001812682,
    "parallel": 100,
    "p99_time": 0.10591746160011098,
    "mean_time": 0.09476679669395671,
    "mean_precisions": 0.9792200000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.10474307970252994,
    "rps": 962.9109544458719,
    "parallel": 100,
    "p99_time": 0.1068703083289438,
    "mean_time": 0.09542352173114195,
    "mean_precisions": 0.99508,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.10508840409638652,
    "rps": 955.7854835756287,
    "parallel": 100,
    "p99_time": 0.10625545015071111,
    "mean_time": 0.09508348495701502,
    "mean_precisions": 0.9952799999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.10772385375021258,
    "rps": 938.1768309631607,
    "parallel": 100,
    "p99_time": 0.10998561429441907,
    "mean_time": 0.09838302442732239,
    "mean_precisions": 0.9952799999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.1789610220974282,
    "rps": 572.1482847986709,
    "parallel": 100,
    "p99_time": 0.18086378936546682,
    "mean_time": 0.16860170916402567,
    "mean_precisions": 0.98182,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.17993541365540294,
    "rps": 567.1963926323622,
    "parallel": 100,
    "p99_time": 0.18193471560422042,
    "mean_time": 0.1706973305448235,
    "mean_precisions": 0.998,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.18346221199826687,
    "rps": 560.1982346511239,
    "parallel": 100,
    "p99_time": 0.18643496806071197,
    "mean_time": 0.1726626338971924,
    "mean_precisions": 0.9982200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.18266819404998386,
    "rps": 558.7464272689623,
    "parallel": 100,
    "p99_time": 0.18462460084672785,
    "mean_time": 0.17325559460680087,
    "mean_precisions": 0.9982200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.3081170490993827,
    "rps": 332.8458808737706,
    "parallel": 100,
    "p99_time": 0.3118134850480419,
    "mean_time": 0.2941017594692108,
    "mean_precisions": 0.9828800000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.3098762462941522,
    "rps": 330.50212879871617,
    "parallel": 100,
    "p99_time": 0.31347584133000056,
    "mean_time": 0.2960600625743973,
    "mean_precisions": 0.9992400000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.0034004813482169994,
    "rps": 290.28278189627025,
    "parallel": 1,
    "p99_time": 0.0037390828555362563,
    "mean_time": 0.002842914285212464,
    "mean_precisions": 0.99034,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.31013268024944407,
    "rps": 330.41369151785017,
    "parallel": 100,
    "p99_time": 0.31413459448027425,
    "mean_time": 0.2963543079087918,
    "mean_precisions": 0.9994599999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.31190008055127694,
    "rps": 328.6594602041053,
    "parallel": 100,
    "p99_time": 0.31514897171000483,
    "mean_time": 0.2978965999945896,
    "mean_precisions": 0.9994799999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.004218454998408561,
    "rps": 245.8903084205283,
    "parallel": 1,
    "p99_time": 0.0046349881404603365,
    "mean_time": 0.0034429905548880924,
    "mean_precisions": 0.9792200000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.004257933298140415,
    "rps": 244.10172203895223,
    "parallel": 1,
    "p99_time": 0.004666098957604846,
    "mean_time": 0.0034733857295344934,
    "mean_precisions": 0.99508,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.004282714698638302,
    "rps": 243.24092657720303,
    "parallel": 1,
    "p99_time": 0.004743045379509567,
    "mean_time": 0.0034880256135671516,
    "mean_precisions": 0.9952799999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.004341250599100022,
    "rps": 239.3577678103729,
    "parallel": 1,
    "p99_time": 0.004780585562693887,
    "mean_time": 0.0035391428261864347,
    "mean_precisions": 0.9952799999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.006562077704438707,
    "rps": 172.6956923272781,
    "parallel": 1,
    "p99_time": 0.00713680858440057,
    "mean_time": 0.005137985429796391,
    "mean_precisions": 0.98182,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 226.4939720389666,
    "total_upload_time": 1386.15487282502,
    "p95_time": 0.006739825953627587,
    "rps": 169.86108011271733,
    "parallel": 1,
    "p99_time": 0.00755406555879745,
    "mean_time": 0.005221365747618256,
    "mean_precisions": 0.998,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.003632355341687798,
    "rps": 314.0948285901794,
    "parallel": 1,
    "p99_time": 0.0040634915977716445,
    "mean_time": 0.003122801478765905,
    "mean_precisions": 0.937702,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.004294592421501874,
    "rps": 263.98153242777835,
    "parallel": 1,
    "p99_time": 0.004726139232516289,
    "mean_time": 0.0037208881712518633,
    "mean_precisions": 0.9812060000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.005522051453590393,
    "rps": 209.44064474967416,
    "parallel": 1,
    "p99_time": 0.00637790510430932,
    "mean_time": 0.004706361664459109,
    "mean_precisions": 0.9948239999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.00785698750987649,
    "rps": 153.87991985598336,
    "parallel": 1,
    "p99_time": 0.008962721945717933,
    "mean_time": 0.006426009119208902,
    "mean_precisions": 0.9985029999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.006101479846984148,
    "rps": 193.59764277647255,
    "parallel": 1,
    "p99_time": 0.00707970291376114,
    "mean_time": 0.005091384366620332,
    "mean_precisions": 0.9847480000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.006125191086903214,
    "rps": 192.96225636193105,
    "parallel": 1,
    "p99_time": 0.007164068296551705,
    "mean_time": 0.0051119858596473935,
    "mean_precisions": 0.995976,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.006072344863787293,
    "rps": 193.61560378588757,
    "parallel": 1,
    "p99_time": 0.006912986347451807,
    "mean_time": 0.00509606679501012,
    "mean_precisions": 0.996641,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.007849178742617367,
    "rps": 154.97415482106382,
    "parallel": 1,
    "p99_time": 0.009047340163961056,
    "mean_time": 0.006380788511224091,
    "mean_precisions": 0.9985029999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.06449475889094174,
    "rps": 1561.0883003264832,
    "parallel": 100,
    "p99_time": 0.12246593835763635,
    "mean_time": 0.062296775241475554,
    "mean_precisions": 0.937702,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.0783220250159502,
    "rps": 1299.005600006,
    "parallel": 100,
    "p99_time": 0.08036034711636604,
    "mean_time": 0.07416963666770607,
    "mean_precisions": 0.9812060000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.10614654566161334,
    "rps": 969.2823564321977,
    "parallel": 100,
    "p99_time": 0.11042241482064129,
    "mean_time": 0.10101092435140163,
    "mean_precisions": 0.9946740000000002,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.16077821515500546,
    "rps": 649.8848876476767,
    "parallel": 100,
    "p99_time": 0.16525816237553953,
    "mean_time": 0.151500752123259,
    "mean_precisions": 0.9984740000000002,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.005519934557378292,
    "rps": 209.7970283396572,
    "parallel": 1,
    "p99_time": 0.006183885503560306,
    "mean_time": 0.004698471211828291,
    "mean_precisions": 0.994674,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.07726021520793437,
    "rps": 1329.799574214118,
    "parallel": 100,
    "p99_time": 0.08053844133391977,
    "mean_time": 0.07300931119946763,
    "mean_precisions": 0.9550360000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.09066592180170117,
    "rps": 1133.734845338433,
    "parallel": 100,
    "p99_time": 0.09361574565060438,
    "mean_time": 0.08591629439014942,
    "mean_precisions": 0.9818819999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.12286164010874927,
    "rps": 832.780287456797,
    "parallel": 100,
    "p99_time": 0.12576568739488722,
    "mean_time": 0.11786416020197794,
    "mean_precisions": 0.9948239999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.18230862249620258,
    "rps": 566.6391413097132,
    "parallel": 100,
    "p99_time": 0.18610799860209226,
    "mean_time": 0.17399556362507865,
    "mean_precisions": 0.9985029999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.09805143396370111,
    "rps": 1038.8356458838414,
    "parallel": 100,
    "p99_time": 0.10120791738852862,
    "mean_time": 0.09340705563649535,
    "mean_precisions": 0.9778130000000002,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.09841421605087816,
    "rps": 1039.5509574566095,
    "parallel": 100,
    "p99_time": 0.10075923547148705,
    "mean_time": 0.09393766997409984,
    "mean_precisions": 0.988059,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.12224212400615216,
    "rps": 839.5238941436968,
    "parallel": 100,
    "p99_time": 0.1244937498215586,
    "mean_time": 0.11691220250353217,
    "mean_precisions": 0.9948239999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.18244141270406544,
    "rps": 568.3772028790183,
    "parallel": 100,
    "p99_time": 0.18634326679632068,
    "mean_time": 0.17341831127190963,
    "mean_precisions": 0.9985029999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.13701359364204108,
    "rps": 753.166575056714,
    "parallel": 100,
    "p99_time": 0.1406666036322713,
    "mean_time": 0.13043268980132416,
    "mean_precisions": 0.9847480000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.1372160329017788,
    "rps": 751.4003634874854,
    "parallel": 100,
    "p99_time": 0.13994560105726123,
    "mean_time": 0.1306988419882022,
    "mean_precisions": 0.995976,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.00785912899300456,
    "rps": 153.74971849951947,
    "parallel": 1,
    "p99_time": 0.00869321112520993,
    "mean_time": 0.0064322674508206544,
    "mean_precisions": 0.9984740000000002,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.1389716801699251,
    "rps": 741.1577947272513,
    "parallel": 100,
    "p99_time": 0.14161698957905172,
    "mean_time": 0.13253115194449203,
    "mean_precisions": 0.9966410000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.18082182756625115,
    "rps": 571.7708025312654,
    "parallel": 100,
    "p99_time": 0.1841467997711152,
    "mean_time": 0.1724477424994111,
    "mean_precisions": 0.9985029999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.0039335030131042,
    "rps": 296.1055240472772,
    "parallel": 1,
    "p99_time": 0.004445553366094828,
    "mean_time": 0.0033163429856300354,
    "mean_precisions": 0.9550360000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.004244591621682048,
    "rps": 265.6239493669492,
    "parallel": 1,
    "p99_time": 0.004848863566294313,
    "mean_time": 0.003700254795327783,
    "mean_precisions": 0.9818819999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.005472219269722699,
    "rps": 210.42190120722034,
    "parallel": 1,
    "p99_time": 0.006094692209735514,
    "mean_time": 0.004683523830212652,
    "mean_precisions": 0.9948239999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.008000344224274158,
    "rps": 152.33018075027772,
    "parallel": 1,
    "p99_time": 0.009369549443945293,
    "mean_time": 0.0064858150322921575,
    "mean_precisions": 0.9985029999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.004628342762589455,
    "rps": 246.53947567737765,
    "parallel": 1,
    "p99_time": 0.005291406316682698,
    "mean_time": 0.0039894491981714965,
    "mean_precisions": 0.9778130000000002,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 312.3308781730011,
    "total_upload_time": 5484.725805805996,
    "p95_time": 0.004599289502948522,
    "rps": 245.89327324423022,
    "parallel": 1,
    "p99_time": 0.005396050121635199,
    "mean_time": 0.004000012410152703,
    "mean_precisions": 0.988059,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.006299698038492349,
    "rps": 203.6174923491529,
    "parallel": 1,
    "p99_time": 0.012785102766938502,
    "mean_time": 0.004823657226283104,
    "mean_precisions": 0.86407,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.0075079112779349085,
    "rps": 159.33106618400424,
    "parallel": 1,
    "p99_time": 0.008759995906148102,
    "mean_time": 0.006181106130825355,
    "mean_precisions": 0.94269,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.011472372256685048,
    "rps": 108.2584484547531,
    "parallel": 1,
    "p99_time": 0.012636177923996001,
    "mean_time": 0.009127053432166576,
    "mean_precisions": 0.97931,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.017899149062577634,
    "rps": 69.69404514356222,
    "parallel": 1,
    "p99_time": 0.02015628748573363,
    "mean_time": 0.01420939748454839,
    "mean_precisions": 0.99343,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.01374874033499509,
    "rps": 93.2012473679039,
    "parallel": 1,
    "p99_time": 0.015146919817198068,
    "mean_time": 0.010604590672068297,
    "mean_precisions": 0.98119,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.012996053195092828,
    "rps": 94.57648668807377,
    "parallel": 1,
    "p99_time": 0.014766908138990401,
    "mean_time": 0.010444377473788336,
    "mean_precisions": 0.9863200000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.013386774284299461,
    "rps": 92.46917669674664,
    "parallel": 1,
    "p99_time": 0.015775402334984392,
    "mean_time": 0.010690964435227216,
    "mean_precisions": 0.98631,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.018683503021020443,
    "rps": 68.90767180258987,
    "parallel": 1,
    "p99_time": 0.021090031589847055,
    "mean_time": 0.014359958151122554,
    "mean_precisions": 0.99343,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.07716072091134266,
    "rps": 1179.163772157904,
    "parallel": 100,
    "p99_time": 0.07896238782675936,
    "mean_time": 0.06302839161059819,
    "mean_precisions": 0.8640699999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.11989055309677496,
    "rps": 824.9725329066027,
    "parallel": 100,
    "p99_time": 0.12281018616864457,
    "mean_time": 0.09655774197820574,
    "mean_precisions": 0.94269,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.19049290244001896,
    "rps": 533.621235782354,
    "parallel": 100,
    "p99_time": 0.1939648574963212,
    "mean_time": 0.1634060430736281,
    "mean_precisions": 0.97896,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.32376524454448374,
    "rps": 323.5925454723652,
    "parallel": 100,
    "p99_time": 0.3303351556463167,
    "mean_time": 0.28123076761560517,
    "mean_precisions": 0.99333,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.01173449378693476,
    "rps": 106.02738270009273,
    "parallel": 1,
    "p99_time": 0.013593927903566509,
    "mean_time": 0.009320605878718198,
    "mean_precisions": 0.97896,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.10981031277915461,
    "rps": 932.804697990332,
    "parallel": 100,
    "p99_time": 0.11361783581087366,
    "mean_time": 0.08267490359372459,
    "mean_precisions": 0.89851,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.13586628027260303,
    "rps": 735.2206589074266,
    "parallel": 100,
    "p99_time": 0.13807811353588476,
    "mean_time": 0.11270478692092001,
    "mean_precisions": 0.94353,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.21637317733839154,
    "rps": 474.77101173435557,
    "parallel": 100,
    "p99_time": 0.22013721988769247,
    "mean_time": 0.18557482428033836,
    "mean_precisions": 0.97931,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.35542153562419115,
    "rps": 295.2537756876141,
    "parallel": 100,
    "p99_time": 0.3606251259148121,
    "mean_time": 0.3086348201148212,
    "mean_precisions": 0.99343,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.15777578469133005,
    "rps": 654.7879802138701,
    "parallel": 100,
    "p99_time": 0.16187235072255135,
    "mean_time": 0.12902564586303197,
    "mean_precisions": 0.95604,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.15513565501896665,
    "rps": 646.2295319431335,
    "parallel": 100,
    "p99_time": 0.1577831773320213,
    "mean_time": 0.129804846375715,
    "mean_precisions": 0.95968,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.2183348712744191,
    "rps": 474.3538971633378,
    "parallel": 100,
    "p99_time": 0.22228992401622236,
    "mean_time": 0.18576079903217033,
    "mean_precisions": 0.9793099999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.363912296819035,
    "rps": 291.0145210525226,
    "parallel": 100,
    "p99_time": 0.37076412489870564,
    "mean_time": 0.3139931566268206,
    "mean_precisions": 0.99343,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.24803968211635946,
    "rps": 421.3265587409793,
    "parallel": 100,
    "p99_time": 0.2521665922086686,
    "mean_time": 0.21210462415101938,
    "mean_precisions": 0.98119,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.25193785016890613,
    "rps": 413.81788796458466,
    "parallel": 100,
    "p99_time": 0.2546921824011952,
    "mean_time": 0.21546326875011437,
    "mean_precisions": 0.9863200000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.018841893540229648,
    "rps": 67.57582462611364,
    "parallel": 1,
    "p99_time": 0.021194823274854568,
    "mean_time": 0.014655510283773765,
    "mean_precisions": 0.99333,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.26820643664104865,
    "rps": 405.19776461229117,
    "parallel": 100,
    "p99_time": 0.27507952944841235,
    "mean_time": 0.22097897489438764,
    "mean_precisions": 0.98631,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.3526334504247643,
    "rps": 297.15985983338,
    "parallel": 100,
    "p99_time": 0.3586601919354871,
    "mean_time": 0.3074057440632023,
    "mean_precisions": 0.99343,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.006241296615917235,
    "rps": 196.4038245256464,
    "parallel": 1,
    "p99_time": 0.008542035303544254,
    "mean_time": 0.005002306124195457,
    "mean_precisions": 0.89851,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.007790911069605499,
    "rps": 156.4528425490311,
    "parallel": 1,
    "p99_time": 0.009806272122077643,
    "mean_time": 0.006292299551423639,
    "mean_precisions": 0.94353,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.011528092809021473,
    "rps": 107.65973528147192,
    "parallel": 1,
    "p99_time": 0.013103246618993578,
    "mean_time": 0.009172835884382948,
    "mean_precisions": 0.97931,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.017788523330818862,
    "rps": 70.36235247723607,
    "parallel": 1,
    "p99_time": 0.01945099770091474,
    "mean_time": 0.014080394621938467,
    "mean_precisions": 0.99343,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.00845428896136582,
    "rps": 142.3764182788505,
    "parallel": 1,
    "p99_time": 0.010339636709541081,
    "mean_time": 0.006920541208004579,
    "mean_precisions": 0.9560400000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.75860126799944,
    "total_upload_time": 821.8218694449988,
    "p95_time": 0.009093259589280932,
    "rps": 137.5037198052846,
    "parallel": 1,
    "p99_time": 0.010559268360957502,
    "mean_time": 0.00716753516276367,
    "mean_precisions": 0.9596800000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.005015788200944369,
    "rps": 245.84705613904237,
    "parallel": 1,
    "p99_time": 0.007007773821387674,
    "mean_time": 0.004003404388781928,
    "mean_precisions": 0.768253,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.006121869400885768,
    "rps": 205.44657822275082,
    "parallel": 1,
    "p99_time": 0.00800476928885474,
    "mean_time": 0.00479944649197314,
    "mean_precisions": 0.864684,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.008332697799050947,
    "rps": 154.7342436220804,
    "parallel": 1,
    "p99_time": 0.010463682568552034,
    "mean_time": 0.006386507563078703,
    "mean_precisions": 0.926592,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.012572252800237037,
    "rps": 103.72915152819375,
    "parallel": 1,
    "p99_time": 0.014717415332452221,
    "mean_time": 0.009544492121729127,
    "mean_precisions": 0.966832,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.009354480298497943,
    "rps": 138.65956916386065,
    "parallel": 1,
    "p99_time": 0.011579204431254767,
    "mean_time": 0.007133376753193806,
    "mean_precisions": 0.9070060000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.009349584250594485,
    "rps": 138.5407541533227,
    "parallel": 1,
    "p99_time": 0.011384348630635945,
    "mean_time": 0.00713827960459057,
    "mean_precisions": 0.942383,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.010031167750639725,
    "rps": 134.6927381980177,
    "parallel": 1,
    "p99_time": 0.012564145709329753,
    "mean_time": 0.007337691940885634,
    "mean_precisions": 0.9433,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.01232247200241544,
    "rps": 104.74297895973005,
    "parallel": 1,
    "p99_time": 0.014207932279859965,
    "mean_time": 0.009458438030890465,
    "mean_precisions": 0.966832,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.057998962600686356,
    "rps": 1896.1055401012356,
    "parallel": 100,
    "p99_time": 0.06483243177961415,
    "mean_time": 0.050061315803502655,
    "mean_precisions": 0.768253,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.071513018648875,
    "rps": 1494.9048464475725,
    "parallel": 100,
    "p99_time": 0.07584317799919518,
    "mean_time": 0.06419350375278882,
    "mean_precisions": 0.864684,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.10471620469870685,
    "rps": 1030.934483090955,
    "parallel": 100,
    "p99_time": 0.10944454409083847,
    "mean_time": 0.09462066865501838,
    "mean_precisions": 0.926592,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.1637001490480543,
    "rps": 644.934136863484,
    "parallel": 100,
    "p99_time": 0.16867026068150154,
    "mean_time": 0.1525623449865936,
    "mean_precisions": 0.966832,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.00822042660020088,
    "rps": 156.3841905053834,
    "parallel": 1,
    "p99_time": 0.010531550010855427,
    "mean_time": 0.00632178140707656,
    "mean_precisions": 0.926592,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.061076400401725545,
    "rps": 1751.0500897671116,
    "parallel": 100,
    "p99_time": 0.06785374705930737,
    "mean_time": 0.05417622881239804,
    "mean_precisions": 0.7977850000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.07226961230007874,
    "rps": 1479.9087966542302,
    "parallel": 100,
    "p99_time": 0.07610961536720424,
    "mean_time": 0.06507409290180258,
    "mean_precisions": 0.864684,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.10666811059963947,
    "rps": 1027.025039528175,
    "parallel": 100,
    "p99_time": 0.1123760815296555,
    "mean_time": 0.09469417129386894,
    "mean_precisions": 0.926592,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.16476648645257227,
    "rps": 644.747508467804,
    "parallel": 100,
    "p99_time": 0.17052493980892908,
    "mean_time": 0.1525362061313099,
    "mean_precisions": 0.966832,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.08037538265180046,
    "rps": 1329.0479807948225,
    "parallel": 100,
    "p99_time": 0.08571591482872463,
    "mean_time": 0.07262176831178585,
    "mean_precisions": 0.863814,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.0816591131979294,
    "rps": 1319.3866739901932,
    "parallel": 100,
    "p99_time": 0.08798039267810964,
    "mean_time": 0.07342920276671139,
    "mean_precisions": 0.888975,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.10526325704940973,
    "rps": 1022.792835340542,
    "parallel": 100,
    "p99_time": 0.11058345450797788,
    "mean_time": 0.09497089921420956,
    "mean_precisions": 0.926592,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.16353653045298414,
    "rps": 646.2599899687298,
    "parallel": 100,
    "p99_time": 0.1691545485972529,
    "mean_time": 0.15213541340760384,
    "mean_precisions": 0.9668320000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.11764997210048023,
    "rps": 894.1067979289777,
    "parallel": 100,
    "p99_time": 0.12226111863725238,
    "mean_time": 0.10936362437790667,
    "mean_precisions": 0.907006,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.11817605484848172,
    "rps": 893.8871204608204,
    "parallel": 100,
    "p99_time": 0.12162519748992055,
    "mean_time": 0.10940001676106004,
    "mean_precisions": 0.942383,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.012617267950918174,
    "rps": 103.30372352421242,
    "parallel": 1,
    "p99_time": 0.01470630196195998,
    "mean_time": 0.009591384019711404,
    "mean_precisions": 0.966832,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.12043818180009111,
    "rps": 885.5869721167459,
    "parallel": 100,
    "p99_time": 0.12485219575122757,
    "mean_time": 0.11030751367489065,
    "mean_precisions": 0.9433,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.16744027840177295,
    "rps": 636.7775702946767,
    "parallel": 100,
    "p99_time": 0.17291677597804667,
    "mean_time": 0.1544330206810966,
    "mean_precisions": 0.966832,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.005333575999793537,
    "rps": 231.93333876885302,
    "parallel": 1,
    "p99_time": 0.007199020630141606,
    "mean_time": 0.004246408202786915,
    "mean_precisions": 0.7977850000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.006299615949683353,
    "rps": 202.8693647423792,
    "parallel": 1,
    "p99_time": 0.007947995532013011,
    "mean_time": 0.004861637334914485,
    "mean_precisions": 0.864684,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.008424219699554668,
    "rps": 153.60326989500678,
    "parallel": 1,
    "p99_time": 0.010643201509519716,
    "mean_time": 0.006436684389406582,
    "mean_precisions": 0.926592,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.012555679000070083,
    "rps": 103.60116717113438,
    "parallel": 1,
    "p99_time": 0.014678333788506283,
    "mean_time": 0.009556874174398763,
    "mean_precisions": 0.966832,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.006684332401709978,
    "rps": 189.22747614802947,
    "parallel": 1,
    "p99_time": 0.008425029881109374,
    "mean_time": 0.005216023788313396,
    "mean_precisions": 0.863814,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 57.3555402359998,
    "total_upload_time": 1340.6456618529992,
    "p95_time": 0.006727855450481,
    "rps": 189.1969482910381,
    "parallel": 1,
    "p99_time": 0.00857189036181808,
    "mean_time": 0.005215772836906399,
    "mean_precisions": 0.888975,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.00292757515089761,
    "rps": 342.80080171564055,
    "parallel": 1,
    "p99_time": 0.0031854603590909425,
    "mean_time": 0.002362274597029318,
    "mean_precisions": 0.9766,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.0028927393952471905,
    "rps": 342.14373221992884,
    "parallel": 1,
    "p99_time": 0.00316055514078471,
    "mean_time": 0.0023604592845542357,
    "mean_precisions": 0.9871599999999998,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.006286769146026927,
    "rps": 184.71112768127827,
    "parallel": 1,
    "p99_time": 0.007001072099810705,
    "mean_time": 0.004751374328782549,
    "mean_precisions": 0.99782,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.0061891459507023685,
    "rps": 187.28956986265646,
    "parallel": 1,
    "p99_time": 0.006754631848889406,
    "mean_time": 0.004688292808640108,
    "mean_precisions": 0.9978400000000002,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.009738837302938919,
    "rps": 128.3316596249405,
    "parallel": 1,
    "p99_time": 0.011148567650379847,
    "mean_time": 0.007129327198427927,
    "mean_precisions": 0.9876799999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.009590765496977838,
    "rps": 129.22487145375342,
    "parallel": 1,
    "p99_time": 0.010680904688197193,
    "mean_time": 0.00707310653260356,
    "mean_precisions": 0.99902,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.009989890299766558,
    "rps": 125.77628294539755,
    "parallel": 1,
    "p99_time": 0.011524741648172502,
    "mean_time": 0.007282540887752839,
    "mean_precisions": 0.99916,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.009807758452370764,
    "rps": 127.41217630108945,
    "parallel": 1,
    "p99_time": 0.010833274290562273,
    "mean_time": 0.007185296373169695,
    "mean_precisions": 0.99918,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.004061328803800281,
    "rps": 1217.7224745422834,
    "parallel": 100,
    "p99_time": 0.009287501431099394,
    "mean_time": 0.00305585846308968,
    "mean_precisions": 0.9766,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.003958113001135644,
    "rps": 1217.696524364609,
    "parallel": 100,
    "p99_time": 0.0076836468562396535,
    "mean_time": 0.00299411238917819,
    "mean_precisions": 0.9871599999999998,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.004132799501530826,
    "rps": 1223.285764072953,
    "parallel": 100,
    "p99_time": 0.007706382668620801,
    "mean_time": 0.003056302932857943,
    "mean_precisions": 0.9872800000000002,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.007457589201658265,
    "rps": 1207.6408499280863,
    "parallel": 100,
    "p99_time": 0.009848851343995194,
    "mean_time": 0.004539614966545195,
    "mean_precisions": 0.99044,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.0029334537535760322,
    "rps": 336.1942722462762,
    "parallel": 1,
    "p99_time": 0.003238477699342185,
    "mean_time": 0.0024087715711430062,
    "mean_precisions": 0.9872800000000002,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.10429367760189052,
    "rps": 973.0096535018897,
    "parallel": 100,
    "p99_time": 0.10783384402770026,
    "mean_time": 0.09396466385351523,
    "mean_precisions": 0.9840400000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.10628631720101112,
    "rps": 957.2376641387114,
    "parallel": 100,
    "p99_time": 0.10779007385201113,
    "mean_time": 0.09522906130678457,
    "mean_precisions": 0.9952199999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.10724474905000535,
    "rps": 942.3921289389225,
    "parallel": 100,
    "p99_time": 0.11008011900346902,
    "mean_time": 0.09653534412613808,
    "mean_precisions": 0.9953400000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.10774978810186439,
    "rps": 943.7249580463406,
    "parallel": 100,
    "p99_time": 0.10929383958842663,
    "mean_time": 0.09723028940780205,
    "mean_precisions": 0.99536,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.1787169211474975,
    "rps": 575.5677495998359,
    "parallel": 100,
    "p99_time": 0.18204898110983778,
    "mean_time": 0.16793432205217104,
    "mean_precisions": 0.9865200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.17967122935297083,
    "rps": 573.0935206284884,
    "parallel": 100,
    "p99_time": 0.18448639413407364,
    "mean_time": 0.16847539942684234,
    "mean_precisions": 0.9976799999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.178804526847307,
    "rps": 573.5585017698286,
    "parallel": 100,
    "p99_time": 0.18272990565943473,
    "mean_time": 0.16843252378520265,
    "mean_precisions": 0.99782,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.18203369870425376,
    "rps": 564.3793121175013,
    "parallel": 100,
    "p99_time": 0.18594477206592275,
    "mean_time": 0.17125935925806698,
    "mean_precisions": 0.99784,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.3036538747513987,
    "rps": 339.8100837162976,
    "parallel": 100,
    "p99_time": 0.30889727209585544,
    "mean_time": 0.2880973162583701,
    "mean_precisions": 0.9876799999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.30711366429677583,
    "rps": 335.9601420982168,
    "parallel": 100,
    "p99_time": 0.31389698692277307,
    "mean_time": 0.2913140099641634,
    "mean_precisions": 0.99902,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.003272750852556783,
    "rps": 310.5765898425054,
    "parallel": 1,
    "p99_time": 0.0035476742740138444,
    "mean_time": 0.002640792566217715,
    "mean_precisions": 0.99044,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.305776768200667,
    "rps": 336.903922295625,
    "parallel": 100,
    "p99_time": 0.3094239860311063,
    "mean_time": 0.2903863941785894,
    "mean_precisions": 0.99916,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.3093164377489302,
    "rps": 333.1618678244739,
    "parallel": 100,
    "p99_time": 0.3179257902097015,
    "mean_time": 0.29373896233156704,
    "mean_precisions": 0.99918,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.0041034752004634354,
    "rps": 260.46029246336997,
    "parallel": 1,
    "p99_time": 0.004534001048814389,
    "mean_time": 0.0032220285570263513,
    "mean_precisions": 0.9840400000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.004062443647126201,
    "rps": 262.0325021282389,
    "parallel": 1,
    "p99_time": 0.0045010817961883744,
    "mean_time": 0.0032008462742334812,
    "mean_precisions": 0.9952200000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.004146204352582572,
    "rps": 259.1840517078486,
    "parallel": 1,
    "p99_time": 0.004615866301901408,
    "mean_time": 0.003237200288925669,
    "mean_precisions": 0.99534,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.004175331404258032,
    "rps": 256.20100078741393,
    "parallel": 1,
    "p99_time": 0.004576404987819844,
    "mean_time": 0.0032849572729784994,
    "mean_precisions": 0.9953599999999998,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.006162354548723671,
    "rps": 188.06817402295763,
    "parallel": 1,
    "p99_time": 0.006640154297347182,
    "mean_time": 0.004664570320000348,
    "mean_precisions": 0.9865200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 233.2000428129686,
    "total_upload_time": 922.791550293914,
    "p95_time": 0.006251063446688932,
    "rps": 186.77767235199477,
    "parallel": 1,
    "p99_time": 0.006811735144801787,
    "mean_time": 0.004705115996638779,
    "mean_precisions": 0.9976799999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.003937211306765676,
    "rps": 297.6649516399929,
    "parallel": 1,
    "p99_time": 0.004710145834833386,
    "mean_time": 0.003299022163171321,
    "mean_precisions": 0.94411,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.004597763251513242,
    "rps": 250.98269755168573,
    "parallel": 1,
    "p99_time": 0.00500685827806592,
    "mean_time": 0.003920775342080742,
    "mean_precisions": 0.982068,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.006182611687108872,
    "rps": 198.13162269885578,
    "parallel": 1,
    "p99_time": 0.007054410502314568,
    "mean_time": 0.00497916405973956,
    "mean_precisions": 0.9947830000000002,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.008993615908548235,
    "rps": 142.02391123478088,
    "parallel": 1,
    "p99_time": 0.010251027178019286,
    "mean_time": 0.006964854209218174,
    "mean_precisions": 0.9983910000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.006914742942899466,
    "rps": 179.26833513931,
    "parallel": 1,
    "p99_time": 0.007763776499778033,
    "mean_time": 0.005505137762986123,
    "mean_precisions": 0.9862550000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.007054250128567216,
    "rps": 177.53938763929597,
    "parallel": 1,
    "p99_time": 0.008150480501353741,
    "mean_time": 0.005561942641809582,
    "mean_precisions": 0.995864,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.006975436117500067,
    "rps": 177.09113052276578,
    "parallel": 1,
    "p99_time": 0.00783712489530444,
    "mean_time": 0.005575662750471383,
    "mean_precisions": 0.996525,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.009149621007964015,
    "rps": 140.77862470475745,
    "parallel": 1,
    "p99_time": 0.010613254178315403,
    "mean_time": 0.0070284499448724095,
    "mean_precisions": 0.9983910000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.0653162139467895,
    "rps": 1544.8053113087342,
    "parallel": 100,
    "p99_time": 0.12989846081472992,
    "mean_time": 0.06303801689632237,
    "mean_precisions": 0.94411,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.08091919282451272,
    "rps": 1267.9287883335378,
    "parallel": 100,
    "p99_time": 0.08262545002624393,
    "mean_time": 0.07668159373253584,
    "mean_precisions": 0.982068,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.11196328913792968,
    "rps": 928.6231247982244,
    "parallel": 100,
    "p99_time": 0.11707772898487746,
    "mean_time": 0.10550066408393904,
    "mean_precisions": 0.9945370000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.16523425932973623,
    "rps": 627.471373662422,
    "parallel": 100,
    "p99_time": 0.16887737956829368,
    "mean_time": 0.15697577877175062,
    "mean_precisions": 0.998332,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.006180587923154235,
    "rps": 195.37116408158596,
    "parallel": 1,
    "p99_time": 0.006763476841151718,
    "mean_time": 0.0050490937183611095,
    "mean_precisions": 0.9945370000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.07894128677435219,
    "rps": 1296.0146913100261,
    "parallel": 100,
    "p99_time": 0.08288881639949977,
    "mean_time": 0.07498289523404092,
    "mean_precisions": 0.9593139999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.09189414163120091,
    "rps": 1113.2460206446867,
    "parallel": 100,
    "p99_time": 0.09408403322100639,
    "mean_time": 0.08758371911300346,
    "mean_precisions": 0.982843,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.12700986065901815,
    "rps": 812.5138731651964,
    "parallel": 100,
    "p99_time": 0.12939044092781843,
    "mean_time": 0.12088537822002544,
    "mean_precisions": 0.994783,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.18727972274646162,
    "rps": 552.9858968041367,
    "parallel": 100,
    "p99_time": 0.19067826888523998,
    "mean_time": 0.1783661928205751,
    "mean_precisions": 0.998391,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.10225097453221679,
    "rps": 1005.1421335330614,
    "parallel": 100,
    "p99_time": 0.10666722361929715,
    "mean_time": 0.09688010449782014,
    "mean_precisions": 0.9794350000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.10114508573897182,
    "rps": 1012.4414284489878,
    "parallel": 100,
    "p99_time": 0.10282161574810743,
    "mean_time": 0.09646764069786296,
    "mean_precisions": 0.9883189999999998,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.12671122481115163,
    "rps": 812.0074234525146,
    "parallel": 100,
    "p99_time": 0.1292517673969269,
    "mean_time": 0.12098892869604752,
    "mean_precisions": 0.994783,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.18856543730944395,
    "rps": 550.4232158568121,
    "parallel": 100,
    "p99_time": 0.19160029945895077,
    "mean_time": 0.17916562693808227,
    "mean_precisions": 0.998391,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.14236501790583134,
    "rps": 726.0743538271273,
    "parallel": 100,
    "p99_time": 0.14520461806096138,
    "mean_time": 0.13542661452721805,
    "mean_precisions": 0.9862550000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.14250981686636804,
    "rps": 721.4088525650295,
    "parallel": 100,
    "p99_time": 0.145232300395146,
    "mean_time": 0.135629871991463,
    "mean_precisions": 0.995864,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.008970894664525985,
    "rps": 142.24234784461564,
    "parallel": 1,
    "p99_time": 0.010042305439710618,
    "mean_time": 0.006956465593911707,
    "mean_precisions": 0.998332,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.1447397185023874,
    "rps": 714.8071252253167,
    "parallel": 100,
    "p99_time": 0.14752543647773564,
    "mean_time": 0.13756739853788166,
    "mean_precisions": 0.996525,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.1878037879243493,
    "rps": 551.174030858665,
    "parallel": 100,
    "p99_time": 0.19089397705160083,
    "mean_time": 0.17890148383788765,
    "mean_precisions": 0.998391,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.003985596494749188,
    "rps": 284.3389744654495,
    "parallel": 1,
    "p99_time": 0.004513916773721576,
    "mean_time": 0.0034551244732923805,
    "mean_precisions": 0.9593139999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.00470388107933104,
    "rps": 249.38569390127032,
    "parallel": 1,
    "p99_time": 0.005381251564249396,
    "mean_time": 0.003943681065458804,
    "mean_precisions": 0.982843,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.0061619744636118405,
    "rps": 196.89549397276912,
    "parallel": 1,
    "p99_time": 0.006743700308725238,
    "mean_time": 0.005009413599502295,
    "mean_precisions": 0.9947830000000002,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.009601048426702617,
    "rps": 138.4719607562445,
    "parallel": 1,
    "p99_time": 0.011201300881803036,
    "mean_time": 0.007142403004970401,
    "mean_precisions": 0.9983910000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.005077505251392721,
    "rps": 233.24186756095247,
    "parallel": 1,
    "p99_time": 0.0058491690084338235,
    "mean_time": 0.0042215669088065625,
    "mean_precisions": 0.9794350000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 299.6633782239951,
    "total_upload_time": 3242.479995766,
    "p95_time": 0.00509298020042479,
    "rps": 231.83154146212868,
    "parallel": 1,
    "p99_time": 0.0058868041075766115,
    "mean_time": 0.004246954713016749,
    "mean_precisions": 0.9883190000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.004826936929021031,
    "rps": 253.77583562320922,
    "parallel": 1,
    "p99_time": 0.005349968278314917,
    "mean_time": 0.0038559293998405336,
    "mean_precisions": 0.88774,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.006897847016807646,
    "rps": 182.98627965687672,
    "parallel": 1,
    "p99_time": 0.007469428060576319,
    "mean_time": 0.005363679878646508,
    "mean_precisions": 0.95262,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.011951679293997585,
    "rps": 109.30039147018621,
    "parallel": 1,
    "p99_time": 0.013142344621010124,
    "mean_time": 0.009026628461200744,
    "mean_precisions": 0.9885700000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.018266110692638903,
    "rps": 72.52784582656973,
    "parallel": 1,
    "p99_time": 0.020749910308513787,
    "mean_time": 0.01365027177729644,
    "mean_precisions": 0.99655,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.013483857456594705,
    "rps": 97.87998524510817,
    "parallel": 1,
    "p99_time": 0.01441281077452004,
    "mean_time": 0.010092912464169785,
    "mean_precisions": 0.9926500000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.0131958601414226,
    "rps": 99.15574260459636,
    "parallel": 1,
    "p99_time": 0.014345481286291033,
    "mean_time": 0.00996760748536326,
    "mean_precisions": 0.99267,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.013411861960776148,
    "rps": 97.94385383402765,
    "parallel": 1,
    "p99_time": 0.014323198471684008,
    "mean_time": 0.010083000544458627,
    "mean_precisions": 0.9926600000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.018300816672854124,
    "rps": 71.80128788353176,
    "parallel": 1,
    "p99_time": 0.02052312495186925,
    "mean_time": 0.013793325104052201,
    "mean_precisions": 0.99655,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.10293038017116488,
    "rps": 971.3940593264316,
    "parallel": 100,
    "p99_time": 0.11908184493426231,
    "mean_time": 0.0808008745207917,
    "mean_precisions": 0.88774,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.15473974925698714,
    "rps": 662.912517931106,
    "parallel": 100,
    "p99_time": 0.1570986474864185,
    "mean_time": 0.12743509872653522,
    "mean_precisions": 0.95262,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.24787055834895,
    "rps": 420.81808264088784,
    "parallel": 100,
    "p99_time": 0.2513786082691513,
    "mean_time": 0.2122456634962,
    "mean_precisions": 0.98309,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.4168750471551902,
    "rps": 262.4667529182535,
    "parallel": 100,
    "p99_time": 0.43460835122969,
    "mean_time": 0.34995012506865897,
    "mean_precisions": 0.9947,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.010439198766835033,
    "rps": 123.08995979597555,
    "parallel": 1,
    "p99_time": 0.011860735758673399,
    "mean_time": 0.008011484526097774,
    "mean_precisions": 0.9830900000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.15181497251614928,
    "rps": 712.3442486001973,
    "parallel": 100,
    "p99_time": 0.1538334783911705,
    "mean_time": 0.11718644620780833,
    "mean_precisions": 0.9400899999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.19194278785726054,
    "rps": 535.1226444474521,
    "parallel": 100,
    "p99_time": 0.19504715098068118,
    "mean_time": 0.16208718193019742,
    "mean_precisions": 0.9674100000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.3134016965748742,
    "rps": 336.69865696531616,
    "parallel": 100,
    "p99_time": 0.3178064465220086,
    "mean_time": 0.26932737982319666,
    "mean_precisions": 0.9885700000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.5194484494277276,
    "rps": 207.25815144702707,
    "parallel": 100,
    "p99_time": 0.5275418360461481,
    "mean_time": 0.446436691605486,
    "mean_precisions": 0.99655,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.2257679679314606,
    "rps": 470.0982929142436,
    "parallel": 100,
    "p99_time": 0.22908067302545532,
    "mean_time": 0.187591954105068,
    "mean_precisions": 0.97713,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.2270469841896556,
    "rps": 458.6554217992882,
    "parallel": 100,
    "p99_time": 0.23114466055994853,
    "mean_time": 0.192899466952309,
    "mean_precisions": 0.9771200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.31012529248837384,
    "rps": 340.03004160187606,
    "parallel": 100,
    "p99_time": 0.31768354137660937,
    "mean_time": 0.2670250102505088,
    "mean_precisions": 0.9885700000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.515908032329753,
    "rps": 208.32527165992164,
    "parallel": 100,
    "p99_time": 0.5258548478316516,
    "mean_time": 0.4446048555178568,
    "mean_precisions": 0.99655,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.35723839545389635,
    "rps": 302.20454668962765,
    "parallel": 100,
    "p99_time": 0.365072162207216,
    "mean_time": 0.3020114416182041,
    "mean_precisions": 0.9926500000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.3589589157490991,
    "rps": 298.0388604702851,
    "parallel": 100,
    "p99_time": 0.3665338893327862,
    "mean_time": 0.3064530757202301,
    "mean_precisions": 0.99267,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.016183545207604764,
    "rps": 80.624667255194,
    "parallel": 1,
    "p99_time": 0.017980995040852574,
    "mean_time": 0.01226493841712363,
    "mean_precisions": 0.9947,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.37087102797813715,
    "rps": 289.97858106424195,
    "parallel": 100,
    "p99_time": 0.3763914360431954,
    "mean_time": 0.3157374066566117,
    "mean_precisions": 0.9926600000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.5197115857503377,
    "rps": 208.94196359863773,
    "parallel": 100,
    "p99_time": 0.5279204226052389,
    "mean_time": 0.44325536047527564,
    "mean_precisions": 0.99655,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.006049264909233898,
    "rps": 207.16084066052392,
    "parallel": 1,
    "p99_time": 0.006709489196073263,
    "mean_time": 0.004735366416629404,
    "mean_precisions": 0.9400899999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.007496009033638984,
    "rps": 167.57209898972923,
    "parallel": 1,
    "p99_time": 0.008236071560531851,
    "mean_time": 0.0058661408799234776,
    "mean_precisions": 0.9674100000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.01188439050456509,
    "rps": 110.31604293226056,
    "parallel": 1,
    "p99_time": 0.013082761547993867,
    "mean_time": 0.008937832078663633,
    "mean_precisions": 0.9885700000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.01781882122159004,
    "rps": 73.7731283681584,
    "parallel": 1,
    "p99_time": 0.019524978792760522,
    "mean_time": 0.0134089174491819,
    "mean_precisions": 0.99655,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.008848541602492332,
    "rps": 147.02977029806985,
    "parallel": 1,
    "p99_time": 0.009856188774574547,
    "mean_time": 0.006697882741689682,
    "mean_precisions": 0.97713,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 130.2387644770006,
    "total_upload_time": 564.2466391889993,
    "p95_time": 0.00923871942795813,
    "rps": 141.2378651801444,
    "parallel": 1,
    "p99_time": 0.01039277443429455,
    "mean_time": 0.006964290323434398,
    "mean_precisions": 0.9771200000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.005348882649559527,
    "rps": 238.11720543927626,
    "parallel": 1,
    "p99_time": 0.007190620649853373,
    "mean_time": 0.004135330425704524,
    "mean_precisions": 0.794008,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.006638398749782935,
    "rps": 194.08683654381124,
    "parallel": 1,
    "p99_time": 0.008499712927805377,
    "mean_time": 0.0050833357908897595,
    "mean_precisions": 0.883129,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.009192422150226776,
    "rps": 144.1926886792913,
    "parallel": 1,
    "p99_time": 0.011362628501665317,
    "mean_time": 0.006861109507094079,
    "mean_precisions": 0.9374180000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.014173025201671406,
    "rps": 95.5528229401709,
    "parallel": 1,
    "p99_time": 0.01645740192994708,
    "mean_time": 0.01037285999051528,
    "mean_precisions": 0.9721219999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.01063920155047526,
    "rps": 126.18450017609942,
    "parallel": 1,
    "p99_time": 0.012771307741568313,
    "mean_time": 0.007842832368594463,
    "mean_precisions": 0.9137870000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.010753975501575041,
    "rps": 128.02384196079217,
    "parallel": 1,
    "p99_time": 0.012845473278575813,
    "mean_time": 0.007733120899197092,
    "mean_precisions": 0.950959,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.010520702299436377,
    "rps": 128.67466705713232,
    "parallel": 1,
    "p99_time": 0.012408233161513637,
    "mean_time": 0.0076912332602976675,
    "mean_precisions": 0.951909,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.013855254802911075,
    "rps": 97.06451657248473,
    "parallel": 1,
    "p99_time": 0.016030160889968104,
    "mean_time": 0.010209797089480707,
    "mean_precisions": 0.9721219999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.05990112299950852,
    "rps": 1811.1709365167162,
    "parallel": 100,
    "p99_time": 0.06641664051159751,
    "mean_time": 0.05229428701376855,
    "mean_precisions": 0.794008,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.07581676199879439,
    "rps": 1416.9173989493354,
    "parallel": 100,
    "p99_time": 0.08022861389028549,
    "mean_time": 0.0683095560490201,
    "mean_precisions": 0.883129,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.11033733624954038,
    "rps": 964.3454184673118,
    "parallel": 100,
    "p99_time": 0.11514003174095706,
    "mean_time": 0.10154605717341328,
    "mean_precisions": 0.9374180000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.1730538238005465,
    "rps": 616.4001138612091,
    "parallel": 100,
    "p99_time": 0.17950206016987066,
    "mean_time": 0.1597704433226947,
    "mean_precisions": 0.9721219999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.009278446949065256,
    "rps": 143.27929023650432,
    "parallel": 1,
    "p99_time": 0.011282397989270979,
    "mean_time": 0.00690528605981126,
    "mean_precisions": 0.9374180000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.06194392305133078,
    "rps": 1742.564607468769,
    "parallel": 100,
    "p99_time": 0.06648361098224996,
    "mean_time": 0.05431952260338876,
    "mean_precisions": 0.8198610000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.07285810669964121,
    "rps": 1482.0684662250126,
    "parallel": 100,
    "p99_time": 0.07692660343935132,
    "mean_time": 0.0650000975147963,
    "mean_precisions": 0.883129,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.1083105992513083,
    "rps": 988.7428921472692,
    "parallel": 100,
    "p99_time": 0.11412649416135537,
    "mean_time": 0.09866723091479689,
    "mean_precisions": 0.9374180000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.1727896027981842,
    "rps": 618.5456522878742,
    "parallel": 100,
    "p99_time": 0.1782777640399945,
    "mean_time": 0.15923907760106268,
    "mean_precisions": 0.9721219999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.08438114280088484,
    "rps": 1281.7602605205211,
    "parallel": 100,
    "p99_time": 0.08890775947893417,
    "mean_time": 0.07559312314851085,
    "mean_precisions": 0.8770379999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.08389871540039166,
    "rps": 1273.7233119444447,
    "parallel": 100,
    "p99_time": 0.08782126964841155,
    "mean_time": 0.07590560168447992,
    "mean_precisions": 0.904217,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.10809307125164196,
    "rps": 995.5137443887558,
    "parallel": 100,
    "p99_time": 0.11462948987071286,
    "mean_time": 0.09815083460079004,
    "mean_precisions": 0.9374180000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.17249465255099494,
    "rps": 621.0260597552174,
    "parallel": 100,
    "p99_time": 0.18227510320914012,
    "mean_time": 0.15848840193243413,
    "mean_precisions": 0.9721219999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.12442271940017235,
    "rps": 863.1734612197707,
    "parallel": 100,
    "p99_time": 0.12944855671299593,
    "mean_time": 0.11339653287101864,
    "mean_precisions": 0.9137870000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.12227952785106026,
    "rps": 863.8230545907587,
    "parallel": 100,
    "p99_time": 0.1257964409395936,
    "mean_time": 0.11318882687359728,
    "mean_precisions": 0.950959,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.014338638549270399,
    "rps": 95.23978908862902,
    "parallel": 1,
    "p99_time": 0.01652398735230236,
    "mean_time": 0.010404528706603378,
    "mean_precisions": 0.9721219999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.12583555124747361,
    "rps": 846.9585433748302,
    "parallel": 100,
    "p99_time": 0.12975421571027254,
    "mean_time": 0.1156975248378858,
    "mean_precisions": 0.9519090000000002,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.17314086530132045,
    "rps": 618.9531682414228,
    "parallel": 100,
    "p99_time": 0.18032235277678413,
    "mean_time": 0.15893067674679368,
    "mean_precisions": 0.9721219999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.005950303602730846,
    "rps": 220.3839752133424,
    "parallel": 1,
    "p99_time": 0.007762614300154383,
    "mean_time": 0.004471681554388852,
    "mean_precisions": 0.8198610000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.006706859500991407,
    "rps": 192.56776574432084,
    "parallel": 1,
    "p99_time": 0.008435716389867596,
    "mean_time": 0.005125350982807868,
    "mean_precisions": 0.883129,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.009282024548519984,
    "rps": 143.38758894542184,
    "parallel": 1,
    "p99_time": 0.01124872809134104,
    "mean_time": 0.006900329003710067,
    "mean_precisions": 0.9374180000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.014304903350057427,
    "rps": 95.42143365950153,
    "parallel": 1,
    "p99_time": 0.016466331330666436,
    "mean_time": 0.010381656272738838,
    "mean_precisions": 0.9721219999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.007342009499916456,
    "rps": 178.91492478919267,
    "parallel": 1,
    "p99_time": 0.009251489907001092,
    "mean_time": 0.005519016721780645,
    "mean_precisions": 0.8770379999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 54.16067582500182,
    "total_upload_time": 650.4005357880014,
    "p95_time": 0.007485520299815106,
    "rps": 175.62430598909498,
    "parallel": 1,
    "p99_time": 0.009319100887478272,
    "mean_time": 0.005623239995203767,
    "mean_precisions": 0.904217,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.0031929479966493093,
    "rps": 316.49294616033507,
    "parallel": 1,
    "p99_time": 0.003663063765634434,
    "mean_time": 0.0025845825515702016,
    "mean_precisions": 0.9799399999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.003128117803134956,
    "rps": 319.1132749085913,
    "parallel": 1,
    "p99_time": 0.003539099645131501,
    "mean_time": 0.0025649284036204337,
    "mean_precisions": 0.9915200000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.006967740851541749,
    "rps": 166.83177717923547,
    "parallel": 1,
    "p99_time": 0.008248329851194287,
    "mean_time": 0.005336475100186362,
    "mean_precisions": 0.9989600000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.007350063903140836,
    "rps": 162.79609470796038,
    "parallel": 1,
    "p99_time": 0.008694032263010748,
    "mean_time": 0.00547930150343891,
    "mean_precisions": 0.999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.010999471546165297,
    "rps": 112.57968250020201,
    "parallel": 1,
    "p99_time": 0.012922574028489188,
    "mean_time": 0.008215137808793224,
    "mean_precisions": 0.9871,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.011473174001366717,
    "rps": 110.66309227062395,
    "parallel": 1,
    "p99_time": 0.013731424472425728,
    "mean_time": 0.008366779811329616,
    "mean_precisions": 0.9992400000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.011429018700437155,
    "rps": 110.3457710209493,
    "parallel": 1,
    "p99_time": 0.013626981474080828,
    "mean_time": 0.008395397303438221,
    "mean_precisions": 0.9994599999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.011537097094333149,
    "rps": 110.04280207772973,
    "parallel": 1,
    "p99_time": 0.013708638992247873,
    "mean_time": 0.008423531550259213,
    "mean_precisions": 0.9995,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.005215362400122104,
    "rps": 1223.2356345911467,
    "parallel": 100,
    "p99_time": 0.0087750806038821,
    "mean_time": 0.0036742642609984616,
    "mean_precisions": 0.9799399999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.0049595953045354696,
    "rps": 1238.0016347972962,
    "parallel": 100,
    "p99_time": 0.008626417246123319,
    "mean_time": 0.00354270715782186,
    "mean_precisions": 0.9915200000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.005012023149538436,
    "rps": 1222.3200903482461,
    "parallel": 100,
    "p99_time": 0.008392023176784296,
    "mean_time": 0.003639211266618804,
    "mean_precisions": 0.99174,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.08771416139679786,
    "rps": 1137.2067368851153,
    "parallel": 100,
    "p99_time": 0.08910347227938473,
    "mean_time": 0.07436469856774493,
    "mean_precisions": 0.99418,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.0031643884045479353,
    "rps": 315.9101734973962,
    "parallel": 1,
    "p99_time": 0.003647468678391306,
    "mean_time": 0.002585928245235118,
    "mean_precisions": 0.99174,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.1225573532985436,
    "rps": 836.3698485053685,
    "parallel": 100,
    "p99_time": 0.12427838747804344,
    "mean_time": 0.11236063607726246,
    "mean_precisions": 0.9852200000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.12130032794557337,
    "rps": 838.0629398580444,
    "parallel": 100,
    "p99_time": 0.1227188690102048,
    "mean_time": 0.11197231113582093,
    "mean_precisions": 0.9970600000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.12265514319733484,
    "rps": 830.1672362701112,
    "parallel": 100,
    "p99_time": 0.12470847936769133,
    "mean_time": 0.11357144401086117,
    "mean_precisions": 0.9972799999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.12589260565000587,
    "rps": 810.5016673813172,
    "parallel": 100,
    "p99_time": 0.12843437513554817,
    "mean_time": 0.11652881129981252,
    "mean_precisions": 0.9973200000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.21028945025063878,
    "rps": 489.93082685568123,
    "parallel": 100,
    "p99_time": 0.21407293852076692,
    "mean_time": 0.1983252115015959,
    "mean_precisions": 0.9867400000000002,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.20732283664656279,
    "rps": 493.02078290794907,
    "parallel": 100,
    "p99_time": 0.20972947840964482,
    "mean_time": 0.1971646874586033,
    "mean_precisions": 0.99874,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.20899930954983575,
    "rps": 490.4987744578714,
    "parallel": 100,
    "p99_time": 0.21240580505698745,
    "mean_time": 0.19806377444618412,
    "mean_precisions": 0.9989600000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.21037077269793372,
    "rps": 487.5507682057056,
    "parallel": 100,
    "p99_time": 0.2131531086598261,
    "mean_time": 0.1990525277396795,
    "mean_precisions": 0.999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.3575860871515033,
    "rps": 288.68544127428146,
    "parallel": 100,
    "p99_time": 0.36219995334497074,
    "mean_time": 0.3397199949425776,
    "mean_precisions": 0.9871,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.35589446514859446,
    "rps": 287.9896330551543,
    "parallel": 100,
    "p99_time": 0.36116261462229887,
    "mean_time": 0.3393890881404048,
    "mean_precisions": 0.9992400000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.0035857149505318375,
    "rps": 282.71101788014596,
    "parallel": 1,
    "p99_time": 0.004058636038753322,
    "mean_time": 0.002928582192391332,
    "mean_precisions": 0.99418,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.35654609674929816,
    "rps": 288.1401571094111,
    "parallel": 100,
    "p99_time": 0.36082146862259834,
    "mean_time": 0.34040105630483447,
    "mean_precisions": 0.9994599999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.35650457400261076,
    "rps": 288.13004548133966,
    "parallel": 100,
    "p99_time": 0.36085687036960734,
    "mean_time": 0.34032679860065984,
    "mean_precisions": 0.9995,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.004501762296422385,
    "rps": 237.1057939236194,
    "parallel": 1,
    "p99_time": 0.005154918473417644,
    "mean_time": 0.0035800906889824546,
    "mean_precisions": 0.9852200000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.004588867352140369,
    "rps": 235.27547462885053,
    "parallel": 1,
    "p99_time": 0.005244783627567819,
    "mean_time": 0.003613570384591003,
    "mean_precisions": 0.9970600000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.004526655649533496,
    "rps": 235.5855874284299,
    "parallel": 1,
    "p99_time": 0.005094112288788893,
    "mean_time": 0.0036108278000130667,
    "mean_precisions": 0.9972799999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.004551806548988679,
    "rps": 233.5077310232007,
    "parallel": 1,
    "p99_time": 0.0051885942000808455,
    "mean_time": 0.0036487636413483414,
    "mean_precisions": 0.9973200000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.00707825350073108,
    "rps": 165.11866125793927,
    "parallel": 1,
    "p99_time": 0.008383364857654677,
    "mean_time": 0.005391468475930742,
    "mean_precisions": 0.98674,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 211.02451519703027,
    "total_upload_time": 1466.1785857389914,
    "p95_time": 0.006983328948626878,
    "rps": 165.93900472714083,
    "parallel": 1,
    "p99_time": 0.008281566252771882,
    "mean_time": 0.005359760838780494,
    "mean_precisions": 0.99874,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.0038842292502522455,
    "rps": 290.8387974319324,
    "parallel": 1,
    "p99_time": 0.0042544695269316445,
    "mean_time": 0.003373310421500355,
    "mean_precisions": 0.9568810000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.004932938003912568,
    "rps": 238.5639108522972,
    "parallel": 1,
    "p99_time": 0.005446110963821412,
    "mean_time": 0.004126933655142784,
    "mean_precisions": 0.987966,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.0067712937481701355,
    "rps": 182.57447074307626,
    "parallel": 1,
    "p99_time": 0.0077936196327209484,
    "mean_time": 0.0054077868316322565,
    "mean_precisions": 0.997115,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.009977215947583317,
    "rps": 130.9935326848331,
    "parallel": 1,
    "p99_time": 0.011686729704961181,
    "mean_time": 0.007559895937796682,
    "mean_precisions": 0.9992719999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.0075282270554453135,
    "rps": 167.77209169840862,
    "parallel": 1,
    "p99_time": 0.008774044401943685,
    "mean_time": 0.005891086027212441,
    "mean_precisions": 0.9895200000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.007777943974360821,
    "rps": 163.62734010803325,
    "parallel": 1,
    "p99_time": 0.009341247268021107,
    "mean_time": 0.0060368599319830536,
    "mean_precisions": 0.9974639999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.007701742416247725,
    "rps": 163.9280549917959,
    "parallel": 1,
    "p99_time": 0.009103872096166015,
    "mean_time": 0.006028718965407461,
    "mean_precisions": 0.998167,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.010520516196265815,
    "rps": 127.19178786087897,
    "parallel": 1,
    "p99_time": 0.012464241757988933,
    "mean_time": 0.007782757866382599,
    "mean_precisions": 0.9992719999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.06979698403738438,
    "rps": 1443.3965920470669,
    "parallel": 100,
    "p99_time": 0.1420357613265515,
    "mean_time": 0.06773549893405288,
    "mean_precisions": 0.9568810000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.08775056432932615,
    "rps": 1168.8400959725882,
    "parallel": 100,
    "p99_time": 0.08970607715658843,
    "mean_time": 0.08372798609752208,
    "mean_precisions": 0.987966,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.12372435131110252,
    "rps": 837.8127728025478,
    "parallel": 100,
    "p99_time": 0.12995154674164952,
    "mean_time": 0.11710037905201316,
    "mean_precisions": 0.996972,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.18845259645022452,
    "rps": 551.5870404155712,
    "parallel": 100,
    "p99_time": 0.19396227740682662,
    "mean_time": 0.1778742370273918,
    "mean_precisions": 0.999242,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.006611748738214373,
    "rps": 184.43663520186348,
    "parallel": 1,
    "p99_time": 0.007235284242779016,
    "mean_time": 0.00535012704404071,
    "mean_precisions": 0.996972,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.0856708476319909,
    "rps": 1203.9635877922915,
    "parallel": 100,
    "p99_time": 0.09077388334088028,
    "mean_time": 0.08074793108934536,
    "mean_precisions": 0.969993,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.1021023298613727,
    "rps": 1009.5412945777273,
    "parallel": 100,
    "p99_time": 0.10487266905605794,
    "mean_time": 0.09668478172654286,
    "mean_precisions": 0.9886220000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.14124808921478688,
    "rps": 730.9085462061206,
    "parallel": 100,
    "p99_time": 0.1443850488215685,
    "mean_time": 0.13448200436290353,
    "mean_precisions": 0.997115,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.21629795683547853,
    "rps": 481.2222314798457,
    "parallel": 100,
    "p99_time": 0.22238509383983912,
    "mean_time": 0.205168613840919,
    "mean_precisions": 0.9992719999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.11149684195406735,
    "rps": 913.7717702470578,
    "parallel": 100,
    "p99_time": 0.11478370054624976,
    "mean_time": 0.10644237516745925,
    "mean_precisions": 0.985044,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.11245358227752149,
    "rps": 913.8456473897762,
    "parallel": 100,
    "p99_time": 0.11514584362506868,
    "mean_time": 0.1070811926287599,
    "mean_precisions": 0.9925370000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.14176362599246203,
    "rps": 729.0400466595104,
    "parallel": 100,
    "p99_time": 0.144172772904858,
    "mean_time": 0.13475510448161512,
    "mean_precisions": 0.997115,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.21657544164918363,
    "rps": 479.96023294443904,
    "parallel": 100,
    "p99_time": 0.22089592896401883,
    "mean_time": 0.20568115142956375,
    "mean_precisions": 0.9992719999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.16022578459233044,
    "rps": 645.8826311203396,
    "parallel": 100,
    "p99_time": 0.16395907555706798,
    "mean_time": 0.15244788051778452,
    "mean_precisions": 0.9895200000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.16204378553666174,
    "rps": 640.1168131565113,
    "parallel": 100,
    "p99_time": 0.16462654422037304,
    "mean_time": 0.15379880814738572,
    "mean_precisions": 0.9974639999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.00977788446471095,
    "rps": 131.7164199493089,
    "parallel": 1,
    "p99_time": 0.010768051575869322,
    "mean_time": 0.007515338387805969,
    "mean_precisions": 0.999242,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.16293517546728253,
    "rps": 631.124492596922,
    "parallel": 100,
    "p99_time": 0.16574700040742757,
    "mean_time": 0.1554080946257338,
    "mean_precisions": 0.998167,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.21639539571478963,
    "rps": 480.58791386302056,
    "parallel": 100,
    "p99_time": 0.22108564868569375,
    "mean_time": 0.2054424409811385,
    "mean_precisions": 0.9992719999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.00433347295038402,
    "rps": 269.1656610812095,
    "parallel": 1,
    "p99_time": 0.00497845952399075,
    "mean_time": 0.0036497666923329232,
    "mean_precisions": 0.969993,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.004849506868049502,
    "rps": 240.13654273470007,
    "parallel": 1,
    "p99_time": 0.005556117119267583,
    "mean_time": 0.004094500043801963,
    "mean_precisions": 0.9886220000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.006737992633134124,
    "rps": 183.35060561413346,
    "parallel": 1,
    "p99_time": 0.00790247994475067,
    "mean_time": 0.0053816678753122685,
    "mean_precisions": 0.997115,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.010453616781160234,
    "rps": 128.30215539752209,
    "parallel": 1,
    "p99_time": 0.012540089190006258,
    "mean_time": 0.007718469075206667,
    "mean_precisions": 0.9992719999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.005407083826139568,
    "rps": 220.93542934880145,
    "parallel": 1,
    "p99_time": 0.006338818082585933,
    "mean_time": 0.004460901757329702,
    "mean_precisions": 0.985044,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 315.59964870099793,
    "total_upload_time": 5906.782383591999,
    "p95_time": 0.00540353418327868,
    "rps": 221.6389302153718,
    "parallel": 1,
    "p99_time": 0.006305704945698382,
    "mean_time": 0.0044455983601510525,
    "mean_precisions": 0.9925369999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.006537337566260246,
    "rps": 185.26626003214457,
    "parallel": 1,
    "p99_time": 0.011624066159129136,
    "mean_time": 0.005305777332512662,
    "mean_precisions": 0.90714,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.009044961060862987,
    "rps": 138.41778014612228,
    "parallel": 1,
    "p99_time": 0.009906519243959336,
    "mean_time": 0.0071084280621726064,
    "mean_precisions": 0.9653800000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.013833478547167032,
    "rps": 94.82980210971108,
    "parallel": 1,
    "p99_time": 0.014955095071345568,
    "mean_time": 0.010415122153470293,
    "mean_precisions": 0.98979,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.021584574750158934,
    "rps": 61.3109015205212,
    "parallel": 1,
    "p99_time": 0.024627901399508118,
    "mean_time": 0.016158971355529503,
    "mean_precisions": 0.9969000000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.01589318229816854,
    "rps": 83.0392067261832,
    "parallel": 1,
    "p99_time": 0.01695366671308875,
    "mean_time": 0.011911626193206758,
    "mean_precisions": 0.99276,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.015920348791405557,
    "rps": 82.18432936693574,
    "parallel": 1,
    "p99_time": 0.017109613493084905,
    "mean_time": 0.012041521282866598,
    "mean_precisions": 0.9934700000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.016546740254852917,
    "rps": 80.30761064407852,
    "parallel": 1,
    "p99_time": 0.01849263684591278,
    "mean_time": 0.012325360247166827,
    "mean_precisions": 0.9934700000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.021612852870021015,
    "rps": 61.130654537242854,
    "parallel": 1,
    "p99_time": 0.02339096078881994,
    "mean_time": 0.01620144203887321,
    "mean_precisions": 0.9969000000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.08995231593726202,
    "rps": 1033.5958443468592,
    "parallel": 100,
    "p99_time": 0.09265100059332326,
    "mean_time": 0.07475134134199471,
    "mean_precisions": 0.9071400000000001,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.14259643206605688,
    "rps": 710.2300612095148,
    "parallel": 100,
    "p99_time": 0.14478681686334313,
    "mean_time": 0.1182570780562237,
    "mean_precisions": 0.96538,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.2490596454008482,
    "rps": 443.4222418825957,
    "parallel": 100,
    "p99_time": 0.25602740393718704,
    "mean_time": 0.2014250150991138,
    "mean_precisions": 0.989,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.37849958739243444,
    "rps": 281.2923165617399,
    "parallel": 100,
    "p99_time": 0.38553066533990205,
    "mean_time": 0.3258416352381464,
    "mean_precisions": 0.9966999999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.013578111468814312,
    "rps": 94.54077340540917,
    "parallel": 1,
    "p99_time": 0.014388957717455924,
    "mean_time": 0.010437351145315915,
    "mean_precisions": 0.989,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.11989973505260422,
    "rps": 828.4944844503161,
    "parallel": 100,
    "p99_time": 0.12406034212792293,
    "mean_time": 0.09686485717399046,
    "mean_precisions": 0.93821,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.16175739596365019,
    "rps": 631.2274931276049,
    "parallel": 100,
    "p99_time": 0.1652666907873936,
    "mean_time": 0.1340577483724337,
    "mean_precisions": 0.9677700000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.27212625183165073,
    "rps": 388.78502640352366,
    "parallel": 100,
    "p99_time": 0.27713196248048916,
    "mean_time": 0.23137554819555953,
    "mean_precisions": 0.9897900000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.4298801931785419,
    "rps": 249.58919004820095,
    "parallel": 100,
    "p99_time": 0.44065105240559205,
    "mean_time": 0.36923381394473836,
    "mean_precisions": 0.9969000000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.18662400073371826,
    "rps": 562.0288934729701,
    "parallel": 100,
    "p99_time": 0.19016064922092482,
    "mean_time": 0.15385586665966547,
    "mean_precisions": 0.97753,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.189807183528319,
    "rps": 545.9515054184872,
    "parallel": 100,
    "p99_time": 0.1928446568432264,
    "mean_time": 0.1582914603888057,
    "mean_precisions": 0.9782000000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.2616001075948588,
    "rps": 403.9842108904598,
    "parallel": 100,
    "p99_time": 0.268926803173963,
    "mean_time": 0.22162284592888318,
    "mean_precisions": 0.9897900000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.4293361209682189,
    "rps": 251.17373580755617,
    "parallel": 100,
    "p99_time": 0.43920255545526743,
    "mean_time": 0.366306857023621,
    "mean_precisions": 0.9969,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.29801751649938524,
    "rps": 360.33111729692314,
    "parallel": 100,
    "p99_time": 0.30497251289198174,
    "mean_time": 0.25079849461559206,
    "mean_precisions": 0.99276,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.30179625529563053,
    "rps": 352.7097193588506,
    "parallel": 100,
    "p99_time": 0.308766182414256,
    "mean_time": 0.25596494843950496,
    "mean_precisions": 0.9934700000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.02120854634558782,
    "rps": 61.846974291577176,
    "parallel": 1,
    "p99_time": 0.022184180603362618,
    "mean_time": 0.016014611597405748,
    "mean_precisions": 0.9967,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.30938532662112267,
    "rps": 342.4998193626648,
    "parallel": 100,
    "p99_time": 0.3168508180696517,
    "mean_time": 0.2645798328085803,
    "mean_precisions": 0.9934700000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.4228646832401864,
    "rps": 252.17188673421106,
    "parallel": 100,
    "p99_time": 0.43282728142803534,
    "mean_time": 0.3653319147343282,
    "mean_precisions": 0.9969000000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.00694188781781122,
    "rps": 176.57807906037047,
    "parallel": 1,
    "p99_time": 0.007676118572708219,
    "mean_time": 0.0055598763434682045,
    "mean_precisions": 0.93821,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.009109948738478124,
    "rps": 138.26889123584303,
    "parallel": 1,
    "p99_time": 0.009869466931559144,
    "mean_time": 0.007116410645889118,
    "mean_precisions": 0.96777,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.013579499477054922,
    "rps": 95.41025194299542,
    "parallel": 1,
    "p99_time": 0.014684123345650732,
    "mean_time": 0.010339612314943224,
    "mean_precisions": 0.98979,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.021686712431255726,
    "rps": 61.35883481844061,
    "parallel": 1,
    "p99_time": 0.023249188051559032,
    "mean_time": 0.016146288816351443,
    "mean_precisions": 0.9969000000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.009908735647331923,
    "rps": 127.5960257906237,
    "parallel": 1,
    "p99_time": 0.010806207503192123,
    "mean_time": 0.007728069499135018,
    "mean_precisions": 0.97753,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 124.44633961199906,
    "total_upload_time": 1049.5203025640003,
    "p95_time": 0.009842474898323416,
    "rps": 127.86634874329467,
    "parallel": 1,
    "p99_time": 0.010304281620774418,
    "mean_time": 0.007711650119395927,
    "mean_precisions": 0.9782000000000001,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.005582639597923841,
    "rps": 227.42397027587765,
    "parallel": 1,
    "p99_time": 0.0072961906985438,
    "mean_time": 0.004331894514824671,
    "mean_precisions": 0.813608,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.007121627750348124,
    "rps": 181.66296638687814,
    "parallel": 1,
    "p99_time": 0.009048129077855271,
    "mean_time": 0.0054341242727838105,
    "mean_precisions": 0.904964,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.010455031199126094,
    "rps": 129.91905901764832,
    "parallel": 1,
    "p99_time": 0.01239935849902395,
    "mean_time": 0.007614629627686009,
    "mean_precisions": 0.955727,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.016259186301431326,
    "rps": 83.01701224180944,
    "parallel": 1,
    "p99_time": 0.018630785671666678,
    "mean_time": 0.01194076230669707,
    "mean_precisions": 0.9839979999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.011925750299997161,
    "rps": 113.09041012917807,
    "parallel": 1,
    "p99_time": 0.013993647988536397,
    "mean_time": 0.008755788136901902,
    "mean_precisions": 0.9245110000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.012081400849820055,
    "rps": 112.16000589506798,
    "parallel": 1,
    "p99_time": 0.014133924791713078,
    "mean_time": 0.008822913397686353,
    "mean_precisions": 0.967224,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.011727248147508355,
    "rps": 112.9542185050599,
    "parallel": 1,
    "p99_time": 0.01376058920803189,
    "mean_time": 0.008759815833190078,
    "mean_precisions": 0.968167,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.016027594051774938,
    "rps": 84.13117194671128,
    "parallel": 1,
    "p99_time": 0.01820019032002165,
    "mean_time": 0.011783517629402922,
    "mean_precisions": 0.9839979999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.06385831505158421,
    "rps": 1678.6502182026022,
    "parallel": 100,
    "p99_time": 0.07011102457137898,
    "mean_time": 0.056421628842396605,
    "mean_precisions": 0.813608,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.0849482885989346,
    "rps": 1260.3791557046131,
    "parallel": 100,
    "p99_time": 0.08918959786064079,
    "mean_time": 0.07705502032480617,
    "mean_precisions": 0.904964,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.12927099194839684,
    "rps": 829.5007655773967,
    "parallel": 100,
    "p99_time": 0.13466263173155313,
    "mean_time": 0.11808057532369458,
    "mean_precisions": 0.955727,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.21084056420149863,
    "rps": 506.91589540692877,
    "parallel": 100,
    "p99_time": 0.21866901627829066,
    "mean_time": 0.1946168167758209,
    "mean_precisions": 0.9839979999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.010282178198212932,
    "rps": 130.8900757757543,
    "parallel": 1,
    "p99_time": 0.012202759086831069,
    "mean_time": 0.007558422927300489,
    "mean_precisions": 0.955727,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.06881165489885462,
    "rps": 1556.5959289288928,
    "parallel": 100,
    "p99_time": 0.07504901920907286,
    "mean_time": 0.06103677921931012,
    "mean_precisions": 0.8392959999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.08662092640115589,
    "rps": 1255.264511734607,
    "parallel": 100,
    "p99_time": 0.09120610467896768,
    "mean_time": 0.07697169795640074,
    "mean_precisions": 0.9049640000000001,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.129348195852981,
    "rps": 826.5407553514983,
    "parallel": 100,
    "p99_time": 0.13416614287190898,
    "mean_time": 0.11822591758669951,
    "mean_precisions": 0.955727,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.21129853505262872,
    "rps": 504.83824530033604,
    "parallel": 100,
    "p99_time": 0.21795130672006052,
    "mean_time": 0.19538346574940152,
    "mean_precisions": 0.9839979999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.09587193469997146,
    "rps": 1112.1642917695124,
    "parallel": 100,
    "p99_time": 0.10097453553215019,
    "mean_time": 0.08747276774008024,
    "mean_precisions": 0.8944639999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.09822580505006044,
    "rps": 1100.3250531306985,
    "parallel": 100,
    "p99_time": 0.10304863449091499,
    "mean_time": 0.08841737793171014,
    "mean_precisions": 0.92545,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.13388714129723667,
    "rps": 806.9869351708141,
    "parallel": 100,
    "p99_time": 0.14148937931022376,
    "mean_time": 0.1214384742701899,
    "mean_precisions": 0.955727,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.21009847654950134,
    "rps": 506.7267662272639,
    "parallel": 100,
    "p99_time": 0.2172477569988405,
    "mean_time": 0.19460286192151144,
    "mean_precisions": 0.9839979999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.15180236704854905,
    "rps": 707.6775116579797,
    "parallel": 100,
    "p99_time": 0.15859228004967008,
    "mean_time": 0.1385829178044005,
    "mean_precisions": 0.9245110000000001,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.15097879800068767,
    "rps": 704.5429615682343,
    "parallel": 100,
    "p99_time": 0.15774741310935497,
    "mean_time": 0.13921355778259822,
    "mean_precisions": 0.967224,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.016130656246787112,
    "rps": 83.88738928706148,
    "parallel": 1,
    "p99_time": 0.01850896165076847,
    "mean_time": 0.011817532682093589,
    "mean_precisions": 0.9839979999999999,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.15361249599918664,
    "rps": 698.6176349950272,
    "parallel": 100,
    "p99_time": 0.1591394273311744,
    "mean_time": 0.14066686740371406,
    "mean_precisions": 0.968167,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.21323105954979837,
    "rps": 500.91853659972827,
    "parallel": 100,
    "p99_time": 0.21917914415156703,
    "mean_time": 0.19694542292498554,
    "mean_precisions": 0.9839979999999999,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.006062976603061541,
    "rps": 211.76084755536627,
    "parallel": 1,
    "p99_time": 0.007884908330233885,
    "mean_time": 0.004655748034329736,
    "mean_precisions": 0.8392959999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.007165037598497292,
    "rps": 178.80634835588467,
    "parallel": 1,
    "p99_time": 0.008847917967250396,
    "mean_time": 0.005521662611198917,
    "mean_precisions": 0.904964,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.010554725198562664,
    "rps": 128.63715120408077,
    "parallel": 1,
    "p99_time": 0.01245789860888181,
    "mean_time": 0.007690396308115305,
    "mean_precisions": 0.955727,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 4
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.016144076650743956,
    "rps": 83.52197169318549,
    "parallel": 1,
    "p99_time": 0.018370442602317783,
    "mean_time": 0.01186355145770758,
    "mean_precisions": 0.9839979999999999,
    "engine_params": {
      "hnsw_ef": 128,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.007823960101086411,
    "rps": 165.92558004636197,
    "parallel": 1,
    "p99_time": 0.009871000020284557,
    "mean_time": 0.0059569287243717555,
    "mean_precisions": 0.8944639999999999,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 1
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "qdrant-sq-rps-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 56.98392875300124,
    "total_upload_time": 1360.4550918610003,
    "p95_time": 0.00781075020331627,
    "rps": 165.09690569581252,
    "parallel": 1,
    "p99_time": 0.009808100221234782,
    "mean_time": 0.005985161145175152,
    "mean_precisions": 0.92545,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 2
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2192.37910383899,
    "total_upload_time": 2192.37912874599,
    "p95_time": 0.001765958685427904,
    "rps": 512.5211803764972,
    "parallel": 1,
    "p99_time": 0.002011626544408501,
    "mean_time": 0.0014255613788962363,
    "mean_precisions": 0.9445399999999999,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2192.37910383899,
    "total_upload_time": 2192.37912874599,
    "p95_time": 0.002703960123471916,
    "rps": 367.36077417340226,
    "parallel": 1,
    "p99_time": 0.002917625168338418,
    "mean_time": 0.0021791588883846996,
    "mean_precisions": 0.97072,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2192.37910383899,
    "total_upload_time": 2192.37912874599,
    "p95_time": 0.13315143754589373,
    "rps": 749.2497883291563,
    "parallel": 100,
    "p99_time": 0.13690384661953434,
    "mean_time": 0.11530571954015177,
    "mean_precisions": 0.9437399999999999,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2192.37910383899,
    "total_upload_time": 2192.37912874599,
    "p95_time": 0.22221663245290985,
    "rps": 453.1363478132374,
    "parallel": 100,
    "p99_time": 0.23119989476690536,
    "mean_time": 0.2022631016093772,
    "mean_precisions": 0.9705,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2192.37910383899,
    "total_upload_time": 2192.37912874599,
    "p95_time": 0.38838665540970396,
    "rps": 261.3421993537078,
    "parallel": 100,
    "p99_time": 0.39914794581884055,
    "mean_time": 0.3630443374354974,
    "mean_precisions": 0.9833200000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2192.37910383899,
    "total_upload_time": 2192.37912874599,
    "p95_time": 0.703798810049193,
    "rps": 145.27898168609048,
    "parallel": 100,
    "p99_time": 0.7431616272160319,
    "mean_time": 0.6659487584022223,
    "mean_precisions": 0.9909599999999998,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2192.37910383899,
    "total_upload_time": 2192.37912874599,
    "p95_time": 0.004560387856326997,
    "rps": 241.30566378057526,
    "parallel": 1,
    "p99_time": 0.005150761501863601,
    "mean_time": 0.0035307142487727107,
    "mean_precisions": 0.9832199999999999,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2192.37910383899,
    "total_upload_time": 2192.37912874599,
    "p95_time": 0.007664836919866503,
    "rps": 155.93834335203402,
    "parallel": 1,
    "p99_time": 0.008119565560482444,
    "mean_time": 0.005765930220112204,
    "mean_precisions": 0.9908799999999999,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2192.37910383899,
    "total_upload_time": 2192.37912874599,
    "p95_time": 0.10495293852873147,
    "rps": 951.4999898785771,
    "parallel": 100,
    "p99_time": 0.10818031296133995,
    "mean_time": 0.08763290171083063,
    "mean_precisions": 0.9445400000000002,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2192.37910383899,
    "total_upload_time": 2192.37912874599,
    "p95_time": 0.17033172107767314,
    "rps": 588.6344965528888,
    "parallel": 100,
    "p99_time": 0.17786735691130165,
    "mean_time": 0.152490919953119,
    "mean_precisions": 0.97072,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2192.37910383899,
    "total_upload_time": 2192.37912874599,
    "p95_time": 0.2968188801547513,
    "rps": 340.7761193000768,
    "parallel": 100,
    "p99_time": 0.3102973283315079,
    "mean_time": 0.2753342120080255,
    "mean_precisions": 0.9832200000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2192.37910383899,
    "total_upload_time": 2192.37912874599,
    "p95_time": 0.5318029865855352,
    "rps": 191.6445301741714,
    "parallel": 100,
    "p99_time": 0.5496276061888784,
    "mean_time": 0.5007067615341395,
    "mean_precisions": 0.9908800000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 6375.538888047915,
    "total_upload_time": 6375.53892127797,
    "p95_time": 0.002745398879051208,
    "rps": 457.56727761839215,
    "parallel": 1,
    "p99_time": 0.002985947043634951,
    "mean_time": 0.0021383474389556796,
    "mean_precisions": 0.8470840000000001,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 6375.538888047915,
    "total_upload_time": 6375.53892127797,
    "p95_time": 0.0020758309867233036,
    "rps": 511.4749037897442,
    "parallel": 1,
    "p99_time": 0.0021756630437448623,
    "mean_time": 0.0019096202999353408,
    "mean_precisions": 0.8795880000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 6375.538888047915,
    "total_upload_time": 6375.53892127797,
    "p95_time": 0.0027228948893025513,
    "rps": 411.5659592794447,
    "parallel": 1,
    "p99_time": 0.0030924741039052607,
    "mean_time": 0.0023817957537248732,
    "mean_precisions": 0.943448,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 6375.538888047915,
    "total_upload_time": 6375.53892127797,
    "p95_time": 0.0037739060586318373,
    "rps": 299.65659367350577,
    "parallel": 1,
    "p99_time": 0.004015810391865671,
    "mean_time": 0.003283495113719255,
    "mean_precisions": 0.9763060000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 6375.538888047915,
    "total_upload_time": 6375.53892127797,
    "p95_time": 0.08701752123888581,
    "rps": 1216.9945192807152,
    "parallel": 100,
    "p99_time": 0.09257428194861861,
    "mean_time": 0.07686781959692016,
    "mean_precisions": 0.8470840000000001,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 6375.538888047915,
    "total_upload_time": 6375.53892127797,
    "p95_time": 0.09437870997935534,
    "rps": 1108.281998310728,
    "parallel": 100,
    "p99_time": 0.09820946664083749,
    "mean_time": 0.08583313514529728,
    "mean_precisions": 0.8795880000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 6375.538888047915,
    "total_upload_time": 6375.53892127797,
    "p95_time": 0.13872507656924427,
    "rps": 742.8976784622524,
    "parallel": 100,
    "p99_time": 0.14366176002193243,
    "mean_time": 0.12949284925586543,
    "mean_precisions": 0.943448,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 6375.538888047915,
    "total_upload_time": 6375.53892127797,
    "p95_time": 0.22461233758367596,
    "rps": 458.1827879644706,
    "parallel": 100,
    "p99_time": 0.23004472963511943,
    "mean_time": 0.21354976964360103,
    "mean_precisions": 0.9763060000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2276.143508987,
    "total_upload_time": 2276.143526369,
    "p95_time": 0.003348443959839642,
    "rps": 354.69551545140035,
    "parallel": 1,
    "p99_time": 0.003697923175059259,
    "mean_time": 0.0027537867058999837,
    "mean_precisions": 0.6838099999999999,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2276.143508987,
    "total_upload_time": 2276.143526369,
    "p95_time": 0.003333620633929968,
    "rps": 335.9799339434045,
    "parallel": 1,
    "p99_time": 0.0034910950111225244,
    "mean_time": 0.0029065533173270523,
    "mean_precisions": 0.7293900000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2276.143508987,
    "total_upload_time": 2276.143526369,
    "p95_time": 0.304480323754251,
    "rps": 409.93001229354957,
    "parallel": 100,
    "p99_time": 0.3195434066287999,
    "mean_time": 0.22395872871702885,
    "mean_precisions": 0.6845600000000001,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2276.143508987,
    "total_upload_time": 2276.143526369,
    "p95_time": 0.30440242174590715,
    "rps": 353.0792026490498,
    "parallel": 100,
    "p99_time": 0.3456648173498979,
    "mean_time": 0.262719840943013,
    "mean_precisions": 0.73091,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2276.143508987,
    "total_upload_time": 2276.143526369,
    "p95_time": 0.504961500151694,
    "rps": 210.62183802548736,
    "parallel": 100,
    "p99_time": 0.674977706867503,
    "mean_time": 0.45128476956313535,
    "mean_precisions": 0.83775,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2276.143508987,
    "total_upload_time": 2276.143526369,
    "p95_time": 0.8611481152867781,
    "rps": 122.33021239919641,
    "parallel": 100,
    "p99_time": 1.267118319625588,
    "mean_time": 0.7847896679979603,
    "mean_precisions": 0.9113199999999999,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2276.143508987,
    "total_upload_time": 2276.143526369,
    "p95_time": 0.005180240888148546,
    "rps": 223.44630472497727,
    "parallel": 1,
    "p99_time": 0.005360815650783479,
    "mean_time": 0.004398696376010775,
    "mean_precisions": 0.83746,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2276.143508987,
    "total_upload_time": 2276.143526369,
    "p95_time": 0.007738323137164116,
    "rps": 150.21445383078608,
    "parallel": 1,
    "p99_time": 0.007959280982613563,
    "mean_time": 0.006574135246220976,
    "mean_precisions": 0.9106899999999999,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2276.143508987,
    "total_upload_time": 2276.143526369,
    "p95_time": 0.18491605040617287,
    "rps": 616.7876930997176,
    "parallel": 100,
    "p99_time": 0.25535558400675656,
    "mean_time": 0.14541560847079382,
    "mean_precisions": 0.6838099999999999,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2276.143508987,
    "total_upload_time": 2276.143526369,
    "p95_time": 0.25767913486342875,
    "rps": 490.3899013884211,
    "parallel": 100,
    "p99_time": 0.467288903077133,
    "mean_time": 0.1858950407570228,
    "mean_precisions": 0.7293900000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2276.143508987,
    "total_upload_time": 2276.143526369,
    "p95_time": 0.3399913621135056,
    "rps": 310.91742876099687,
    "parallel": 100,
    "p99_time": 0.4991764600807801,
    "mean_time": 0.2992797650480643,
    "mean_precisions": 0.83746,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2276.143508987,
    "total_upload_time": 2276.143526369,
    "p95_time": 0.5773780713323503,
    "rps": 186.87211733211421,
    "parallel": 100,
    "p99_time": 0.9036434197006747,
    "mean_time": 0.5068136965162121,
    "mean_precisions": 0.91069,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1068.2731124040001,
    "total_upload_time": 1068.2731326450012,
    "p95_time": 0.001965370611287653,
    "rps": 558.1894871097937,
    "parallel": 1,
    "p99_time": 0.0021692596655339003,
    "mean_time": 0.0017484929434023798,
    "mean_precisions": 0.67761,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1068.2731124040001,
    "total_upload_time": 1068.2731326450012,
    "p95_time": 0.0020399883622303602,
    "rps": 534.3807269362268,
    "parallel": 1,
    "p99_time": 0.002236107117496431,
    "mean_time": 0.0018286724375560879,
    "mean_precisions": 0.71158,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1068.2731124040001,
    "total_upload_time": 1068.2731326450012,
    "p95_time": 0.08124506941530853,
    "rps": 1303.1738271919041,
    "parallel": 100,
    "p99_time": 0.08604492616839708,
    "mean_time": 0.07198467176398263,
    "mean_precisions": 0.67761,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1068.2731124040001,
    "total_upload_time": 1068.2731326450012,
    "p95_time": 0.09032631870359183,
    "rps": 1155.2850076300176,
    "parallel": 100,
    "p99_time": 0.09509446962270887,
    "mean_time": 0.08141120792925358,
    "mean_precisions": 0.7115799999999999,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1068.2731124040001,
    "total_upload_time": 1068.2731326450012,
    "p95_time": 0.13390008492860944,
    "rps": 778.8428586005351,
    "parallel": 100,
    "p99_time": 0.13865072046406568,
    "mean_time": 0.12406940838471055,
    "mean_precisions": 0.791124,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1068.2731124040001,
    "total_upload_time": 1068.2731326450012,
    "p95_time": 0.22137565058656036,
    "rps": 466.7034954605751,
    "parallel": 100,
    "p99_time": 0.2268624419765547,
    "mean_time": 0.20981322343735956,
    "mean_precisions": 0.854567,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1068.2731124040001,
    "total_upload_time": 1068.2731326450012,
    "p95_time": 0.0026167095638811584,
    "rps": 427.48548572968383,
    "parallel": 1,
    "p99_time": 0.0028801781218498945,
    "mean_time": 0.002294981972826645,
    "mean_precisions": 0.7911239999999999,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1068.2731124040001,
    "total_upload_time": 1068.2731326450012,
    "p95_time": 0.0037726826267316937,
    "rps": 301.9373097323495,
    "parallel": 1,
    "p99_time": 0.0039867338445037604,
    "mean_time": 0.0032617435083258897,
    "mean_precisions": 0.854567,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 16,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2716.839889235038,
    "total_upload_time": 2716.839941203012,
    "p95_time": 0.0025149185676127672,
    "rps": 405.27571103878387,
    "parallel": 1,
    "p99_time": 0.002728842585347594,
    "mean_time": 0.0019252598335035146,
    "mean_precisions": 0.96454,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2716.839889235038,
    "total_upload_time": 2716.839941203012,
    "p95_time": 0.003787593240849674,
    "rps": 302.2896685036637,
    "parallel": 1,
    "p99_time": 0.004051107922568918,
    "mean_time": 0.002731754630059004,
    "mean_precisions": 0.9820400000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2716.839889235038,
    "total_upload_time": 2716.839941203012,
    "p95_time": 0.1764691032207338,
    "rps": 571.9559875378236,
    "parallel": 100,
    "p99_time": 0.18509888747299555,
    "mean_time": 0.15658437014101073,
    "mean_precisions": 0.964,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2716.839889235038,
    "total_upload_time": 2716.839941203012,
    "p95_time": 0.3000681290170178,
    "rps": 338.8022373300674,
    "parallel": 100,
    "p99_time": 0.3118369347392583,
    "mean_time": 0.27514483668929895,
    "mean_precisions": 0.9821,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2716.839889235038,
    "total_upload_time": 2716.839941203012,
    "p95_time": 0.5233462882664753,
    "rps": 197.16733849755994,
    "parallel": 100,
    "p99_time": 0.5413400576979621,
    "mean_time": 0.4860303394280374,
    "mean_precisions": 0.9907600000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2716.839889235038,
    "total_upload_time": 2716.839941203012,
    "p95_time": 0.9278768608608516,
    "rps": 111.75743784671884,
    "parallel": 100,
    "p99_time": 1.1218799779121766,
    "mean_time": 0.869603735895257,
    "mean_precisions": 0.9951,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2716.839889235038,
    "total_upload_time": 2716.839941203012,
    "p95_time": 0.00655362370889634,
    "rps": 193.27568604048173,
    "parallel": 1,
    "p99_time": 0.00701730691827834,
    "mean_time": 0.0045456727921031415,
    "mean_precisions": 0.9904400000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2716.839889235038,
    "total_upload_time": 2716.839941203012,
    "p95_time": 0.011394155048765243,
    "rps": 120.00714998197446,
    "parallel": 1,
    "p99_time": 0.012200398994609715,
    "mean_time": 0.007670970933418721,
    "mean_precisions": 0.9950399999999999,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2716.839889235038,
    "total_upload_time": 2716.839941203012,
    "p95_time": 0.14157529359217733,
    "rps": 709.3973915317498,
    "parallel": 100,
    "p99_time": 0.14655400683172048,
    "mean_time": 0.12311818505926057,
    "mean_precisions": 0.96454,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2716.839889235038,
    "total_upload_time": 2716.839941203012,
    "p95_time": 0.2381763603538275,
    "rps": 423.84967422444134,
    "parallel": 100,
    "p99_time": 0.24816630517132587,
    "mean_time": 0.2156269720823504,
    "mean_precisions": 0.9820400000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2716.839889235038,
    "total_upload_time": 2716.839941203012,
    "p95_time": 0.4161380055360496,
    "rps": 246.4768681248039,
    "parallel": 100,
    "p99_time": 0.47103918008971996,
    "mean_time": 0.3860557958729565,
    "mean_precisions": 0.9904400000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2716.839889235038,
    "total_upload_time": 2716.839941203012,
    "p95_time": 0.7423638090724125,
    "rps": 139.3089135953914,
    "parallel": 100,
    "p99_time": 0.762291580894962,
    "mean_time": 0.6970693084154278,
    "mean_precisions": 0.9950400000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8900.957602256,
    "total_upload_time": 8900.957642181,
    "p95_time": 0.002845554199939214,
    "rps": 427.5305124288614,
    "parallel": 1,
    "p99_time": 0.0032239529906655665,
    "mean_time": 0.0022909002594971753,
    "mean_precisions": 0.9016299999999999,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8900.957602256,
    "total_upload_time": 8900.957642181,
    "p95_time": 0.0025005889498970644,
    "rps": 442.5138731412586,
    "parallel": 1,
    "p99_time": 0.0026239985493157294,
    "mean_time": 0.0022117501253920637,
    "mean_precisions": 0.9257689999999998,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8900.957602256,
    "total_upload_time": 8900.957642181,
    "p95_time": 0.0035369665500184053,
    "rps": 332.5505145544317,
    "parallel": 1,
    "p99_time": 0.003835777739514015,
    "mean_time": 0.0029566914664048453,
    "mean_precisions": 0.9691630000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8900.957602256,
    "total_upload_time": 8900.957642181,
    "p95_time": 0.00532480774945725,
    "rps": 227.73152989636228,
    "parallel": 1,
    "p99_time": 0.005591963768747519,
    "mean_time": 0.004335515227397445,
    "mean_precisions": 0.9885130000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8900.957602256,
    "total_upload_time": 8900.957642181,
    "p95_time": 0.1113658332005798,
    "rps": 925.287348457845,
    "parallel": 100,
    "p99_time": 0.11780790869022895,
    "mean_time": 0.1020350181318956,
    "mean_precisions": 0.9016299999999999,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8900.957602256,
    "total_upload_time": 8900.957642181,
    "p95_time": 0.12708551934983917,
    "rps": 814.1355567822136,
    "parallel": 100,
    "p99_time": 0.13094979034915014,
    "mean_time": 0.11831710083140005,
    "mean_precisions": 0.9257690000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8900.957602256,
    "total_upload_time": 8900.957642181,
    "p95_time": 0.19704694560014105,
    "rps": 522.8054047141256,
    "parallel": 100,
    "p99_time": 0.20130484427903866,
    "mean_time": 0.18651108241589737,
    "mean_precisions": 0.9691630000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8900.957602256,
    "total_upload_time": 8900.957642181,
    "p95_time": 0.3294885690996125,
    "rps": 312.87120088368937,
    "parallel": 100,
    "p99_time": 0.3363346664708115,
    "mean_time": 0.31465429858351673,
    "mean_precisions": 0.988513,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 3023.9638444250004,
    "total_upload_time": 3023.963863234,
    "p95_time": 0.004088034760206938,
    "rps": 301.3381622225464,
    "parallel": 1,
    "p99_time": 0.0045852189790457475,
    "mean_time": 0.0032489213990047573,
    "mean_precisions": 0.75673,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 3023.9638444250004,
    "total_upload_time": 3023.963863234,
    "p95_time": 0.00435541805345565,
    "rps": 274.90246719665396,
    "parallel": 1,
    "p99_time": 0.004573556734248996,
    "mean_time": 0.0035637677842751147,
    "mean_precisions": 0.79898,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 3023.9638444250004,
    "total_upload_time": 3023.963863234,
    "p95_time": 0.3319566988058796,
    "rps": 320.58963502153154,
    "parallel": 100,
    "p99_time": 0.4048545064285281,
    "mean_time": 0.2909577050548833,
    "mean_precisions": 0.7561100000000001,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 3023.9638444250004,
    "total_upload_time": 3023.963863234,
    "p95_time": 0.4183463864443183,
    "rps": 261.7406053139904,
    "parallel": 100,
    "p99_time": 0.4954190700834442,
    "mean_time": 0.3605685254141572,
    "mean_precisions": 0.79904,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 3023.9638444250004,
    "total_upload_time": 3023.963863234,
    "p95_time": 0.727220140650752,
    "rps": 154.03289837940062,
    "parallel": 100,
    "p99_time": 0.8243053956812946,
    "mean_time": 0.6196348143430951,
    "mean_precisions": 0.89246,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 3023.9638444250004,
    "total_upload_time": 3023.963863234,
    "p95_time": 1.202162289000262,
    "rps": 91.16469003844416,
    "parallel": 100,
    "p99_time": 1.2103979651651753,
    "mean_time": 1.059849562145857,
    "mean_precisions": 0.9491400000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 3023.9638444250004,
    "total_upload_time": 3023.963863234,
    "p95_time": 0.006364908837713301,
    "rps": 191.47202356566913,
    "parallel": 1,
    "p99_time": 0.006654498684220016,
    "mean_time": 0.005144685640465468,
    "mean_precisions": 0.89252,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 3023.9638444250004,
    "total_upload_time": 3023.963863234,
    "p95_time": 0.010499625676311552,
    "rps": 120.81474012064264,
    "parallel": 1,
    "p99_time": 0.01107638543471694,
    "mean_time": 0.008178980393800885,
    "mean_precisions": 0.94911,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 3023.9638444250004,
    "total_upload_time": 3023.963863234,
    "p95_time": 0.22107764112297443,
    "rps": 490.3750268770091,
    "parallel": 100,
    "p99_time": 0.36395068287849425,
    "mean_time": 0.18681591615080834,
    "mean_precisions": 0.75673,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 3023.9638444250004,
    "total_upload_time": 3023.963863234,
    "p95_time": 0.2968928416259586,
    "rps": 405.5542778468381,
    "parallel": 100,
    "p99_time": 0.36885961197316647,
    "mean_time": 0.22676570973126217,
    "mean_precisions": 0.79898,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 3023.9638444250004,
    "total_upload_time": 3023.963863234,
    "p95_time": 0.43067704439163207,
    "rps": 253.45900471518905,
    "parallel": 100,
    "p99_time": 0.6385784194618463,
    "mean_time": 0.37155112050799655,
    "mean_precisions": 0.89252,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 3023.9638444250004,
    "total_upload_time": 3023.963863234,
    "p95_time": 0.7332641478860751,
    "rps": 146.5948637203976,
    "parallel": 100,
    "p99_time": 0.8346880039945245,
    "mean_time": 0.6490412406157702,
    "mean_precisions": 0.94911,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1493.2289679839996,
    "total_upload_time": 1493.2289850919988,
    "p95_time": 0.0021117515163496135,
    "rps": 526.855192142521,
    "parallel": 1,
    "p99_time": 0.0022694228310137987,
    "mean_time": 0.0018556294245179743,
    "mean_precisions": 0.746803,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1493.2289679839996,
    "total_upload_time": 1493.2289850919988,
    "p95_time": 0.002390924701467156,
    "rps": 483.4938266489475,
    "parallel": 1,
    "p99_time": 0.0030649704346433285,
    "mean_time": 0.0020258281017187982,
    "mean_precisions": 0.7765280000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1493.2289679839996,
    "total_upload_time": 1493.2289850919988,
    "p95_time": 0.14777968329908617,
    "rps": 710.5916105584909,
    "parallel": 100,
    "p99_time": 0.15411037993028007,
    "mean_time": 0.13653884924167686,
    "mean_precisions": 0.746426,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1493.2289679839996,
    "total_upload_time": 1493.2289850919988,
    "p95_time": 0.17309045449928817,
    "rps": 610.7007141207487,
    "parallel": 100,
    "p99_time": 0.19052791445959885,
    "mean_time": 0.1590468846827953,
    "mean_precisions": 0.7765350000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1493.2289679839996,
    "total_upload_time": 1493.2289850919988,
    "p95_time": 0.2795676088000619,
    "rps": 380.13387627002805,
    "parallel": 100,
    "p99_time": 0.3096956831170246,
    "mean_time": 0.25838973518560815,
    "mean_precisions": 0.848585,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1493.2289679839996,
    "total_upload_time": 1493.2289850919988,
    "p95_time": 0.4824010553527841,
    "rps": 218.64553600317075,
    "parallel": 100,
    "p99_time": 0.5048441737270333,
    "mean_time": 0.4519084791312034,
    "mean_precisions": 0.905226,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1493.2289679839996,
    "total_upload_time": 1493.2289850919988,
    "p95_time": 0.003234258433803916,
    "rps": 365.72937628283677,
    "parallel": 1,
    "p99_time": 0.0035903034685179592,
    "mean_time": 0.0026837246392853557,
    "mean_precisions": 0.848757,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1493.2289679839996,
    "total_upload_time": 1493.2289850919988,
    "p95_time": 0.0048025816446170206,
    "rps": 248.6330395088177,
    "parallel": 1,
    "p99_time": 0.005063577429391445,
    "mean_time": 0.0039683257785625755,
    "mean_precisions": 0.9053060000000002,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1493.2289679839996,
    "total_upload_time": 1493.2289850919988,
    "p95_time": 0.09413202311843634,
    "rps": 1109.9502734056482,
    "parallel": 100,
    "p99_time": 0.0981672410760075,
    "mean_time": 0.08538694439036772,
    "mean_precisions": 0.7468030000000001,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1493.2289679839996,
    "total_upload_time": 1493.2289850919988,
    "p95_time": 0.10762822786346078,
    "rps": 974.5386361487067,
    "parallel": 100,
    "p99_time": 0.11313827283680443,
    "mean_time": 0.09842868469376118,
    "mean_precisions": 0.776528,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1493.2289679839996,
    "total_upload_time": 1493.2289850919988,
    "p95_time": 0.1702191462740302,
    "rps": 613.9573892934046,
    "parallel": 100,
    "p99_time": 0.17746043163351716,
    "mean_time": 0.15850725196418353,
    "mean_precisions": 0.848757,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 1493.2289679839996,
    "total_upload_time": 1493.2289850919988,
    "p95_time": 0.2901867773849517,
    "rps": 359.43752632403135,
    "parallel": 100,
    "p99_time": 0.29954279484692964,
    "mean_time": 0.273504185807053,
    "mean_precisions": 0.9053059999999999,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 128
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5549.50345068099,
    "total_upload_time": 5549.5034793280065,
    "p95_time": 0.0025954404147341846,
    "rps": 386.7493649435134,
    "parallel": 1,
    "p99_time": 0.0028214818425476556,
    "mean_time": 0.0020498221099376677,
    "mean_precisions": 0.97516,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5549.50345068099,
    "total_upload_time": 5549.5034793280065,
    "p95_time": 0.004254005011171102,
    "rps": 261.2983990900943,
    "parallel": 1,
    "p99_time": 0.004543602555058897,
    "mean_time": 0.003226681993249804,
    "mean_precisions": 0.9884800000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5549.50345068099,
    "total_upload_time": 5549.5034793280065,
    "p95_time": 0.20118594548257535,
    "rps": 501.1805971543752,
    "parallel": 100,
    "p99_time": 0.2551682625757534,
    "mean_time": 0.18003587844274008,
    "mean_precisions": 0.97546,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5549.50345068099,
    "total_upload_time": 5549.5034793280065,
    "p95_time": 0.3480429499002639,
    "rps": 292.19191929532985,
    "parallel": 100,
    "p99_time": 0.542341586368857,
    "mean_time": 0.31747489681523294,
    "mean_precisions": 0.9888400000000002,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5549.50345068099,
    "total_upload_time": 5549.5034793280065,
    "p95_time": 0.6107644305709983,
    "rps": 167.81511288221105,
    "parallel": 100,
    "p99_time": 0.666897930055275,
    "mean_time": 0.5751882856638054,
    "mean_precisions": 0.9948799999999999,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5549.50345068099,
    "total_upload_time": 5549.5034793280065,
    "p95_time": 1.0905112906300929,
    "rps": 94.22576266735427,
    "parallel": 100,
    "p99_time": 1.1482134829153077,
    "mean_time": 1.0378452595609473,
    "mean_precisions": 0.99784,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5549.50345068099,
    "total_upload_time": 5549.5034793280065,
    "p95_time": 0.007338574947789312,
    "rps": 165.04355438518425,
    "parallel": 1,
    "p99_time": 0.007843892574310306,
    "mean_time": 0.005423267833516002,
    "mean_precisions": 0.9947799999999999,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5549.50345068099,
    "total_upload_time": 5549.5034793280065,
    "p95_time": 0.012892606970854105,
    "rps": 100.81692388525947,
    "parallel": 1,
    "p99_time": 0.013834240315482024,
    "mean_time": 0.00923673729710281,
    "mean_precisions": 0.9977799999999999,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5549.50345068099,
    "total_upload_time": 5549.5034793280065,
    "p95_time": 0.16085022543556987,
    "rps": 625.2743524937949,
    "parallel": 100,
    "p99_time": 0.16735004829242825,
    "mean_time": 0.14065617762301116,
    "mean_precisions": 0.97516,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5549.50345068099,
    "total_upload_time": 5549.5034793280065,
    "p95_time": 0.27834774295333775,
    "rps": 363.97211316967457,
    "parallel": 100,
    "p99_time": 0.49805527332238864,
    "mean_time": 0.25215711603565144,
    "mean_precisions": 0.9884799999999999,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5549.50345068099,
    "total_upload_time": 5549.5034793280065,
    "p95_time": 0.4931268169777468,
    "rps": 208.39288253006197,
    "parallel": 100,
    "p99_time": 0.5814369672490284,
    "mean_time": 0.4554217465573922,
    "mean_precisions": 0.9947799999999999,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5549.50345068099,
    "total_upload_time": 5549.5034793280065,
    "p95_time": 0.8861319731455296,
    "rps": 116.53327634909284,
    "parallel": 100,
    "p99_time": 0.9738863661745566,
    "mean_time": 0.8360304634119384,
    "mean_precisions": 0.9977799999999999,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 17099.494859004,
    "total_upload_time": 17099.494889343,
    "p95_time": 0.002711502400779863,
    "rps": 443.567442040425,
    "parallel": 1,
    "p99_time": 0.003095408762419539,
    "mean_time": 0.0022100107041129378,
    "mean_precisions": 0.9198310000000002,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 17099.494859004,
    "total_upload_time": 17099.494889343,
    "p95_time": 0.002641041403148847,
    "rps": 423.4535932338339,
    "parallel": 1,
    "p99_time": 0.0031446343412608276,
    "mean_time": 0.0023158190868158273,
    "mean_precisions": 0.942351,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 17099.494859004,
    "total_upload_time": 17099.494889343,
    "p95_time": 0.005031988701557565,
    "rps": 271.8030212580239,
    "parallel": 1,
    "p99_time": 0.005545139869609557,
    "mean_time": 0.0036256147175816296,
    "mean_precisions": 0.9790700000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 17099.494859004,
    "total_upload_time": 17099.494889343,
    "p95_time": 0.006066322648985078,
    "rps": 202.4546698357374,
    "parallel": 1,
    "p99_time": 0.006596394621483342,
    "mean_time": 0.004880165740522352,
    "mean_precisions": 0.993334,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 17099.494859004,
    "total_upload_time": 17099.494889343,
    "p95_time": 0.11905856920002407,
    "rps": 871.8750335368854,
    "parallel": 100,
    "p99_time": 0.12297039172801306,
    "mean_time": 0.11030253051161526,
    "mean_precisions": 0.9198310000000002,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 17099.494859004,
    "total_upload_time": 17099.494889343,
    "p95_time": 0.13677496944728773,
    "rps": 755.4905409540679,
    "parallel": 100,
    "p99_time": 0.14075841993020732,
    "mean_time": 0.12816314872539916,
    "mean_precisions": 0.942351,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 17099.494859004,
    "total_upload_time": 17099.494889343,
    "p95_time": 0.2150327962508527,
    "rps": 478.7114112638543,
    "parallel": 100,
    "p99_time": 0.21941035127019862,
    "mean_time": 0.2041994366660063,
    "mean_precisions": 0.9790700000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 17099.494859004,
    "total_upload_time": 17099.494889343,
    "p95_time": 0.36133333340221724,
    "rps": 284.681791406387,
    "parallel": 100,
    "p99_time": 0.3677200755099693,
    "mean_time": 0.3462303664458832,
    "mean_precisions": 0.993334,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 6112.999194021002,
    "total_upload_time": 6112.999212087001,
    "p95_time": 0.0039991717087104915,
    "rps": 294.5765632051821,
    "parallel": 1,
    "p99_time": 0.004353603557683527,
    "mean_time": 0.0033217724608257415,
    "mean_precisions": 0.8046200000000001,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 6112.999194021002,
    "total_upload_time": 6112.999212087001,
    "p95_time": 0.004482199088670313,
    "rps": 264.0435673605152,
    "parallel": 1,
    "p99_time": 0.004741469277068973,
    "mean_time": 0.0037088067438453436,
    "mean_precisions": 0.84511,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 6112.999194021002,
    "total_upload_time": 6112.999212087001,
    "p95_time": 0.3821402254427085,
    "rps": 283.46588405046754,
    "parallel": 100,
    "p99_time": 0.5073361724196002,
    "mean_time": 0.33279669344188006,
    "mean_precisions": 0.80451,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 6112.999194021002,
    "total_upload_time": 6112.999212087001,
    "p95_time": 0.4505511544113688,
    "rps": 235.79366550205089,
    "parallel": 100,
    "p99_time": 0.6056402164035535,
    "mean_time": 0.3999071139860316,
    "mean_precisions": 0.8457199999999999,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 6112.999194021002,
    "total_upload_time": 6112.999212087001,
    "p95_time": 0.7849787088016456,
    "rps": 140.14450279782795,
    "parallel": 100,
    "p99_time": 0.7953324702072132,
    "mean_time": 0.6803823774509947,
    "mean_precisions": 0.92751,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 6112.999194021002,
    "total_upload_time": 6112.999212087001,
    "p95_time": 1.3782735948399931,
    "rps": 81.40737343328036,
    "parallel": 100,
    "p99_time": 1.4938700837799115,
    "mean_time": 1.1897825312350614,
    "mean_precisions": 0.9703700000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 6112.999194021002,
    "total_upload_time": 6112.999212087001,
    "p95_time": 0.007272006780840456,
    "rps": 171.0609634631763,
    "parallel": 1,
    "p99_time": 0.008407074925489722,
    "mean_time": 0.005763449343387038,
    "mean_precisions": 0.92755,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 6112.999194021002,
    "total_upload_time": 6112.999212087001,
    "p95_time": 0.011381184542551636,
    "rps": 109.40810611093407,
    "parallel": 1,
    "p99_time": 0.01209674306679517,
    "mean_time": 0.009030055647250264,
    "mean_precisions": 0.97047,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 6112.999194021002,
    "total_upload_time": 6112.999212087001,
    "p95_time": 0.23812829186208545,
    "rps": 437.7154769188336,
    "parallel": 100,
    "p99_time": 0.31775105006527155,
    "mean_time": 0.21097068405244498,
    "mean_precisions": 0.80462,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 6112.999194021002,
    "total_upload_time": 6112.999212087001,
    "p95_time": 0.2835431628162041,
    "rps": 376.430913823421,
    "parallel": 100,
    "p99_time": 0.5019653119612485,
    "mean_time": 0.2474792289212346,
    "mean_precisions": 0.8451100000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 6112.999194021002,
    "total_upload_time": 6112.999212087001,
    "p95_time": 0.4667601119494066,
    "rps": 227.50397239209343,
    "parallel": 100,
    "p99_time": 0.4752515207789838,
    "mean_time": 0.4160785322412848,
    "mean_precisions": 0.92755,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 6112.999194021002,
    "total_upload_time": 6112.999212087001,
    "p95_time": 0.8323792233830318,
    "rps": 129.66777360913807,
    "parallel": 100,
    "p99_time": 1.0655025727348402,
    "mean_time": 0.7396801782432012,
    "mean_precisions": 0.97047,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 2926.213012655,
    "total_upload_time": 2926.2130292750007,
    "p95_time": 0.002373611787334084,
    "rps": 495.88862887949404,
    "parallel": 1,
    "p99_time": 0.0029885531449690495,
    "mean_time": 0.00197105154087767,
    "mean_precisions": 0.7655259999999999,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 2926.213012655,
    "total_upload_time": 2926.2130292750007,
    "p95_time": 0.002336571249179542,
    "rps": 474.3624824339466,
    "parallel": 1,
    "p99_time": 0.002533404575660825,
    "mean_time": 0.0020627193035557866,
    "mean_precisions": 0.796248,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 2926.213012655,
    "total_upload_time": 2926.2130292750007,
    "p95_time": 0.15454141399804938,
    "rps": 684.5871895492783,
    "parallel": 100,
    "p99_time": 0.1693174908896981,
    "mean_time": 0.14178700624338963,
    "mean_precisions": 0.765484,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 2926.213012655,
    "total_upload_time": 2926.2130292750007,
    "p95_time": 0.18306419725031445,
    "rps": 572.4994112945466,
    "parallel": 100,
    "p99_time": 0.19120645078088275,
    "mean_time": 0.17036115193938894,
    "mean_precisions": 0.796147,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 2926.213012655,
    "total_upload_time": 2926.2130292750007,
    "p95_time": 0.299772673447842,
    "rps": 348.02235505335295,
    "parallel": 100,
    "p99_time": 0.3092566318590616,
    "mean_time": 0.2820777932005862,
    "mean_precisions": 0.869721,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 2926.213012655,
    "total_upload_time": 2926.2130292750007,
    "p95_time": 0.518883843799631,
    "rps": 200.20392335589443,
    "parallel": 100,
    "p99_time": 0.5305090123822447,
    "mean_time": 0.49428447423789623,
    "mean_precisions": 0.925108,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 2926.213012655,
    "total_upload_time": 2926.2130292750007,
    "p95_time": 0.003260821010917425,
    "rps": 354.5831482021425,
    "parallel": 1,
    "p99_time": 0.0034664128161966804,
    "mean_time": 0.0027728368646930904,
    "mean_precisions": 0.8697860000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 2926.213012655,
    "total_upload_time": 2926.2130292750007,
    "p95_time": 0.005012881243601441,
    "rps": 235.6824974585061,
    "parallel": 1,
    "p99_time": 0.0052325435820966965,
    "mean_time": 0.004184244300052524,
    "mean_precisions": 0.9251389999999999,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 2926.213012655,
    "total_upload_time": 2926.2130292750007,
    "p95_time": 0.0962938996264711,
    "rps": 1084.0614355568773,
    "parallel": 100,
    "p99_time": 0.10037840476725252,
    "mean_time": 0.08775270192571916,
    "mean_precisions": 0.765526,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 2926.213012655,
    "total_upload_time": 2926.2130292750007,
    "p95_time": 0.11358507624827326,
    "rps": 922.0775319325622,
    "parallel": 100,
    "p99_time": 0.11808123981580139,
    "mean_time": 0.10421627390864305,
    "mean_precisions": 0.7962480000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 2926.213012655,
    "total_upload_time": 2926.2130292750007,
    "p95_time": 0.1792137029347941,
    "rps": 578.431239507105,
    "parallel": 100,
    "p99_time": 0.1849926298018545,
    "mean_time": 0.16838497349089013,
    "mean_precisions": 0.8697860000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 2926.213012655,
    "total_upload_time": 2926.2130292750007,
    "p95_time": 0.30895526020321995,
    "rps": 333.4821792539523,
    "parallel": 100,
    "p99_time": 0.31711538522038607,
    "mean_time": 0.294230717962794,
    "mean_precisions": 0.9251389999999999,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 10910.278148930985,
    "total_upload_time": 10910.278176284977,
    "p95_time": 0.0025969251058995725,
    "rps": 375.9359538861344,
    "parallel": 1,
    "p99_time": 0.002778031136840583,
    "mean_time": 0.0021309463661164044,
    "mean_precisions": 0.9793,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 10910.278148930985,
    "total_upload_time": 10910.278176284977,
    "p95_time": 0.004282927373424172,
    "rps": 249.19154455898587,
    "parallel": 1,
    "p99_time": 0.004528938150033355,
    "mean_time": 0.003405808195937425,
    "mean_precisions": 0.99164,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 10910.278148930985,
    "total_upload_time": 10910.278176284977,
    "p95_time": 0.21953330902615562,
    "rps": 457.3862847912672,
    "parallel": 100,
    "p99_time": 0.23827404527692136,
    "mean_time": 0.20010005205083872,
    "mean_precisions": 0.9799400000000001,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 10910.278148930985,
    "total_upload_time": 10910.278176284977,
    "p95_time": 0.38459395693207626,
    "rps": 263.29341748439066,
    "parallel": 100,
    "p99_time": 0.44653708848112805,
    "mean_time": 0.3601157831795048,
    "mean_precisions": 0.9920200000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 10910.278148930985,
    "total_upload_time": 10910.278176284977,
    "p95_time": 0.6874474475771422,
    "rps": 148.35761502091083,
    "parallel": 100,
    "p99_time": 0.7089763982256445,
    "mean_time": 0.6525305509758648,
    "mean_precisions": 0.9970399999999999,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 10910.278148930985,
    "total_upload_time": 10910.278176284977,
    "p95_time": 1.2274973522202346,
    "rps": 83.81183760648828,
    "parallel": 100,
    "p99_time": 1.4242764039145552,
    "mean_time": 1.1682942975790473,
    "mean_precisions": 0.99864,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 10910.278148930985,
    "total_upload_time": 10910.278176284977,
    "p95_time": 0.0073664642870426185,
    "rps": 157.63828695535273,
    "parallel": 1,
    "p99_time": 0.007801927737891674,
    "mean_time": 0.005703287442307919,
    "mean_precisions": 0.9968599999999999,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 10910.278148930985,
    "total_upload_time": 10910.278176284977,
    "p95_time": 0.013188816886395217,
    "rps": 93.81960831653996,
    "parallel": 1,
    "p99_time": 0.013943847692571582,
    "mean_time": 0.009973209669347852,
    "mean_precisions": 0.9986599999999999,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 10910.278148930985,
    "total_upload_time": 10910.278176284977,
    "p95_time": 0.17301298391539605,
    "rps": 579.4085115629597,
    "parallel": 100,
    "p99_time": 0.17985712995752695,
    "mean_time": 0.15283483393639327,
    "mean_precisions": 0.9793,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 10910.278148930985,
    "total_upload_time": 10910.278176284977,
    "p95_time": 0.2988632217282429,
    "rps": 337.3548762635344,
    "parallel": 100,
    "p99_time": 0.3560698534315453,
    "mean_time": 0.2777310832571238,
    "mean_precisions": 0.99164,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 10910.278148930985,
    "total_upload_time": 10910.278176284977,
    "p95_time": 0.5343329657334834,
    "rps": 190.8875098561454,
    "parallel": 100,
    "p99_time": 0.5826482756156478,
    "mean_time": 0.5024129792012274,
    "mean_precisions": 0.9968600000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 10910.278148930985,
    "total_upload_time": 10910.278176284977,
    "p95_time": 1.0798818924231457,
    "rps": 105.00084802728756,
    "parallel": 100,
    "p99_time": 1.3112401228910313,
    "mean_time": 0.9285428511422128,
    "mean_precisions": 0.9986599999999999,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 31594.153414040004,
    "total_upload_time": 31594.153464609,
    "p95_time": 0.003451258899804088,
    "rps": 392.58684094234735,
    "parallel": 1,
    "p99_time": 0.0038766051154379973,
    "mean_time": 0.0024941156644170404,
    "mean_precisions": 0.926876,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 31594.153414040004,
    "total_upload_time": 31594.153464609,
    "p95_time": 0.003388846250163624,
    "rps": 348.2231126361008,
    "parallel": 1,
    "p99_time": 0.0036696244899940213,
    "mean_time": 0.0028116996315235157,
    "mean_precisions": 0.948268,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 31594.153414040004,
    "total_upload_time": 31594.153464609,
    "p95_time": 0.004084325701114721,
    "rps": 283.10158418482524,
    "parallel": 1,
    "p99_time": 0.004292602005662048,
    "mean_time": 0.003464925830462016,
    "mean_precisions": 0.982878,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 31594.153414040004,
    "total_upload_time": 31594.153464609,
    "p95_time": 0.00620668144802039,
    "rps": 192.66247703207077,
    "parallel": 1,
    "p99_time": 0.006832851128783663,
    "mean_time": 0.0051226480058903685,
    "mean_precisions": 0.9951980000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 31594.153414040004,
    "total_upload_time": 31594.153464609,
    "p95_time": 0.12426601964725706,
    "rps": 834.0800982427318,
    "parallel": 100,
    "p99_time": 0.1283589401151403,
    "mean_time": 0.11522460913593531,
    "mean_precisions": 0.926876,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 31594.153414040004,
    "total_upload_time": 31594.153464609,
    "p95_time": 0.14328853795377652,
    "rps": 720.1586100657264,
    "parallel": 100,
    "p99_time": 0.1472206530438416,
    "mean_time": 0.13417714102999234,
    "mean_precisions": 0.948268,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 31594.153414040004,
    "total_upload_time": 31594.153464609,
    "p95_time": 0.2261082945522503,
    "rps": 453.5937040096153,
    "parallel": 100,
    "p99_time": 0.23124280362004357,
    "mean_time": 0.215262622099492,
    "mean_precisions": 0.982878,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 31594.153414040004,
    "total_upload_time": 31594.153464609,
    "p95_time": 0.38318401890101084,
    "rps": 268.1642906959779,
    "parallel": 100,
    "p99_time": 0.38959941076849647,
    "mean_time": 0.3676395128065604,
    "mean_precisions": 0.9951980000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 11629.966227657991,
    "total_upload_time": 11629.966247874996,
    "p95_time": 0.0042884347029030325,
    "rps": 273.43679914773713,
    "parallel": 1,
    "p99_time": 0.0045928264595568175,
    "mean_time": 0.0035840803971514106,
    "mean_precisions": 0.8316099999999998,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 11629.966227657991,
    "total_upload_time": 11629.966247874996,
    "p95_time": 0.0048233819194138045,
    "rps": 244.56252067008197,
    "parallel": 1,
    "p99_time": 0.005336343301460146,
    "mean_time": 0.004012371118180454,
    "mean_precisions": 0.8710399999999999,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 11629.966227657991,
    "total_upload_time": 11629.966247874996,
    "p95_time": 0.40129935355289487,
    "rps": 262.5100885749777,
    "parallel": 100,
    "p99_time": 0.49792887589981544,
    "mean_time": 0.3599708980708674,
    "mean_precisions": 0.83085,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 11629.966227657991,
    "total_upload_time": 11629.966247874996,
    "p95_time": 0.494529214004433,
    "rps": 217.18933696173323,
    "parallel": 100,
    "p99_time": 0.5035445680306293,
    "mean_time": 0.43849622755400197,
    "mean_precisions": 0.87088,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 11629.966227657991,
    "total_upload_time": 11629.966247874996,
    "p95_time": 0.8814564266896923,
    "rps": 122.13113456531124,
    "parallel": 100,
    "p99_time": 0.9767611336310802,
    "mean_time": 0.7838382385670557,
    "mean_precisions": 0.9461799999999999,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 11629.966227657991,
    "total_upload_time": 11629.966247874996,
    "p95_time": 1.5292853593440667,
    "rps": 71.7130032917569,
    "parallel": 100,
    "p99_time": 1.9593636549840447,
    "mean_time": 1.3482440629350458,
    "mean_precisions": 0.9811100000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 11629.966227657991,
    "total_upload_time": 11629.966247874996,
    "p95_time": 0.007850912283174694,
    "rps": 156.675007496927,
    "parallel": 1,
    "p99_time": 0.009444913542829454,
    "mean_time": 0.006301133095752448,
    "mean_precisions": 0.94614,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 11629.966227657991,
    "total_upload_time": 11629.966247874996,
    "p95_time": 0.012432286096736788,
    "rps": 100.53662098074682,
    "parallel": 1,
    "p99_time": 0.01363002293743193,
    "mean_time": 0.009838161436840891,
    "mean_precisions": 0.98102,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 11629.966227657991,
    "total_upload_time": 11629.966247874996,
    "p95_time": 0.24381494750268756,
    "rps": 418.3817401416314,
    "parallel": 100,
    "p99_time": 0.45352216221857816,
    "mean_time": 0.22082974288519472,
    "mean_precisions": 0.8316099999999998,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 11629.966227657991,
    "total_upload_time": 11629.966247874996,
    "p95_time": 0.3844886865001172,
    "rps": 348.20579906998773,
    "parallel": 100,
    "p99_time": 0.5534559293091297,
    "mean_time": 0.26758842227933927,
    "mean_precisions": 0.87104,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 11629.966227657991,
    "total_upload_time": 11629.966247874996,
    "p95_time": 0.5159622454550117,
    "rps": 206.4838555039072,
    "parallel": 100,
    "p99_time": 1.0065319355018436,
    "mean_time": 0.45773238478414713,
    "mean_precisions": 0.9461400000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 11629.966227657991,
    "total_upload_time": 11629.966247874996,
    "p95_time": 0.9043424285482615,
    "rps": 117.8689657697663,
    "parallel": 100,
    "p99_time": 0.9144877930125221,
    "mean_time": 0.815856038406957,
    "mean_precisions": 0.98102,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 5475.873295309,
    "total_upload_time": 5475.873313191998,
    "p95_time": 0.002253576717339456,
    "rps": 499.3062518568755,
    "parallel": 1,
    "p99_time": 0.0025685014715418225,
    "mean_time": 0.0019569266473874448,
    "mean_precisions": 0.7725129999999999,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 5475.873295309,
    "total_upload_time": 5475.873313191998,
    "p95_time": 0.0023848160635679956,
    "rps": 462.0786613727635,
    "parallel": 1,
    "p99_time": 0.0026174320513382564,
    "mean_time": 0.0021146031751297415,
    "mean_precisions": 0.804121,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 5475.873295309,
    "total_upload_time": 5475.873313191998,
    "p95_time": 0.15939703794774687,
    "rps": 665.1366712725479,
    "parallel": 100,
    "p99_time": 0.16861959273839602,
    "mean_time": 0.14541342871750748,
    "mean_precisions": 0.77224,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 5475.873295309,
    "total_upload_time": 5475.873313191998,
    "p95_time": 0.18759632609999244,
    "rps": 553.7566186047918,
    "parallel": 100,
    "p99_time": 0.1928223389789855,
    "mean_time": 0.17623549356052026,
    "mean_precisions": 0.8037340000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 5475.873295309,
    "total_upload_time": 5475.873313191998,
    "p95_time": 0.30985700450128206,
    "rps": 334.34593882662733,
    "parallel": 100,
    "p99_time": 0.3176804040373827,
    "mean_time": 0.29421144535991733,
    "mean_precisions": 0.8780630000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 5475.873295309,
    "total_upload_time": 5475.873313191998,
    "p95_time": 0.5528744375011229,
    "rps": 191.7011975774943,
    "parallel": 100,
    "p99_time": 0.5693747955889922,
    "mean_time": 0.5163422421921893,
    "mean_precisions": 0.9331290000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 5475.873295309,
    "total_upload_time": 5475.873313191998,
    "p95_time": 0.0033127824775874616,
    "rps": 344.32128232544835,
    "parallel": 1,
    "p99_time": 0.0035027512488886715,
    "mean_time": 0.002854994060937315,
    "mean_precisions": 0.8780449999999999,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 5475.873295309,
    "total_upload_time": 5475.873313191998,
    "p95_time": 0.005123072699643671,
    "rps": 227.33365526384014,
    "parallel": 1,
    "p99_time": 0.005347140966914595,
    "mean_time": 0.004344162546424195,
    "mean_precisions": 0.9331859999999998,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 5475.873295309,
    "total_upload_time": 5475.873313191998,
    "p95_time": 0.09770751306787133,
    "rps": 1066.7045651231288,
    "parallel": 100,
    "p99_time": 0.10234162330627442,
    "mean_time": 0.08936011200957,
    "mean_precisions": 0.772513,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 5475.873295309,
    "total_upload_time": 5475.873313191998,
    "p95_time": 0.11363435739185661,
    "rps": 912.0385780597151,
    "parallel": 100,
    "p99_time": 0.11726646097376943,
    "mean_time": 0.10511748783127405,
    "mean_precisions": 0.804121,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 5475.873295309,
    "total_upload_time": 5475.873313191998,
    "p95_time": 0.18425394310615956,
    "rps": 560.0542867572963,
    "parallel": 100,
    "p99_time": 0.18890257142018527,
    "mean_time": 0.1740535263047088,
    "mean_precisions": 0.8780450000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 5475.873295309,
    "total_upload_time": 5475.873313191998,
    "p95_time": 0.3181208850350231,
    "rps": 324.68842846334985,
    "parallel": 100,
    "p99_time": 0.32626147476956247,
    "mean_time": 0.3032409775185864,
    "mean_precisions": 0.9331860000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 32,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 6402.126676108048,
    "total_upload_time": 6402.126701645029,
    "p95_time": 0.00341892174910754,
    "rps": 337.952258291684,
    "parallel": 1,
    "p99_time": 0.0037164100585505367,
    "mean_time": 0.002411369971279055,
    "mean_precisions": 0.98146,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 6402.126676108048,
    "total_upload_time": 6402.126701645029,
    "p95_time": 0.005613349797204137,
    "rps": 227.2950217861939,
    "parallel": 1,
    "p99_time": 0.006026325034908951,
    "mean_time": 0.0037862919813022016,
    "mean_precisions": 0.99164,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 6402.126676108048,
    "total_upload_time": 6402.126701645029,
    "p95_time": 0.24960622476937716,
    "rps": 408.32845273271136,
    "parallel": 100,
    "p99_time": 0.2647127518767958,
    "mean_time": 0.22354015802340582,
    "mean_precisions": 0.9817,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 6402.126676108048,
    "total_upload_time": 6402.126701645029,
    "p95_time": 0.4316268985916395,
    "rps": 238.11998269609794,
    "parallel": 100,
    "p99_time": 0.6959051962394737,
    "mean_time": 0.3983232086225762,
    "mean_precisions": 0.99182,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 6402.126676108048,
    "total_upload_time": 6402.126701645029,
    "p95_time": 0.7628487698821118,
    "rps": 135.997067065185,
    "parallel": 100,
    "p99_time": 1.1795142571558248,
    "mean_time": 0.7083396567074466,
    "mean_precisions": 0.99644,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 6402.126676108048,
    "total_upload_time": 6402.126701645029,
    "p95_time": 1.3590744563902262,
    "rps": 76.46283388027227,
    "parallel": 100,
    "p99_time": 1.4062379531370246,
    "mean_time": 1.2749271767156547,
    "mean_precisions": 0.9986,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 6402.126676108048,
    "total_upload_time": 6402.126701645029,
    "p95_time": 0.009683820069767535,
    "rps": 142.98242581632837,
    "parallel": 1,
    "p99_time": 0.010493039125576616,
    "mean_time": 0.00634042820269242,
    "mean_precisions": 0.9965200000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 6402.126676108048,
    "total_upload_time": 6402.126701645029,
    "p95_time": 0.016863991995342074,
    "rps": 84.87891642599416,
    "parallel": 1,
    "p99_time": 0.01829229161143303,
    "mean_time": 0.011082763555366545,
    "mean_precisions": 0.9985599999999999,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 6402.126676108048,
    "total_upload_time": 6402.126701645029,
    "p95_time": 0.2011010726215318,
    "rps": 503.76697727961425,
    "parallel": 100,
    "p99_time": 0.21327452555764728,
    "mean_time": 0.18086404764596373,
    "mean_precisions": 0.9814600000000002,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 6402.126676108048,
    "total_upload_time": 6402.126701645029,
    "p95_time": 0.34298856765963137,
    "rps": 298.90653898295017,
    "parallel": 100,
    "p99_time": 0.37816208404954527,
    "mean_time": 0.31441796267684546,
    "mean_precisions": 0.99164,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 6402.126676108048,
    "total_upload_time": 6402.126701645029,
    "p95_time": 0.6182354090036825,
    "rps": 168.24081609145858,
    "parallel": 100,
    "p99_time": 0.6534872404905037,
    "mean_time": 0.5738948708157986,
    "mean_precisions": 0.9965200000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 6402.126676108048,
    "total_upload_time": 6402.126701645029,
    "p95_time": 1.1036532958736642,
    "rps": 94.78593908388089,
    "parallel": 100,
    "p99_time": 1.1282646376639607,
    "mean_time": 1.0327559477200732,
    "mean_precisions": 0.9985600000000002,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 19994.136571595,
    "total_upload_time": 19994.136607792003,
    "p95_time": 0.003577484198467573,
    "rps": 340.8898626444283,
    "parallel": 1,
    "p99_time": 0.003974664093257162,
    "mean_time": 0.0028830985690976377,
    "mean_precisions": 0.938484,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 19994.136571595,
    "total_upload_time": 19994.136607792003,
    "p95_time": 0.003170314955787034,
    "rps": 375.5741696029754,
    "parallel": 1,
    "p99_time": 0.0034132223689812237,
    "mean_time": 0.002611032608518144,
    "mean_precisions": 0.9564819999999999,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 19994.136571595,
    "total_upload_time": 19994.136607792003,
    "p95_time": 0.004696266658720559,
    "rps": 265.88308804905535,
    "parallel": 1,
    "p99_time": 0.005505699266359448,
    "mean_time": 0.0037078830303915312,
    "mean_precisions": 0.9847940000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 19994.136571595,
    "total_upload_time": 19994.136607792003,
    "p95_time": 0.0071721008069289376,
    "rps": 181.7933064285863,
    "parallel": 1,
    "p99_time": 0.007690094464924187,
    "mean_time": 0.005445570965424122,
    "mean_precisions": 0.99529,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 19994.136571595,
    "total_upload_time": 19994.136607792003,
    "p95_time": 0.13846044661258927,
    "rps": 749.5364073477599,
    "parallel": 100,
    "p99_time": 0.142563080881082,
    "mean_time": 0.12923536201678798,
    "mean_precisions": 0.938484,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 19994.136571595,
    "total_upload_time": 19994.136607792003,
    "p95_time": 0.1618937877457938,
    "rps": 638.3805398628598,
    "parallel": 100,
    "p99_time": 0.16649720731482376,
    "mean_time": 0.15235518755491068,
    "mean_precisions": 0.9564819999999999,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 19994.136571595,
    "total_upload_time": 19994.136607792003,
    "p95_time": 0.25630503249849423,
    "rps": 403.681696138684,
    "parallel": 100,
    "p99_time": 0.2628356207588513,
    "mean_time": 0.24263819529488972,
    "mean_precisions": 0.9847940000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 19994.136571595,
    "total_upload_time": 19994.136607792003,
    "p95_time": 0.43403014889845504,
    "rps": 239.06829372205385,
    "parallel": 100,
    "p99_time": 0.4454867905208085,
    "mean_time": 0.41257836485026056,
    "mean_precisions": 0.9952900000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 7052.908509621993,
    "total_upload_time": 7052.908530914996,
    "p95_time": 0.0048934386111795895,
    "rps": 256.9512165315704,
    "parallel": 1,
    "p99_time": 0.0053972975490614765,
    "mean_time": 0.0038180523654446005,
    "mean_precisions": 0.83905,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 7052.908509621993,
    "total_upload_time": 7052.908530914996,
    "p95_time": 0.00605608623009175,
    "rps": 216.3304003099133,
    "parallel": 1,
    "p99_time": 0.007559680342674255,
    "mean_time": 0.0045450012846849856,
    "mean_precisions": 0.8760800000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 7052.908509621993,
    "total_upload_time": 7052.908530914996,
    "p95_time": 0.4776713671562902,
    "rps": 231.65690023717778,
    "parallel": 100,
    "p99_time": 0.4925293553827214,
    "mean_time": 0.4078483626119851,
    "mean_precisions": 0.83899,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 7052.908509621993,
    "total_upload_time": 7052.908530914996,
    "p95_time": 0.5683218176083755,
    "rps": 189.42868552984868,
    "parallel": 100,
    "p99_time": 0.663068717647402,
    "mean_time": 0.5021166075269721,
    "mean_precisions": 0.87578,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 7052.908509621993,
    "total_upload_time": 7052.908530914996,
    "p95_time": 1.0115355320966046,
    "rps": 113.26933708076204,
    "parallel": 100,
    "p99_time": 1.0659179392678197,
    "mean_time": 0.8479306337315938,
    "mean_precisions": 0.9452600000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 7052.908509621993,
    "total_upload_time": 7052.908530914996,
    "p95_time": 1.7366309840537724,
    "rps": 65.70425512267575,
    "parallel": 100,
    "p99_time": 1.7454566497178166,
    "mean_time": 1.4830194074142637,
    "mean_precisions": 0.9791700000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 7052.908509621993,
    "total_upload_time": 7052.908530914996,
    "p95_time": 0.008774688420817255,
    "rps": 149.24882524163235,
    "parallel": 1,
    "p99_time": 0.009326341454870999,
    "mean_time": 0.00661595610063523,
    "mean_precisions": 0.9453400000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 7052.908509621993,
    "total_upload_time": 7052.908530914996,
    "p95_time": 0.014951583417132496,
    "rps": 89.85962031508252,
    "parallel": 1,
    "p99_time": 0.018412696854211385,
    "mean_time": 0.011001651582308114,
    "mean_precisions": 0.97914,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 7052.908509621993,
    "total_upload_time": 7052.908530914996,
    "p95_time": 0.2976256208727136,
    "rps": 370.16084063635765,
    "parallel": 100,
    "p99_time": 0.4208288290631026,
    "mean_time": 0.24999261737894266,
    "mean_precisions": 0.83905,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 7052.908509621993,
    "total_upload_time": 7052.908530914996,
    "p95_time": 0.3363423234783113,
    "rps": 318.44393082104466,
    "parallel": 100,
    "p99_time": 0.4308691699057817,
    "mean_time": 0.2942479261704721,
    "mean_precisions": 0.8760800000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 7052.908509621993,
    "total_upload_time": 7052.908530914996,
    "p95_time": 0.5759978600777685,
    "rps": 190.83279926883048,
    "parallel": 100,
    "p99_time": 0.8808745274832472,
    "mean_time": 0.4977704247096553,
    "mean_precisions": 0.9453400000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 7052.908509621993,
    "total_upload_time": 7052.908530914996,
    "p95_time": 1.0115404185838996,
    "rps": 109.15400205114247,
    "parallel": 100,
    "p99_time": 1.0191279615834354,
    "mean_time": 0.8836541013387031,
    "mean_precisions": 0.9791400000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 3715.911056585999,
    "total_upload_time": 3715.9110759450014,
    "p95_time": 0.0027944878675043574,
    "rps": 435.78339166406766,
    "parallel": 1,
    "p99_time": 0.003276185286231339,
    "mean_time": 0.0022489686225540934,
    "mean_precisions": 0.8113889999999999,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 3715.911056585999,
    "total_upload_time": 3715.9110759450014,
    "p95_time": 0.0028129765763878815,
    "rps": 419.51772932600414,
    "parallel": 1,
    "p99_time": 0.003020837446674705,
    "mean_time": 0.0023377922895364465,
    "mean_precisions": 0.8398329999999999,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 3715.911056585999,
    "total_upload_time": 3715.9110759450014,
    "p95_time": 0.19299377490460756,
    "rps": 542.1536732544216,
    "parallel": 100,
    "p99_time": 0.19953700313388256,
    "mean_time": 0.17958329572172368,
    "mean_precisions": 0.811314,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 3715.911056585999,
    "total_upload_time": 3715.9110759450014,
    "p95_time": 0.22441339645301922,
    "rps": 465.53572502577924,
    "parallel": 100,
    "p99_time": 0.2298282624949934,
    "mean_time": 0.21055183333590685,
    "mean_precisions": 0.8396080000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 3715.911056585999,
    "total_upload_time": 3715.9110759450014,
    "p95_time": 0.4025280642526923,
    "rps": 263.5616157704116,
    "parallel": 100,
    "p99_time": 0.41299044992600104,
    "mean_time": 0.37329863008128084,
    "mean_precisions": 0.9059790000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 3715.911056585999,
    "total_upload_time": 3715.9110759450014,
    "p95_time": 0.7098848033980175,
    "rps": 148.72574400406617,
    "parallel": 100,
    "p99_time": 0.7324243593548454,
    "mean_time": 0.6661103751464194,
    "mean_precisions": 0.952421,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 3715.911056585999,
    "total_upload_time": 3715.9110759450014,
    "p95_time": 0.004206854593940079,
    "rps": 293.66144289241674,
    "parallel": 1,
    "p99_time": 0.0044396199285984045,
    "mean_time": 0.0033552634980063886,
    "mean_precisions": 0.9059960000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 3715.911056585999,
    "total_upload_time": 3715.9110759450014,
    "p95_time": 0.006616116221994162,
    "rps": 191.0943462786622,
    "parallel": 1,
    "p99_time": 0.006927804173901677,
    "mean_time": 0.0051771478338167075,
    "mean_precisions": 0.952484,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 3715.911056585999,
    "total_upload_time": 3715.9110759450014,
    "p95_time": 0.11851975510362535,
    "rps": 885.1601316922576,
    "parallel": 100,
    "p99_time": 0.12345883218105883,
    "mean_time": 0.1084874452019576,
    "mean_precisions": 0.8113889999999999,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 3715.911056585999,
    "total_upload_time": 3715.9110759450014,
    "p95_time": 0.1403074754634872,
    "rps": 740.901431291332,
    "parallel": 100,
    "p99_time": 0.14562618945725267,
    "mean_time": 0.1300193214699626,
    "mean_precisions": 0.8398329999999999,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 3715.911056585999,
    "total_upload_time": 3715.9110759450014,
    "p95_time": 0.2378907864214852,
    "rps": 448.5514854244508,
    "parallel": 100,
    "p99_time": 0.26221142037771644,
    "mean_time": 0.21836558240889573,
    "mean_precisions": 0.9059959999999999,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 3715.911056585999,
    "total_upload_time": 3715.9110759450014,
    "p95_time": 0.40458990584593263,
    "rps": 257.663004238594,
    "parallel": 100,
    "p99_time": 0.41482991573400796,
    "mean_time": 0.3831274474136531,
    "mean_precisions": 0.952484,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 256
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 13742.546759146964,
    "total_upload_time": 13742.546788036998,
    "p95_time": 0.0037124474998563527,
    "rps": 306.4136282863512,
    "parallel": 1,
    "p99_time": 0.003958312273025513,
    "mean_time": 0.0027084966636262836,
    "mean_precisions": 0.98618,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 13742.546759146964,
    "total_upload_time": 13742.546788036998,
    "p95_time": 0.006316635641269386,
    "rps": 196.056144964852,
    "parallel": 1,
    "p99_time": 0.006725107110105455,
    "mean_time": 0.004475510700512678,
    "mean_precisions": 0.99472,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 13742.546759146964,
    "total_upload_time": 13742.546788036998,
    "p95_time": 0.2914948615740286,
    "rps": 347.9368103002331,
    "parallel": 100,
    "p99_time": 0.30101221279473983,
    "mean_time": 0.26833482845119433,
    "mean_precisions": 0.9861,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 13742.546759146964,
    "total_upload_time": 13742.546788036998,
    "p95_time": 0.5138384575839154,
    "rps": 199.58535076007783,
    "parallel": 100,
    "p99_time": 0.5365605387016449,
    "mean_time": 0.4805132686686469,
    "mean_precisions": 0.9946599999999999,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 13742.546759146964,
    "total_upload_time": 13742.546788036998,
    "p95_time": 0.9238441336696269,
    "rps": 112.40132790497668,
    "parallel": 100,
    "p99_time": 1.0358427994407249,
    "mean_time": 0.8665805471482221,
    "mean_precisions": 0.9977,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 13742.546759146964,
    "total_upload_time": 13742.546788036998,
    "p95_time": 1.6481364141742234,
    "rps": 63.065244553397136,
    "parallel": 100,
    "p99_time": 1.715572138593416,
    "mean_time": 1.5588982669066405,
    "mean_precisions": 0.9992599999999998,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 13742.546759146964,
    "total_upload_time": 13742.546788036998,
    "p95_time": 0.011084489920176568,
    "rps": 121.39258424030014,
    "parallel": 1,
    "p99_time": 0.011868973919190468,
    "mean_time": 0.007582496636826545,
    "mean_precisions": 0.9978799999999999,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 13742.546759146964,
    "total_upload_time": 13742.546788036998,
    "p95_time": 0.019227348361164333,
    "rps": 71.53915468860419,
    "parallel": 1,
    "p99_time": 0.02063118523918093,
    "mean_time": 0.013280626127589495,
    "mean_precisions": 0.99928,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 13742.546759146964,
    "total_upload_time": 13742.546788036998,
    "p95_time": 0.23408081394154578,
    "rps": 434.1676803532485,
    "parallel": 100,
    "p99_time": 0.2502043119305745,
    "mean_time": 0.21254857775056735,
    "mean_precisions": 0.9861800000000001,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 13742.546759146964,
    "total_upload_time": 13742.546788036998,
    "p95_time": 0.40791105723474175,
    "rps": 250.4699213360804,
    "parallel": 100,
    "p99_time": 0.42025766015052796,
    "mean_time": 0.3802195941878483,
    "mean_precisions": 0.99472,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 13742.546759146964,
    "total_upload_time": 13742.546788036998,
    "p95_time": 0.7320837782928721,
    "rps": 141.23177618247323,
    "parallel": 100,
    "p99_time": 0.8191873843502254,
    "mean_time": 0.6844215286637656,
    "mean_precisions": 0.9978800000000001,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 13742.546759146964,
    "total_upload_time": 13742.546788036998,
    "p95_time": 1.448128025257029,
    "rps": 78.28656520663937,
    "parallel": 100,
    "p99_time": 1.5848955199168995,
    "mean_time": 1.252979363711551,
    "mean_precisions": 0.9992800000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 40278.94373696999,
    "total_upload_time": 40278.943770205995,
    "p95_time": 0.0032086467501358127,
    "rps": 381.6541735529214,
    "parallel": 1,
    "p99_time": 0.0036309680904378183,
    "mean_time": 0.002572175571067783,
    "mean_precisions": 0.9515720000000001,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 40278.94373696999,
    "total_upload_time": 40278.943770205995,
    "p95_time": 0.0033822166027675845,
    "rps": 358.16589942333275,
    "parallel": 1,
    "p99_time": 0.003741282018308994,
    "mean_time": 0.0027402509769191966,
    "mean_precisions": 0.967144,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 40278.94373696999,
    "total_upload_time": 40278.943770205995,
    "p95_time": 0.005049959654570557,
    "rps": 249.3184729203404,
    "parallel": 1,
    "p99_time": 0.005461627678159857,
    "mean_time": 0.003955904039693996,
    "mean_precisions": 0.99016,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 40278.94373696999,
    "total_upload_time": 40278.943770205995,
    "p95_time": 0.007904191449051723,
    "rps": 166.15959954357263,
    "parallel": 1,
    "p99_time": 0.008590073686500546,
    "mean_time": 0.0059623539755790265,
    "mean_precisions": 0.99745,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 40278.94373696999,
    "total_upload_time": 40278.943770205995,
    "p95_time": 0.15015316699791584,
    "rps": 689.6532955104525,
    "parallel": 100,
    "p99_time": 0.15562319766482688,
    "mean_time": 0.14012933698157867,
    "mean_precisions": 0.9515720000000001,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 40278.94373696999,
    "total_upload_time": 40278.943770205995,
    "p95_time": 0.1753091790516919,
    "rps": 589.1967848726741,
    "parallel": 100,
    "p99_time": 0.17981523566239047,
    "mean_time": 0.16523378104903821,
    "mean_precisions": 0.967144,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 40278.94373696999,
    "total_upload_time": 40278.943770205995,
    "p95_time": 0.282978090155666,
    "rps": 365.05643177539133,
    "parallel": 100,
    "p99_time": 0.2890258594807528,
    "mean_time": 0.26877986798195924,
    "mean_precisions": 0.99016,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 40278.94373696999,
    "total_upload_time": 40278.943770205995,
    "p95_time": 0.763169078307692,
    "rps": 193.43202788068595,
    "parallel": 100,
    "p99_time": 0.8861760631385551,
    "mean_time": 0.5107679245649575,
    "mean_precisions": 0.99745,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 13900.352298923011,
    "total_upload_time": 13900.352323341009,
    "p95_time": 0.0052597869886085395,
    "rps": 236.51776072626555,
    "parallel": 1,
    "p99_time": 0.005491651860065758,
    "mean_time": 0.004151399974245578,
    "mean_precisions": 0.8769600000000001,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 13900.352298923011,
    "total_upload_time": 13900.352323341009,
    "p95_time": 0.006310066906735301,
    "rps": 201.34254492981873,
    "parallel": 1,
    "p99_time": 0.006694799703545869,
    "mean_time": 0.004880302447360009,
    "mean_precisions": 0.9081200000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 13900.352298923011,
    "total_upload_time": 13900.352323341009,
    "p95_time": 0.5476909440571035,
    "rps": 203.9931244497709,
    "parallel": 100,
    "p99_time": 0.5897977469496254,
    "mean_time": 0.46434709350207415,
    "mean_precisions": 0.877,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 13900.352298923011,
    "total_upload_time": 13900.352323341009,
    "p95_time": 0.6522354056469339,
    "rps": 171.94273845101054,
    "parallel": 100,
    "p99_time": 0.9501668593479553,
    "mean_time": 0.5541599402839638,
    "mean_precisions": 0.9082,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 13900.352298923011,
    "total_upload_time": 13900.352323341009,
    "p95_time": 1.1096972713494324,
    "rps": 99.41015771237915,
    "parallel": 100,
    "p99_time": 1.1348453114413133,
    "mean_time": 0.9690884838421043,
    "mean_precisions": 0.96547,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 13900.352298923011,
    "total_upload_time": 13900.352323341009,
    "p95_time": 2.333265061362181,
    "rps": 54.88406422954279,
    "parallel": 100,
    "p99_time": 2.3532022876726115,
    "mean_time": 1.771663031613207,
    "mean_precisions": 0.98843,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 13900.352298923011,
    "total_upload_time": 13900.352323341009,
    "p95_time": 0.009802173799835143,
    "rps": 131.9361204282315,
    "parallel": 1,
    "p99_time": 0.010410227212123573,
    "mean_time": 0.007479651453439146,
    "mean_precisions": 0.96548,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 13900.352298923011,
    "total_upload_time": 13900.352323341009,
    "p95_time": 0.01638320602942258,
    "rps": 80.80050314178787,
    "parallel": 1,
    "p99_time": 0.01739573644474149,
    "mean_time": 0.012241401988081635,
    "mean_precisions": 0.9884200000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 13900.352298923011,
    "total_upload_time": 13900.352323341009,
    "p95_time": 0.32507796834688635,
    "rps": 327.51292592944543,
    "parallel": 100,
    "p99_time": 0.3350870940554887,
    "mean_time": 0.28319663542276247,
    "mean_precisions": 0.8769600000000001,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 13900.352298923011,
    "total_upload_time": 13900.352323341009,
    "p95_time": 0.39390412864740926,
    "rps": 278.06416863675076,
    "parallel": 100,
    "p99_time": 0.45188659567385914,
    "mean_time": 0.33762985169002785,
    "mean_precisions": 0.9081200000000001,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 13900.352298923011,
    "total_upload_time": 13900.352323341009,
    "p95_time": 0.6806750227930024,
    "rps": 160.13078542388885,
    "parallel": 100,
    "p99_time": 0.6881538429297507,
    "mean_time": 0.5963881652234122,
    "mean_precisions": 0.96548,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 13900.352298923011,
    "total_upload_time": 13900.352323341009,
    "p95_time": 1.2172074255766347,
    "rps": 93.51538059955655,
    "parallel": 100,
    "p99_time": 1.638469669581391,
    "mean_time": 1.0260545512707904,
    "mean_precisions": 0.9884200000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 8026.321081697002,
    "total_upload_time": 8026.321097831002,
    "p95_time": 0.00299488955643028,
    "rps": 409.3899563285632,
    "parallel": 1,
    "p99_time": 0.0035129945911467077,
    "mean_time": 0.002395261928578839,
    "mean_precisions": 0.829937,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 8026.321081697002,
    "total_upload_time": 8026.321097831002,
    "p95_time": 0.0031507006846368314,
    "rps": 376.7554780695916,
    "parallel": 1,
    "p99_time": 0.0033808371936902403,
    "mean_time": 0.0026040162189863623,
    "mean_precisions": 0.858978,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 8026.321081697002,
    "total_upload_time": 8026.321097831002,
    "p95_time": 0.21582989699709287,
    "rps": 482.0166617566867,
    "parallel": 100,
    "p99_time": 0.22138162387658666,
    "mean_time": 0.2027436989451002,
    "mean_precisions": 0.8298189999999999,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 8026.321081697002,
    "total_upload_time": 8026.321097831002,
    "p95_time": 0.25923347985044526,
    "rps": 400.05270427147144,
    "parallel": 100,
    "p99_time": 0.26797387338636325,
    "mean_time": 0.24545179943462644,
    "mean_precisions": 0.8589039999999999,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 8026.321081697002,
    "total_upload_time": 8026.321097831002,
    "p95_time": 0.46135011390069847,
    "rps": 227.40265181390495,
    "parallel": 100,
    "p99_time": 0.47206946667713057,
    "mean_time": 0.4340385924723414,
    "mean_precisions": 0.92501,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 8026.321081697002,
    "total_upload_time": 8026.321097831002,
    "p95_time": 0.9772361030991306,
    "rps": 114.67599734848551,
    "parallel": 100,
    "p99_time": 1.0150786271493417,
    "mean_time": 0.8655731039208578,
    "mean_precisions": 0.9674369999999999,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 8026.321081697002,
    "total_upload_time": 8026.321097831002,
    "p95_time": 0.004761694604530929,
    "rps": 258.75610529003694,
    "parallel": 1,
    "p99_time": 0.005252905860543252,
    "mean_time": 0.003809127248171717,
    "mean_precisions": 0.924989,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 8026.321081697002,
    "total_upload_time": 8026.321097831002,
    "p95_time": 0.0075771082658320655,
    "rps": 166.24699132348118,
    "parallel": 1,
    "p99_time": 0.008265600958839062,
    "mean_time": 0.005955231940047816,
    "mean_precisions": 0.9674369999999999,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 8026.321081697002,
    "total_upload_time": 8026.321097831002,
    "p95_time": 0.14094893955625593,
    "rps": 765.8033151321213,
    "parallel": 100,
    "p99_time": 0.14762994749471547,
    "mean_time": 0.12560096623101272,
    "mean_precisions": 0.829937,
    "engine_params": {
      "ef": 64,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 8026.321081697002,
    "total_upload_time": 8026.321097831002,
    "p95_time": 0.1678074919851497,
    "rps": 647.1724934561521,
    "parallel": 100,
    "p99_time": 0.1743435323191807,
    "mean_time": 0.149489944031043,
    "mean_precisions": 0.858978,
    "engine_params": {
      "ef": 128,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 8026.321081697002,
    "total_upload_time": 8026.321097831002,
    "p95_time": 0.2878142051864415,
    "rps": 379.903361786728,
    "parallel": 100,
    "p99_time": 0.29950497577432544,
    "mean_time": 0.2585998423461802,
    "mean_precisions": 0.924989,
    "engine_params": {
      "ef": 256,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "redis",
    "setup_name": "redis-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 8026.321081697002,
    "total_upload_time": 8026.321097831002,
    "p95_time": 0.5114796354901046,
    "rps": 216.3377190586565,
    "parallel": 100,
    "p99_time": 0.5243103523179888,
    "mean_time": 0.45716036826814527,
    "mean_precisions": 0.9674370000000001,
    "engine_params": {
      "ef": 512,
      "hnsw_config": {
        "M": 64,
        "EF_CONSTRUCTION": 512
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 843.3206597169628,
    "total_upload_time": 843.3206871029688,
    "p95_time": 0.01522877526585944,
    "rps": 67.34022129566705,
    "parallel": 1,
    "p99_time": 0.016654045587056326,
    "mean_time": 0.014157023558218497,
    "mean_precisions": 0.94532,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 843.3206597169628,
    "total_upload_time": 843.3206871029688,
    "p95_time": 0.016503569547785448,
    "rps": 62.89347729377089,
    "parallel": 1,
    "p99_time": 0.017680931022041477,
    "mean_time": 0.015181771953392308,
    "mean_precisions": 0.9702200000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 843.3206597169628,
    "total_upload_time": 843.3206871029688,
    "p95_time": 0.5675910157297042,
    "rps": 360.556140785458,
    "parallel": 100,
    "p99_time": 1.0418111439805944,
    "mean_time": 0.2718027016739827,
    "mean_precisions": 0.94532,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 843.3206597169628,
    "total_upload_time": 843.3206871029688,
    "p95_time": 0.4878178683982697,
    "rps": 348.223850185987,
    "parallel": 100,
    "p99_time": 0.9051783049694515,
    "mean_time": 0.28267263337104814,
    "mean_precisions": 0.9702200000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 843.3206597169628,
    "total_upload_time": 843.3206871029688,
    "p95_time": 0.5072619904240129,
    "rps": 310.31256200722584,
    "parallel": 100,
    "p99_time": 0.7238084591511897,
    "mean_time": 0.3178085503917304,
    "mean_precisions": 0.9834400000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 843.3206597169628,
    "total_upload_time": 843.3206871029688,
    "p95_time": 0.5914960173889996,
    "rps": 268.5950679056473,
    "parallel": 100,
    "p99_time": 0.769616716609453,
    "mean_time": 0.36741443801204443,
    "mean_precisions": 0.99082,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 843.3206597169628,
    "total_upload_time": 843.3206871029688,
    "p95_time": 0.019442422973224894,
    "rps": 55.03206797888427,
    "parallel": 1,
    "p99_time": 0.020619515439029783,
    "mean_time": 0.01744311281251721,
    "mean_precisions": 0.98344,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 843.3206597169628,
    "total_upload_time": 843.3206871029688,
    "p95_time": 0.02429983814363368,
    "rps": 46.163504703185794,
    "parallel": 1,
    "p99_time": 0.025462950533838014,
    "mean_time": 0.020894608789589257,
    "mean_precisions": 0.99082,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 4249.170375510999,
    "total_upload_time": 4249.170390752999,
    "p95_time": 0.012595308500021923,
    "rps": 123.15882590315042,
    "parallel": 1,
    "p99_time": 0.019562580997626373,
    "mean_time": 0.008042437455087202,
    "mean_precisions": 0.8474299999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 4249.170375510999,
    "total_upload_time": 4249.170390752999,
    "p95_time": 0.00967769500239228,
    "rps": 130.8111893154177,
    "parallel": 1,
    "p99_time": 0.012527432939932626,
    "mean_time": 0.007568946827307809,
    "mean_precisions": 0.8798289999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 4249.170375510999,
    "total_upload_time": 4249.170390752999,
    "p95_time": 0.5536399066484589,
    "rps": 688.3519421239191,
    "parallel": 100,
    "p99_time": 0.9227483752887206,
    "mean_time": 0.143095149822189,
    "mean_precisions": 0.8474299999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 4249.170375510999,
    "total_upload_time": 4249.170390752999,
    "p95_time": 0.49014220204935477,
    "rps": 774.5863471205512,
    "parallel": 100,
    "p99_time": 0.7424820228200408,
    "mean_time": 0.12774895844636047,
    "mean_precisions": 0.8798290000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 4249.170375510999,
    "total_upload_time": 4249.170390752999,
    "p95_time": 0.5459510695982315,
    "rps": 640.3742730862461,
    "parallel": 100,
    "p99_time": 0.9221149305197114,
    "mean_time": 0.15472544720671869,
    "mean_precisions": 0.9435040000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 4249.170375510999,
    "total_upload_time": 4249.170390752999,
    "p95_time": 0.4656441117993381,
    "rps": 569.4830246059206,
    "parallel": 100,
    "p99_time": 0.6114321360898977,
    "mean_time": 0.17405993095339073,
    "mean_precisions": 0.976275,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 4249.170375510999,
    "total_upload_time": 4249.170390752999,
    "p95_time": 0.011418262949882773,
    "rps": 112.53357575693532,
    "parallel": 1,
    "p99_time": 0.013922928190331732,
    "mean_time": 0.008806356606390182,
    "mean_precisions": 0.9435040000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 4249.170375510999,
    "total_upload_time": 4249.170390752999,
    "p95_time": 0.013532070548717455,
    "rps": 91.53949919623662,
    "parallel": 1,
    "p99_time": 0.016715880897172613,
    "mean_time": 0.010840437649301747,
    "mean_precisions": 0.976275,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 739.6677053900003,
    "total_upload_time": 739.667722491,
    "p95_time": 0.01735964275003425,
    "rps": 63.25958607164398,
    "parallel": 1,
    "p99_time": 0.026121951670311318,
    "mean_time": 0.015689058375003697,
    "mean_precisions": 0.68299,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 739.6677053900003,
    "total_upload_time": 739.667722491,
    "p95_time": 0.017119191949905143,
    "rps": 64.4336011705784,
    "parallel": 1,
    "p99_time": 0.023463722170381503,
    "mean_time": 0.015418671956988874,
    "mean_precisions": 0.72843,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 739.6677053900003,
    "total_upload_time": 739.667722491,
    "p95_time": 0.7319060269500821,
    "rps": 302.5590667338187,
    "parallel": 100,
    "p99_time": 1.0591935272103365,
    "mean_time": 0.31523502210200516,
    "mean_precisions": 0.68299,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 739.6677053900003,
    "total_upload_time": 739.667722491,
    "p95_time": 0.5669408295503672,
    "rps": 312.8410019714198,
    "parallel": 100,
    "p99_time": 0.7079431993097928,
    "mean_time": 0.30074658506900503,
    "mean_precisions": 0.72843,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 739.6677053900003,
    "total_upload_time": 739.667722491,
    "p95_time": 0.6354942155998742,
    "rps": 275.48381471673446,
    "parallel": 100,
    "p99_time": 0.8428557762295803,
    "mean_time": 0.3463511030340105,
    "mean_precisions": 0.83796,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 739.6677053900003,
    "total_upload_time": 739.667722491,
    "p95_time": 1.065751175549849,
    "rps": 242.31334427116985,
    "parallel": 100,
    "p99_time": 1.4423787559694208,
    "mean_time": 0.3904036949249985,
    "mean_precisions": 0.9106400000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 739.6677053900003,
    "total_upload_time": 739.667722491,
    "p95_time": 0.020242081699370827,
    "rps": 54.83445998855009,
    "parallel": 1,
    "p99_time": 0.02385451028966599,
    "mean_time": 0.01813195053101299,
    "mean_precisions": 0.83796,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 739.6677053900003,
    "total_upload_time": 739.667722491,
    "p95_time": 0.024036166050382234,
    "rps": 47.06615655399186,
    "parallel": 1,
    "p99_time": 0.02947776120000526,
    "mean_time": 0.021138637494997965,
    "mean_precisions": 0.91064,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 556.3655720269999,
    "total_upload_time": 556.3655865159999,
    "p95_time": 0.007779649049916766,
    "rps": 174.5468938304436,
    "parallel": 1,
    "p99_time": 0.009769540108100048,
    "mean_time": 0.005655229331637384,
    "mean_precisions": 0.679485,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 556.3655720269999,
    "total_upload_time": 556.3655865159999,
    "p95_time": 0.006568646655068732,
    "rps": 174.8481187437991,
    "parallel": 1,
    "p99_time": 0.009359051045321396,
    "mean_time": 0.00564187794221798,
    "mean_precisions": 0.712433,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 556.3655720269999,
    "total_upload_time": 556.3655865159999,
    "p95_time": 0.5415047466449321,
    "rps": 800.9435757359909,
    "parallel": 100,
    "p99_time": 1.3087407008113225,
    "mean_time": 0.12310272525195615,
    "mean_precisions": 0.6792309999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 556.3655720269999,
    "total_upload_time": 556.3655865159999,
    "p95_time": 0.48686404990294235,
    "rps": 787.6600983061387,
    "parallel": 100,
    "p99_time": 1.6949882728599197,
    "mean_time": 0.12561355773173127,
    "mean_precisions": 0.7123,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 556.3655720269999,
    "total_upload_time": 556.3655865159999,
    "p95_time": 0.6287005709476943,
    "rps": 720.0008258065833,
    "parallel": 100,
    "p99_time": 1.4938149033191448,
    "mean_time": 0.13742820671157824,
    "mean_precisions": 0.7913079999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 556.3655720269999,
    "total_upload_time": 556.3655865159999,
    "p95_time": 0.5768373881473954,
    "rps": 603.3238586498919,
    "parallel": 100,
    "p99_time": 1.0835837595968048,
    "mean_time": 0.16438596991137894,
    "mean_precisions": 0.854554,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 556.3655720269999,
    "total_upload_time": 556.3655865159999,
    "p95_time": 0.007435480304411609,
    "rps": 152.60865672174515,
    "parallel": 1,
    "p99_time": 0.010557079364662061,
    "mean_time": 0.0064754163097764834,
    "mean_precisions": 0.791481,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-16-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 556.3655720269999,
    "total_upload_time": 556.3655865159999,
    "p95_time": 0.009447779663605615,
    "rps": 121.6082563335823,
    "parallel": 1,
    "p99_time": 0.012990633092704236,
    "mean_time": 0.008144564888911555,
    "mean_precisions": 0.854635,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 16
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 994.3648578700377,
    "total_upload_time": 994.3649148400291,
    "p95_time": 0.016127244755625724,
    "rps": 64.41651484994249,
    "parallel": 1,
    "p99_time": 0.01709960294130725,
    "mean_time": 0.014813666523736902,
    "mean_precisions": 0.9631799999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 994.3648578700377,
    "total_upload_time": 994.3649148400291,
    "p95_time": 0.01855106630246155,
    "rps": 58.1197434107439,
    "parallel": 1,
    "p99_time": 0.01981345670181327,
    "mean_time": 0.01645602744779317,
    "mean_precisions": 0.98188,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 994.3648578700377,
    "total_upload_time": 994.3649148400291,
    "p95_time": 0.4746456619614037,
    "rps": 358.12411676135434,
    "parallel": 100,
    "p99_time": 0.694129477957031,
    "mean_time": 0.274361309977225,
    "mean_precisions": 0.9631800000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 994.3648578700377,
    "total_upload_time": 994.3649148400291,
    "p95_time": 0.48671832077961885,
    "rps": 326.0283472703862,
    "parallel": 100,
    "p99_time": 0.654792692558258,
    "mean_time": 0.3015593706819229,
    "mean_precisions": 0.9818800000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 994.3648578700377,
    "total_upload_time": 994.3649148400291,
    "p95_time": 0.585207399688079,
    "rps": 291.82671591091776,
    "parallel": 100,
    "p99_time": 0.9851770003064309,
    "mean_time": 0.33815139169543984,
    "mean_precisions": 0.9907400000000002,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 994.3648578700377,
    "total_upload_time": 994.3649148400291,
    "p95_time": 0.6629838636785281,
    "rps": 235.47686734335878,
    "parallel": 100,
    "p99_time": 0.8232696147949907,
    "mean_time": 0.41950722479602554,
    "mean_precisions": 0.9952199999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 994.3648578700377,
    "total_upload_time": 994.3649148400291,
    "p95_time": 0.022634481184650213,
    "rps": 50.42069304052409,
    "parallel": 1,
    "p99_time": 0.02403421462629922,
    "mean_time": 0.019085715388553217,
    "mean_precisions": 0.9907400000000002,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 994.3648578700377,
    "total_upload_time": 994.3649148400291,
    "p95_time": 0.030226204186328688,
    "rps": 40.33459443584504,
    "parallel": 1,
    "p99_time": 0.03220919487823267,
    "mean_time": 0.024007467196916696,
    "mean_precisions": 0.9952199999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 5022.256726595006,
    "total_upload_time": 5022.256740265002,
    "p95_time": 0.0727481894966331,
    "rps": 25.61300719023531,
    "parallel": 1,
    "p99_time": 0.09062530099312426,
    "mean_time": 0.03888817855450616,
    "mean_precisions": 0.9019220000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 5022.256726595006,
    "total_upload_time": 5022.256740265002,
    "p95_time": 0.0476014435509569,
    "rps": 25.60346191872536,
    "parallel": 1,
    "p99_time": 0.05490256241188036,
    "mean_time": 0.03889792805506732,
    "mean_precisions": 0.9258870000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 5022.256726595006,
    "total_upload_time": 5022.256740265002,
    "p95_time": 7.207678628652502,
    "rps": 20.428664123327597,
    "parallel": 100,
    "p99_time": 8.00379792695021,
    "mean_time": 4.888012854177892,
    "mean_precisions": 0.9019220000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 5022.256726595006,
    "total_upload_time": 5022.256740265002,
    "p95_time": 4.351621749190963,
    "rps": 36.172441486587374,
    "parallel": 100,
    "p99_time": 5.1571036981187355,
    "mean_time": 2.756166138745587,
    "mean_precisions": 0.9258869999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 5022.256726595006,
    "total_upload_time": 5022.256740265002,
    "p95_time": 4.958008048299962,
    "rps": 27.712826215996394,
    "parallel": 100,
    "p99_time": 5.65677754515753,
    "mean_time": 3.6001363975869376,
    "mean_precisions": 0.9691630000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 5022.256726595006,
    "total_upload_time": 5022.256740265002,
    "p95_time": 4.996125274861697,
    "rps": 27.697301223243183,
    "parallel": 100,
    "p99_time": 5.6980997332884,
    "mean_time": 3.6016563176588097,
    "mean_precisions": 0.9885120000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 5022.256726595006,
    "total_upload_time": 5022.256740265002,
    "p95_time": 0.04929014460503822,
    "rps": 24.526228983288384,
    "parallel": 1,
    "p99_time": 0.056085780847060965,
    "mean_time": 0.04061486547902168,
    "mean_precisions": 0.9691630000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 5022.256726595006,
    "total_upload_time": 5022.256740265002,
    "p95_time": 0.051346257595287166,
    "rps": 23.89046807236223,
    "parallel": 1,
    "p99_time": 0.05878724864509422,
    "mean_time": 0.041696624087830425,
    "mean_precisions": 0.9885120000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 881.557393436,
    "total_upload_time": 881.5574071440005,
    "p95_time": 0.019986793700172707,
    "rps": 57.95636709106786,
    "parallel": 1,
    "p99_time": 0.031266084789731384,
    "mean_time": 0.017153933398005392,
    "mean_precisions": 0.75525,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 881.557393436,
    "total_upload_time": 881.5574071440005,
    "p95_time": 0.02075970545047312,
    "rps": 54.37325295560483,
    "parallel": 1,
    "p99_time": 0.032034933449431244,
    "mean_time": 0.018286960297013138,
    "mean_precisions": 0.79879,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 881.557393436,
    "total_upload_time": 881.5574071440005,
    "p95_time": 0.6562358872495678,
    "rps": 295.0730876415492,
    "parallel": 100,
    "p99_time": 0.7756810043387667,
    "mean_time": 0.32262225347099593,
    "mean_precisions": 0.75525,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 881.557393436,
    "total_upload_time": 881.5574071440005,
    "p95_time": 0.5774839830506606,
    "rps": 278.01714729818286,
    "parallel": 100,
    "p99_time": 2.740935793958833,
    "mean_time": 0.34327524790699315,
    "mean_precisions": 0.79879,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 881.557393436,
    "total_upload_time": 881.5574071440005,
    "p95_time": 0.9181657221501154,
    "rps": 249.99070653290522,
    "parallel": 100,
    "p99_time": 1.1749033815393521,
    "mean_time": 0.3817680353619908,
    "mean_precisions": 0.89149,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 881.557393436,
    "total_upload_time": 881.5574071440005,
    "p95_time": 0.8341241038508087,
    "rps": 202.5133078921865,
    "parallel": 100,
    "p99_time": 1.1195473410997692,
    "mean_time": 0.46887773686401124,
    "mean_precisions": 0.9476400000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 881.557393436,
    "total_upload_time": 881.5574071440005,
    "p95_time": 0.023423920499499217,
    "rps": 49.828695561906656,
    "parallel": 1,
    "p99_time": 0.02842067983028755,
    "mean_time": 0.019960392566006704,
    "mean_precisions": 0.89149,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 881.557393436,
    "total_upload_time": 881.5574071440005,
    "p95_time": 0.029908669398719213,
    "rps": 39.713074450877414,
    "parallel": 1,
    "p99_time": 0.03254222875988489,
    "mean_time": 0.02506771656001001,
    "mean_precisions": 0.94764,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 765.5428848360007,
    "total_upload_time": 765.5428980510005,
    "p95_time": 0.008164127440250012,
    "rps": 163.5555355484557,
    "parallel": 1,
    "p99_time": 0.010459640326444064,
    "mean_time": 0.006038516633430845,
    "mean_precisions": 0.7468040000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 765.5428848360007,
    "total_upload_time": 765.5428980510005,
    "p95_time": 0.007147414638893678,
    "rps": 161.16509226891492,
    "parallel": 1,
    "p99_time": 0.010074893095588778,
    "mean_time": 0.0061289692249149085,
    "mean_precisions": 0.7765820000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 765.5428848360007,
    "total_upload_time": 765.5428980510005,
    "p95_time": 0.4860289624004501,
    "rps": 840.8258343168707,
    "parallel": 100,
    "p99_time": 1.8394208670932866,
    "mean_time": 0.11757640678003808,
    "mean_precisions": 0.7466940000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 765.5428848360007,
    "total_upload_time": 765.5428980510005,
    "p95_time": 0.5746176213586289,
    "rps": 807.4773351468832,
    "parallel": 100,
    "p99_time": 1.5665157227148305,
    "mean_time": 0.12221946521689969,
    "mean_precisions": 0.776591,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 765.5428848360007,
    "total_upload_time": 765.5428980510005,
    "p95_time": 0.524640337643359,
    "rps": 701.7792993763564,
    "parallel": 100,
    "p99_time": 1.329954752515189,
    "mean_time": 0.141098515133014,
    "mean_precisions": 0.8488290000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 765.5428848360007,
    "total_upload_time": 765.5428980510005,
    "p95_time": 0.46400184624144447,
    "rps": 541.5155331402559,
    "parallel": 100,
    "p99_time": 1.041635735902674,
    "mean_time": 0.18323096984555595,
    "mean_precisions": 0.905198,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 765.5428848360007,
    "total_upload_time": 765.5428980510005,
    "p95_time": 0.008772029650572222,
    "rps": 133.3874979110193,
    "parallel": 1,
    "p99_time": 0.011479479760746472,
    "mean_time": 0.007415734122495633,
    "mean_precisions": 0.848875,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-128",
    "dataset_name": "glove-100-angular",
    "upload_time": 765.5428848360007,
    "total_upload_time": 765.5428980510005,
    "p95_time": 0.012467860709875822,
    "rps": 98.45246588688146,
    "parallel": 1,
    "p99_time": 0.014639544118545036,
    "mean_time": 0.01007373308785318,
    "mean_precisions": 0.905466,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 128,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1558.8598351570545,
    "total_upload_time": 1558.8598632450448,
    "p95_time": 0.0168429579003714,
    "rps": 62.27452869195641,
    "parallel": 1,
    "p99_time": 0.02010206695820674,
    "mean_time": 0.015354767360060941,
    "mean_precisions": 0.97544,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1558.8598351570545,
    "total_upload_time": 1558.8598632450448,
    "p95_time": 0.019410210123169236,
    "rps": 55.4780798308694,
    "parallel": 1,
    "p99_time": 0.02058047521102708,
    "mean_time": 0.017285823385033292,
    "mean_precisions": 0.98856,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1558.8598351570545,
    "total_upload_time": 1558.8598632450448,
    "p95_time": 0.465421090304153,
    "rps": 352.50685769034175,
    "parallel": 100,
    "p99_time": 0.7823982045607412,
    "mean_time": 0.2794463231375208,
    "mean_precisions": 0.9754400000000002,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1558.8598351570545,
    "total_upload_time": 1558.8598632450448,
    "p95_time": 0.49396754650224467,
    "rps": 316.34462746387806,
    "parallel": 100,
    "p99_time": 0.7358942784398097,
    "mean_time": 0.31133481576974736,
    "mean_precisions": 0.9885599999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1558.8598351570545,
    "total_upload_time": 1558.8598632450448,
    "p95_time": 0.571543828773429,
    "rps": 273.7983434917226,
    "parallel": 100,
    "p99_time": 0.825715062749224,
    "mean_time": 0.3604836656297906,
    "mean_precisions": 0.9947799999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1558.8598351570545,
    "total_upload_time": 1558.8598632450448,
    "p95_time": 0.7247987551614642,
    "rps": 213.86115697680174,
    "parallel": 100,
    "p99_time": 0.9012946943443974,
    "mean_time": 0.4622558355553076,
    "mean_precisions": 0.9979400000000002,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1558.8598351570545,
    "total_upload_time": 1558.8598632450448,
    "p95_time": 0.024388861897750757,
    "rps": 46.63070134096561,
    "parallel": 1,
    "p99_time": 0.02576907947601285,
    "mean_time": 0.020680391426803543,
    "mean_precisions": 0.9947800000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1558.8598351570545,
    "total_upload_time": 1558.8598632450448,
    "p95_time": 0.03364598968473729,
    "rps": 35.945436620021546,
    "parallel": 1,
    "p99_time": 0.03543745213362855,
    "mean_time": 0.027003182709158864,
    "mean_precisions": 0.9979400000000002,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8155.138606392997,
    "total_upload_time": 8155.138621056001,
    "p95_time": 0.0766208445493248,
    "rps": 23.66565023874646,
    "parallel": 1,
    "p99_time": 0.08785810974441123,
    "mean_time": 0.042106091231040775,
    "mean_precisions": 0.9200640000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8155.138606392997,
    "total_upload_time": 8155.138621056001,
    "p95_time": 0.04824622894957428,
    "rps": 26.463569506515693,
    "parallel": 1,
    "p99_time": 0.05557969578730991,
    "mean_time": 0.03763336600842449,
    "mean_precisions": 0.9423210000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8155.138606392997,
    "total_upload_time": 8155.138621056001,
    "p95_time": 6.739490905810089,
    "rps": 25.878548893297374,
    "parallel": 100,
    "p99_time": 7.654196956583765,
    "mean_time": 3.8548853042517557,
    "mean_precisions": 0.920064,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8155.138606392997,
    "total_upload_time": 8155.138621056001,
    "p95_time": 4.694987515747197,
    "rps": 34.90374676325125,
    "parallel": 100,
    "p99_time": 5.446151642423647,
    "mean_time": 2.8570713279081654,
    "mean_precisions": 0.9423210000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8155.138606392997,
    "total_upload_time": 8155.138621056001,
    "p95_time": 4.993139286882069,
    "rps": 28.096236155005137,
    "parallel": 100,
    "p99_time": 5.657810605008279,
    "mean_time": 3.550324359199742,
    "mean_precisions": 0.979034,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8155.138606392997,
    "total_upload_time": 8155.138621056001,
    "p95_time": 5.746991247213737,
    "rps": 24.087412229006453,
    "parallel": 100,
    "p99_time": 6.547868284509461,
    "mean_time": 4.14225105576044,
    "mean_precisions": 0.993333,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8155.138606392997,
    "total_upload_time": 8155.138621056001,
    "p95_time": 0.04689465484334505,
    "rps": 25.984618512243042,
    "parallel": 1,
    "p99_time": 0.053465919362788564,
    "mean_time": 0.038330463452737606,
    "mean_precisions": 0.979034,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8155.138606392997,
    "total_upload_time": 8155.138621056001,
    "p95_time": 0.051725752901984355,
    "rps": 23.619435172972498,
    "parallel": 1,
    "p99_time": 0.05956182521593293,
    "mean_time": 0.04218057967784698,
    "mean_precisions": 0.993333,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1549.2811875930001,
    "total_upload_time": 1549.281206435,
    "p95_time": 0.0190748090989473,
    "rps": 58.57154831275604,
    "parallel": 1,
    "p99_time": 0.022623327999899627,
    "mean_time": 0.016968341936993966,
    "mean_precisions": 0.80352,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1549.2811875930001,
    "total_upload_time": 1549.281206435,
    "p95_time": 0.019851437049419468,
    "rps": 56.88305099744382,
    "parallel": 1,
    "p99_time": 0.023961648700678777,
    "mean_time": 0.017472521446008613,
    "mean_precisions": 0.84418,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1549.2811875930001,
    "total_upload_time": 1549.281206435,
    "p95_time": 0.9080061996512085,
    "rps": 283.8306566983521,
    "parallel": 100,
    "p99_time": 1.3579724310098935,
    "mean_time": 0.3343424563709923,
    "mean_precisions": 0.80352,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1549.2811875930001,
    "total_upload_time": 1549.281206435,
    "p95_time": 0.7930725416001219,
    "rps": 260.87246657301,
    "parallel": 100,
    "p99_time": 1.0641467991402351,
    "mean_time": 0.3657358937150693,
    "mean_precisions": 0.84418,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1549.2811875930001,
    "total_upload_time": 1549.281206435,
    "p95_time": 0.7557019373505681,
    "rps": 230.9397173791055,
    "parallel": 100,
    "p99_time": 0.967704182400248,
    "mean_time": 0.41384739849598734,
    "mean_precisions": 0.92722,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1549.2811875930001,
    "total_upload_time": 1549.281206435,
    "p95_time": 0.9247355569492356,
    "rps": 179.98580177322918,
    "parallel": 100,
    "p99_time": 1.2317238206305956,
    "mean_time": 0.5272355056970192,
    "mean_precisions": 0.9702900000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1549.2811875930001,
    "total_upload_time": 1549.281206435,
    "p95_time": 0.024862609500632966,
    "rps": 46.965200629762776,
    "parallel": 1,
    "p99_time": 0.02767371491030644,
    "mean_time": 0.021179852760980795,
    "mean_precisions": 0.92722,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1549.2811875930001,
    "total_upload_time": 1549.281206435,
    "p95_time": 0.033245957249346245,
    "rps": 36.064609462075914,
    "parallel": 1,
    "p99_time": 0.03658154957998704,
    "mean_time": 0.027610375826983728,
    "mean_precisions": 0.97029,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 1335.7662973850001,
    "total_upload_time": 1335.7663151750003,
    "p95_time": 0.0072120463592000306,
    "rps": 161.39489080934203,
    "parallel": 1,
    "p99_time": 0.01004109077504836,
    "mean_time": 0.006119924280245323,
    "mean_precisions": 0.7656860000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 1335.7662973850001,
    "total_upload_time": 1335.7663151750003,
    "p95_time": 0.00741707067354582,
    "rps": 154.91643928114084,
    "parallel": 1,
    "p99_time": 0.010300739303638699,
    "mean_time": 0.006381553887334303,
    "mean_precisions": 0.7963180000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 1335.7662973850001,
    "total_upload_time": 1335.7663151750003,
    "p95_time": 0.5849916293474959,
    "rps": 799.6047125959175,
    "parallel": 100,
    "p99_time": 1.4445539310565807,
    "mean_time": 0.12374357671405159,
    "mean_precisions": 0.76578,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 1335.7662973850001,
    "total_upload_time": 1335.7663151750003,
    "p95_time": 0.5322547697564002,
    "rps": 762.3673144627495,
    "parallel": 100,
    "p99_time": 1.5489520327620274,
    "mean_time": 0.129778788133747,
    "mean_precisions": 0.796543,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 1335.7662973850001,
    "total_upload_time": 1335.7663151750003,
    "p95_time": 0.5222645492496658,
    "rps": 647.056595443313,
    "parallel": 100,
    "p99_time": 1.0365208149002896,
    "mean_time": 0.15317935014837566,
    "mean_precisions": 0.8697119999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 1335.7662973850001,
    "total_upload_time": 1335.7663151750003,
    "p95_time": 0.45125350679954834,
    "rps": 497.8528398600358,
    "parallel": 100,
    "p99_time": 0.7782429872461966,
    "mean_time": 0.19948714598404185,
    "mean_precisions": 0.9251729999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 1335.7662973850001,
    "total_upload_time": 1335.7663151750003,
    "p95_time": 0.009435082490381318,
    "rps": 123.8960514120047,
    "parallel": 1,
    "p99_time": 0.012062291470938367,
    "mean_time": 0.007986096309151617,
    "mean_precisions": 0.8697790000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 1335.7662973850001,
    "total_upload_time": 1335.7663151750003,
    "p95_time": 0.013502029910159762,
    "rps": 90.82893171802553,
    "parallel": 1,
    "p99_time": 0.015577996865031321,
    "mean_time": 0.010923416640024516,
    "mean_precisions": 0.9250439999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2771.5427476380137,
    "total_upload_time": 2771.5427743790206,
    "p95_time": 0.016835480454028585,
    "rps": 61.50746628876224,
    "parallel": 1,
    "p99_time": 0.01771256809181069,
    "mean_time": 0.015551943964778912,
    "mean_precisions": 0.9791,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2771.5427476380137,
    "total_upload_time": 2771.5427743790206,
    "p95_time": 0.019740751152858137,
    "rps": 53.73841339433956,
    "parallel": 1,
    "p99_time": 0.02064873149385676,
    "mean_time": 0.01786769931340823,
    "mean_precisions": 0.9916799999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2771.5427476380137,
    "total_upload_time": 2771.5427743790206,
    "p95_time": 0.530125635638251,
    "rps": 346.2407760765031,
    "parallel": 100,
    "p99_time": 0.960585241016816,
    "mean_time": 0.2836881090287701,
    "mean_precisions": 0.9791,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2771.5427476380137,
    "total_upload_time": 2771.5427743790206,
    "p95_time": 0.5190822412259878,
    "rps": 313.887445168345,
    "parallel": 100,
    "p99_time": 0.939072462049081,
    "mean_time": 0.31399696767177665,
    "mean_precisions": 0.9916799999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2771.5427476380137,
    "total_upload_time": 2771.5427743790206,
    "p95_time": 0.5836064251983771,
    "rps": 262.5808279131341,
    "parallel": 100,
    "p99_time": 0.7251913014752791,
    "mean_time": 0.37590538648853544,
    "mean_precisions": 0.9969,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2771.5427476380137,
    "total_upload_time": 2771.5427743790206,
    "p95_time": 0.7174954638350756,
    "rps": 205.42763723555115,
    "parallel": 100,
    "p99_time": 0.8953138582676199,
    "mean_time": 0.48153051286410775,
    "mean_precisions": 0.9986200000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2771.5427476380137,
    "total_upload_time": 2771.5427743790206,
    "p95_time": 0.025150982700870374,
    "rps": 44.282284943680665,
    "parallel": 1,
    "p99_time": 0.026319063659757377,
    "mean_time": 0.021797319324535783,
    "mean_precisions": 0.9969,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 2771.5427476380137,
    "total_upload_time": 2771.5427743790206,
    "p95_time": 0.03468061416060664,
    "rps": 33.99824996143273,
    "parallel": 1,
    "p99_time": 0.03649081600364298,
    "mean_time": 0.028597855708084534,
    "mean_precisions": 0.9986200000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 14841.105200933001,
    "total_upload_time": 14841.105214221985,
    "p95_time": 0.08108182080031838,
    "rps": 20.532595744881263,
    "parallel": 1,
    "p99_time": 0.0913250823339331,
    "mean_time": 0.048564703295042276,
    "mean_precisions": 0.926732,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 14841.105200933001,
    "total_upload_time": 14841.105214221985,
    "p95_time": 0.04961498228367418,
    "rps": 24.57774488758759,
    "parallel": 1,
    "p99_time": 0.05763594262214611,
    "mean_time": 0.040564238387535444,
    "mean_precisions": 0.9481719999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 14841.105200933001,
    "total_upload_time": 14841.105214221985,
    "p95_time": 5.299771125496773,
    "rps": 25.774605011875295,
    "parallel": 100,
    "p99_time": 5.95406163337495,
    "mean_time": 3.8706715475870705,
    "mean_precisions": 0.926732,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 14841.105200933001,
    "total_upload_time": 14841.105214221985,
    "p95_time": 5.345599429275898,
    "rps": 25.46417484819506,
    "parallel": 100,
    "p99_time": 6.052834190951253,
    "mean_time": 3.9182957254142265,
    "mean_precisions": 0.9481720000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 14841.105200933001,
    "total_upload_time": 14841.105214221985,
    "p95_time": 6.248729398658906,
    "rps": 23.368828895302926,
    "parallel": 100,
    "p99_time": 7.151005372402724,
    "mean_time": 4.267955043469079,
    "mean_precisions": 0.9828040000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 14841.105200933001,
    "total_upload_time": 14841.105214221985,
    "p95_time": 6.761238494208356,
    "rps": 19.234069994403274,
    "parallel": 100,
    "p99_time": 7.7444557473564055,
    "mean_time": 5.187629677497398,
    "mean_precisions": 0.9952040000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 14841.105200933001,
    "total_upload_time": 14841.105214221985,
    "p95_time": 0.05212220721296035,
    "rps": 23.20820270528188,
    "parallel": 1,
    "p99_time": 0.059419968018773944,
    "mean_time": 0.04296152876591659,
    "mean_precisions": 0.9828040000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 14841.105200933001,
    "total_upload_time": 14841.105214221985,
    "p95_time": 0.05732682085072156,
    "rps": 21.19157782020568,
    "parallel": 1,
    "p99_time": 0.06554340075905202,
    "mean_time": 0.047055455834383614,
    "mean_precisions": 0.9952040000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2707.8273376079997,
    "total_upload_time": 2707.8273556740005,
    "p95_time": 0.01960081509942029,
    "rps": 57.75803395242784,
    "parallel": 1,
    "p99_time": 0.022852822149834535,
    "mean_time": 0.01721278104905832,
    "mean_precisions": 0.8296,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2707.8273376079997,
    "total_upload_time": 2707.8273556740005,
    "p95_time": 0.020220669549689773,
    "rps": 55.55124920728748,
    "parallel": 1,
    "p99_time": 0.023443422150139667,
    "mean_time": 0.01789656243301397,
    "mean_precisions": 0.8701599999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2707.8273376079997,
    "total_upload_time": 2707.8273556740005,
    "p95_time": 0.6293252652995761,
    "rps": 282.97556235883314,
    "parallel": 100,
    "p99_time": 0.9121193386808225,
    "mean_time": 0.3322760982170257,
    "mean_precisions": 0.8296,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2707.8273376079997,
    "total_upload_time": 2707.8273556740005,
    "p95_time": 1.1516103395993014,
    "rps": 281.1213916457418,
    "parallel": 100,
    "p99_time": 1.2642168350499554,
    "mean_time": 0.337783044717964,
    "mean_precisions": 0.87016,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2707.8273376079997,
    "total_upload_time": 2707.8273556740005,
    "p95_time": 1.0112791732000002,
    "rps": 231.91814706156856,
    "parallel": 100,
    "p99_time": 1.6745272835788636,
    "mean_time": 0.4124651558530022,
    "mean_precisions": 0.94574,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2707.8273376079997,
    "total_upload_time": 2707.8273556740005,
    "p95_time": 0.859707909100507,
    "rps": 175.50627817813776,
    "parallel": 100,
    "p99_time": 1.0117214237590086,
    "mean_time": 0.5490002400220201,
    "mean_precisions": 0.9807800000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2707.8273376079997,
    "total_upload_time": 2707.8273556740005,
    "p95_time": 0.025388150949675035,
    "rps": 45.4276293590785,
    "parallel": 1,
    "p99_time": 0.02826432673926319,
    "mean_time": 0.021903270123000765,
    "mean_precisions": 0.94574,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 2707.8273376079997,
    "total_upload_time": 2707.8273556740005,
    "p95_time": 0.034743634449841916,
    "rps": 34.24426412436944,
    "parallel": 1,
    "p99_time": 0.037311901780358314,
    "mean_time": 0.02908646128794135,
    "mean_precisions": 0.98078,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 1421.4643510050082,
    "total_upload_time": 1421.464364519008,
    "p95_time": 0.009632314294867677,
    "rps": 134.96845388961995,
    "parallel": 1,
    "p99_time": 0.012518825027218556,
    "mean_time": 0.007337302466361143,
    "mean_precisions": 0.772648,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 1421.4643510050082,
    "total_upload_time": 1421.464364519008,
    "p95_time": 0.009370540253439683,
    "rps": 133.46040719738357,
    "parallel": 1,
    "p99_time": 0.011757101240509658,
    "mean_time": 0.0074210223606613,
    "mean_precisions": 0.803902,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 1421.4643510050082,
    "total_upload_time": 1421.464364519008,
    "p95_time": 0.5367853381998412,
    "rps": 799.4945627353541,
    "parallel": 100,
    "p99_time": 1.5045514758487115,
    "mean_time": 0.12373817348007869,
    "mean_precisions": 0.7726479999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 1421.4643510050082,
    "total_upload_time": 1421.464364519008,
    "p95_time": 0.5376164954483099,
    "rps": 767.8805228036817,
    "parallel": 100,
    "p99_time": 1.2788118857660449,
    "mean_time": 0.12870975729076162,
    "mean_precisions": 0.803902,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 1421.4643510050082,
    "total_upload_time": 1421.464364519008,
    "p95_time": 0.4872585675489971,
    "rps": 643.1856431661689,
    "parallel": 100,
    "p99_time": 1.0731516798914535,
    "mean_time": 0.1540871262507644,
    "mean_precisions": 0.8779309999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 1421.4643510050082,
    "total_upload_time": 1421.464364519008,
    "p95_time": 0.4970056598016526,
    "rps": 486.91198462312093,
    "parallel": 100,
    "p99_time": 1.149188031736269,
    "mean_time": 0.20385336056007655,
    "mean_precisions": 0.933041,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 1421.4643510050082,
    "total_upload_time": 1421.464364519008,
    "p95_time": 0.01181981089757755,
    "rps": 105.46211944219533,
    "parallel": 1,
    "p99_time": 0.014126645505602942,
    "mean_time": 0.009405641619217931,
    "mean_precisions": 0.8779310000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-32-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 1421.4643510050082,
    "total_upload_time": 1421.464364519008,
    "p95_time": 0.016475586245360316,
    "rps": 75.12218595073384,
    "parallel": 1,
    "p99_time": 0.01926168675476222,
    "mean_time": 0.013228492212141282,
    "mean_precisions": 0.933041,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 32
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1740.096154630999,
    "total_upload_time": 1740.0961824600236,
    "p95_time": 0.018261916437768377,
    "rps": 59.41056984377296,
    "parallel": 1,
    "p99_time": 0.022494001541053885,
    "mean_time": 0.016109269905753898,
    "mean_precisions": 0.9811,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1740.096154630999,
    "total_upload_time": 1740.0961824600236,
    "p95_time": 0.02177402099769097,
    "rps": 52.25742138471868,
    "parallel": 1,
    "p99_time": 0.022950781061081216,
    "mean_time": 0.01836932753970614,
    "mean_precisions": 0.9918,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1740.096154630999,
    "total_upload_time": 1740.0961824600236,
    "p95_time": 0.49630179703817723,
    "rps": 338.9880617794378,
    "parallel": 100,
    "p99_time": 1.1193235024449018,
    "mean_time": 0.2904277851964929,
    "mean_precisions": 0.9811,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1740.096154630999,
    "total_upload_time": 1740.0961824600236,
    "p95_time": 0.541499021454365,
    "rps": 305.46560677108863,
    "parallel": 100,
    "p99_time": 0.7856871872628134,
    "mean_time": 0.32276910134365316,
    "mean_precisions": 0.9918,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1740.096154630999,
    "total_upload_time": 1740.0961824600236,
    "p95_time": 0.6206463604146848,
    "rps": 253.21126837623535,
    "parallel": 100,
    "p99_time": 0.8364177004963863,
    "mean_time": 0.3900654865434277,
    "mean_precisions": 0.9962599999999998,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1740.096154630999,
    "total_upload_time": 1740.0961824600236,
    "p95_time": 0.7717496731405846,
    "rps": 196.13858399198242,
    "parallel": 100,
    "p99_time": 0.9096593400195709,
    "mean_time": 0.5042889157099184,
    "mean_precisions": 0.99864,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1740.096154630999,
    "total_upload_time": 1740.0961824600236,
    "p95_time": 0.02857325700460933,
    "rps": 42.89819477846872,
    "parallel": 1,
    "p99_time": 0.03012039221939632,
    "mean_time": 0.022519489342067392,
    "mean_precisions": 0.99626,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 1740.096154630999,
    "total_upload_time": 1740.0961824600236,
    "p95_time": 0.039667319046566264,
    "rps": 32.75180616382175,
    "parallel": 1,
    "p99_time": 0.042270344006828976,
    "mean_time": 0.029702995147334876,
    "mean_precisions": 0.99864,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8704.59071141691,
    "total_upload_time": 8704.590727785951,
    "p95_time": 0.061917708331020546,
    "rps": 23.549587036030264,
    "parallel": 1,
    "p99_time": 0.07207358935265804,
    "mean_time": 0.042303827749320774,
    "mean_precisions": 0.9385040000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8704.59071141691,
    "total_upload_time": 8704.590727785951,
    "p95_time": 0.04496661595185286,
    "rps": 27.43505019589237,
    "parallel": 1,
    "p99_time": 0.053034679613774664,
    "mean_time": 0.03629559228443541,
    "mean_precisions": 0.956478,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8704.59071141691,
    "total_upload_time": 8704.590727785951,
    "p95_time": 2.041012721613515,
    "rps": 70.88505930619799,
    "parallel": 100,
    "p99_time": 2.3917052063299344,
    "mean_time": 1.406430238441797,
    "mean_precisions": 0.9385040000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8704.59071141691,
    "total_upload_time": 8704.590727785951,
    "p95_time": 2.8490930959640535,
    "rps": 54.0426941839196,
    "parallel": 100,
    "p99_time": 3.3801590878306893,
    "mean_time": 1.8451743570839405,
    "mean_precisions": 0.956478,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8704.59071141691,
    "total_upload_time": 8704.590727785951,
    "p95_time": 3.233851811854401,
    "rps": 43.55342322492103,
    "parallel": 100,
    "p99_time": 3.717070886592848,
    "mean_time": 2.290053879076126,
    "mean_precisions": 0.9847600000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8704.59071141691,
    "total_upload_time": 8704.590727785951,
    "p95_time": 8.041812533378835,
    "rps": 19.80572018808973,
    "parallel": 100,
    "p99_time": 8.952998306218069,
    "mean_time": 5.038636551273335,
    "mean_precisions": 0.9952639999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8704.59071141691,
    "total_upload_time": 8704.590727785951,
    "p95_time": 0.047961498494259985,
    "rps": 25.644663505599485,
    "parallel": 1,
    "p99_time": 0.05577418090426363,
    "mean_time": 0.038837476331554356,
    "mean_precisions": 0.9847600000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 8704.59071141691,
    "total_upload_time": 8704.590727785951,
    "p95_time": 0.05395066029159352,
    "rps": 22.97128542455472,
    "parallel": 1,
    "p99_time": 0.0612034053343814,
    "mean_time": 0.04337816989633721,
    "mean_precisions": 0.9952640000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1729.5955671350002,
    "total_upload_time": 1729.5955831299998,
    "p95_time": 0.0209944600000199,
    "rps": 55.45150858754732,
    "parallel": 1,
    "p99_time": 0.027263348959095303,
    "mean_time": 0.017931621688032466,
    "mean_precisions": 0.83909,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1729.5955671350002,
    "total_upload_time": 1729.5955831299998,
    "p95_time": 0.021898949900787557,
    "rps": 53.51945626516454,
    "parallel": 1,
    "p99_time": 0.024724115090866687,
    "mean_time": 0.01857959014698099,
    "mean_precisions": 0.8757,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1729.5955671350002,
    "total_upload_time": 1729.5955831299998,
    "p95_time": 0.957111809550679,
    "rps": 273.4766347307772,
    "parallel": 100,
    "p99_time": 1.4788778437596373,
    "mean_time": 0.342882958708009,
    "mean_precisions": 0.8390899999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1729.5955671350002,
    "total_upload_time": 1729.5955831299998,
    "p95_time": 1.1097607669999887,
    "rps": 271.1101330457562,
    "parallel": 100,
    "p99_time": 1.364087735060275,
    "mean_time": 0.3505438545060206,
    "mean_precisions": 0.8757,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1729.5955671350002,
    "total_upload_time": 1729.5955831299998,
    "p95_time": 1.3503046753511623,
    "rps": 224.523583817278,
    "parallel": 100,
    "p99_time": 1.866496002400563,
    "mean_time": 0.42640840384698825,
    "mean_precisions": 0.94511,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1729.5955671350002,
    "total_upload_time": 1729.5955831299998,
    "p95_time": 0.9181490559999474,
    "rps": 168.42823112082363,
    "parallel": 100,
    "p99_time": 1.2282799346603313,
    "mean_time": 0.5729823342260097,
    "mean_precisions": 0.97879,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1729.5955671350002,
    "total_upload_time": 1729.5955831299998,
    "p95_time": 0.028186642650416614,
    "rps": 43.180962576265756,
    "parallel": 1,
    "p99_time": 0.031661689420161565,
    "mean_time": 0.02304828191197339,
    "mean_precisions": 0.9451100000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 1729.5955671350002,
    "total_upload_time": 1729.5955831299998,
    "p95_time": 0.037947855449965574,
    "rps": 33.170236924724314,
    "parallel": 1,
    "p99_time": 0.04130098243986139,
    "mean_time": 0.030032834626019394,
    "mean_precisions": 0.97879,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 999.1489786919992,
    "total_upload_time": 999.1489940519969,
    "p95_time": 0.010405285049637312,
    "rps": 123.9085376214679,
    "parallel": 1,
    "p99_time": 0.01322696756644291,
    "mean_time": 0.00799793167760945,
    "mean_precisions": 0.811333,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 999.1489786919992,
    "total_upload_time": 999.1489940519969,
    "p95_time": 0.01091727034508949,
    "rps": 116.07725079333237,
    "parallel": 1,
    "p99_time": 0.013212797740998216,
    "mean_time": 0.008540774767275433,
    "mean_precisions": 0.839675,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 999.1489786919992,
    "total_upload_time": 999.1489940519969,
    "p95_time": 0.5084315900050567,
    "rps": 761.7867700431334,
    "parallel": 100,
    "p99_time": 1.520642867662685,
    "mean_time": 0.12968026442215777,
    "mean_precisions": 0.811333,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 999.1489786919992,
    "total_upload_time": 999.1489940519969,
    "p95_time": 0.5097812663523653,
    "rps": 714.3811740826227,
    "parallel": 100,
    "p99_time": 1.385721785192146,
    "mean_time": 0.13799547185132396,
    "mean_precisions": 0.839675,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 999.1489786919992,
    "total_upload_time": 999.1489940519969,
    "p95_time": 0.45331975873850733,
    "rps": 570.491390307715,
    "parallel": 100,
    "p99_time": 0.641610021659435,
    "mean_time": 0.17384529871535195,
    "mean_precisions": 0.905943,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 999.1489786919992,
    "total_upload_time": 999.1489940519969,
    "p95_time": 0.47062022059981234,
    "rps": 409.61902758919024,
    "parallel": 100,
    "p99_time": 0.5806611652389985,
    "mean_time": 0.24223926477610075,
    "mean_precisions": 0.952471,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 999.1489786919992,
    "total_upload_time": 999.1489940519969,
    "p95_time": 0.01455624300506315,
    "rps": 88.21814999489703,
    "parallel": 1,
    "p99_time": 0.01659884078850155,
    "mean_time": 0.011257369381035096,
    "mean_precisions": 0.905943,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-256",
    "dataset_name": "glove-100-angular",
    "upload_time": 999.1489786919992,
    "total_upload_time": 999.1489940519969,
    "p95_time": 0.021475766551884587,
    "rps": 61.43045605942063,
    "parallel": 1,
    "p99_time": 0.02368345173163107,
    "mean_time": 0.016195262410960278,
    "mean_precisions": 0.9524710000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 256,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5162.220006061019,
    "total_upload_time": 5162.220024460985,
    "p95_time": 0.019036853444413283,
    "rps": 56.5777729328718,
    "parallel": 1,
    "p99_time": 0.020019949490088045,
    "mean_time": 0.01692445103416685,
    "mean_precisions": 0.9865,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5162.220006061019,
    "total_upload_time": 5162.220024460985,
    "p95_time": 0.023250818977248854,
    "rps": 48.49246140863899,
    "parallel": 1,
    "p99_time": 0.02477735658816528,
    "mean_time": 0.019823217672819738,
    "mean_precisions": 0.995,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5162.220006061019,
    "total_upload_time": 5162.220024460985,
    "p95_time": 0.502773699568934,
    "rps": 324.28128471681146,
    "parallel": 100,
    "p99_time": 0.8677392215025614,
    "mean_time": 0.30362212065731875,
    "mean_precisions": 0.9865,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5162.220006061019,
    "total_upload_time": 5162.220024460985,
    "p95_time": 0.5513018256722717,
    "rps": 285.06509454550906,
    "parallel": 100,
    "p99_time": 0.8243101931596178,
    "mean_time": 0.3460643683924456,
    "mean_precisions": 0.995,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5162.220006061019,
    "total_upload_time": 5162.220024460985,
    "p95_time": 0.6841393774986501,
    "rps": 228.2937548823379,
    "parallel": 100,
    "p99_time": 1.0578379774926017,
    "mean_time": 0.4329168316560099,
    "mean_precisions": 0.9979400000000002,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5162.220006061019,
    "total_upload_time": 5162.220024460985,
    "p95_time": 0.8885986231209245,
    "rps": 171.5805724555225,
    "parallel": 100,
    "p99_time": 1.1235727549874,
    "mean_time": 0.5767127501324052,
    "mean_precisions": 0.99936,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5162.220006061019,
    "total_upload_time": 5162.220024460985,
    "p95_time": 0.031392817120649855,
    "rps": 38.56057114858553,
    "parallel": 1,
    "p99_time": 0.033273721082950944,
    "mean_time": 0.025104229410144036,
    "mean_precisions": 0.9979400000000002,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 5162.220006061019,
    "total_upload_time": 5162.220024460985,
    "p95_time": 0.044423037231899797,
    "rps": 28.738319523319863,
    "parallel": 1,
    "p99_time": 0.047261685662088,
    "mean_time": 0.03393005233503645,
    "mean_precisions": 0.9993599999999998,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 18619.640847976087,
    "total_upload_time": 18619.64085597708,
    "p95_time": 0.021325345203513268,
    "rps": 89.14690934094527,
    "parallel": 1,
    "p99_time": 0.036590271355817106,
    "mean_time": 0.011137679444532842,
    "mean_precisions": 0.9516310000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 18619.640847976087,
    "total_upload_time": 18619.64085597708,
    "p95_time": 0.012154754181392488,
    "rps": 101.34378002865037,
    "parallel": 1,
    "p99_time": 0.01536529421922751,
    "mean_time": 0.009786549068510066,
    "mean_precisions": 0.967145,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 18619.640847976087,
    "total_upload_time": 18619.64085597708,
    "p95_time": 0.48136888878652806,
    "rps": 561.5110984562132,
    "parallel": 100,
    "p99_time": 1.3285364601947376,
    "mean_time": 0.1761950451175333,
    "mean_precisions": 0.9516310000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 18619.640847976087,
    "total_upload_time": 18619.64085597708,
    "p95_time": 0.47991044418304224,
    "rps": 581.9255338478639,
    "parallel": 100,
    "p99_time": 0.7124839262035677,
    "mean_time": 0.16982518977955915,
    "mean_precisions": 0.967145,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 18619.640847976087,
    "total_upload_time": 18619.64085597708,
    "p95_time": 0.4820694484689738,
    "rps": 479.41336332198057,
    "parallel": 100,
    "p99_time": 0.6485609923780435,
    "mean_time": 0.20672493139384315,
    "mean_precisions": 0.990145,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 18619.640847976087,
    "total_upload_time": 18619.64085597708,
    "p95_time": 0.6181396572792436,
    "rps": 347.5575779236824,
    "parallel": 100,
    "p99_time": 0.7870022110745781,
    "mean_time": 0.2855607651470578,
    "mean_precisions": 0.9974629999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 18619.640847976087,
    "total_upload_time": 18619.64085597708,
    "p95_time": 0.016402634629048406,
    "rps": 78.09982402565737,
    "parallel": 1,
    "p99_time": 0.01978409736882896,
    "mean_time": 0.012723508987517562,
    "mean_precisions": 0.990145,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 18619.640847976087,
    "total_upload_time": 18619.64085597708,
    "p95_time": 0.023993802379118273,
    "rps": 56.64980974688641,
    "parallel": 1,
    "p99_time": 0.02651176935178229,
    "mean_time": 0.017562987592082937,
    "mean_precisions": 0.9974630000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 4297.052305635998,
    "total_upload_time": 4297.052317862997,
    "p95_time": 0.021912331701059884,
    "rps": 53.46529923353254,
    "parallel": 1,
    "p99_time": 0.02580642769047699,
    "mean_time": 0.018598540308994417,
    "mean_precisions": 0.87649,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 4297.052305635998,
    "total_upload_time": 4297.052317862997,
    "p95_time": 0.023025527100071483,
    "rps": 51.19236744703102,
    "parallel": 1,
    "p99_time": 0.0261189386081969,
    "mean_time": 0.019425366597948596,
    "mean_precisions": 0.9073499999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 4297.052305635998,
    "total_upload_time": 4297.052317862997,
    "p95_time": 0.8310682516499582,
    "rps": 277.5758489809165,
    "parallel": 100,
    "p99_time": 1.1387113560514261,
    "mean_time": 0.34237474061403916,
    "mean_precisions": 0.87649,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 4297.052305635998,
    "total_upload_time": 4297.052317862997,
    "p95_time": 0.6529163342000174,
    "rps": 265.31131370344093,
    "parallel": 100,
    "p99_time": 0.8021321737498144,
    "mean_time": 0.3596832333319544,
    "mean_precisions": 0.9073499999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 4297.052305635998,
    "total_upload_time": 4297.052317862997,
    "p95_time": 1.0855714960514882,
    "rps": 217.98833515985217,
    "parallel": 100,
    "p99_time": 1.7236228212702551,
    "mean_time": 0.43818065468000716,
    "mean_precisions": 0.96487,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 4297.052305635998,
    "total_upload_time": 4297.052317862997,
    "p95_time": 0.9340353785000838,
    "rps": 157.3041272036864,
    "parallel": 100,
    "p99_time": 1.1558141190106106,
    "mean_time": 0.6131564987010097,
    "mean_precisions": 0.98826,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 4297.052305635998,
    "total_upload_time": 4297.052317862997,
    "p95_time": 0.02993975160188711,
    "rps": 40.72381640273594,
    "parallel": 1,
    "p99_time": 0.03525936406946129,
    "mean_time": 0.024440927106010348,
    "mean_precisions": 0.9648700000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 4297.052305635998,
    "total_upload_time": 4297.052317862997,
    "p95_time": 0.04084926105024351,
    "rps": 30.639818784548066,
    "parallel": 1,
    "p99_time": 0.044664956992601215,
    "mean_time": 0.03251303227891913,
    "mean_precisions": 0.98826,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 2264.6131451020046,
    "total_upload_time": 2264.6131602820096,
    "p95_time": 0.010639625447947764,
    "rps": 118.97895655098486,
    "parallel": 1,
    "p99_time": 0.012862064416549421,
    "mean_time": 0.008332077103835763,
    "mean_precisions": 0.8297599999999998,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 2264.6131451020046,
    "total_upload_time": 2264.6131602820096,
    "p95_time": 0.011492794506193603,
    "rps": 109.69608993847133,
    "parallel": 1,
    "p99_time": 0.013693084846163413,
    "mean_time": 0.009042470944476372,
    "mean_precisions": 0.8588050000000002,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 2264.6131451020046,
    "total_upload_time": 2264.6131602820096,
    "p95_time": 0.535365632151661,
    "rps": 727.1351434670827,
    "parallel": 100,
    "p99_time": 1.198309447404027,
    "mean_time": 0.13582328219446935,
    "mean_precisions": 0.82976,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 2264.6131451020046,
    "total_upload_time": 2264.6131602820096,
    "p95_time": 0.4989529016529554,
    "rps": 692.7953025263276,
    "parallel": 100,
    "p99_time": 0.8789769689187249,
    "mean_time": 0.14284967350124644,
    "mean_precisions": 0.8588049999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 2264.6131451020046,
    "total_upload_time": 2264.6131602820096,
    "p95_time": 0.43852247280665313,
    "rps": 535.3260116355016,
    "parallel": 100,
    "p99_time": 0.684233708592366,
    "mean_time": 0.18498322348502116,
    "mean_precisions": 0.9250029999999999,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 2264.6131451020046,
    "total_upload_time": 2264.6131602820096,
    "p95_time": 0.5002305480942595,
    "rps": 372.105960788005,
    "parallel": 100,
    "p99_time": 0.9408152778606746,
    "mean_time": 0.26658168856194825,
    "mean_precisions": 0.9674630000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 2264.6131451020046,
    "total_upload_time": 2264.6131602820096,
    "p95_time": 0.015471919803530907,
    "rps": 81.82611918382425,
    "parallel": 1,
    "p99_time": 0.017576566939824262,
    "mean_time": 0.012138554801678402,
    "mean_precisions": 0.925003,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "weaviate",
    "setup_name": "weaviate-m-64-ef-512",
    "dataset_name": "glove-100-angular",
    "upload_time": 2264.6131451020046,
    "total_upload_time": 2264.6131602820096,
    "p95_time": 0.02266294505316182,
    "rps": 57.32407646446201,
    "parallel": 1,
    "p99_time": 0.02483990800814354,
    "mean_time": 0.017358162075582367,
    "mean_precisions": 0.9674630000000001,
    "engine_params": {
      "vectorIndexConfig": {
        "efConstruction": 512,
        "maxConnections": 64
      }
    }
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.004480395436286927,
    "mean_precisions": 0.0006799999999999999,
    "std_time": 0.0007471424883573968,
    "min_time": 0.0028298422694206238,
    "max_time": 0.008031703531742096,
    "rps": 218.13500817742212,
    "p95_time": 0.005871691554784775,
    "p99_time": 0.006504287272691726
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 768
    },
    "mean_time": 0.021851983334124088,
    "mean_precisions": 0.9997,
    "std_time": 0.004086419786240401,
    "min_time": 0.010089434683322906,
    "max_time": 0.057309575378894806,
    "rps": 44.01651078885993,
    "p95_time": 0.028376154601573944,
    "p99_time": 0.03166193790733815
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512
    },
    "mean_time": 0.01712130515873432,
    "mean_precisions": 0.9994799999999999,
    "std_time": 0.003382782002901269,
    "min_time": 0.0076367855072021484,
    "max_time": 0.048894912004470825,
    "rps": 55.54454339833684,
    "p95_time": 0.022374054417014122,
    "p99_time": 0.026004442200064676
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.0070186911672353745,
    "mean_precisions": 8e-05,
    "std_time": 0.007144956494168896,
    "min_time": 0.002001248300075531,
    "max_time": 0.06799298524856567,
    "rps": 1947.9942619843225,
    "p95_time": 0.022297485917806614,
    "p99_time": 0.03386905126273631
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.004225439012050629,
    "mean_precisions": 0.0006799999999999999,
    "std_time": 0.0007411067541842095,
    "min_time": 0.002792663872241974,
    "max_time": 0.012756898999214172,
    "rps": 231.4746352813251,
    "p95_time": 0.0051484316587448115,
    "p99_time": 0.0059150058776140215
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 512
    },
    "mean_time": 0.12044585274383425,
    "mean_precisions": 0.993318,
    "std_time": 0.0489614019867233,
    "min_time": 0.008892528712749481,
    "max_time": 0.6145511120557785,
    "rps": 819.9899565231119,
    "p95_time": 0.19911026358604428,
    "p99_time": 0.36609325334429815
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 16
    },
    "mean_time": 0.008170963626354933,
    "mean_precisions": 0.9198219999999999,
    "std_time": 0.0018804236332124558,
    "min_time": 0.002757929265499115,
    "max_time": 0.022626623511314392,
    "rps": 120.83669248504333,
    "p95_time": 0.011402865499258041,
    "p99_time": 0.012871528565883637
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.11362008100003004,
    "mean_precisions": 0.9987400000000002,
    "std_time": 0.027587271720347376,
    "min_time": 0.007395073771476746,
    "max_time": 0.1515020951628685,
    "rps": 790.9555908869177,
    "p95_time": 0.13292907774448395,
    "p99_time": 0.1374668061733246
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64
    },
    "mean_time": 0.0051748522527515885,
    "mean_precisions": 0.97131,
    "std_time": 0.0022654364560294625,
    "min_time": 0.0030117034912109375,
    "max_time": 0.2122090607881546,
    "rps": 190.10396705303054,
    "p95_time": 0.006477253511548041,
    "p99_time": 0.007453557997941974
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.0049079121872782705,
    "mean_precisions": 8e-05,
    "std_time": 0.00329673847153811,
    "min_time": 0.0019280090928077698,
    "max_time": 0.026616983115673065,
    "rps": 1801.2838155761212,
    "p95_time": 0.01242399290204048,
    "p99_time": 0.016677141711115836
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 32
    },
    "mean_time": 0.0046842283889651296,
    "mean_precisions": 0.97682,
    "std_time": 0.0008396865413826708,
    "min_time": 0.002921290695667267,
    "max_time": 0.030231647193431854,
    "rps": 184.7602745322827,
    "p95_time": 0.005832406878471375,
    "p99_time": 0.006826613247394565
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.1755619554489851,
    "mean_precisions": 0.585015,
    "std_time": 0.015810547341286507,
    "min_time": 0.034929320216178894,
    "max_time": 0.21787714213132858,
    "rps": 560.3412815218113,
    "p95_time": 0.19637399949133394,
    "p99_time": 0.20414033196866513
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.009410444191098212,
    "mean_precisions": 0.99924,
    "std_time": 0.0017050653842100327,
    "min_time": 0.005053229629993439,
    "max_time": 0.03189630061388016,
    "rps": 97.83801442010721,
    "p95_time": 0.01191256046295166,
    "p99_time": 0.013702717646956445
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.021964891469478606,
    "mean_precisions": 0.98772,
    "std_time": 0.017935190797226795,
    "min_time": 0.0034108608961105347,
    "max_time": 0.09353230893611908,
    "rps": 1137.2904807838013,
    "p95_time": 0.056370240449905414,
    "p99_time": 0.07218575663864614
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.5074246859319508,
    "mean_precisions": 0.800803,
    "std_time": 0.03875883154716944,
    "min_time": 0.05635330080986023,
    "max_time": 0.6518196985125542,
    "rps": 195.52261049301006,
    "p95_time": 0.5607513211667537,
    "p99_time": 0.5873798964172602
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.004574519865214824,
    "mean_precisions": 9e-05,
    "std_time": 0.0027818866749282733,
    "min_time": 0.0018946677446365356,
    "max_time": 0.023361369967460632,
    "rps": 1670.6635685054298,
    "p95_time": 0.010496727377176275,
    "p99_time": 0.014376171156764025
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.1164011278912425,
    "mean_precisions": 0.99892,
    "std_time": 0.02216592237286677,
    "min_time": 0.007892809808254242,
    "max_time": 0.1616494357585907,
    "rps": 782.8844812986952,
    "p95_time": 0.13245736844837666,
    "p99_time": 0.1490292969346047
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.017296725119650365,
    "mean_precisions": 0.860558,
    "std_time": 0.003691490539330818,
    "min_time": 0.006467841565608978,
    "max_time": 0.04082011431455612,
    "rps": 57.38362367654503,
    "p95_time": 0.023386659100651738,
    "p99_time": 0.02651019886136055
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 256
    },
    "mean_time": 0.012167324225604534,
    "mean_precisions": 0.979058,
    "std_time": 0.0029095905265114504,
    "min_time": 0.004269875586032867,
    "max_time": 0.024769768118858337,
    "rps": 81.41225383523243,
    "p95_time": 0.017183453962206836,
    "p99_time": 0.01939737290143967
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.853048293967545,
    "mean_precisions": 0.7701140000000001,
    "std_time": 0.05718962428464591,
    "min_time": 0.07986327260732651,
    "max_time": 1.0095321759581566,
    "rps": 116.13072250528465,
    "p95_time": 0.9105214104056358,
    "p99_time": 0.9464087969064713
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.47670613202303647,
    "mean_precisions": 0.8006280000000001,
    "std_time": 0.039679037442282704,
    "min_time": 0.04421664774417877,
    "max_time": 0.6235795617103577,
    "rps": 207.89703034913853,
    "p95_time": 0.5412707973271609,
    "p99_time": 0.5831051029264928
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.5460062876001001,
    "mean_precisions": 0.800803,
    "std_time": 0.049113737689121334,
    "min_time": 0.04557245224714279,
    "max_time": 0.6789117604494095,
    "rps": 181.62772002862917,
    "p95_time": 0.6136487800627947,
    "p99_time": 0.6366404112428427
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 256
    },
    "mean_time": 0.10114564417898655,
    "mean_precisions": 0.9950399999999998,
    "std_time": 0.03514314062092781,
    "min_time": 0.007459118962287903,
    "max_time": 0.2930614799261093,
    "rps": 845.4959659288512,
    "p95_time": 0.15693290829658513,
    "p99_time": 0.20107008256018172
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.2679203824415803,
    "mean_precisions": 0.574874,
    "std_time": 0.020751191980924573,
    "min_time": 0.050374798476696014,
    "max_time": 0.3407926559448242,
    "rps": 368.2157354649308,
    "p95_time": 0.29987659491598606,
    "p99_time": 0.31378423146903517
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.004758812442421913,
    "mean_precisions": 8e-05,
    "std_time": 0.003776241461147686,
    "min_time": 0.0019223839044570923,
    "max_time": 0.045304663479328156,
    "rps": 1671.54592731128,
    "p95_time": 0.01195533126592636,
    "p99_time": 0.019247085154056546
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512
    },
    "mean_time": 0.014986786849796771,
    "mean_precisions": 0.99679,
    "std_time": 0.0030389922445426924,
    "min_time": 0.005178391933441162,
    "max_time": 0.03299751877784729,
    "rps": 66.00175595770938,
    "p95_time": 0.019474531710147857,
    "p99_time": 0.021834911108016965
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.005434188939630985,
    "mean_precisions": 8e-05,
    "std_time": 0.003993619714792581,
    "min_time": 0.002162635326385498,
    "max_time": 0.04079630970954895,
    "rps": 1622.6519763762922,
    "p95_time": 0.013037363067269315,
    "p99_time": 0.022156840264797195
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "glove-100-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 256
    },
    "mean_time": 0.09358612768873573,
    "mean_precisions": 0.8698310000000001,
    "std_time": 0.028852604092754815,
    "min_time": 0.010928496718406677,
    "max_time": 0.34451595693826675,
    "rps": 1052.6589944957818,
    "p95_time": 0.14875358268618583,
    "p99_time": 0.1952276539802552
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64
    },
    "mean_time": 0.005135823415219784,
    "mean_precisions": 0.8730450000000001,
    "std_time": 0.0008877593129042332,
    "min_time": 0.0028060749173164368,
    "max_time": 0.017971858382225037,
    "rps": 191.7020587753479,
    "p95_time": 0.00644184872508049,
    "p99_time": 0.007510941922664644
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.2632609289251268,
    "mean_precisions": 0.575156,
    "std_time": 0.020740111952216356,
    "min_time": 0.03670384734869003,
    "max_time": 0.3656586706638336,
    "rps": 375.0008026038711,
    "p95_time": 0.29163695126771927,
    "p99_time": 0.30190135799348355
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.006611773237586022,
    "mean_precisions": 9e-05,
    "std_time": 0.006114313445123139,
    "min_time": 0.002032652497291565,
    "max_time": 0.033789873123168945,
    "rps": 1639.6480299470131,
    "p95_time": 0.021333723515272126,
    "p99_time": 0.02815360806882381
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.00454532082080841,
    "mean_precisions": 0.9890399999999999,
    "std_time": 0.0012529366510198236,
    "min_time": 0.002489611506462097,
    "max_time": 0.0384315550327301,
    "rps": 189.08960137948495,
    "p95_time": 0.005553491413593292,
    "p99_time": 0.007259057536721236
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.006933108574151993,
    "mean_precisions": 0.9982,
    "std_time": 0.0015463819823722375,
    "min_time": 0.003581896424293518,
    "max_time": 0.041521355509757996,
    "rps": 128.76312600495243,
    "p95_time": 0.00857260785996914,
    "p99_time": 0.0100516390055418
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 64
    },
    "mean_time": 0.008259143303334713,
    "mean_precisions": 0.9198219999999999,
    "std_time": 0.0019491720893601043,
    "min_time": 0.0031573325395584106,
    "max_time": 0.022735245525836945,
    "rps": 119.67807498089859,
    "p95_time": 0.011663890257477758,
    "p99_time": 0.013254693672060967
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.005149661108851433,
    "mean_precisions": 9e-05,
    "std_time": 0.003178714512369109,
    "min_time": 0.002091728150844574,
    "max_time": 0.024204879999160767,
    "rps": 1670.8849445028866,
    "p95_time": 0.011713034659624099,
    "p99_time": 0.017300296276807785
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.005067771278321743,
    "mean_precisions": 9e-05,
    "std_time": 0.004124990641479919,
    "min_time": 0.001987062394618988,
    "max_time": 0.04409327358007431,
    "rps": 1587.1836452466487,
    "p95_time": 0.012437714636325831,
    "p99_time": 0.024803455770015713
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 16
    },
    "mean_time": 0.0045859677515923975,
    "mean_precisions": 0.7922319999999999,
    "std_time": 0.0009439610443978415,
    "min_time": 0.0026021674275398254,
    "max_time": 0.03390693664550781,
    "rps": 214.34135453966627,
    "p95_time": 0.005819830298423766,
    "p99_time": 0.0070179919898510044
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.2902714566901326,
    "mean_precisions": 0.700085,
    "std_time": 0.025958479695843046,
    "min_time": 0.04011803865432739,
    "max_time": 0.37135427445173264,
    "rps": 340.6193439382281,
    "p95_time": 0.3277714543044567,
    "p99_time": 0.3487044981122017
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.005634973630309105,
    "mean_precisions": 9e-05,
    "std_time": 0.005541930951706501,
    "min_time": 0.0018603727221488953,
    "max_time": 0.047046028077602386,
    "rps": 1692.2740995851198,
    "p95_time": 0.01670420691370964,
    "p99_time": 0.03171819888055324
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 128
    },
    "mean_time": 0.06941885279864073,
    "mean_precisions": 0.8446600000000001,
    "std_time": 0.04927634654632184,
    "min_time": 0.005823351442813873,
    "max_time": 0.39418869465589523,
    "rps": 1123.9460670935646,
    "p95_time": 0.12657947279512882,
    "p99_time": 0.33673172011971475
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 32
    },
    "mean_time": 0.00474732895642519,
    "mean_precisions": 0.9777399999999999,
    "std_time": 0.0008574372906526379,
    "min_time": 0.002860322594642639,
    "max_time": 0.026513226330280304,
    "rps": 183.13231077869742,
    "p95_time": 0.005787048488855363,
    "p99_time": 0.006781518980860716
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.010711087027192116,
    "mean_precisions": 0.99718,
    "std_time": 0.009079808123909055,
    "min_time": 0.0036059916019439697,
    "max_time": 0.15485339611768723,
    "rps": 1069.140934222432,
    "p95_time": 0.01906779333949089,
    "p99_time": 0.026657006815075886
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.020340103467553855,
    "mean_precisions": 0.778193,
    "std_time": 0.002884412971550445,
    "min_time": 0.011412113904953003,
    "max_time": 0.04633055627346039,
    "rps": 48.830382573963405,
    "p95_time": 0.025275003537535666,
    "p99_time": 0.028577734455466273
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.02838339397609234,
    "mean_precisions": 0.99718,
    "std_time": 0.027460809694387377,
    "min_time": 0.00363004207611084,
    "max_time": 0.09652172029018402,
    "rps": 1141.9769084820873,
    "p95_time": 0.08479352109134197,
    "p99_time": 0.08797647066414356
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.03363277817517519,
    "mean_precisions": 0.99572,
    "std_time": 0.023564427955137076,
    "min_time": 0.003646068274974823,
    "max_time": 0.09690900146961212,
    "rps": 1165.1363820169179,
    "p95_time": 0.07473676912486554,
    "p99_time": 0.08109940432012082
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.01328623605519533,
    "mean_precisions": 0.6480640000000001,
    "std_time": 0.0020313123152176757,
    "min_time": 0.00682387501001358,
    "max_time": 0.0347030907869339,
    "rps": 74.64018452540904,
    "p95_time": 0.016647061705589293,
    "p99_time": 0.018887044638395318
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 256
    },
    "mean_time": 0.09089380787238478,
    "mean_precisions": 0.979058,
    "std_time": 0.02560582580888292,
    "min_time": 0.00426289439201355,
    "max_time": 0.2677493542432785,
    "rps": 1079.1599606879702,
    "p95_time": 0.13309605568647384,
    "p99_time": 0.17366395786404623
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.0823083954691887,
    "mean_precisions": 0.382329,
    "std_time": 0.0114151017129187,
    "min_time": 0.013192504644393921,
    "max_time": 0.14356877654790878,
    "rps": 1175.8627669613845,
    "p95_time": 0.10862661153078075,
    "p99_time": 0.11807072289288045
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "glove-100-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 32
    },
    "mean_time": 0.00821009050309658,
    "mean_precisions": 0.7658360000000001,
    "std_time": 0.002183859051249749,
    "min_time": 0.0033687353134155273,
    "max_time": 0.10583571344614029,
    "rps": 120.35865990596189,
    "p95_time": 0.011579040065407751,
    "p99_time": 0.013165342137217522
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.48845221636369823,
    "mean_precisions": 0.675084,
    "std_time": 0.03287540144631313,
    "min_time": 0.06525521725416183,
    "max_time": 0.6448201984167099,
    "rps": 202.97905942141267,
    "p95_time": 0.5285895258188248,
    "p99_time": 0.5683109697699548
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 256
    },
    "mean_time": 0.11113178087770939,
    "mean_precisions": 0.9269700000000001,
    "std_time": 0.03734035992491416,
    "min_time": 0.012949727475643158,
    "max_time": 0.29745445400476456,
    "rps": 791.5095056522531,
    "p95_time": 0.18460987135767937,
    "p99_time": 0.22139518268406388
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 16
    },
    "mean_time": 0.06713248923793436,
    "mean_precisions": 0.9198219999999999,
    "std_time": 0.06100574057446163,
    "min_time": 0.012259259819984436,
    "max_time": 0.6770351454615593,
    "rps": 1457.5488936629486,
    "p95_time": 0.17774363793432704,
    "p99_time": 0.36878149330616006
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 16
    },
    "mean_time": 0.004044967678189277,
    "mean_precisions": 0.8802199999999999,
    "std_time": 0.0018524518622187272,
    "min_time": 0.001532129943370819,
    "max_time": 0.028074733912944794,
    "rps": 1100.7122685160127,
    "p95_time": 0.006651218980550767,
    "p99_time": 0.010999107658863083
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256
    },
    "mean_time": 0.00864504151493311,
    "mean_precisions": 0.9737630000000002,
    "std_time": 0.0015479613791830602,
    "min_time": 0.004370972514152527,
    "max_time": 0.02451770007610321,
    "rps": 114.43425677710935,
    "p95_time": 0.010970422253012656,
    "p99_time": 0.012267853617668155
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "glove-100-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 512
    },
    "mean_time": 0.019037304791808127,
    "mean_precisions": 0.9252779999999999,
    "std_time": 0.004902638451016146,
    "min_time": 0.006212800741195679,
    "max_time": 0.07620350271463394,
    "rps": 52.190495451650676,
    "p95_time": 0.02698462456464767,
    "p99_time": 0.03045054934918881
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.00531208997964859,
    "mean_precisions": 9e-05,
    "std_time": 0.0036236402962780225,
    "min_time": 0.0020565763115882874,
    "max_time": 0.029841452836990356,
    "rps": 1648.4757445446712,
    "p95_time": 0.013326237350702276,
    "p99_time": 0.02007056914269923
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 768
    },
    "mean_time": 0.013496877720952033,
    "mean_precisions": 0.9967280000000001,
    "std_time": 0.002618629055872071,
    "min_time": 0.005434013903141022,
    "max_time": 0.03433552384376526,
    "rps": 73.494584550326,
    "p95_time": 0.01764165349304676,
    "p99_time": 0.019815212041139608
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.006103335848450661,
    "mean_precisions": 0.99234,
    "std_time": 0.0021959207413563882,
    "min_time": 0.002691112458705902,
    "max_time": 0.02869129180908203,
    "rps": 1116.3537726868685,
    "p95_time": 0.00956333689391613,
    "p99_time": 0.014266762062907284
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.005182716824114322,
    "mean_precisions": 9e-05,
    "std_time": 0.003678593991469798,
    "min_time": 0.0020270273089408875,
    "max_time": 0.035925254225730896,
    "rps": 1685.371226122546,
    "p95_time": 0.01243561916053295,
    "p99_time": 0.01839186191558837
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 512
    },
    "mean_time": 0.18436653186380864,
    "mean_precisions": 0.97004,
    "std_time": 0.09244894212254864,
    "min_time": 0.016842953860759735,
    "max_time": 0.5720648840069771,
    "rps": 496.1772705559017,
    "p95_time": 0.3403670031577349,
    "p99_time": 0.45458246834576094
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 768
    },
    "mean_time": 0.0276640338152647,
    "mean_precisions": 0.98312,
    "std_time": 0.005999316293869946,
    "min_time": 0.010062336921691895,
    "max_time": 0.04740024358034134,
    "rps": 35.882276073231914,
    "p95_time": 0.0368166159838438,
    "p99_time": 0.04275936380028724
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.019156839127838613,
    "mean_precisions": 0.9971200000000001,
    "std_time": 0.015426811885369672,
    "min_time": 0.0038836821913719177,
    "max_time": 0.08378414064645767,
    "rps": 1129.7634075111182,
    "p95_time": 0.057878265902400014,
    "p99_time": 0.06253200463950635
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.005480401501059532,
    "mean_precisions": 8e-05,
    "std_time": 0.004072967004317715,
    "min_time": 0.0018131956458091736,
    "max_time": 0.03072243183851242,
    "rps": 1696.3661054096415,
    "p95_time": 0.014548555389046666,
    "p99_time": 0.020996697321534155
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.08275347576290369,
    "mean_precisions": 0.46571399999999996,
    "std_time": 0.008252722795874648,
    "min_time": 0.02010750025510788,
    "max_time": 0.12983636558055878,
    "rps": 1173.9521251857823,
    "p95_time": 0.09397073052823543,
    "p99_time": 0.10175525791943074
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.0051876833736896515,
    "mean_precisions": 9e-05,
    "std_time": 0.00397274331994948,
    "min_time": 0.0020389780402183533,
    "max_time": 0.033887483179569244,
    "rps": 1609.1298841925993,
    "p95_time": 0.013650632649660106,
    "p99_time": 0.02058875821530819
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 128
    },
    "mean_time": 0.00836098615527153,
    "mean_precisions": 0.9966,
    "std_time": 0.0018692530377446928,
    "min_time": 0.004217423498630524,
    "max_time": 0.053902216255664825,
    "rps": 109.00818610481299,
    "p95_time": 0.010962647572159768,
    "p99_time": 0.012636370956897739
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.27215547954440117,
    "mean_precisions": 0.574874,
    "std_time": 0.02312206323345665,
    "min_time": 0.04417804628610611,
    "max_time": 0.36544299125671387,
    "rps": 363.17884942796974,
    "p95_time": 0.311222080886364,
    "p99_time": 0.3303933408111334
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.0055763581946492195,
    "mean_precisions": 0.9624,
    "std_time": 0.002989796520985414,
    "min_time": 0.002436615526676178,
    "max_time": 0.04626266658306122,
    "rps": 1123.9888631201347,
    "p95_time": 0.008537739887833599,
    "p99_time": 0.019852399900555623
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.0132932209007442,
    "mean_precisions": 0.6480640000000001,
    "std_time": 0.0020290292403550014,
    "min_time": 0.006725974380970001,
    "max_time": 0.032481685280799866,
    "rps": 74.59195712990388,
    "p95_time": 0.016651586815714835,
    "p99_time": 0.0188314575701952
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 32
    },
    "mean_time": 0.0044147233456373215,
    "mean_precisions": 0.9431400000000002,
    "std_time": 0.0009898749248587345,
    "min_time": 0.0019534677267074585,
    "max_time": 0.0133805051445961,
    "rps": 194.2630763013858,
    "p95_time": 0.006032183021306993,
    "p99_time": 0.007073785737156871
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 128
    },
    "mean_time": 0.009130402356386185,
    "mean_precisions": 0.989,
    "std_time": 0.0022586832064867054,
    "min_time": 0.003227613866329193,
    "max_time": 0.02195288985967636,
    "rps": 100.39456964961002,
    "p95_time": 0.012877415865659715,
    "p99_time": 0.01462867058813572
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.013032188943773507,
    "mean_precisions": 0.775163,
    "std_time": 0.00273524171093857,
    "min_time": 0.005170084536075592,
    "max_time": 0.03600727766752243,
    "rps": 76.04922265807807,
    "p95_time": 0.017516903579235077,
    "p99_time": 0.020051660612225533
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 64
    },
    "mean_time": 0.009410772368311882,
    "mean_precisions": 0.8044300000000001,
    "std_time": 0.002026194511104359,
    "min_time": 0.00431331992149353,
    "max_time": 0.017516590654850006,
    "rps": 104.83230347377035,
    "p95_time": 0.012856646254658698,
    "p99_time": 0.014495530426502225
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.00418408115208149,
    "mean_precisions": 0.0006799999999999999,
    "std_time": 0.0007176321729043796,
    "min_time": 0.002791665494441986,
    "max_time": 0.009310580790042877,
    "rps": 233.70024748181675,
    "p95_time": 0.005457364395260811,
    "p99_time": 0.0064207898080348965
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.25804078494757415,
    "mean_precisions": 0.699823,
    "std_time": 0.020319614322367174,
    "min_time": 0.03811376541852951,
    "max_time": 0.3407420217990875,
    "rps": 382.9372762380688,
    "p95_time": 0.2886566411703825,
    "p99_time": 0.30252980284392833
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "glove-100-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 64
    },
    "mean_time": 0.052294338762015107,
    "mean_precisions": 0.7658360000000001,
    "std_time": 0.021668723077828585,
    "min_time": 0.003829583525657654,
    "max_time": 0.32492808997631073,
    "rps": 1864.6678078565697,
    "p95_time": 0.08113358132541176,
    "p99_time": 0.13493999212980276
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.11897453841865063,
    "mean_precisions": 0.9987400000000002,
    "std_time": 0.015395458056400892,
    "min_time": 0.0269545316696167,
    "max_time": 0.14852504432201385,
    "rps": 791.7929492201076,
    "p95_time": 0.13335011936724186,
    "p99_time": 0.13915172636508943
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.08284467781558633,
    "mean_precisions": 0.382329,
    "std_time": 0.009846038375534097,
    "min_time": 0.008952639997005463,
    "max_time": 0.28830046206712723,
    "rps": 1167.7882594730575,
    "p95_time": 0.0952776327729225,
    "p99_time": 0.10071468442678452
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 16
    },
    "mean_time": 0.004518511051684618,
    "mean_precisions": 0.9272819999999999,
    "std_time": 0.0011865850065372616,
    "min_time": 0.0024643167853355408,
    "max_time": 0.05132419615983963,
    "rps": 217.34853153849767,
    "p95_time": 0.005868760123848914,
    "p99_time": 0.008639913052320501
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512
    },
    "mean_time": 0.010543542736023665,
    "mean_precisions": 0.9993800000000002,
    "std_time": 0.002260603105151694,
    "min_time": 0.004332996904850006,
    "max_time": 0.03264457732439041,
    "rps": 93.86128411888771,
    "p95_time": 0.014140275865793228,
    "p99_time": 0.016009612902998925
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.0058811936378479,
    "mean_precisions": 8e-05,
    "std_time": 0.004811254382751389,
    "min_time": 0.0019491985440254211,
    "max_time": 0.04472001641988754,
    "rps": 1639.343523044043,
    "p95_time": 0.016163682192564005,
    "p99_time": 0.024818373024463648
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.005167141444981098,
    "mean_precisions": 9e-05,
    "std_time": 0.0033946116191229756,
    "min_time": 0.0020462647080421448,
    "max_time": 0.027448691427707672,
    "rps": 1615.6855750902762,
    "p95_time": 0.01170117557048797,
    "p99_time": 0.017945892289280892
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.14579809173196553,
    "mean_precisions": 0.47611499999999995,
    "std_time": 0.013418955274492963,
    "min_time": 0.026780448853969574,
    "max_time": 0.19145651161670685,
    "rps": 673.3010490064946,
    "p95_time": 0.16499021425843238,
    "p99_time": 0.17646769158542158
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.0797286086447537,
    "mean_precisions": 0.38232900000000003,
    "std_time": 0.009267874294394747,
    "min_time": 0.015353947877883911,
    "max_time": 0.1360236331820488,
    "rps": 1215.0087357366087,
    "p95_time": 0.09520776383578776,
    "p99_time": 0.10210632376372814
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.08185450702309609,
    "mean_precisions": 0.382329,
    "std_time": 0.006439416734721765,
    "min_time": 0.05620992183685303,
    "max_time": 0.2863415703177452,
    "rps": 1191.681796311066,
    "p95_time": 0.0919233925640583,
    "p99_time": 0.10644311793148518
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.004639150573313236,
    "mean_precisions": 0.97934,
    "std_time": 0.0014750559044434763,
    "min_time": 0.002212837338447571,
    "max_time": 0.019260555505752563,
    "rps": 1056.3087062335,
    "p95_time": 0.006963747739791871,
    "p99_time": 0.01116618186235429
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.14396463498175144,
    "mean_precisions": 0.47626100000000005,
    "std_time": 0.011034788156363709,
    "min_time": 0.03482852876186371,
    "max_time": 0.21196433901786804,
    "rps": 682.1615566501862,
    "p95_time": 0.16076595820486544,
    "p99_time": 0.16783683873713018
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 768
    },
    "mean_time": 0.021957681599259378,
    "mean_precisions": 0.99976,
    "std_time": 0.004117142752975997,
    "min_time": 0.010274730622768402,
    "max_time": 0.05920068919658661,
    "rps": 43.80316703067958,
    "p95_time": 0.028669653087854387,
    "p99_time": 0.03184819601476194
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.08863206726834177,
    "mean_precisions": 0.46571399999999996,
    "std_time": 0.011352736970906161,
    "min_time": 0.01868608593940735,
    "max_time": 0.12530285120010376,
    "rps": 1094.1297769932241,
    "p95_time": 0.10660504177212715,
    "p99_time": 0.11432673543691636
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 16
    },
    "mean_time": 0.006609776347875595,
    "mean_precisions": 0.8377899999999999,
    "std_time": 0.002226711322526494,
    "min_time": 0.0031746327877044678,
    "max_time": 0.031277626752853394,
    "rps": 148.8144812215309,
    "p95_time": 0.01028965301811695,
    "p99_time": 0.015007822439074515
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.02588987010344863,
    "mean_precisions": 0.922583,
    "std_time": 0.005555396778103814,
    "min_time": 0.009517975151538849,
    "max_time": 0.051363252103328705,
    "rps": 38.391717109394946,
    "p95_time": 0.035161966085433954,
    "p99_time": 0.03974257223308087
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64
    },
    "mean_time": 0.0050302794709801675,
    "mean_precisions": 0.971484,
    "std_time": 0.0008182378589391043,
    "min_time": 0.003021128475666046,
    "max_time": 0.018547460436820984,
    "rps": 195.55342207398778,
    "p95_time": 0.006274597346782683,
    "p99_time": 0.007292689159512521
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 768
    },
    "mean_time": 0.013829180309921503,
    "mean_precisions": 0.9967310000000001,
    "std_time": 0.0026805192560716857,
    "min_time": 0.005735799670219421,
    "max_time": 0.02792704850435257,
    "rps": 71.73924709570557,
    "p95_time": 0.018179908767342566,
    "p99_time": 0.020500449910759926
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256
    },
    "mean_time": 0.007953377413004637,
    "mean_precisions": 0.9976459999999999,
    "std_time": 0.0015822702469932134,
    "min_time": 0.003426983952522278,
    "max_time": 0.035408034920692444,
    "rps": 124.32095747634204,
    "p95_time": 0.010245782881975174,
    "p99_time": 0.011696541309356689
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.8767276901245117,
    "mean_precisions": 0.7702620000000001,
    "std_time": 0.06485236545415507,
    "min_time": 0.09374664723873138,
    "max_time": 1.2610862404108047,
    "rps": 113.2647200353959,
    "p95_time": 0.9543021269142627,
    "p99_time": 1.1171463115513331
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.00898917248994112,
    "mean_precisions": 0.9979399999999999,
    "std_time": 0.0017468549309391848,
    "min_time": 0.004814609885215759,
    "max_time": 0.03980100899934769,
    "rps": 102.71996310837704,
    "p95_time": 0.011312469840049744,
    "p99_time": 0.013096007630228999
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.0060482060506939885,
    "mean_precisions": 0.9923400000000001,
    "std_time": 0.002004301533502888,
    "min_time": 0.002781316637992859,
    "max_time": 0.023740090429782867,
    "rps": 1112.6067791699993,
    "p95_time": 0.009618715196847916,
    "p99_time": 0.013640605434775372
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.49483704556152225,
    "mean_precisions": 0.674938,
    "std_time": 0.0399342261857773,
    "min_time": 0.05157226324081421,
    "max_time": 0.6243183389306068,
    "rps": 200.38880454710323,
    "p95_time": 0.558285016939044,
    "p99_time": 0.5856009068340063
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 128
    },
    "mean_time": 0.00928612656891346,
    "mean_precisions": 0.97277,
    "std_time": 0.0016879826132372017,
    "min_time": 0.005619116127490997,
    "max_time": 0.025061942636966705,
    "rps": 106.40775507582245,
    "p95_time": 0.011572286486625671,
    "p99_time": 0.013104434311389922
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64
    },
    "mean_time": 0.00643671223372221,
    "mean_precisions": 0.9915199999999998,
    "std_time": 0.0013204814856160813,
    "min_time": 0.0037748441100120544,
    "max_time": 0.03439582884311676,
    "rps": 138.15573293775566,
    "p95_time": 0.008016689494252206,
    "p99_time": 0.009374096766114236
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.0041914753541350365,
    "mean_precisions": 0.0006799999999999999,
    "std_time": 0.0006468048413203435,
    "min_time": 0.00280848890542984,
    "max_time": 0.01028316468000412,
    "rps": 233.6984240899341,
    "p95_time": 0.005147303268313408,
    "p99_time": 0.006000803038477897
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.11954507678598165,
    "mean_precisions": 0.99892,
    "std_time": 0.019401867660166654,
    "min_time": 0.022144019603729248,
    "max_time": 0.17504312843084335,
    "rps": 784.1102077128145,
    "p95_time": 0.13420185148715974,
    "p99_time": 0.16201713599264625
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 768
    },
    "mean_time": 0.02209391864016652,
    "mean_precisions": 0.9967550000000001,
    "std_time": 0.005662662442482976,
    "min_time": 0.005996450781822205,
    "max_time": 0.08697360754013062,
    "rps": 44.9607891086212,
    "p95_time": 0.03148018568754195,
    "p99_time": 0.03576496168971063
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "glove-100-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 768
    },
    "mean_time": 0.21223943948671223,
    "mean_precisions": 0.9500130000000001,
    "std_time": 0.08374095473796643,
    "min_time": 0.016874656081199646,
    "max_time": 0.7934052720665932,
    "rps": 466.6839574921938,
    "p95_time": 0.3446578614413738,
    "p99_time": 0.4588169217854741
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.8630887733116746,
    "mean_precisions": 0.7701140000000001,
    "std_time": 0.06318754504244138,
    "min_time": 0.08169237524271011,
    "max_time": 1.0600669533014297,
    "rps": 115.0272825799148,
    "p95_time": 0.9366376776248216,
    "p99_time": 1.0041539272665978
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.0048354616090655325,
    "mean_precisions": 0.97906,
    "std_time": 0.0015837360251559204,
    "min_time": 0.002253510057926178,
    "max_time": 0.025031857192516327,
    "rps": 1103.1313324689695,
    "p95_time": 0.007108142599463464,
    "p99_time": 0.011773183047771456
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.004394248004257679,
    "mean_precisions": 0.9489,
    "std_time": 0.00504517326478688,
    "min_time": 0.0021518170833587646,
    "max_time": 0.09052097797393799,
    "rps": 1181.8644616864597,
    "p95_time": 0.005769677087664607,
    "p99_time": 0.02879833050072199
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.08133651536181569,
    "mean_precisions": 0.38240100000000005,
    "std_time": 0.009354992791734759,
    "min_time": 0.01148930937051773,
    "max_time": 0.11875279247760773,
    "rps": 1187.868949484276,
    "p95_time": 0.0952006459236145,
    "p99_time": 0.1042533641308546
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.14610270093232394,
    "mean_precisions": 0.47611500000000007,
    "std_time": 0.012670177197340569,
    "min_time": 0.03166281431913376,
    "max_time": 0.35595817118883133,
    "rps": 672.2964232134888,
    "p95_time": 0.16346458494663238,
    "p99_time": 0.17640183538198473
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.004193591713905334,
    "mean_precisions": 0.0006799999999999999,
    "std_time": 0.0006970069897095863,
    "min_time": 0.0027261152863502502,
    "max_time": 0.014743730425834656,
    "rps": 233.11707014034744,
    "p95_time": 0.005147913098335265,
    "p99_time": 0.005702376291155815
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512
    },
    "mean_time": 0.011834433336555959,
    "mean_precisions": 0.9921840000000001,
    "std_time": 0.0021933557758171286,
    "min_time": 0.005248650908470154,
    "max_time": 0.03214675188064575,
    "rps": 83.66325567193533,
    "p95_time": 0.015319421514868734,
    "p99_time": 0.017064734399318694
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.14747562072053552,
    "mean_precisions": 0.47626100000000005,
    "std_time": 0.012085494497534321,
    "min_time": 0.046229615807533264,
    "max_time": 0.20423389226198196,
    "rps": 667.6091532234625,
    "p95_time": 0.16721679903566836,
    "p99_time": 0.18011770509183408
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256
    },
    "mean_time": 0.01124361040443182,
    "mean_precisions": 0.99073,
    "std_time": 0.002022374706383929,
    "min_time": 0.005039677023887634,
    "max_time": 0.02461620420217514,
    "rps": 87.84687234288494,
    "p95_time": 0.014436277374625205,
    "p99_time": 0.016005442291498185
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "glove-100-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 64
    },
    "mean_time": 0.00825531240478158,
    "mean_precisions": 0.7658360000000001,
    "std_time": 0.0020722150950446905,
    "min_time": 0.0036999359726905823,
    "max_time": 0.04338357597589493,
    "rps": 119.75333262804963,
    "p95_time": 0.011613027751445766,
    "p99_time": 0.013283054456114772
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.15039408722147346,
    "mean_precisions": 0.47611500000000007,
    "std_time": 0.014735366328834926,
    "min_time": 0.025110460817813873,
    "max_time": 0.2003793939948082,
    "rps": 652.4858669798396,
    "p95_time": 0.17065009623765945,
    "p99_time": 0.1775751915574074
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.00561834579706192,
    "mean_precisions": 8e-05,
    "std_time": 0.003835825118277978,
    "min_time": 0.0019531026482582092,
    "max_time": 0.032217711210250854,
    "rps": 1631.477671308815,
    "p95_time": 0.01373648978769779,
    "p99_time": 0.017750973403453826
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.005876109339296818,
    "mean_precisions": 9e-05,
    "std_time": 0.004505672169878505,
    "min_time": 0.001965433359146118,
    "max_time": 0.03536033630371094,
    "rps": 1636.0855341272777,
    "p95_time": 0.015251212939620017,
    "p99_time": 0.02321546263992786
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512
    },
    "mean_time": 0.011482530934363603,
    "mean_precisions": 0.9921409999999999,
    "std_time": 0.0021832581381966056,
    "min_time": 0.005143851041793823,
    "max_time": 0.026467666029930115,
    "rps": 86.28597761399217,
    "p95_time": 0.01508365124464035,
    "p99_time": 0.016827151626348496
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.1475901778101921,
    "mean_precisions": 0.5845319999999999,
    "std_time": 0.015836841664357938,
    "min_time": 0.02694307267665863,
    "max_time": 0.1954842209815979,
    "rps": 667.006024191083,
    "p95_time": 0.17428273409605027,
    "p99_time": 0.18348919913172723
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.025894605918228626,
    "mean_precisions": 0.922583,
    "std_time": 0.005563398450852188,
    "min_time": 0.00938301533460617,
    "max_time": 0.05467740446329117,
    "rps": 38.38459461265354,
    "p95_time": 0.03491643741726874,
    "p99_time": 0.03906170353293419
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.003974520608782769,
    "mean_precisions": 0.0006799999999999999,
    "std_time": 0.0007995315785437397,
    "min_time": 0.0027517080307006836,
    "max_time": 0.014642402529716492,
    "rps": 246.39050659922395,
    "p95_time": 0.004828160256147384,
    "p99_time": 0.006336254477500914
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.005369873932003975,
    "mean_precisions": 0.9838800000000001,
    "std_time": 0.002161177025797862,
    "min_time": 0.0024543479084968567,
    "max_time": 0.030314788222312927,
    "rps": 1107.9937543558751,
    "p95_time": 0.008037870749831203,
    "p99_time": 0.015717912539839757
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.005608465167880058,
    "mean_precisions": 0.9840399999999999,
    "std_time": 0.0030320172261757887,
    "min_time": 0.002437397837638855,
    "max_time": 0.048318177461624146,
    "rps": 1131.500814685104,
    "p95_time": 0.008964461460709575,
    "p99_time": 0.0188388253748417
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.010583064980059863,
    "mean_precisions": 0.583499,
    "std_time": 0.0016140375460699493,
    "min_time": 0.005897641181945801,
    "max_time": 0.04496775567531586,
    "rps": 93.58429140626525,
    "p95_time": 0.013118025660514827,
    "p99_time": 0.014886438101530076
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "glove-100-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 32
    },
    "mean_time": 0.052352747324854135,
    "mean_precisions": 0.7658360000000001,
    "std_time": 0.019114292735199385,
    "min_time": 0.004508912563323975,
    "max_time": 0.21372316032648087,
    "rps": 1850.4260702275851,
    "p95_time": 0.08257660940289495,
    "p99_time": 0.1323186120390893
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 32
    },
    "mean_time": 0.00831065788641572,
    "mean_precisions": 0.9198219999999999,
    "std_time": 0.00201268533411733,
    "min_time": 0.00361555814743042,
    "max_time": 0.021388284862041473,
    "rps": 118.86299059119918,
    "p95_time": 0.011761964857578277,
    "p99_time": 0.014014512524008755
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.9102649196505547,
    "mean_precisions": 0.880691,
    "std_time": 0.07583565390306354,
    "min_time": 0.07683310657739639,
    "max_time": 1.1063499227166176,
    "rps": 109.07065340824516,
    "p95_time": 1.0135263454169035,
    "p99_time": 1.0475460637360812
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 512
    },
    "mean_time": 0.02112676339894533,
    "mean_precisions": 0.9979,
    "std_time": 0.005559625106355057,
    "min_time": 0.00631500780582428,
    "max_time": 0.04307936131954193,
    "rps": 45.53095624229522,
    "p95_time": 0.030294620618224143,
    "p99_time": 0.03514691054821015
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.0043341156765818595,
    "mean_precisions": 0.0006799999999999999,
    "std_time": 0.0007097179398909297,
    "min_time": 0.0029222965240478516,
    "max_time": 0.01147548109292984,
    "rps": 225.5491909081508,
    "p95_time": 0.005410863831639289,
    "p99_time": 0.0061653469502925854
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 32
    },
    "mean_time": 0.00932059720903635,
    "mean_precisions": 0.8044300000000001,
    "std_time": 0.002133271852181936,
    "min_time": 0.003880046308040619,
    "max_time": 0.01668192446231842,
    "rps": 105.86413627547532,
    "p95_time": 0.012965454161167145,
    "p99_time": 0.014761053025722504
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.004744307160377503,
    "mean_precisions": 9e-05,
    "std_time": 0.0032835244333606086,
    "min_time": 0.0017455965280532837,
    "max_time": 0.03437275439500809,
    "rps": 1606.6722630212266,
    "p95_time": 0.011088008433580399,
    "p99_time": 0.01838865488767624
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.46562612374797463,
    "mean_precisions": 0.8006280000000001,
    "std_time": 0.0328318654903727,
    "min_time": 0.058709971606731415,
    "max_time": 0.5579517185688019,
    "rps": 212.6904843146519,
    "p95_time": 0.5072245858609676,
    "p99_time": 0.5268952485919
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 768
    },
    "mean_time": 0.02828742053359747,
    "mean_precisions": 0.9986,
    "std_time": 0.007324281147677148,
    "min_time": 0.008637912571430206,
    "max_time": 0.057104215025901794,
    "rps": 34.147712296031585,
    "p95_time": 0.04053969979286194,
    "p99_time": 0.04637528479099276
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 128
    },
    "mean_time": 0.006376950710266828,
    "mean_precisions": 0.991144,
    "std_time": 0.0012401752891974763,
    "min_time": 0.0035218745470046997,
    "max_time": 0.03800571709871292,
    "rps": 154.69129487324207,
    "p95_time": 0.008014655113220213,
    "p99_time": 0.009356105625629428
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 768
    },
    "mean_time": 0.012238733936846257,
    "mean_precisions": 0.999699,
    "std_time": 0.0027751721547460205,
    "min_time": 0.004982225596904755,
    "max_time": 0.03577856719493866,
    "rps": 80.97120896656703,
    "p95_time": 0.016807027533650393,
    "p99_time": 0.01901933282613755
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.014393267568945885,
    "mean_precisions": 0.808264,
    "std_time": 0.0031346395812028058,
    "min_time": 0.005565531551837921,
    "max_time": 0.034908413887023926,
    "rps": 68.9252660200716,
    "p95_time": 0.019696376472711562,
    "p99_time": 0.02279053919017315
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256
    },
    "mean_time": 0.011337457309663295,
    "mean_precisions": 0.9985200000000001,
    "std_time": 0.002285309948199433,
    "min_time": 0.0055599212646484375,
    "max_time": 0.03444669395685196,
    "rps": 82.56202490134328,
    "p95_time": 0.014724574238061906,
    "p99_time": 0.01684671416878701
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.005678920827805996,
    "mean_precisions": 9e-05,
    "std_time": 0.006415203797570789,
    "min_time": 0.002137981355190277,
    "max_time": 0.05833226442337036,
    "rps": 1715.1366192952787,
    "p95_time": 0.01457633152604102,
    "p99_time": 0.03406606003642082
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.9177081179007888,
    "mean_precisions": 0.880691,
    "std_time": 0.07181157801475313,
    "min_time": 0.0821673721075058,
    "max_time": 1.107127234339714,
    "rps": 108.10427735885439,
    "p95_time": 1.0119951091706754,
    "p99_time": 1.0464050007611514
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 256
    },
    "mean_time": 0.01395265162140131,
    "mean_precisions": 0.9950399999999999,
    "std_time": 0.003658285862373585,
    "min_time": 0.004631794989109039,
    "max_time": 0.03188150376081467,
    "rps": 67.72599737508926,
    "p95_time": 0.02029160410165787,
    "p99_time": 0.023039246201515196
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.016287016883492468,
    "mean_precisions": 0.9657599999999998,
    "std_time": 0.014863611360874657,
    "min_time": 0.003002963960170746,
    "max_time": 0.08965841680765152,
    "rps": 1130.5655823093448,
    "p95_time": 0.05678956210613252,
    "p99_time": 0.07180664092302323
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.005121964268386364,
    "mean_precisions": 8e-05,
    "std_time": 0.003593341303582499,
    "min_time": 0.0020707249641418457,
    "max_time": 0.03279842436313629,
    "rps": 1746.9580457708673,
    "p95_time": 0.011792212724685667,
    "p99_time": 0.020675695687532417
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.4860768850825727,
    "mean_precisions": 0.675084,
    "std_time": 0.038728044866326465,
    "min_time": 0.04302596300840378,
    "max_time": 0.631571389734745,
    "rps": 203.97198581387752,
    "p95_time": 0.5438009474426507,
    "p99_time": 0.5822865796089173
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.855126423586905,
    "mean_precisions": 0.7701140000000001,
    "std_time": 0.06909391289761613,
    "min_time": 0.08836773782968521,
    "max_time": 1.2738312631845474,
    "rps": 116.1003936873388,
    "p95_time": 0.9280795019119977,
    "p99_time": 1.1507376290857794
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.2717128619082272,
    "mean_precisions": 0.575156,
    "std_time": 0.025183097649953273,
    "min_time": 0.04127616435289383,
    "max_time": 0.3518640920519829,
    "rps": 363.7940361121224,
    "p95_time": 0.3161789532750845,
    "p99_time": 0.33140917010605336
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.008572451348602772,
    "mean_precisions": 0.98682,
    "std_time": 0.006976484213534459,
    "min_time": 0.002959340810775757,
    "max_time": 0.07708755135536194,
    "rps": 1137.9187520328921,
    "p95_time": 0.018019832670688646,
    "p99_time": 0.04381339527666577
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "glove-100-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 128
    },
    "mean_time": 0.009294566784054041,
    "mean_precisions": 0.796424,
    "std_time": 0.0022095870597412877,
    "min_time": 0.0038054361939430237,
    "max_time": 0.03588467836380005,
    "rps": 106.42092794610356,
    "p95_time": 0.013020506501197814,
    "p99_time": 0.014826916232705118
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.004603237740695477,
    "mean_precisions": 8e-05,
    "std_time": 0.0033825670340169103,
    "min_time": 0.0020564720034599304,
    "max_time": 0.027715526521205902,
    "rps": 1619.3352724905883,
    "p95_time": 0.011212018877267825,
    "p99_time": 0.01941172651946544
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.08888254074156285,
    "mean_precisions": 0.4655990000000001,
    "std_time": 0.010348191904651156,
    "min_time": 0.009288199245929718,
    "max_time": 0.12753497064113617,
    "rps": 1089.8062614099651,
    "p95_time": 0.10226132273674012,
    "p99_time": 0.10867541439831258
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.007746537692844868,
    "mean_precisions": 0.9986799999999999,
    "std_time": 0.0011251333027309414,
    "min_time": 0.004146963357925415,
    "max_time": 0.016727827489376068,
    "rps": 117.64391825819988,
    "p95_time": 0.009591607749462128,
    "p99_time": 0.010561688691377646
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.10260434207171201,
    "mean_precisions": 0.4655990000000001,
    "std_time": 0.010739737400784384,
    "min_time": 0.013873808085918427,
    "max_time": 0.14046847820281982,
    "rps": 952.6049712044332,
    "p95_time": 0.11771538145840169,
    "p99_time": 0.12335620194673538
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 128
    },
    "mean_time": 0.017770936235785486,
    "mean_precisions": 0.989,
    "std_time": 0.024386160190596674,
    "min_time": 0.0023769810795783997,
    "max_time": 0.1538664624094963,
    "rps": 1057.697062184308,
    "p95_time": 0.07616823613643647,
    "p99_time": 0.11316791817545903
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "glove-100-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 16
    },
    "mean_time": 0.008086206033080816,
    "mean_precisions": 0.7658360000000001,
    "std_time": 0.0018927529363891383,
    "min_time": 0.003509603440761566,
    "max_time": 0.026706606149673462,
    "rps": 122.05208223850029,
    "p95_time": 0.011376974731683729,
    "p99_time": 0.013008719459176069
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64
    },
    "mean_time": 0.00685955087095499,
    "mean_precisions": 0.9256700000000001,
    "std_time": 0.0013320458996282892,
    "min_time": 0.004227183759212494,
    "max_time": 0.028004474937915802,
    "rps": 143.58356091450884,
    "p95_time": 0.008373359963297843,
    "p99_time": 0.009326113983988759
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 128
    },
    "mean_time": 0.006833284655213356,
    "mean_precisions": 0.9353400000000002,
    "std_time": 0.0010901899094407517,
    "min_time": 0.003717266023159027,
    "max_time": 0.022035889327526093,
    "rps": 144.51713274522538,
    "p95_time": 0.008392894640564919,
    "p99_time": 0.009548971503973009
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.012952756579965353,
    "mean_precisions": 0.775163,
    "std_time": 0.002694018467038704,
    "min_time": 0.0052212998270988464,
    "max_time": 0.03473607450723648,
    "rps": 76.52995483028903,
    "p95_time": 0.017431089654564854,
    "p99_time": 0.019633287712931633
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 32
    },
    "mean_time": 0.04574725053459406,
    "mean_precisions": 0.9198219999999999,
    "std_time": 0.013616615826593926,
    "min_time": 0.004739880561828613,
    "max_time": 0.15079057216644287,
    "rps": 2087.6034356225573,
    "p95_time": 0.0669560708105564,
    "p99_time": 0.08757663868367674
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 16
    },
    "mean_time": 0.006878264464437961,
    "mean_precisions": 0.8386300000000001,
    "std_time": 0.002209317754928668,
    "min_time": 0.0037223100662231445,
    "max_time": 0.037408068776130676,
    "rps": 142.89341997282713,
    "p95_time": 0.01092555224895477,
    "p99_time": 0.01456243015825748
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 16
    },
    "mean_time": 0.004070880529284477,
    "mean_precisions": 0.9442200000000001,
    "std_time": 0.0012679294353433593,
    "min_time": 0.0022203996777534485,
    "max_time": 0.032746635377407074,
    "rps": 210.35274498773677,
    "p95_time": 0.00564023368060589,
    "p99_time": 0.009085506796836859
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 64
    },
    "mean_time": 0.004994372883439064,
    "mean_precisions": 0.9753799999999999,
    "std_time": 0.0017617227696735715,
    "min_time": 0.001891009509563446,
    "max_time": 0.02341213822364807,
    "rps": 1142.1335853238206,
    "p95_time": 0.007160965353250505,
    "p99_time": 0.011339130848646328
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.4862937736712396,
    "mean_precisions": 0.675084,
    "std_time": 0.04030921029037395,
    "min_time": 0.05512373149394989,
    "max_time": 0.6504380851984024,
    "rps": 203.74956766754505,
    "p95_time": 0.5519488383084535,
    "p99_time": 0.5857069635391235
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.4591725120507181,
    "mean_precisions": 0.8006280000000001,
    "std_time": 0.030851147069523417,
    "min_time": 0.05626166611909866,
    "max_time": 0.5728506222367287,
    "rps": 215.8557361203557,
    "p95_time": 0.4967249449342489,
    "p99_time": 0.5239843038469553
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 16
    },
    "mean_time": 0.004581387761235237,
    "mean_precisions": 0.9275540000000001,
    "std_time": 0.0013197255760851248,
    "min_time": 0.0026193931698799133,
    "max_time": 0.05453946441411972,
    "rps": 214.37303832362278,
    "p95_time": 0.005957573652267454,
    "p99_time": 0.00923775985836984
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 768
    },
    "mean_time": 0.018199578560888767,
    "mean_precisions": 0.99835,
    "std_time": 0.0037874570727057287,
    "min_time": 0.006962403655052185,
    "max_time": 0.03828006982803345,
    "rps": 54.34619478535142,
    "p95_time": 0.023710034787654877,
    "p99_time": 0.0282889711111784
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.8776796663284302,
    "mean_precisions": 0.8801260000000001,
    "std_time": 0.07330883287097138,
    "min_time": 0.08405039459466934,
    "max_time": 1.1883305758237839,
    "rps": 112.98484247796652,
    "p95_time": 0.992485174536705,
    "p99_time": 1.0761686543375253
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.08307977120578289,
    "mean_precisions": 0.465714,
    "std_time": 0.009291067996425446,
    "min_time": 0.009366527199745178,
    "max_time": 0.11977894604206085,
    "rps": 1164.094492223166,
    "p95_time": 0.09355887100100517,
    "p99_time": 0.09935690112411977
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "glove-100-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 768
    },
    "mean_time": 0.02492550444304943,
    "mean_precisions": 0.9500130000000001,
    "std_time": 0.006332713502505834,
    "min_time": 0.008456170558929443,
    "max_time": 0.0862748920917511,
    "rps": 39.886077991084136,
    "p95_time": 0.035383519157767294,
    "p99_time": 0.039462078139185904
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.005111335963010788,
    "mean_precisions": 8e-05,
    "std_time": 0.00355637765620761,
    "min_time": 0.0018052756786346436,
    "max_time": 0.034000128507614136,
    "rps": 1653.6973871804323,
    "p95_time": 0.012262447923421859,
    "p99_time": 0.01918734736740589
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 128
    },
    "mean_time": 0.008338055604696274,
    "mean_precisions": 0.99666,
    "std_time": 0.0015631285415551005,
    "min_time": 0.004221081733703613,
    "max_time": 0.027626216411590576,
    "rps": 110.22352264405126,
    "p95_time": 0.01067420393228531,
    "p99_time": 0.012340990453958518
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.0041981363669037815,
    "mean_precisions": 0.0006799999999999999,
    "std_time": 0.0006687451531226012,
    "min_time": 0.002563267946243286,
    "max_time": 0.009312406182289124,
    "rps": 232.77704205243774,
    "p95_time": 0.0053653806447982785,
    "p99_time": 0.00629528373479843
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.263488911986351,
    "mean_precisions": 0.575156,
    "std_time": 0.020686292023497765,
    "min_time": 0.03703615069389343,
    "max_time": 0.3402317985892296,
    "rps": 374.4571899779619,
    "p95_time": 0.29045416936278345,
    "p99_time": 0.30693335548043255
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.26310264821872115,
    "mean_precisions": 0.699823,
    "std_time": 0.020226996960124793,
    "min_time": 0.034597985446453094,
    "max_time": 0.3462546467781067,
    "rps": 375.3613037808015,
    "p95_time": 0.2912648182362318,
    "p99_time": 0.30691205531358723
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.006519340811669826,
    "mean_precisions": 0.9926599999999999,
    "std_time": 0.003529555662999997,
    "min_time": 0.0026969462633132935,
    "max_time": 0.05281611531972885,
    "rps": 1062.8235280240442,
    "p95_time": 0.010377271473407746,
    "p99_time": 0.023730679452419298
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.15410564297661186,
    "mean_precisions": 0.585015,
    "std_time": 0.014891871809709356,
    "min_time": 0.02497774362564087,
    "max_time": 0.21580731868743896,
    "rps": 637.870927480613,
    "p95_time": 0.1793315928429365,
    "p99_time": 0.1948155677318573
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.14505406075268984,
    "mean_precisions": 0.5845319999999999,
    "std_time": 0.011331815914039242,
    "min_time": 0.03594783693552017,
    "max_time": 0.18733800947666168,
    "rps": 677.4991874465592,
    "p95_time": 0.1634619753807783,
    "p99_time": 0.17189648561179638
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.00533303490281105,
    "mean_precisions": 8e-05,
    "std_time": 0.004560820009238237,
    "min_time": 0.0019250214099884033,
    "max_time": 0.04170024394989014,
    "rps": 1649.6667080954455,
    "p95_time": 0.014005829766392707,
    "p99_time": 0.02483648233115673
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.004992138363420964,
    "mean_precisions": 8e-05,
    "std_time": 0.0037749341642514455,
    "min_time": 0.0019496753811836243,
    "max_time": 0.039254896342754364,
    "rps": 1638.4920851752947,
    "p95_time": 0.012587087601423262,
    "p99_time": 0.01973336778581142
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.854337043761462,
    "mean_precisions": 0.770262,
    "std_time": 0.05701011764290672,
    "min_time": 0.08613546937704086,
    "max_time": 1.0543848723173141,
    "rps": 116.2248009755077,
    "p95_time": 0.9187783684581516,
    "p99_time": 0.9795864995568991
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.25607537368386984,
    "mean_precisions": 0.699823,
    "std_time": 0.019779599035777477,
    "min_time": 0.039520591497421265,
    "max_time": 0.32575536519289017,
    "rps": 385.477619456295,
    "p95_time": 0.2828246638178825,
    "p99_time": 0.2936143407970667
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.017220107494294642,
    "mean_precisions": 0.860558,
    "std_time": 0.003756186582164162,
    "min_time": 0.006504185497760773,
    "max_time": 0.03656014800071716,
    "rps": 57.62976611693013,
    "p95_time": 0.02355230115354061,
    "p99_time": 0.026961802765727044
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.010810184398293496,
    "mean_precisions": 0.709689,
    "std_time": 0.0025494645347955798,
    "min_time": 0.004242122173309326,
    "max_time": 0.13240764290094376,
    "rps": 91.67131970293484,
    "p95_time": 0.014288897439837455,
    "p99_time": 0.016676717624068263
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 32
    },
    "mean_time": 0.004489036376029253,
    "mean_precisions": 0.9344119999999999,
    "std_time": 0.0008822952854450046,
    "min_time": 0.002441219985485077,
    "max_time": 0.03339041769504547,
    "rps": 218.74947369341706,
    "p95_time": 0.0054991643875837316,
    "p99_time": 0.0063954370468854915
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.2694340584166348,
    "mean_precisions": 0.699823,
    "std_time": 0.024232279221921504,
    "min_time": 0.033963270485401154,
    "max_time": 0.35798922181129456,
    "rps": 366.5145423609492,
    "p95_time": 0.3059218816459179,
    "p99_time": 0.31980268195271494
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.1479948347710073,
    "mean_precisions": 0.5845319999999999,
    "std_time": 0.013451789833533005,
    "min_time": 0.023272909224033356,
    "max_time": 0.1973297894001007,
    "rps": 663.3632912136593,
    "p95_time": 0.1653856486082077,
    "p99_time": 0.17338408388197424
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.004980968795716762,
    "mean_precisions": 8e-05,
    "std_time": 0.0037528027334405413,
    "min_time": 0.0019507035613059998,
    "max_time": 0.035063646733760834,
    "rps": 1637.684872274768,
    "p95_time": 0.01303853169083595,
    "p99_time": 0.020612817630171774
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.015159072750806808,
    "mean_precisions": 0.9971200000000001,
    "std_time": 0.011768400474311581,
    "min_time": 0.0037652775645256042,
    "max_time": 0.1450950801372528,
    "rps": 1078.7017585449337,
    "p95_time": 0.03644898720085621,
    "p99_time": 0.044451807513833076
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.005646650809049606,
    "mean_precisions": 0.9961,
    "std_time": 0.001343975740062278,
    "min_time": 0.0031562969088554382,
    "max_time": 0.046798110008239746,
    "rps": 156.64368643879783,
    "p95_time": 0.006830585747957229,
    "p99_time": 0.007791801095008856
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 512
    },
    "mean_time": 0.01774585579559207,
    "mean_precisions": 0.993318,
    "std_time": 0.004568751533819334,
    "min_time": 0.005170442163944244,
    "max_time": 0.0742778405547142,
    "rps": 55.95636147094427,
    "p95_time": 0.025161072239279745,
    "p99_time": 0.02903288416564465
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 64
    },
    "mean_time": 0.06317007677182555,
    "mean_precisions": 0.9198220000000001,
    "std_time": 0.04640620250318889,
    "min_time": 0.004403166472911835,
    "max_time": 0.42958641052246094,
    "rps": 1512.4483303853558,
    "p95_time": 0.17411880046129216,
    "p99_time": 0.2684603400528438
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.005182648487389088,
    "mean_precisions": 9e-05,
    "std_time": 0.004016391093252798,
    "min_time": 0.002006642520427704,
    "max_time": 0.028183192014694214,
    "rps": 1648.112820549218,
    "p95_time": 0.013706256821751594,
    "p99_time": 0.022177784964442247
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 512
    },
    "mean_time": 0.021511161215603352,
    "mean_precisions": 0.97004,
    "std_time": 0.005122367243952936,
    "min_time": 0.006685331463813782,
    "max_time": 0.07207008451223373,
    "rps": 46.14087689591744,
    "p95_time": 0.02973242700099945,
    "p99_time": 0.032991822883486746
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.0050252841040492055,
    "mean_precisions": 9e-05,
    "std_time": 0.003641141755076873,
    "min_time": 0.0019367486238479614,
    "max_time": 0.026675857603549957,
    "rps": 1680.5671783605796,
    "p95_time": 0.013200297579169273,
    "p99_time": 0.020428567677736275
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 32
    },
    "mean_time": 0.004703093662858009,
    "mean_precisions": 0.802534,
    "std_time": 0.0007834074766151126,
    "min_time": 0.0027328655123710632,
    "max_time": 0.018290884792804718,
    "rps": 208.95514170283323,
    "p95_time": 0.0058526791632175406,
    "p99_time": 0.0067582991719246
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.010339424924552441,
    "mean_precisions": 0.9656600000000002,
    "std_time": 0.004496198380999669,
    "min_time": 0.0033121705055236816,
    "max_time": 0.04731515049934387,
    "rps": 1150.0433331701722,
    "p95_time": 0.01941996440291405,
    "p99_time": 0.02361872613430025
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.11845728992074728,
    "mean_precisions": 0.99892,
    "std_time": 0.024574619579174003,
    "min_time": 0.0094832181930542,
    "max_time": 0.16339293867349625,
    "rps": 769.4139701659481,
    "p95_time": 0.1368652954697609,
    "p99_time": 0.1455498092621565
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.47965667339116336,
    "mean_precisions": 0.675084,
    "std_time": 0.03620927898010128,
    "min_time": 0.06071963161230087,
    "max_time": 0.5907045304775238,
    "rps": 206.73973369013487,
    "p95_time": 0.5364076055586338,
    "p99_time": 0.557960703894496
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.009181646662950516,
    "mean_precisions": 0.99898,
    "std_time": 0.0016589861041404047,
    "min_time": 0.004343509674072266,
    "max_time": 0.03128591179847717,
    "rps": 100.40903717860117,
    "p95_time": 0.011626685410737992,
    "p99_time": 0.013313786536455168
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "glove-100-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 512
    },
    "mean_time": 0.1511210735924542,
    "mean_precisions": 0.925278,
    "std_time": 0.05917776913335474,
    "min_time": 0.008629605174064636,
    "max_time": 0.7466762363910675,
    "rps": 653.2362342703746,
    "p95_time": 0.2602505531162023,
    "p99_time": 0.3353223599493504
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.11588455126434564,
    "mean_precisions": 0.99892,
    "std_time": 0.0288625562267295,
    "min_time": 0.006630517542362213,
    "max_time": 0.16422396898269653,
    "rps": 757.0939775566133,
    "p95_time": 0.13999751210212708,
    "p99_time": 0.14616313524544244
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.291524902356416,
    "mean_precisions": 0.700085,
    "std_time": 0.029101567239556037,
    "min_time": 0.0414266362786293,
    "max_time": 0.5279372707009315,
    "rps": 339.1790437817515,
    "p95_time": 0.33781562112271785,
    "p99_time": 0.3564504622668028
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64
    },
    "mean_time": 0.006054661080241204,
    "mean_precisions": 0.991,
    "std_time": 0.0011051358462254698,
    "min_time": 0.003388024866580963,
    "max_time": 0.026135623455047607,
    "rps": 147.83355814793842,
    "p95_time": 0.007642294093966485,
    "p99_time": 0.008744375407695775
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 768
    },
    "mean_time": 0.012472173576056957,
    "mean_precisions": 0.999692,
    "std_time": 0.0027454570562460996,
    "min_time": 0.004796139895915985,
    "max_time": 0.03831201046705246,
    "rps": 79.40560375575667,
    "p95_time": 0.01707264892756939,
    "p99_time": 0.01913885094225407
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.01956426095068455,
    "mean_precisions": 0.9958,
    "std_time": 0.01189124620784196,
    "min_time": 0.0032943934202194214,
    "max_time": 0.05884454399347305,
    "rps": 1136.9461946547722,
    "p95_time": 0.04401731491088867,
    "p99_time": 0.05018682323396206
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.00999809503555298,
    "mean_precisions": 0.99718,
    "std_time": 0.003894576306028357,
    "min_time": 0.0036815330386161804,
    "max_time": 0.03545287996530533,
    "rps": 1132.2557179742473,
    "p95_time": 0.017968469858169557,
    "p99_time": 0.02341880507767202
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.4753720563076437,
    "mean_precisions": 0.674938,
    "std_time": 0.029810470728224653,
    "min_time": 0.06222870200872421,
    "max_time": 0.5951086357235909,
    "rps": 208.58949341292367,
    "p95_time": 0.5053842246532441,
    "p99_time": 0.5307341887801886
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 128
    },
    "mean_time": 0.006647583985328674,
    "mean_precisions": 0.9351810000000002,
    "std_time": 0.0011254187409037975,
    "min_time": 0.0035584643483161926,
    "max_time": 0.024736031889915466,
    "rps": 148.48293411088994,
    "p95_time": 0.008328376337885855,
    "p99_time": 0.009577228128910069
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.06466188479661941,
    "mean_precisions": 0.99764,
    "std_time": 0.02073561591574575,
    "min_time": 0.004772476851940155,
    "max_time": 0.09753325581550598,
    "rps": 1160.4235709377847,
    "p95_time": 0.08450859561562539,
    "p99_time": 0.08793287113308906
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.006171625183522701,
    "mean_precisions": 0.9926599999999999,
    "std_time": 0.0021542806904182848,
    "min_time": 0.002978086471557617,
    "max_time": 0.024520643055438995,
    "rps": 1100.2880152234827,
    "p95_time": 0.010124193504452712,
    "p99_time": 0.01515055485069752
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512
    },
    "mean_time": 0.017116144920885562,
    "mean_precisions": 0.99936,
    "std_time": 0.003393185597910026,
    "min_time": 0.007709071040153503,
    "max_time": 0.04868008941411972,
    "rps": 55.59095377902165,
    "p95_time": 0.02245369777083397,
    "p99_time": 0.025150600224733363
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.4858869138084352,
    "mean_precisions": 0.6749379999999999,
    "std_time": 0.033962491920008595,
    "min_time": 0.08044958859682083,
    "max_time": 0.615445964038372,
    "rps": 204.01050850047574,
    "p95_time": 0.5304703805595636,
    "p99_time": 0.5719777623564005
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256
    },
    "mean_time": 0.008233944404870271,
    "mean_precisions": 0.9975719999999999,
    "std_time": 0.0016120867063227071,
    "min_time": 0.0041113123297691345,
    "max_time": 0.037144869565963745,
    "rps": 119.75961811587186,
    "p95_time": 0.010516122356057167,
    "p99_time": 0.011977075561881071
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 32
    },
    "mean_time": 0.0614174218326807,
    "mean_precisions": 0.8044300000000001,
    "std_time": 0.021754584665142393,
    "min_time": 0.009301446378231049,
    "max_time": 0.17703330516815186,
    "rps": 1319.281829869172,
    "p95_time": 0.10314942561089993,
    "p99_time": 0.13491454899311064
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 128
    },
    "mean_time": 0.009281246811151505,
    "mean_precisions": 0.97264,
    "std_time": 0.0016852655744443144,
    "min_time": 0.005570225417613983,
    "max_time": 0.026997916400432587,
    "rps": 106.09071576241739,
    "p95_time": 0.011449598148465155,
    "p99_time": 0.013299781531095501
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.014499636214226484,
    "mean_precisions": 0.6837639999999999,
    "std_time": 0.002253182247718981,
    "min_time": 0.0076484158635139465,
    "max_time": 0.04141956567764282,
    "rps": 68.39010202804911,
    "p95_time": 0.0183202788233757,
    "p99_time": 0.020839600190520287
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.1127272344917059,
    "mean_precisions": 0.9987400000000002,
    "std_time": 0.024376272179320913,
    "min_time": 0.008518196642398834,
    "max_time": 0.15024231374263763,
    "rps": 795.936545991531,
    "p95_time": 0.13000917360186579,
    "p99_time": 0.1339804182201624
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.0051919015198946,
    "mean_precisions": 9e-05,
    "std_time": 0.003592378785902409,
    "min_time": 0.0020104125142097473,
    "max_time": 0.028355374932289124,
    "rps": 1748.5883675007144,
    "p95_time": 0.013216399401426309,
    "p99_time": 0.018658393025398255
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.006355389893054962,
    "mean_precisions": 8e-05,
    "std_time": 0.00505695185293873,
    "min_time": 0.0018941015005111694,
    "max_time": 0.030585646629333496,
    "rps": 1830.0120706214457,
    "p95_time": 0.01762052960693836,
    "p99_time": 0.023528112918138503
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.8627613600343466,
    "mean_precisions": 0.770114,
    "std_time": 0.058863152303895466,
    "min_time": 0.08852820098400116,
    "max_time": 1.0090005546808243,
    "rps": 115.13062744520073,
    "p95_time": 0.9403252113610506,
    "p99_time": 0.9700518995523453
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.008347662238776685,
    "mean_precisions": 0.965,
    "std_time": 0.005539547510164598,
    "min_time": 0.002729669213294983,
    "max_time": 0.07432574778795242,
    "rps": 1129.179337029905,
    "p95_time": 0.021722399815917035,
    "p99_time": 0.03334289498627186
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.09109530906230211,
    "mean_precisions": 0.46571399999999996,
    "std_time": 0.038894481654433294,
    "min_time": 0.05924350023269653,
    "max_time": 0.5114186704158783,
    "rps": 1073.8661089679874,
    "p95_time": 0.10644044689834113,
    "p99_time": 0.2785510376095814
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.005160332135856152,
    "mean_precisions": 8e-05,
    "std_time": 0.0037107682337629414,
    "min_time": 0.0019690245389938354,
    "max_time": 0.030625298619270325,
    "rps": 1664.6806581917913,
    "p95_time": 0.01334461234509945,
    "p99_time": 0.01925075128674507
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 32
    },
    "mean_time": 0.00439592449888587,
    "mean_precisions": 0.8017569999999998,
    "std_time": 0.000776105282252358,
    "min_time": 0.0027567967772483826,
    "max_time": 0.01564043015241623,
    "rps": 223.43457725266947,
    "p95_time": 0.005618338286876678,
    "p99_time": 0.006551898121833802
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.09881721138879657,
    "mean_precisions": 0.465599,
    "std_time": 0.041625071267249375,
    "min_time": 0.0711657777428627,
    "max_time": 0.6673009246587753,
    "rps": 991.3812960993505,
    "p95_time": 0.10783969238400458,
    "p99_time": 0.25316943593325847
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 16
    },
    "mean_time": 0.0034357855558395387,
    "mean_precisions": 0.8802199999999999,
    "std_time": 0.0008310942279521608,
    "min_time": 0.001694314181804657,
    "max_time": 0.019382692873477936,
    "rps": 239.8787220137129,
    "p95_time": 0.004706765338778496,
    "p99_time": 0.005589491724967962
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.0077829255029559135,
    "mean_precisions": 0.9986799999999999,
    "std_time": 0.001642378577369373,
    "min_time": 0.004474073648452759,
    "max_time": 0.04236411303281784,
    "rps": 117.38691359012904,
    "p95_time": 0.009554187953472138,
    "p99_time": 0.010847963541746185
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.014084261953830718,
    "mean_precisions": 0.9971200000000001,
    "std_time": 0.007247061677773511,
    "min_time": 0.003873690962791443,
    "max_time": 0.055969804525375366,
    "rps": 1114.3298499621699,
    "p95_time": 0.03004930652678013,
    "p99_time": 0.03565630592405796
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.0047579089477658276,
    "mean_precisions": 0.9487200000000001,
    "std_time": 0.008397812878062896,
    "min_time": 0.001966327428817749,
    "max_time": 0.1253240928053856,
    "rps": 1150.5222168332166,
    "p95_time": 0.005735807120800023,
    "p99_time": 0.056961178407073126
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.0077553996533155445,
    "mean_precisions": 0.9868,
    "std_time": 0.0038884939292676566,
    "min_time": 0.003046460449695587,
    "max_time": 0.04931174963712692,
    "rps": 1083.4442860035297,
    "p95_time": 0.013972426578402523,
    "p99_time": 0.026829394996166264
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.8713717394091189,
    "mean_precisions": 0.770262,
    "std_time": 0.06707634651089905,
    "min_time": 0.0941561833024025,
    "max_time": 1.1975015252828598,
    "rps": 113.80753512442708,
    "p95_time": 0.9672020670026541,
    "p99_time": 1.0981463205069308
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.14674148371592163,
    "mean_precisions": 0.47611499999999995,
    "std_time": 0.011902744833715761,
    "min_time": 0.02792815864086151,
    "max_time": 0.1849246323108673,
    "rps": 670.0092758269303,
    "p95_time": 0.16206005215644836,
    "p99_time": 0.1697163673490286
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "glove-100-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 256
    },
    "mean_time": 0.012933329743891954,
    "mean_precisions": 0.8698309999999999,
    "std_time": 0.0032783107050356496,
    "min_time": 0.0042125508189201355,
    "max_time": 0.05508643388748169,
    "rps": 76.68657225775002,
    "p95_time": 0.018288042768836017,
    "p99_time": 0.020578403621912003
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.005554438799619674,
    "mean_precisions": 0.9627400000000002,
    "std_time": 0.002507571462969451,
    "min_time": 0.0024037733674049377,
    "max_time": 0.03479761630296707,
    "rps": 1106.3929364529452,
    "p95_time": 0.008912240341305736,
    "p99_time": 0.017160031795501716
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.01812286006063223,
    "mean_precisions": 0.745013,
    "std_time": 0.0026300889035954333,
    "min_time": 0.009933017194271088,
    "max_time": 0.032254546880722046,
    "rps": 54.78825138235944,
    "p95_time": 0.02268494330346584,
    "p99_time": 0.025264184772968292
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 16
    },
    "mean_time": 0.09139026342332363,
    "mean_precisions": 0.8044300000000001,
    "std_time": 0.09554540286273001,
    "min_time": 0.006653584539890289,
    "max_time": 0.45804042369127274,
    "rps": 937.6495264384547,
    "p95_time": 0.35928838886320585,
    "p99_time": 0.40048120394349096
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.3006509006112814,
    "mean_precisions": 0.7000850000000001,
    "std_time": 0.02536565400339857,
    "min_time": 0.034931622445583344,
    "max_time": 0.4006461426615715,
    "rps": 329.1042782279306,
    "p95_time": 0.3345026791095734,
    "p99_time": 0.3639763086289167
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.08375464890524745,
    "mean_precisions": 0.382401,
    "std_time": 0.009002958750269486,
    "min_time": 0.024928011000156403,
    "max_time": 0.1536203995347023,
    "rps": 1165.9667695548264,
    "p95_time": 0.0998788133263588,
    "p99_time": 0.10912036925554276
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.004835415236651898,
    "mean_precisions": 8e-05,
    "std_time": 0.0039068604569878025,
    "min_time": 0.001963876187801361,
    "max_time": 0.030974097549915314,
    "rps": 1791.5695760654426,
    "p95_time": 0.012850238382816305,
    "p99_time": 0.02299550250172615
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.03916084776371717,
    "mean_precisions": 0.9976799999999999,
    "std_time": 0.0268384586457762,
    "min_time": 0.00428762286901474,
    "max_time": 0.09982207417488098,
    "rps": 1090.4078885903716,
    "p95_time": 0.08793882690370083,
    "p99_time": 0.09209278024733067
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.8749472908824683,
    "mean_precisions": 0.8801260000000001,
    "std_time": 0.07425473200827737,
    "min_time": 0.08490601181983948,
    "max_time": 1.2916238382458687,
    "rps": 113.49191111776271,
    "p95_time": 0.9664209708571434,
    "p99_time": 1.1210106298327458
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 1.0063391310825944,
    "mean_precisions": 0.880691,
    "std_time": 0.08317750746842444,
    "min_time": 0.08636609464883804,
    "max_time": 1.243185169994831,
    "rps": 98.70524621926633,
    "p95_time": 1.113884374499321,
    "p99_time": 1.1577772461622953
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.005169839821755886,
    "mean_precisions": 9e-05,
    "std_time": 0.0038404256639399783,
    "min_time": 0.001996636390686035,
    "max_time": 0.046591587364673615,
    "rps": 1665.7315807948596,
    "p95_time": 0.012498400360345833,
    "p99_time": 0.01973559163510799
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 768
    },
    "mean_time": 0.1776521066725254,
    "mean_precisions": 0.9967550000000001,
    "std_time": 0.07183014795397343,
    "min_time": 0.016241304576396942,
    "max_time": 0.7443099245429039,
    "rps": 556.6095847765075,
    "p95_time": 0.3164466425776481,
    "p99_time": 0.3908740206807852
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.262807197124511,
    "mean_precisions": 0.574874,
    "std_time": 0.019420951471546915,
    "min_time": 0.04105622321367264,
    "max_time": 0.34230172634124756,
    "rps": 375.90988224318863,
    "p95_time": 0.2903237883001566,
    "p99_time": 0.3020451205968857
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.14737045188695191,
    "mean_precisions": 0.5845319999999999,
    "std_time": 0.013283852195004572,
    "min_time": 0.023638710379600525,
    "max_time": 0.1949756070971489,
    "rps": 667.1106452132698,
    "p95_time": 0.16689666248857973,
    "p99_time": 0.17793324157595636
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.8804164786919951,
    "mean_precisions": 0.770262,
    "std_time": 0.06367765761051453,
    "min_time": 0.08649157732725143,
    "max_time": 1.0902054607868195,
    "rps": 112.69709592629624,
    "p95_time": 0.9634788032621143,
    "p99_time": 1.0151119936257602
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.00766862446218729,
    "mean_precisions": 0.9946200000000001,
    "std_time": 0.0033333640963390003,
    "min_time": 0.0031350180506706238,
    "max_time": 0.04717899113893509,
    "rps": 1071.8028417703565,
    "p95_time": 0.012845326215028763,
    "p99_time": 0.02292433105409147
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.16300606675967574,
    "mean_precisions": 0.585015,
    "std_time": 0.0180628227965654,
    "min_time": 0.01937093585729599,
    "max_time": 0.2215069755911827,
    "rps": 604.0079096314167,
    "p95_time": 0.19453504756093024,
    "p99_time": 0.20364553764462473
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.005298276923596859,
    "mean_precisions": 8e-05,
    "std_time": 0.003904399244018746,
    "min_time": 0.0018953979015350342,
    "max_time": 0.03007371723651886,
    "rps": 1626.662928017626,
    "p95_time": 0.013223351165652267,
    "p99_time": 0.02111198917031288
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.014904688932001591,
    "mean_precisions": 0.98766,
    "std_time": 0.010028790935135552,
    "min_time": 0.003467939794063568,
    "max_time": 0.06175524741411209,
    "rps": 1147.822944956188,
    "p95_time": 0.0421801954507828,
    "p99_time": 0.05256113164126874
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 128
    },
    "mean_time": 0.05264149625003338,
    "mean_precisions": 0.9421480000000001,
    "std_time": 0.01395658826830877,
    "min_time": 0.00361044704914093,
    "max_time": 0.15618328005075455,
    "rps": 1849.1444616528713,
    "p95_time": 0.07424964308738703,
    "p99_time": 0.09826415427029137
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.006052738673985004,
    "mean_precisions": 8e-05,
    "std_time": 0.005504104169800093,
    "min_time": 0.0018766969442367554,
    "max_time": 0.06054434925317764,
    "rps": 1708.835782888573,
    "p95_time": 0.015037919208407401,
    "p99_time": 0.029334137439727778
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.17662770710512996,
    "mean_precisions": 0.585015,
    "std_time": 0.014300609238543064,
    "min_time": 0.03683146834373474,
    "max_time": 0.3776378631591797,
    "rps": 557.4523509215405,
    "p95_time": 0.19657807759940624,
    "p99_time": 0.20370360493659972
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 32
    },
    "mean_time": 0.005777226813137531,
    "mean_precisions": 0.8550399999999999,
    "std_time": 0.0010523318709510167,
    "min_time": 0.003591097891330719,
    "max_time": 0.024265609681606293,
    "rps": 170.05570003812534,
    "p95_time": 0.007090201973915099,
    "p99_time": 0.008286458030343054
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64
    },
    "mean_time": 0.0069731145575642585,
    "mean_precisions": 0.9258099999999999,
    "std_time": 0.0011561625532728313,
    "min_time": 0.0040922611951828,
    "max_time": 0.01995198428630829,
    "rps": 140.9887829633523,
    "p95_time": 0.008653000742197036,
    "p99_time": 0.009529301077127456
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.005152756713330746,
    "mean_precisions": 9e-05,
    "std_time": 0.004146733428754162,
    "min_time": 0.0020517781376838684,
    "max_time": 0.040874749422073364,
    "rps": 1705.704557438362,
    "p95_time": 0.013907572254538533,
    "p99_time": 0.021621789559721945
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 64
    },
    "mean_time": 0.05788508754968643,
    "mean_precisions": 0.8044300000000001,
    "std_time": 0.028389680241455183,
    "min_time": 0.005700312554836273,
    "max_time": 0.227157361805439,
    "rps": 1263.0957755525696,
    "p95_time": 0.1187080319970846,
    "p99_time": 0.15891307346522807
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.8490931620724499,
    "mean_precisions": 0.8801260000000001,
    "std_time": 0.06224118437777543,
    "min_time": 0.0871913731098175,
    "max_time": 1.104468010365963,
    "rps": 116.91766024389534,
    "p95_time": 0.926401038467884,
    "p99_time": 1.0004014018177987
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.11450522603988647,
    "mean_precisions": 0.9987400000000002,
    "std_time": 0.021348696589421443,
    "min_time": 0.010266609489917755,
    "max_time": 0.14461634308099747,
    "rps": 798.2106153479942,
    "p95_time": 0.13152780681848525,
    "p99_time": 0.13782419383525848
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256
    },
    "mean_time": 0.008957374804466962,
    "mean_precisions": 0.973791,
    "std_time": 0.0015699894780849136,
    "min_time": 0.003849931061267853,
    "max_time": 0.027460597455501556,
    "rps": 110.39467784483546,
    "p95_time": 0.01128178425133228,
    "p99_time": 0.012745302766561509
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512
    },
    "mean_time": 0.010443749052286148,
    "mean_precisions": 0.999341,
    "std_time": 0.0022253448995037868,
    "min_time": 0.004515744745731354,
    "max_time": 0.03459879010915756,
    "rps": 94.81660697483571,
    "p95_time": 0.01401221491396427,
    "p99_time": 0.01598329044878483
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 16
    },
    "mean_time": 0.00943277058750391,
    "mean_precisions": 0.8044300000000001,
    "std_time": 0.0022942900345327842,
    "min_time": 0.003862820565700531,
    "max_time": 0.03424058109521866,
    "rps": 104.52695681873851,
    "p95_time": 0.01301673725247383,
    "p99_time": 0.014854154661297797
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.5048088026314974,
    "mean_precisions": 0.8008029999999999,
    "std_time": 0.040431095771101606,
    "min_time": 0.05305739492177963,
    "max_time": 0.6278878077864647,
    "rps": 196.2667991588351,
    "p95_time": 0.5640647247433662,
    "p99_time": 0.5864178436994553
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 16
    },
    "mean_time": 0.0041648648530244825,
    "mean_precisions": 0.9430799999999999,
    "std_time": 0.0012038544096498068,
    "min_time": 0.0025726407766342163,
    "max_time": 0.04469577223062515,
    "rps": 205.96045567687207,
    "p95_time": 0.005716387927532198,
    "p99_time": 0.009136088788509382
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.019691603941470386,
    "mean_precisions": 0.885702,
    "std_time": 0.004297113855570616,
    "min_time": 0.007103480398654938,
    "max_time": 0.04555599391460419,
    "rps": 50.438513542620605,
    "p95_time": 0.026624996587634085,
    "p99_time": 0.030568980649113654
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.01820835940092802,
    "mean_precisions": 0.745013,
    "std_time": 0.0026177437428261865,
    "min_time": 0.010236456990242004,
    "max_time": 0.03596843034029007,
    "rps": 54.55997861164504,
    "p95_time": 0.02263386510312557,
    "p99_time": 0.02558289058506489
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.16247052445411683,
    "mean_precisions": 0.47626100000000005,
    "std_time": 0.01601500241267563,
    "min_time": 0.0274043008685112,
    "max_time": 0.2143552601337433,
    "rps": 604.9320014294791,
    "p95_time": 0.18774492517113683,
    "p99_time": 0.20099210344254972
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.9697385131753982,
    "mean_precisions": 0.880691,
    "std_time": 0.07248547464714661,
    "min_time": 0.08011573553085327,
    "max_time": 1.1521756798028946,
    "rps": 102.43998649116556,
    "p95_time": 1.0598529897630216,
    "p99_time": 1.0909621521085502
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 32
    },
    "mean_time": 0.0038431686505675314,
    "mean_precisions": 0.9431400000000002,
    "std_time": 0.0029865899936693777,
    "min_time": 0.0016956925392150879,
    "max_time": 0.2021869271993637,
    "rps": 1135.9271642615265,
    "p95_time": 0.005629927664995193,
    "p99_time": 0.007294313982129098
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.005829784728586674,
    "mean_precisions": 9e-05,
    "std_time": 0.004503367640824387,
    "min_time": 0.002053096890449524,
    "max_time": 0.04493158310651779,
    "rps": 1959.8932638838126,
    "p95_time": 0.014621155336499214,
    "p99_time": 0.022397359758615468
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.00512181194126606,
    "mean_precisions": 8e-05,
    "std_time": 0.003202620829099613,
    "min_time": 0.001805335283279419,
    "max_time": 0.020937256515026093,
    "rps": 1703.3168742573243,
    "p95_time": 0.011578140035271637,
    "p99_time": 0.0179175715893507
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.27416896083056924,
    "mean_precisions": 0.5748740000000001,
    "std_time": 0.02977128569985841,
    "min_time": 0.04596920311450958,
    "max_time": 0.4078040271997452,
    "rps": 360.2961506891449,
    "p95_time": 0.325996657833457,
    "p99_time": 0.38121153838932514
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.02602664421722293,
    "mean_precisions": 0.8325490000000002,
    "std_time": 0.0035135896727007446,
    "min_time": 0.015828877687454224,
    "max_time": 0.0489838570356369,
    "rps": 38.195756284644496,
    "p95_time": 0.03223817497491836,
    "p99_time": 0.035666303262114535
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 128
    },
    "mean_time": 0.00640168487355113,
    "mean_precisions": 0.9911260000000001,
    "std_time": 0.001163328168622376,
    "min_time": 0.003423266112804413,
    "max_time": 0.029677048325538635,
    "rps": 154.15411878333228,
    "p95_time": 0.007989471405744552,
    "p99_time": 0.009140601158142095
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.004048387922346592,
    "mean_precisions": 0.0006799999999999999,
    "std_time": 0.0007195428558190044,
    "min_time": 0.002729274332523346,
    "max_time": 0.013688012957572937,
    "rps": 241.50964429363725,
    "p95_time": 0.004937962815165519,
    "p99_time": 0.005728310495615004
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 32
    },
    "mean_time": 0.005602659247815609,
    "mean_precisions": 0.8536800000000001,
    "std_time": 0.001098568458087218,
    "min_time": 0.0033265575766563416,
    "max_time": 0.02654469758272171,
    "rps": 175.4871335361274,
    "p95_time": 0.006885691359639168,
    "p99_time": 0.008086755797266958
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 16
    },
    "mean_time": 0.004298805858939886,
    "mean_precisions": 0.7914720000000001,
    "std_time": 0.0009117432832518369,
    "min_time": 0.0025219470262527466,
    "max_time": 0.04026878625154495,
    "rps": 228.58282379593334,
    "p95_time": 0.005456290394067764,
    "p99_time": 0.0066054439544677756
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.0059445761069655415,
    "mean_precisions": 8e-05,
    "std_time": 0.005990965937080948,
    "min_time": 0.001955188810825348,
    "max_time": 0.06248115748167038,
    "rps": 1766.3606230360224,
    "p95_time": 0.018528177589178033,
    "p99_time": 0.029482243210077284
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.005214524924755096,
    "mean_precisions": 9e-05,
    "std_time": 0.003556249544843058,
    "min_time": 0.0018728747963905334,
    "max_time": 0.030257321894168854,
    "rps": 1728.408919987555,
    "p95_time": 0.012776487693190572,
    "p99_time": 0.017973921075463296
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 512
    },
    "mean_time": 0.015253273621201515,
    "mean_precisions": 0.99684,
    "std_time": 0.003142578518582242,
    "min_time": 0.006134994328022003,
    "max_time": 0.031722813844680786,
    "rps": 64.92862947890977,
    "p95_time": 0.01999781765043735,
    "p99_time": 0.023084955364465712
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.48095542231947186,
    "mean_precisions": 0.8006280000000001,
    "std_time": 0.037575044435573926,
    "min_time": 0.05870325118303299,
    "max_time": 0.603903517127037,
    "rps": 206.2232340610371,
    "p95_time": 0.5328203324228524,
    "p99_time": 0.560438296571374
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 64
    },
    "mean_time": 0.005327479427307844,
    "mean_precisions": 0.8735060000000001,
    "std_time": 0.0008346765598093186,
    "min_time": 0.003001600503921509,
    "max_time": 0.01814434677362442,
    "rps": 184.9058935942889,
    "p95_time": 0.006610152125358581,
    "p99_time": 0.007492092922329904
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.026129645242542028,
    "mean_precisions": 0.8325490000000002,
    "std_time": 0.0035242487784522634,
    "min_time": 0.014774024486541748,
    "max_time": 0.04652000963687897,
    "rps": 38.05036072000471,
    "p95_time": 0.03224788345396518,
    "p99_time": 0.035835219770669946
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 512
    },
    "mean_time": 0.19542056781947612,
    "mean_precisions": 0.9979,
    "std_time": 0.061744205830202216,
    "min_time": 0.01605089008808136,
    "max_time": 0.5038498714566231,
    "rps": 484.4256281872571,
    "p95_time": 0.30540014430880547,
    "p99_time": 0.37337299183011063
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "glove-100-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 128
    },
    "mean_time": 0.06106927878037095,
    "mean_precisions": 0.796424,
    "std_time": 0.022247733867933453,
    "min_time": 0.010475091636180878,
    "max_time": 0.2887131869792938,
    "rps": 1590.6849486464293,
    "p95_time": 0.09505173601210118,
    "p99_time": 0.14426297858357442
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-latency-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 234.60426425933838,
    "total_upload_time": 3015.7508194744587,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.006926829560101032,
    "mean_precisions": 0.9971,
    "std_time": 0.001562626009453072,
    "min_time": 0.0031652674078941345,
    "max_time": 0.04568696767091751,
    "rps": 128.1225244218958,
    "p95_time": 0.008599357306957245,
    "p99_time": 0.010204501450061805
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 256
    },
    "mean_time": 0.014417905628681183,
    "mean_precisions": 0.9269700000000001,
    "std_time": 0.0031527549047139346,
    "min_time": 0.005131728947162628,
    "max_time": 0.025014668703079224,
    "rps": 68.71180588631508,
    "p95_time": 0.01953311450779438,
    "p99_time": 0.022079397663474082
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 768
    },
    "mean_time": 0.01754934775829315,
    "mean_precisions": 0.99817,
    "std_time": 0.003577528902835559,
    "min_time": 0.00687408447265625,
    "max_time": 0.04068414121866226,
    "rps": 56.48983214294647,
    "p95_time": 0.022729480266571043,
    "p99_time": 0.02552305072546005
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.00772650890648365,
    "mean_precisions": 0.9945599999999999,
    "std_time": 0.002811932786083246,
    "min_time": 0.0032876282930374146,
    "max_time": 0.030778788030147552,
    "rps": 1122.3203712730076,
    "p95_time": 0.01294707506895066,
    "p99_time": 0.01912442125380044
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.2759408831186593,
    "mean_precisions": 0.700085,
    "std_time": 0.020862016470709396,
    "min_time": 0.034619033336639404,
    "max_time": 0.33742260932922363,
    "rps": 358.43887966061396,
    "p95_time": 0.3039752818644047,
    "p99_time": 0.31513441130518915
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 256,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.5247232326485216,
    "mean_precisions": 0.800803,
    "std_time": 0.04278698856217172,
    "min_time": 0.05048178881406784,
    "max_time": 0.656536765396595,
    "rps": 188.94443429988456,
    "p95_time": 0.5847183354198933,
    "p99_time": 0.6126486790180207
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 64
    },
    "mean_time": 0.006202238968014717,
    "mean_precisions": 0.9753799999999999,
    "std_time": 0.0014312920310112366,
    "min_time": 0.0020925775170326233,
    "max_time": 0.018294259905815125,
    "rps": 143.60007334858994,
    "p95_time": 0.008520466461777688,
    "p99_time": 0.009972518831491473
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 32
      }
    },
    "mean_time": 0.273354924660176,
    "mean_precisions": 0.575156,
    "std_time": 0.020229500055070498,
    "min_time": 0.036667756736278534,
    "max_time": 0.3286067917943001,
    "rps": 361.41858389812717,
    "p95_time": 0.3032600976526737,
    "p99_time": 0.3139743869751692
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.0795562740214169,
    "mean_precisions": 0.382401,
    "std_time": 0.009044521980842685,
    "min_time": 0.009944655001163483,
    "max_time": 0.11376143991947174,
    "rps": 1216.2297033316706,
    "p95_time": 0.09168026372790336,
    "p99_time": 0.10149424090981485
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 32
    },
    "mean_time": 0.004490734947472811,
    "mean_precisions": 0.9341279999999998,
    "std_time": 0.0008676018863406574,
    "min_time": 0.00257168710231781,
    "max_time": 0.034271419048309326,
    "rps": 218.77774180449583,
    "p95_time": 0.005585602298378944,
    "p99_time": 0.006688868701457978
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.8677784057796002,
    "mean_precisions": 0.8801260000000001,
    "std_time": 0.06375838247196784,
    "min_time": 0.10046971589326859,
    "max_time": 1.14085753262043,
    "rps": 114.43251481605749,
    "p95_time": 0.9506351895630359,
    "p99_time": 1.0134863317757847
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 128
    },
    "mean_time": 0.010294997476041318,
    "mean_precisions": 0.84466,
    "std_time": 0.002362365185943006,
    "min_time": 0.004509143531322479,
    "max_time": 0.019788749516010284,
    "rps": 95.9448631751515,
    "p95_time": 0.014148061722517013,
    "p99_time": 0.015521935746073722
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256
    },
    "mean_time": 0.011544459901750088,
    "mean_precisions": 0.9910900000000001,
    "std_time": 0.0024954289163007233,
    "min_time": 0.00485452264547348,
    "max_time": 0.03521127998828888,
    "rps": 85.74946978624745,
    "p95_time": 0.014797292649745941,
    "p99_time": 0.01778536856174469
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.007374242278933525,
    "mean_precisions": 0.96536,
    "std_time": 0.0036455064071157514,
    "min_time": 0.0025472119450569153,
    "max_time": 0.05836065113544464,
    "rps": 1140.847753853662,
    "p95_time": 0.012859461829066278,
    "p99_time": 0.024463699236512204
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 768
    },
    "mean_time": 0.2675062173455954,
    "mean_precisions": 0.9831200000000001,
    "std_time": 0.09256302829230748,
    "min_time": 0.019263900816440582,
    "max_time": 0.567847803235054,
    "rps": 348.50664206559,
    "p95_time": 0.4208118688315153,
    "p99_time": 0.48543044202029695
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-rps-m-32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 77.02432788163424,
    "total_upload_time": 662.8942101895809,
    "parallel": 1,
    "engine_params": {
      "hnsw_ef": 256
    },
    "mean_time": 0.011369169692695141,
    "mean_precisions": 0.9985599999999999,
    "std_time": 0.0023529381322650498,
    "min_time": 0.005450643599033356,
    "max_time": 0.03937974572181702,
    "rps": 82.33519992002492,
    "p95_time": 0.014907171949744225,
    "p99_time": 0.0176787728816271
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 16
      }
    },
    "mean_time": 0.14573474756479263,
    "mean_precisions": 0.47626100000000005,
    "std_time": 0.013913267651330314,
    "min_time": 0.032940275967121124,
    "max_time": 0.21062880754470825,
    "rps": 673.98326568842,
    "p95_time": 0.16954429559409614,
    "p99_time": 0.1867264085263014
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 1,
    "engine_params": {
      "ef": 128
    },
    "mean_time": 0.009178170939534902,
    "mean_precisions": 0.942148,
    "std_time": 0.002990441530055449,
    "min_time": 0.0037824809551239014,
    "max_time": 0.217182494699955,
    "rps": 107.71082379055416,
    "p95_time": 0.012876170128583908,
    "p99_time": 0.014843722134828569
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "dbpedia-openai-1M-1536-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 768
    },
    "mean_time": 0.27299471584260465,
    "mean_precisions": 0.9986,
    "std_time": 0.08724191369605973,
    "min_time": 0.02992686629295349,
    "max_time": 0.92873465269804,
    "rps": 357.3401308404161,
    "p95_time": 0.42767847664654257,
    "p99_time": 0.5368738187849523
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.08729166845157743,
    "mean_precisions": 0.382401,
    "std_time": 0.008166519213404244,
    "min_time": 0.07219630479812622,
    "max_time": 0.14393439888954163,
    "rps": 1116.2898158050039,
    "p95_time": 0.10167237110435962,
    "p99_time": 0.11223731465637685
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "glove-100-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 64,
      "quantization": {
        "rescore": true,
        "oversampling": 64
      }
    },
    "mean_time": 0.4885545769162476,
    "mean_precisions": 0.6749379999999999,
    "std_time": 0.03543029270141943,
    "min_time": 0.06038535386323929,
    "max_time": 0.6155696138739586,
    "rps": 202.95544245282872,
    "p95_time": 0.5402877859771251,
    "p99_time": 0.5755366754531861
  },
  {
    "engine_name": "weaviate",
    "setup_name": "latest-weaviate-m32",
    "dataset_name": "glove-100-angular",
    "upload_time": 836.9633269459009,
    "total_upload_time": 836.9633825644851,
    "parallel": 100,
    "engine_params": {
      "ef": 16
    },
    "mean_time": 0.05507431394308805,
    "mean_precisions": 0.765836,
    "std_time": 0.02196383938111323,
    "min_time": 0.005411162972450256,
    "max_time": 0.4006127417087555,
    "rps": 1762.2151163215651,
    "p95_time": 0.0869616236537695,
    "p99_time": 0.11681725747883323
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "deep-image-96-angular",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 512,
      "quantization": {
        "rescore": true,
        "oversampling": 8
      }
    },
    "mean_time": 0.1003286402747035,
    "mean_precisions": 0.465599,
    "std_time": 0.012886676307402858,
    "min_time": 0.011455245316028595,
    "max_time": 0.13597485423088074,
    "rps": 967.13860805656,
    "p95_time": 0.11523332521319389,
    "p99_time": 0.12090472534298898
  },
  {
    "engine_name": "qdrant",
    "setup_name": "latest-qdrant-bq-rps-m-32",
    "dataset_name": "gist-960-euclidean",
    "upload_time": 127.78749691694975,
    "total_upload_time": 678.6138078793883,
    "parallel": 100,
    "engine_params": {
      "hnsw_ef": 768,
      "quantization": {
        "rescore": true,
        "oversampling": 128
      }
    },
    "mean_time": 0.0051844210103154185,
    "mean_precisions": 9e-05,
    "std_time": 0.003848906627028196,
    "min_time": 0.002041175961494446,
    "max_time": 0.03304949402809143,
    "rps": 1702.7639579689035,
    "p95_time": 0.013108184933662413,
    "p99_time": 0.02081113822758197
  }
]

```
                    ## 📄 `https-qdrant-tech-benchmarks-setup.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#setup
                    ## 📄 `https-qdrant-tech-benchmarks-single-node-benchmarks.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#single-node-benchmarks
                    ## 📄 `https-qdrant-tech-benchmarks-single-node-speed-benchmark-2022.md`
                    ```md
                    # https://qdrant.tech/benchmarks/single-node-speed-benchmark-2022/
# Single node benchmarks (2022)
August 23, 2022
  * [Home](https://qdrant.tech/)
  * /
  * [Benchmarks](https://qdrant.tech/benchmarks/)
  * /
  * Single node benchmarks (2022)
Dataset: deep-image-96-angular gist-960-euclidean glove-100-angular
Search threads: 100 8 4 2 1
Plot values:
RPS  Latency  p95 latency  Index time
Engine | Setup | Dataset | Upload Time(m) | Upload + Index Time(m) | Latency(ms) | P95(ms) | P99(ms) | RPS | Precision  
---|---|---|---|---|---|---|---|---|---  
qdrant | _qdrant-rps-m-64-ef-512_ | deep-image-96-angular | 14.096 | 149.32 | 24.73 | 55.75 | 63.73 | 1541.86 | 0.96  
weaviate | _weaviate-m-16-ef-128_ | deep-image-96-angular | 148.70 | 148.70 | 190.94 | 351.75 | 414.16 | 507.33 | 0.94  
milvus | _milvus-m-16-ef-128_ | deep-image-96-angular | 6.074 | 35.28 | 171.50 | 220.26 | 236.97 | 339.44 | 0.97  
elastic | _elastic-m-16-ef-128_ | deep-image-96-angular | 87.54 | 101.16 | 923.031 | 1116.83 | 1671.31 | 95.90 | 0.97  
_Download raw data:[here](https://qdrant.tech/benchmarks/result-2022-08-10.json)_
This is an archived version of Single node benchmarks. Please refer to the new version [here](https://qdrant.tech/benchmarks/single-node-speed-benchmark/).
Share this article
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/benchmarks/single-node-speed-benchmark-2022/)
                    ## 📄 `https-qdrant-tech-benchmarks-single-node-speed-benchmark.md`
                    ```md
                    # https://qdrant.tech/benchmarks/single-node-speed-benchmark/
# Single node benchmarks
August 23, 2022
  * [Home](https://qdrant.tech/)
  * /
  * [Benchmarks](https://qdrant.tech/benchmarks/)
  * /
  * Single node benchmarks
Dataset: dbpedia-openai-1M-1536-angular deep-image-96-angular gist-960-euclidean glove-100-angular
Search threads: 100 1
Plot values:
RPS  Latency  p95 latency  Index time
Engine | Setup | Dataset | Upload Time(m) | Upload + Index Time(m) | Latency(ms) | P95(ms) | P99(ms) | RPS | Precision  
---|---|---|---|---|---|---|---|---|---  
qdrant | _qdrant-sq-rps-m-64-ef-512_ | dbpedia-openai-1M-1536-angular | 3.51 | 24.43 | 3.54 | 4.95 | 8.62 | 1238.0016 | 0.99  
weaviate | _latest-weaviate-m32_ | dbpedia-openai-1M-1536-angular | 13.94 | 13.94 | 4.99 | 7.16 | 11.33 | 1142.13 | 0.97  
elasticsearch | _elasticsearch-m-32-ef-128_ | dbpedia-openai-1M-1536-angular | 19.18 | 83.72 | 22.10 | 72.53 | 135.68 | 716.80 | 0.98  
redis | _redis-m-32-ef-256_ | dbpedia-openai-1M-1536-angular | 92.49 | 92.49 | 140.65 | 160.85 | 167.35 | 625.27 | 0.97  
milvus | _milvus-m-16-ef-128_ | dbpedia-openai-1M-1536-angular | 0.27 | 1.16 | 393.31 | 441.32 | 576.65 | 219.11 | 0.99  
_Download raw data:[here](https://qdrant.tech/benchmarks/results-1-100-thread-2024-06-15.json)_
##  [](https://qdrant.tech/benchmarks/single-node-speed-benchmark/#observations)Observations
Most of the engines have improved since [our last run](https://qdrant.tech/benchmarks/single-node-speed-benchmark-2022/). Both life and software have trade-offs but some clearly do better:
##  [](https://qdrant.tech/benchmarks/single-node-speed-benchmark/#how-to-read-the-results)How to read the results
###  [](https://qdrant.tech/benchmarks/single-node-speed-benchmark/#latency-vs-rps)Latency vs RPS
In our benchmark we test two main search usage scenarios that arise in practice.
###  [](https://qdrant.tech/benchmarks/single-node-speed-benchmark/#tested-datasets)Tested datasets
Our 
Datasets | # Vectors | Dimensions | Distance  
---|---|---|---  
1M | 1536 | cosine  
10M | 96 | cosine  
1M | 960 | euclidean  
1.2M | 100 | cosine  
###  [](https://qdrant.tech/benchmarks/single-node-speed-benchmark/#setup)Setup
![Benchmarks configuration](https://qdrant.tech/benchmarks/client-server.png)
Benchmarks configuration
Please note that some of the configs of some engines crashed on some datasets because of the 25 GB memory limit. That’s why you might see fewer points for some engines on choosing higher precision thresholds.
Share this article
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/benchmarks/single-node-speed-benchmark/)
                    ## 📄 `https-qdrant-tech-benchmarks-tested-datasets.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#tested-datasets
                    ## 📄 `https-qdrant-tech-benchmarks-what-about-closed-source-saas-platforms.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#what-about-closed-source-saas-platforms
                    ## 📄 `https-qdrant-tech-benchmarks-what-do-we-measure.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#what-do-we-measure
                    ## 📄 `https-qdrant-tech-benchmarks-why-filtering-is-not-trivial.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#why-filtering-is-not-trivial
                    ## 📄 `https-qdrant-tech-benchmarks-why-we-decided-to-test-with-the-python-client.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#why-we-decided-to-test-with-the-python-client
                    ## 📄 `https-qdrant-tech-benchmarks-why-you-are-not-comparing-with-faiss-or-annoy.md`
                    ```md
                    # https://qdrant.tech/benchmarks/#why-you-are-not-comparing-with-faiss-or-annoy
                    ## 📄 `https-qdrant-tech-benchmarks.md`
                    ```md
                    # https://qdrant.tech/benchmarks/
                    ## 📄 `https-qdrant-tech-blog-case-study-dailymotion.md`
                    ```md
                    # https://qdrant.tech/blog/case-study-dailymotion/
0
# Dailymotion's Journey to Crafting the Ultimate Content-Driven Video Recommendation Engine with Qdrant Vector Database
Atita Arora
·
February 27, 2024
![Dailymotion's Journey to Crafting the Ultimate Content-Driven Video Recommendation Engine with Qdrant Vector Database](https://qdrant.tech/blog/case-study-dailymotion/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Dailymotion's Journey to Crafting the Ultimate Content-Driven Video Recommendation Engine with Qdrant Vector Database
On this page:
  *     * [Dailymotion’s Journey to Crafting the Ultimate Content-Driven Video Recommendation Engine with Qdrant Vector Database](https://qdrant.tech/blog/case-study-dailymotion/#dailymotions-journey-to-crafting-the-ultimate-content-driven-video-recommendation-engine-with-qdrant-vector-database)
      * [Scale](https://qdrant.tech/blog/case-study-dailymotion/#scale)
      * [Challenge](https://qdrant.tech/blog/case-study-dailymotion/#challenge)
      * [Background / Journey](https://qdrant.tech/blog/case-study-dailymotion/#background--journey)
      * [Solution at glance](https://qdrant.tech/blog/case-study-dailymotion/#solution-at-glance)
      * [Why Qdrant?](https://qdrant.tech/blog/case-study-dailymotion/#why-qdrant)
      * [Data Processing pipeline](https://qdrant.tech/blog/case-study-dailymotion/#data-processing-pipeline)
      * [Results](https://qdrant.tech/blog/case-study-dailymotion/#results)
      * [Outlook / Future plans](https://qdrant.tech/blog/case-study-dailymotion/#outlook--future-plans)
      * [References](https://qdrant.tech/blog/case-study-dailymotion/#references)
##  [](https://qdrant.tech/blog/case-study-dailymotion/#dailymotions-journey-to-crafting-the-ultimate-content-driven-video-recommendation-engine-with-qdrant-vector-database)Dailymotion’s Journey to Crafting the Ultimate Content-Driven Video Recommendation Engine with Qdrant Vector Database
In today’s digital age, the consumption of video content has become ubiquitous, with an overwhelming abundance of options available at our fingertips. However, amidst this vast sea of videos, the challenge lies not in finding content, but in discovering the content that truly resonates with individual preferences and interests and yet is diverse enough to not throw users into their own filter bubble. As viewers, we seek meaningful and relevant videos that enrich our experiences, provoke thought, and spark inspiration.
Dailymotion is not just another video application; it’s a beacon of curated content in an ocean of options. With a steadfast commitment to providing users with meaningful and ethical viewing experiences, Dailymotion stands as the bastion of videos that truly matter.
They aim to boost a dynamic visual dialogue, breaking echo chambers and fostering discovery.
###  [](https://qdrant.tech/blog/case-study-dailymotion/#scale)Scale
  * **420 million+ videos**
  * **2k+ new videos / hour**
  * **13 million+ recommendations / day**
  * **300+ languages in videos**
  * **Required response time < 100 ms**
###  [](https://qdrant.tech/blog/case-study-dailymotion/#challenge)Challenge
  * **Improve video recommendations** across all 3 applications of Dailymotion (mobile app, website and embedded video player on all major French and International sites) as it is the main driver of audience engagement and revenue stream of the platform.
  * Traditional 
  * Video content based recommendation system required processing all the video embedding at scale and in real time, as soon as they are added to the platform
  * Exact neighbor search at the scale and keeping them up to date with new video updates in real time at Dailymotion was unreasonable and unrealistic
  * Precomputed 
  * Platform needs fast recommendations ~ < 100ms
  * Needed fast ANN search on a vector search engine which could support the scale and performance requirements of the platform
###  [](https://qdrant.tech/blog/case-study-dailymotion/#background--journey)Background / Journey
The quest of Dailymotion to deliver an intelligent video recommendation engine providing a curated selection of videos to its users started with a need to present more relevant videos to the first-time users of the platform (cold start problem) and implement an ideal home feed experience to allow users to watch videos that are expected to be relevant, diverse, explainable, and easily tunable.  
This goal accounted for their efforts focused on
They continued their work in 
By now it was clear to the Dailymotion team that the future initiatives will involve overcoming obstacles related to data processing, sentiment analysis, and user experience to provide meaningful and diverse recommendations. The main challenge stayed at the candidate generation process, textual embeddings, opinion mining, along with optimising the efficiency and accuracy of these processes and tackling the complexities of large-scale content curation.
###  [](https://qdrant.tech/blog/case-study-dailymotion/#solution-at-glance)Solution at glance
![solution-at-glance](https://qdrant.tech/case-studies/dailymotion/solution-at-glance.png)
The solution involved implementing a content based Recommendation System leveraging Qdrant to power the similar videos, with the following characteristics.
**Fields used to represent each video** -  
Title , Tags , Description , Transcript (generated by 
**Encoding Model used** - 
  * Supports - 16 languages
###  [](https://qdrant.tech/blog/case-study-dailymotion/#why-qdrant)Why Qdrant?
![quote-from-Samuel](https://qdrant.tech/case-studies/dailymotion/Dailymotion-Quote.jpg)
Looking at the complexity, scale and adaptability of the desired solution, the team decided to leverage Qdrant’s vector database to implement a content-based video recommendation that undoubtedly offered several advantages over other methods:
**1. Efficiency in High-Dimensional Data Handling:**
Video content is inherently high-dimensional, comprising various features such as audio, visual, textual, and contextual elements.  
Qdrant excels in efficiently handling high-dimensional data and out-of-the-box support for all the models with up to 65536 dimensions, making it well-suited for representing and processing complex video features with choice of any embedding model.
**2. Scalability:**
As the volume of video content and user interactions grows, scalability becomes paramount. Qdrant is meticulously designed to scale vertically as well as horizontally, allowing for seamless expansion to accommodate large volumes of data and user interactions without compromising performance.
**3. Fast and Accurate Similarity Search:**
Efficient video recommendation systems rely on identifying similarities between videos to make relevant recommendations. Qdrant leverages advanced HNSW indexing and similarity search algorithms to support fast and accurate retrieval of similar videos based on their feature representations nearly instantly (20ms for this use case)
**4. Flexibility in vector representation with metadata through payloads:**
Qdrant offers flexibility in storing vectors with metadata in form of payloads and offers support for advanced metadata filtering during the similarity search to incorporate custom logic.
**5. Reduced Dimensionality and Storage Requirements:**
Vector representations in Qdrant offer various Quantization and memory mapping techniques to efficiently store and retrieve vectors, leading to reduced storage requirements and computational overhead compared to alternative methods such as content-based filtering or collaborative filtering.
**6. Impressive Benchmarks:**
[Qdrant’s benchmarks](https://qdrant.tech/benchmarks/) has definitely been one of the key motivations for the Dailymotion’s team to try the solution and the team comments that the performance has been only better than the benchmarks.
**7. Ease of usage:**
Qdrant API’s have been immensely easy to get started with as compared to Google Vertex Matching Engine (which was Dailymotion’s initial choice) and the support from the team has been of a huge value to us.
**8. Being able to fetch data by id**
Qdrant allows to retrieve vector point / videos by ids while the Vertex Matching Engine requires a vector input to be able to search for other vectors which was another really important feature for Dailymotion
###  [](https://qdrant.tech/blog/case-study-dailymotion/#data-processing-pipeline)Data Processing pipeline
![data-processing](https://qdrant.tech/case-studies/dailymotion/data-processing-pipeline.png)
Figure shows the streaming architecture of the data processing pipeline that processes everytime a new video is uploaded or updated (Title, Description, Tags, Transcript), an updated embedding is computed and fed directly into Qdrant.
###  [](https://qdrant.tech/blog/case-study-dailymotion/#results)Results
![before-qdrant-results](https://qdrant.tech/case-studies/dailymotion/before-qdrant.png)
There has been a big improvement in the recommended content processing time and quality as the existing system had issues like:
  1. Subpar video recommendations due to long processing time ~ 5 hours
  2. Collaborative recommender tended to recommend and focused on high signal / popular videos
  3. Metadata based recommender focussed only on a very small scope of trusted video sources
  4. The recommendations did not take contents of the video into consideration
![after-qdrant-results](https://qdrant.tech/case-studies/dailymotion/after-qdrant.png)
The new recommender system implementation leveraging Qdrant along with the collaborative recommender offered various advantages :
  1. The processing time for the new video content reduced significantly to a few minutes which enabled the fresh videos to be part of recommendations.
  2. The performant & scalable scope of video recommendation currently processes 22 Million videos and can provide recommendation for videos with fewer interactions too.
  3. The overall huge performance gain on the low signal videos has contributed to more than 3 times increase on the interaction and CTR ( number of clicks) on the recommended videos.
  4. Seamlessly solved the initial cold start and low performance problems with the fresh content.
###  [](https://qdrant.tech/blog/case-study-dailymotion/#outlook--future-plans)Outlook / Future plans
The team is very excited with the results they achieved on their recommender system and wishes to continue building with it.  
They aim to work on Perspective feed next and say
> ”We’ve recently integrated this new recommendation system into our mobile app through a feature called Perspective. The aim of this feature is to disrupt the vertical feed algorithm, allowing users to discover new videos. When browsing their feed, users may encounter a video discussing a particular movie. With Perspective, they have the option to explore different viewpoints on the same topic. Qdrant plays a crucial role in this feature by generating candidate videos related to the subject, ensuring users are exposed to diverse perspectives and preventing them from being confined to an echo chamber where they only encounter similar viewpoints.”  
> Gladys Roch - Machine Learning Engineer
![perspective-feed-with-qdrant](https://qdrant.tech/case-studies/dailymotion/perspective-feed-qdrant.jpg)
The team is also interested in leveraging advanced features like [Qdrant’s Discovery API](https://qdrant.tech/documentation/concepts/explore/#recommendation-api) to promote exploration of content to enable finding not only similar but dissimilar content too by using positive and negative vectors in the queries and making it work with the existing collaborative recommendation model.
###  [](https://qdrant.tech/blog/case-study-dailymotion/#references)References
**2024 -**
**2023 -**
**2022 -**
### Get Started with Qdrant Free
![](https://qdrant.tech/img/rocket.svg)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-dailymotion/)
                    ## 📄 `https-qdrant-tech-blog-case-study-deutsche-telekom.md`
                    ```md
                    # https://qdrant.tech/blog/case-study-deutsche-telekom/
# How Deutsche Telekom Built a Multi-Agent Enterprise Platform Leveraging Qdrant
Manuel Meyer
·
March 07, 2025
![How Deutsche Telekom Built a Multi-Agent Enterprise Platform Leveraging Qdrant](https://qdrant.tech/blog/case-study-deutsche-telekom/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * How Deutsche Telekom Built a Multi-Agent Enterprise Platform Leveraging Qdrant
  *     *       * [Key Requirements for Scaling Enterprise AI Agents](https://qdrant.tech/blog/case-study-deutsche-telekom/#key-requirements-for-scaling-enterprise-ai-agents)
      * [Why Deutsche Telekom Had to Rethink Its AI Stack from the Ground Up](https://qdrant.tech/blog/case-study-deutsche-telekom/#why-deutsche-telekom-had-to-rethink-its-ai-stack-from-the-ground-up)
      * [LMOS: Deutsche Telekom’s Open-Source Multi-Agent AI PaaS for Enterprise AI](https://qdrant.tech/blog/case-study-deutsche-telekom/#lmos-deutsche-telekoms-open-source-multi-agent-ai-paas-for-enterprise-ai)
      * [Why Qdrant? Finding the Right Vector Database for LMOS](https://qdrant.tech/blog/case-study-deutsche-telekom/#why-qdrant-finding-the-right-vector-database-for-lmos)
      * [Scaling AI at Deutsche Telekom & The Future of LMOS](https://qdrant.tech/blog/case-study-deutsche-telekom/#scaling-ai-at-deutsche-telekom--the-future-of-lmos)
      * [Watch livestream with Arun](https://qdrant.tech/blog/case-study-deutsche-telekom/#watch-livestream-with-arun)
**How Deutsche Telekom Built a Scalable, Multi-Agent Enterprise Platform Leveraging Qdrant—Powering Over 2 Million Conversations Across Europe**
![Deutsche Telekom’s AI Competence Center team leading the LMOS platform development](https://qdrant.tech/blog/case-study-deutsche-telekom/dtag-team.jpg)
To achieve this, Telekom developed _(Eng: Ask Magenta)_ , a platform that includes chatbots and voice bots, built as a Platform as a Service (PaaS) to ensure scalability across Deutsche Telekom’s ten European subsidiaries.
“We knew from the start that we couldn’t just deploy RAG, tool calling, and workflows at scale without a platform-first approach,” Arun explains. “When I looked at the challenge, it looked a lot like a distributed systems and engineering challenge, not just an AI problem.”
###  [](https://qdrant.tech/blog/case-study-deutsche-telekom/#key-requirements-for-scaling-enterprise-ai-agents)Key Requirements for Scaling Enterprise AI Agents
While flashy AI demos are easy to build, Deutsche Telekom’s team quickly discovered that scaling AI agents for enterprise use presents a far more complex challenge. “This isn’t just about AI,” Arun explains. “It’s a distributed systems problem that requires rigorous engineering.” Based on their experience deploying AI across multiple regions, they identified three key challenges in scaling AI agents in production:
  1. **Handling Tenancy & Memory Management:** AI workloads spanning 10 different countries require strict data segregation and compliance.
  2. **Horizontal Scaling & Context Sharing**: AI agents require real-time processing while maintaining historical context, so efficiently storing, retrieving, and processing AI-generated context at scale is critical.
  3. **Non-Deterministic Agent Collaboration:** AI agents often exhibit unpredictable behavior, making seamless inter-agent communication and workflow orchestration complex.
“From our experience, these challenges are fundamentally distributed systems problems, not just AI problems,” Arun explains. “We need feedback loops, state management, lifecycle orchestration, and intelligent routing for staggered rollouts. Microservices alone aren’t enough — we need a domain-driven approach to AI agent design.”
This insight led to the formation of 
###  [](https://qdrant.tech/blog/case-study-deutsche-telekom/#why-deutsche-telekom-had-to-rethink-its-ai-stack-from-the-ground-up)Why Deutsche Telekom Had to Rethink Its AI Stack from the Ground Up
The team started its journey in June 2023 with a small-scale Generative AI initiative, focusing on chatbots with customized AI models. Initially, they used LangChain and a major vector database provider for vector search and retrieval, alongside a custom Dense Passage Retrieval (DPR) model fine-tuned for German language use cases.
However, as they scaled, these issues quickly emerged:
  * Memory spikes and operational instability due to the sheer number of components used in the previous provide
  * Complex maintenance requirements, with frequent dependency issues, high operational overhead due to missing memory optimizations, and streamlined deployment.
Despite efforts to improve annotations and tuning, it became evident that this approach wouldn’t scale for Deutsche Telekom.
Additionally, there was a strong need to leverage existing engineering assets, as most developers and systems were already equipped with SDKs and familiar tooling. Rather than building an entirely new stack from scratch, the focus shifted to enabling developers to build AI agents within the tools and frameworks they were already comfortable with. This approach allowed domain experts who understood the APIs and enterprise systems to quickly develop AI agents without disrupting existing workflows.
Recognizing this, the team made a bold decision: to build a **fully-fledged PaaS platform for AI agents** , streamlining development and accelerating deployment of AI Agents.
###  [](https://qdrant.tech/blog/case-study-deutsche-telekom/#lmos-deutsche-telekoms-open-source-multi-agent-ai-paas-for-enterprise-ai)LMOS: Deutsche Telekom’s Open-Source Multi-Agent AI PaaS for Enterprise AI
Recognizing that an AI-driven platform required deep engineering rigor, the Telekom team designed **LMOS (Language Models Operating System)** — a multi-agent PaaS designed for high scalability and modular AI agent deployment. Key technical decisions included:
  * **Choosing Kotlin and JVM** to ensure engineers familiar with existing Deutsche Telekom systems could easily integrate with LMOS.
  * **Moving away from pre-built frameworks** in favor of a ground-up, highly optimized solution tailored to Deutsche Telekom’s specific needs.
  * **Providing a Heroku-like experience** where engineers don’t need to worry about classifiers, agent lifecycles, deployment models, monitoring, and horizontal scaling.
  * **Enterprise Grade while being flexible:** LMOS was built with enterprise-grade scalability, versioning, and multi-tenancy in mind, while also offering the flexibility to integrate agents from other frameworks — not just JVM-based solutions — ensuring interoperability across diverse AI ecosystems.
“Our engineers already knew their APIs — billing, shopping, user profiles. Why should we introduce new abstractions that only complicate the stack?” Arun notes, “also, I envisioned us building the foundations of what I call **agentic computing** , playing a role in shaping the application stacks of the future on top of LLMs.”
![LMOS architecture diagram showing AI agent collaboration and lifecycle management](https://qdrant.tech/blog/case-study-deutsche-telekom/lmos-architecture.png)
LMOS architecture powering AI agent collaboration and lifecycle management in a cloud-native environment.
###  [](https://qdrant.tech/blog/case-study-deutsche-telekom/#why-qdrant-finding-the-right-vector-database-for-lmos)Why Qdrant? Finding the Right Vector Database for LMOS
When Deutsche Telekom began searching for a scalable, high-performance vector database, they faced operational challenges with their initial choice. Seeking a solution better suited to their PaaS-first approach and multitenancy requirements, they evaluated alternatives, and [Qdrant](https://qdrant.tech/qdrant-vector-database/) quickly stood out.
“I was looking for open-source components with deep technical expertise behind them,” Arun recalls. “I looked at Qdrant and immediately loved the simplicity, [Rust-based efficiency](https://qdrant.tech/articles/why-rust/), and [memory management capabilities](https://qdrant.tech/articles/memory-consumption/). These guys knew what they were doing.”
The team structured its evaluation around two key metrics:
  1. **Qualitative metrics** : developer experience, ease of use, memory efficiency features.
  2. **Operational simplicity** : how well it fit into their PaaS-first approach and [multitenancy requirements](https://qdrant.tech/documentation/guides/multiple-partitions/).
Deutsche Telekom’s engineers also cited several standout features that made Qdrant the right fit:
  1. **Simplicity in operations** —Qdrant is lightweight and doesn’t require an excessive component stack.
  2. **Developer experience** —libraries, multi-language clients, and cross-framework support make integrations seamless.
  3. **WebUI & Collection Visualization**—engineers found Qdrant’s [built-in collection visualization](https://qdrant.tech/documentation/web-ui/) tools highly useful.
As part of their evaluation, Deutsche Telekom engineers compared multiple solutions, weighing operational simplicity and reliability.
One engineer summarized their findings: “Qdrant has way fewer components, compared to the another that required required Kafka, Zookeeper, and only had a hot standby for its index and query nodes. If you rescale it, you get downtime. Qdrant stays up.”
###  [](https://qdrant.tech/blog/case-study-deutsche-telekom/#scaling-ai-at-deutsche-telekom--the-future-of-lmos)Scaling AI at Deutsche Telekom & The Future of LMOS
Today, LMOS with Qdrant serves as the backbone for Deutsche Telekom’s AI services, processing over 2 million conversations across three countries. The time required to develop a new agent has dropped from 15 days to just 2.
With 
“For enterprises looking to build their own AI agent platforms, the future isn’t just about AI models — it’s about scalable, open, and opinionated infrastructure. And that’s exactly what we’ve built,” says Arun Joseph.
You can learn more about Deutsche Telekom’s AI Agents and Arun’s vision for LMOS in his 
###  [](https://qdrant.tech/blog/case-study-deutsche-telekom/#watch-livestream-with-arun)Watch livestream with Arun
In this Vector Space talk, Thierry from Qdrant and Arun from Deutsche Telekom talk about the key requirements for scaling enterprise AI agents, key AI stack considerations, and how the team built a Platform as a Service (PaaS) - LMOS (Language Models Operating System) — a multi-agent PaaS designed for high scalability and modular AI agent deployment.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-deutsche-telekom/)
                    ## 📄 `https-qdrant-tech-blog-case-study-hubspot.md`
                    ```md
                    # https://qdrant.tech/blog/case-study-hubspot/
# HubSpot & Qdrant: Scaling an Intelligent AI Assistant
Andre Zayarni
·
March 24, 2025
![HubSpot & Qdrant: Scaling an Intelligent AI Assistant](https://qdrant.tech/blog/case-study-hubspot/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * HubSpot & Qdrant: Scaling an Intelligent AI Assistant
  *     * [**Challenges Scaling an Intelligent AI**](https://qdrant.tech/blog/case-study-hubspot/#challenges-scaling-an-intelligent-ai)
    * [**Why HubSpot Chose Qdrant**](https://qdrant.tech/blog/case-study-hubspot/#why-hubspot-chose-qdrant)
    * [**Faster, More Accurate Search Improves Customer Satisfaction and Engagement**](https://qdrant.tech/blog/case-study-hubspot/#faster-more-accurate-search-improves-customer-satisfaction-and-engagement)
HubSpot, a global leader in CRM solutions, continuously enhances its product suite with powerful AI-driven features. To optimize Breeze AI, its flagship intelligent assistant, HubSpot chose Qdrant as its vector database.
##  [](https://qdrant.tech/blog/case-study-hubspot/#challenges-scaling-an-intelligent-ai)**Challenges Scaling an Intelligent AI**
As HubSpot expanded its AI capabilities, it faced several critical challenges in scaling Breeze AI to meet growing user demands:
  * Delivering highly personalized, context-aware responses required a robust vector search solution that could retrieve data quickly while maintaining accuracy.
  * With increasing user interactions, HubSpot needed a scalable system capable of handling rapid data growth without performance degradation.
  * Integration with HubSpot’s existing AI infrastructure had to be swift and easy to support fast-paced development cycles.
  * HubSpot sought a future-proof vector search solution that could adapt to emerging AI advancements while maintaining high availability.
These challenges made it essential to find a high-performance, developer-friendly vector database that could power Breeze AI efficiently.
##  [](https://qdrant.tech/blog/case-study-hubspot/#why-hubspot-chose-qdrant)**Why HubSpot Chose Qdrant**
After evaluating multiple vector databases, HubSpot selected Qdrant because it significantly outperformed alternatives, ensuring that Breeze AI could quickly retrieve and rank relevant data. This was crucial for recommendation systems and contextual content retrieval, where speed and accuracy directly impact user engagement and satisfaction.
Additionally, Hubspot was able to accelerate its development timelines due to Qdrant’s developer-friendly integration process.
Beyond immediate performance gains, HubSpot’s AI infrastructure prepared itself for scale, ensuring that Breeze AI would continue to deliver real-time, relevant responses without compromising speed.
HubSpot also wanted to implement capabilities such as multi-vector search and sparse vectors, which allow for even more precise and contextually aware AI-driven interactions.
Using Qdrant, HubSpot not only solved immediate scalability challenges but also secured a long-term AI search solution capable of evolving alongside its AI roadmap.
##  [](https://qdrant.tech/blog/case-study-hubspot/#faster-more-accurate-search-improves-customer-satisfaction-and-engagement)**Faster, More Accurate Search Improves Customer Satisfaction and Engagement**
Since integrating Qdrant, HubSpot has significantly enhanced the performance and intelligence of Breeze AI.
Breeze AI now delivers highly personalized, real-time responses with exceptional contextual awareness, leading to improved customer engagement and satisfaction. With an efficient, accurate search engine, they have reduced retrieval times, ensuring that users receive relevant, timely recommendations without lag.
Moreover, HubSpot can support an increasing volume of AI-powered interactions without worrying about infrastructure bottlenecks. The system adapts to growing datasets, maintaining speed and accuracy even as HubSpot’s customer base and AI use cases expand.
From an engineering perspective, HubSpot has accelerated development cycles, bringing new AI-driven features to market faster. The reduced complexity of vector search integration has freed up engineering resources, allowing the team to focus on enhancing AI models and improving user experiences.
Looking ahead, HubSpot is actively evaluating other features, such as sparse vectors and multi-vector search, to further enhance Breeze AI’s recommendation and retrieval capabilities. These innovations will enable even deeper personalization, reinforcing HubSpot’s leadership in AI-driven customer engagement.
* * *
_“Qdrant powers our demanding recommendation and RAG applications. We chose it for its ease of deployment and high performance at scale, and we have been consistently impressed with its results. The platform’s continuous feature enhancements and overall performance gains, coupled with their responsiveness, make Qdrant a reliable solution for our AI infrastructure.”_
**– Srubin Sethu Madhavan, Technical Lead, HubSpot**
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-hubspot/)
                    ## 📄 `https-qdrant-tech-blog-case-study-kairoswealth.md`
                    ```md
                    # https://qdrant.tech/blog/case-study-kairoswealth/
# Kairoswealth & Qdrant: Transforming Wealth Management with AI-Driven Insights and Scalable Vector Search
Qdrant
·
July 10, 2024
![Kairoswealth & Qdrant: Transforming Wealth Management with AI-Driven Insights and Scalable Vector Search](https://qdrant.tech/blog/case-study-kairoswealth/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Kairoswealth & Qdrant: Transforming Wealth Management with AI-Driven Insights and Scalable Vector Search
  *     * [**About Kairoswealth**](https://qdrant.tech/blog/case-study-kairoswealth/#about-kairoswealth)
    * [**Motivations for Adopting a Vector Database**](https://qdrant.tech/blog/case-study-kairoswealth/#motivations-for-adopting-a-vector-database)
    * [**Challenges with Previous Solutions**](https://qdrant.tech/blog/case-study-kairoswealth/#challenges-with-previous-solutions)
    * [**Qdrant Use Cases at Kairoswealth**](https://qdrant.tech/blog/case-study-kairoswealth/#qdrant-use-cases-at-kairoswealth)
    * [**Why Kairoswealth Chose Qdrant**](https://qdrant.tech/blog/case-study-kairoswealth/#why-kairoswealth-chose-qdrant)
    * [**Conclusion**](https://qdrant.tech/blog/case-study-kairoswealth/#conclusion)
    * [**Future Roadmap for Kairoswealth**](https://qdrant.tech/blog/case-study-kairoswealth/#future-roadmap-for-kairoswealth)
![Kairoswealth overview](https://qdrant.tech/blog/case-study-kairoswealth/image2.png)
##  [](https://qdrant.tech/blog/case-study-kairoswealth/#about-kairoswealth)**About Kairoswealth**
![Dashboard Kairoswealth](https://qdrant.tech/blog/case-study-kairoswealth/image3.png)
##  [](https://qdrant.tech/blog/case-study-kairoswealth/#motivations-for-adopting-a-vector-database)**Motivations for Adopting a Vector Database**
“At Kairoswealth we encountered several use cases necessitating the ability to run similarity queries on large datasets. Key applications included product recommendations and retrieval-augmented generation (RAG),” says 
##  [](https://qdrant.tech/blog/case-study-kairoswealth/#challenges-with-previous-solutions)**Challenges with Previous Solutions**
“We faced several critical showstoppers with our previous vector database solution, which led us to seek an alternative,” says Teyssier. These challenges included:
  * **Performance Scalability:** Significant performance degradation occurred as more data was added, despite various optimizations.
  * **Robust Multi-Tenancy:** The previous solution struggled with multi-tenancy, impacting performance.
  * **RAM Footprint:** High memory consumption was an issue.
##  [](https://qdrant.tech/blog/case-study-kairoswealth/#qdrant-use-cases-at-kairoswealth)**Qdrant Use Cases at Kairoswealth**
Kairoswealth leverages Qdrant for several key use cases:
  * **Internal Data RAG:** Efficiently handling internal RAG use cases.
  * **Financial Regulatory Reports RAG:** Managing and generating financial reports.
  * **Recommendations:** Enhancing the accuracy and efficiency of recommendations with the Kairoswealth platform.
![Stock recommendation](https://qdrant.tech/blog/case-study-kairoswealth/image1.png)
##  [](https://qdrant.tech/blog/case-study-kairoswealth/#why-kairoswealth-chose-qdrant)**Why Kairoswealth Chose Qdrant**
Some of the key reasons, why Kairoswealth landed on Qdrant as the vector database of choice are:
  1. **High Performance with 2.4M Vectors:** “Qdrant efficiently handled the indexing of 1.2 million vectors with 16 metadata fields each, maintaining high performance with no degradation. Similarity queries and scrolls run in less than 0.3 seconds. When we doubled the dataset to 2.4 million vectors, performance remained consistent.So we decided to double that to 2.4M vectors, and it’s as if we were inserting our first vector!” says Teyssier.
  2. **8x Memory Efficiency:** The database storage size with Qdrant was eight times smaller than the previous solution, enabling the deployment of the entire dataset on smaller instances and saving significant infrastructure costs.
  3. **Embedded Capabilities:** “Beyond simple search and similarity, Qdrant hosts a bunch of very nice features around recommendation engines, adding positive and negative examples for better spacial narrowing, efficient multi-tenancy, and many more,” says Teyssier.
  4. **Support and Community:** “The Qdrant team, led by Andre Zayarni, provides exceptional support and has a strong passion for data engineering,” notes Teyssier, “the team’s commitment to open-source and their active engagement in helping users, from beginners to veterans, is highly valued by Kairoswealth.”
##  [](https://qdrant.tech/blog/case-study-kairoswealth/#conclusion)**Conclusion**
Kairoswealth’s transition to Qdrant has enabled them to overcome significant challenges related to performance, scalability, and memory efficiency, while also benefiting from advanced features and robust support. This partnership positions Kairoswealth to continue innovating in the wealth management sector, leveraging the power of AI to deliver superior services to their clients.
##  [](https://qdrant.tech/blog/case-study-kairoswealth/#future-roadmap-for-kairoswealth)**Future Roadmap for Kairoswealth**
Kairoswealth is seizing the opportunity to disrupt the wealth management sector, which has traditionally been underserved by technology. For example, they are developing the Kairos Terminal, a natural language interface that translates user queries into OpenBB commands (a set of tools for financial analysis and data visualization within the OpenBB Terminal). With regards to the future of the wealth management sector, Teyssier notes that “the integration of Generative AI will automate back-office tasks such as data collation, data reconciliation, and market research. This technology will also enable wealth managers to scale their services to broader segments, including affluent clients, by automating relationship management and interactions.”
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-kairoswealth/)
                    ## 📄 `https-qdrant-tech-blog-case-study-kern.md`
                    ```md
                    # https://qdrant.tech/blog/case-study-kern/
# Kern AI & Qdrant: Precision AI Solutions for Finance and Insurance
Qdrant
·
August 28, 2024
![Kern AI & Qdrant: Precision AI Solutions for Finance and Insurance](https://qdrant.tech/blog/case-study-kern/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Kern AI & Qdrant: Precision AI Solutions for Finance and Insurance
  *     * [About Kern AI](https://qdrant.tech/blog/case-study-kern/#about-kern-ai)
    * [The Challenge](https://qdrant.tech/blog/case-study-kern/#the-challenge)
    * [The Solution](https://qdrant.tech/blog/case-study-kern/#the-solution)
    * [The Results](https://qdrant.tech/blog/case-study-kern/#the-results)
    * [Outlook](https://qdrant.tech/blog/case-study-kern/#outlook)
![kern-case-study](https://qdrant.tech/blog/case-study-kern/kern-case-study.png)
##  [](https://qdrant.tech/blog/case-study-kern/#about-kern-ai)About Kern AI
With the rise of ChatGPT, Kern AI expanded its platform to support the quick development of accurate and secure Generative AI by integrating large language models (LLMs) like GPT, tailoring solutions specifically for the financial services sector. Kern AI’s solution enhances the reliability of any LLM by modeling and integrating company data in a way LLMs can understand, offering a platform with leading data modeling capabilities.
##  [](https://qdrant.tech/blog/case-study-kern/#the-challenge)The Challenge
Kern AI has partnered with leading insurers to efficiently streamline the process of managing complex customer queries within customer service teams, reducing the time and effort required. Customer inquiries are often complex, and support teams spend significant time locating and interpreting relevant sections in insurance contracts. This process leads to delays in responses and can negatively impact customer satisfaction.
To tackle this, Kern AI developed an internal AI chatbot for first-level support teams. Their platform helps data science teams improve data foundations to expedite application production. By using embeddings to identify relevant data points and outliers, Kern AI ensures more efficient and accurate data handling. To avoid being restricted to a single embedding model, they experimented with various models, including sentiment embeddings, leading them to discover Qdrant.
![kern-user-interface](https://qdrant.tech/blog/case-study-kern/kern-user-interface.png)
_Kern AI Refinery, is an open-source tool to scale, assess and maintain natural language data._
The impact of their solution is evident in the case of 
##  [](https://qdrant.tech/blog/case-study-kern/#the-solution)The Solution
Kern AI discovered Qdrant and was impressed by its interactive Discord community, which highlighted the active support and continuous improvements of the platform. Qdrant was the first vector database the team used, and after testing other alternatives, they chose Qdrant for several reasons:
  * **Multi-vector Storage** : This feature was crucial as it allowed the team to store and manage different search indexes. Given that no single embedding fits all use cases, this capability brought essential diversity to their embeddings, enabling more flexible and robust data handling.
  * **Easy Setup** : Qdrant’s straightforward setup process enabled Kern AI to quickly integrate and start utilizing the database without extensive overhead, which was critical for maintaining development momentum.
  * **Open Source** : The open-source nature of Qdrant aligned with Kern AI’s own product development philosophy. This allowed for greater customization and integration into their existing open-source projects.
  * **Rapid Progress** : Qdrant’s swift advancements and frequent updates ensured that Kern AI could rely on continuous improvements and cutting-edge features to keep their solutions competitive.
  * **Multi-vector Search** : Allowed Kern AI to perform complex queries across different embeddings simultaneously, enhancing the depth and accuracy of their search results.
  * **Hybrid Search/Filters** : Enabled the combination of traditional keyword searches with vector searches, allowing for more nuanced and precise data retrieval.
Kern AI uses Qdrant’s open-source, on-premise solution for both their open-source project and their commercial end-to-end framework. This framework, focused on the financial and insurance markets, is similar to LangChain or LlamaIndex but tailored to the industry-specific needs.
![kern-data-retrieval](https://qdrant.tech/blog/case-study-kern/kern-data-retrieval.png)
_Configuring data retrieval in Kern AI: Fine-tuning search inputs and metadata for optimized information extraction._
##  [](https://qdrant.tech/blog/case-study-kern/#the-results)The Results
Kern AI’s primary use case focuses on enhancing customer service with extreme precision. Leveraging Qdrant’s advanced vector search capabilities, Kern AI consistently maintains hallucination rates under 1%. This exceptional accuracy allows them to build the most precise RAG (Retrieval-Augmented Generation) chatbot for financial services.
Key Achievements:
  * **< 1% Hallucination Rate**: Ensures the highest level of accuracy and reliability in their chatbot solutions for the financial and insurance sector.
  * **Reduced Customer Service Response Times** : Using Kern AI’s solution, Markel Insurance SE reduced response times from five minutes to under 30 seconds, significantly improving customer experience and operational efficiency.
By utilizing Qdrant, Kern AI effectively supports various use cases in financial services, such as:
  * **Claims Management** : Streamlining the claims process by quickly identifying relevant data points.
  * **Similarity Search** : Enhancing incident handling by finding similar cases to improve decision-making quality.
##  [](https://qdrant.tech/blog/case-study-kern/#outlook)Outlook
Kern AI plans to expand its use of Qdrant to support both brownfield and greenfield use cases across the financial and insurance industry.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-kern/)
                    ## 📄 `https-qdrant-tech-blog-case-study-mixpeek.md`
                    ```md
                    # https://qdrant.tech/blog/case-study-mixpeek/
# How Mixpeek Uses Qdrant for Efficient Multimodal Feature Stores
Daniel Azoulai
·
April 08, 2025
![How Mixpeek Uses Qdrant for Efficient Multimodal Feature Stores](https://qdrant.tech/blog/case-study-mixpeek/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * How Mixpeek Uses Qdrant for Efficient Multimodal Feature Stores
  * [How Mixpeek Uses Qdrant for Efficient Multimodal Feature Stores](https://qdrant.tech/blog/case-study-mixpeek/#how-mixpeek-uses-qdrant-for-efficient-multimodal-feature-stores)
    * [About Mixpeek](https://qdrant.tech/blog/case-study-mixpeek/#about-mixpeek)
    * [The Challenge: Optimizing Feature Stores for Complex Retrievers](https://qdrant.tech/blog/case-study-mixpeek/#the-challenge-optimizing-feature-stores-for-complex-retrievers)
    * [Why Mixpeek Chose Qdrant for Feature Stores](https://qdrant.tech/blog/case-study-mixpeek/#why-mixpeek-chose-qdrant-for-feature-stores)
      * [Simplifying Hybrid Retrievers](https://qdrant.tech/blog/case-study-mixpeek/#simplifying-hybrid-retrievers)
      * [40% Faster Query Times with Parallel Retrieval](https://qdrant.tech/blog/case-study-mixpeek/#40-faster-query-times-with-parallel-retrieval)
      * [Optimizing SageMaker Feature Extraction Workflows](https://qdrant.tech/blog/case-study-mixpeek/#optimizing-sagemaker-feature-extraction-workflows)
    * [Supporting Mixpeek’s Taxonomy and Clustering Architecture](https://qdrant.tech/blog/case-study-mixpeek/#supporting-mixpeeks-taxonomy-and-clustering-architecture)
      * [Taxonomies (JOIN Analogue)](https://qdrant.tech/blog/case-study-mixpeek/#taxonomies-join-analogue)
      * [Clustering (GROUP BY Analogue)](https://qdrant.tech/blog/case-study-mixpeek/#clustering-group-by-analogue)
    * [Measurable Improvements After Feature Store Migration](https://qdrant.tech/blog/case-study-mixpeek/#measurable-improvements-after-feature-store-migration)
    * [Future Direction: Supporting Diverse Multimodal Use Cases](https://qdrant.tech/blog/case-study-mixpeek/#future-direction-supporting-diverse-multimodal-use-cases)
    * [Conclusion: Specialized Feature Stores for Multimodal Data Warehousing](https://qdrant.tech/blog/case-study-mixpeek/#conclusion-specialized-feature-stores-for-multimodal-data-warehousing)
#  [](https://qdrant.tech/blog/case-study-mixpeek/#how-mixpeek-uses-qdrant-for-efficient-multimodal-feature-stores)How Mixpeek Uses Qdrant for Efficient Multimodal Feature Stores
![How Mixpeek Uses Qdrant for Efficient Multimodal Feature Stores](https://qdrant.tech/blog/case-study-mixpeek/Case-Study-Mixpeek-Summary-Dark.jpg)
##  [](https://qdrant.tech/blog/case-study-mixpeek/#about-mixpeek)About Mixpeek
##  [](https://qdrant.tech/blog/case-study-mixpeek/#the-challenge-optimizing-feature-stores-for-complex-retrievers)The Challenge: Optimizing Feature Stores for Complex Retrievers
As Mixpeek’s multimodal data warehouse evolved, their feature stores needed to support increasingly complex retrieval patterns. Initially using MongoDB Atlas’s vector search, they encountered limitations when implementing **combining dense and sparse vectors with metadata pre-filtering**.
A critical limitation emerged when implementing **late interaction techniques like ColBERT across video embeddings** , which requires multi-vector indexing. MongoDB’s kNN search could not support these multi-vector representations for this contextual understanding.
Another one of Mixpeek’s customers required **reverse video search** for programmatic ad-serving, where retrievers needed to identify **high-converting video segments** across massive object collections - a task that proved inefficient with MongoDB’s general-purpose database feature stores.
_“We eliminated hundreds of lines of code with what was previously a MongoDB kNN Hybrid search when we replaced it with Qdrant as our feature store.”_ — Ethan Steininger, Mixpeek Founder
![mixpeek-architecture-with-qdrant](https://qdrant.tech/blog/case-study-mixpeek/mixpeek-architecture.jpg)
##  [](https://qdrant.tech/blog/case-study-mixpeek/#why-mixpeek-chose-qdrant-for-feature-stores)Why Mixpeek Chose Qdrant for Feature Stores
After evaluating multiple options including **Postgres with pgvector** and **MongoDB’s kNN search** , Mixpeek selected Qdrant to power 
###  [](https://qdrant.tech/blog/case-study-mixpeek/#simplifying-hybrid-retrievers)Simplifying Hybrid Retrievers
Previously, Mixpeek maintained complex custom logic to merge results from different feature stores. Qdrant’s native support for Reciprocal Rank Fusion (RRF) streamlined their retriever implementations, reducing hybrid search code by **80%**. The multi-vector capabilities also enabled more sophisticated retrieval methods that better captured semantic relationships.
_“Hybrid retrievers with our previous feature stores were challenging. With Qdrant, it just worked.”_
###  [](https://qdrant.tech/blog/case-study-mixpeek/#40-faster-query-times-with-parallel-retrieval)40% Faster Query Times with Parallel Retrieval
For collections with billions of features, Qdrant’s prefetching capabilities enabled parallel retrieval across multiple feature stores. This cut retriever query times by 40%, dropping from ~2.5s to 1.3-1.6s.
_“Prefetching in Qdrant lets us execute multiple feature store retrievals simultaneously and then combine the results, perfectly supporting our retriever pipeline architecture.”_
###  [](https://qdrant.tech/blog/case-study-mixpeek/#optimizing-sagemaker-feature-extraction-workflows)Optimizing SageMaker Feature Extraction Workflows
Mixpeek uses Amazon SageMaker for 
_“We were running inference with SageMaker for feature extraction, and our feature store queries used to be a significant bottleneck. Qdrant shaved off a lot of that time.”_
##  [](https://qdrant.tech/blog/case-study-mixpeek/#supporting-mixpeeks-taxonomy-and-clustering-architecture)Supporting Mixpeek’s Taxonomy and Clustering Architecture
Qdrant proved particularly effective for implementing Mixpeek’s taxonomy and clustering capabilities:
###  [](https://qdrant.tech/blog/case-study-mixpeek/#taxonomies-join-analogue)Taxonomies (JOIN Analogue)
Qdrant’s payload filtering facilitated efficient implementation of both 
###  [](https://qdrant.tech/blog/case-study-mixpeek/#clustering-group-by-analogue)Clustering (GROUP BY Analogue)
The platform’s batch vector search capabilities streamlined 
##  [](https://qdrant.tech/blog/case-study-mixpeek/#measurable-improvements-after-feature-store-migration)Measurable Improvements After Feature Store Migration
The migration to Qdrant as Mixpeek’s feature store brought significant improvements:
  * **40% Faster Retrievers** : Reduced query times from ~2.5s to 1.3-1.6s
  * **80% Code Reduction** : Simplified retriever implementations
  * **Improved Developer Productivity** : Easier implementation of complex retrieval patterns
  * **Optimized Scalability** : Better performance at billion-feature scale
  * **Enhanced Multimodal Retrieval** : Better support for combining different feature types
##  [](https://qdrant.tech/blog/case-study-mixpeek/#future-direction-supporting-diverse-multimodal-use-cases)Future Direction: Supporting Diverse Multimodal Use Cases
Mixpeek’s architecture excels by pre-building specialized feature extractors tightly coupled with retriever pipelines, enabling efficient processing across 
This architectural approach ensures that features extracted during ingestion are precisely what retrievers need for efficient querying, eliminating translation layers that typically slow down multimodal systems.
_“We’re moving towards sophisticated multimodal ontologies, and Qdrant’s specialized capabilities as a feature store will be essential for these advanced retriever strategies.”_
##  [](https://qdrant.tech/blog/case-study-mixpeek/#conclusion-specialized-feature-stores-for-multimodal-data-warehousing)Conclusion: Specialized Feature Stores for Multimodal Data Warehousing
Mixpeek’s journey highlights the importance of specialized feature stores in a multimodal data warehouse architecture. Qdrant’s focus on vector search efficiency made it the ideal choice for powering Mixpeek’s feature stores, enabling more efficient retrievers and ingestion pipelines.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-mixpeek/)
                    ## 📄 `https-qdrant-tech-blog-case-study-nyris.md`
                    ```md
                    # https://qdrant.tech/blog/case-study-nyris/
# Nyris & Qdrant: How Vectors are the Future of Visual Search
Qdrant
·
September 10, 2024
![Nyris & Qdrant: How Vectors are the Future of Visual Search](https://qdrant.tech/blog/case-study-nyris/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Nyris & Qdrant: How Vectors are the Future of Visual Search
  *     * [About Nyris](https://qdrant.tech/blog/case-study-nyris/#about-nyris)
    * [Overcoming Limitations in Visual Product Search](https://qdrant.tech/blog/case-study-nyris/#overcoming-limitations-in-visual-product-search)
    * [The Path to Vector-Based Visual Search](https://qdrant.tech/blog/case-study-nyris/#the-path-to-vector-based-visual-search)
      * [The Selection Process](https://qdrant.tech/blog/case-study-nyris/#the-selection-process)
    * [Key Benefits of Qdrant in Production](https://qdrant.tech/blog/case-study-nyris/#key-benefits-of-qdrant-in-production)
    * [Why Pure-Vector Search is the Future for Product Search](https://qdrant.tech/blog/case-study-nyris/#why-pure-vector-search-is-the-future-for-product-search)
![nyris-case-study](https://qdrant.tech/blog/case-study-nyris/nyris-case-study.png)
##  [](https://qdrant.tech/blog/case-study-nyris/#about-nyris)About Nyris
Founded in 2015 by CTO Markus Lukasson and his sister Anna Lukasson-Herzig, 
Beyond visual search, Nyris also provides synthetic data solutions, particularly for manufacturing and engineering sectors. Often, customers in these industries lack sufficient photos of parts to leverage visual search effectively. However, they do possess CAD files for their products. Nyris generates synthetic images from these CAD files, enabling visual search without needing actual product photos in the database.
Prominent clients such as IKEA, Trumpf (a precision laser manufacturer), and DMG Mori rely on Nyris to support their field engineers in maintaining parts.
![nyris-visual-search](https://qdrant.tech/blog/case-study-nyris/nyris-visual-search.png)
##  [](https://qdrant.tech/blog/case-study-nyris/#overcoming-limitations-in-visual-product-search)Overcoming Limitations in Visual Product Search
During his time at Amazon, Lukasson observed that search engines like Google often outperformed Amazon’s search capabilities for product searches. Recognizing the need for more precise search solutions in industries like e-commerce and spare part management, he identified a significant gap: Traditional keyword-based searches often fail, especially in situations where field engineers struggle to describe parts accurately with keywords. Visual search offers a solution, providing faster and more accurate results by leveraging images, which carry significantly more information than text-based queries.
In their quest for the perfect visual search provider, Nyris ultimately decided to develop their own solution.
##  [](https://qdrant.tech/blog/case-study-nyris/#the-path-to-vector-based-visual-search)The Path to Vector-Based Visual Search
Initially in 2015, the team explored traditional search algorithms based on key value SIFT (Scale Invariant Feature Transform) features to locate specific elements within images. However, they quickly realized that these methods were imprecise and unreliable. To address this, Nyris began experimenting with the first Convolutional Neural Networks (CNNs) to extract embeddings for vector search.
In the early days of vector search, there were few solutions available. Nyris initially developed their own vector search solution but later transitioned to SingleStore. At that time, SingleStore was the only option that could deliver efficient and fast brute-force vector search at scale. As Nyris’s data grew, the need for rapid scaling became evident. They found that many standard database features, such as real-time analytics and atomicity, were unnecessary for their specific needs. Instead, what Nyris required was a solution focused on fast and efficient vector search capabilities, along with features that would enhance the search experience for their customers.
With the emergence of pure-play, native vector search engines, Nyris conducted extensive research and benchmarks. Ultimately, they chose Qdrant as their vector search engine of choice. Qdrant stood out for its accuracy, speed, and the ability to handle large datasets efficiently, meeting all of Nyris’s requirements for a robust and scalable vector search solution.
###  [](https://qdrant.tech/blog/case-study-nyris/#the-selection-process)The Selection Process
As part of their selection process, Nyris evaluated several critical factors to ensure they chose the best vector search engine solution:
  * **Accuracy and Speed** : These were primary considerations. Nyris needed to understand the performance differences between the [HNSW](https://qdrant.tech/articles/filtrable-hnsw/) graph-based approach and brute-force search. In particular, they examined edge cases that required numerous filters, sometimes necessitating a switch to brute-force search. Even in these scenarios, Qdrant demonstrated impressive speed and reliability, meeting Nyris’s stringent performance requirements.
  * **Insert Speed** : Nyris assessed how quickly data could be inserted into the database, including the performance during simultaneous data ingests and query requests. Qdrant excelled in this area, providing the necessary efficiency for their operations.
  * **Total Cost of Ownership** : Nyris analyzed the infrastructure costs and licensing fees associated with each solution. Qdrant offered a competitive total cost of ownership, making it an economically viable option.
  * **Data Sovereignty** : The ability to deploy Qdrant in their own clusters was a key aspect for Nyris, ensuring they maintained control over their data and complied with relevant data sovereignty requirements.
  * **Dedicated Vector Search Engine:** One of the key advantages of Qdrant, as Lukasson highlights, is its specialization as a dedicated, native vector search engine. “Qdrant, being purpose-built for vector search, can introduce relevant features much faster, like [quantization](https://qdrant.tech/documentation/guides/quantization/), integer8 support, and float32 rescoring. These advancements make searches more precise and cost-effective without sacrificing accuracy—exactly what Nyris needs,” said Lukasson. “When optimizing for search accuracy and speed, compromises aren’t an option. Just as you wouldn’t use a truck to race in Formula 1, we needed a solution designed specifically for vector search, not just a general database with vector search tacked on. With every Qdrant release, we gain new, tailored features that directly enhance our use case.”
##  [](https://qdrant.tech/blog/case-study-nyris/#key-benefits-of-qdrant-in-production)Key Benefits of Qdrant in Production
Nyris has found several aspects of Qdrant particularly beneficial in their production environment:
  * **Enhanced Security with JWT** : [JSON Web Tokens](https://qdrant.tech/documentation/guides/security/#granular-access-control-with-jwt) provide enhanced security and performance, critical for safeguarding their data.
  * **Seamless Scalability** : Qdrant’s ability to [scale effortlessly across nodes](https://qdrant.tech/documentation/guides/distributed_deployment/) ensures consistent high performance, even as Nyris’s data volume grows.
  * **Flexible Search Options** : The availability of both graph-based and brute-force search methods offers Nyris the flexibility to tailor the search approach to specific use case requirements.
  * **Versatile Data Handling** : Qdrant imposes almost no restrictions on data types and vector sizes, allowing Nyris to manage diverse and complex datasets effectively.
  * **Built with Rust** : The use of [Rust](https://qdrant.tech/articles/why-rust/) ensures superior performance and future-proofing, while its open-source nature allows Nyris to inspect and customize the code as necessary.
  * **Cost-Effective High Performance Search** : Qdrant’s efficient search capabilities ensure that Nyris can maintain high performance at a reasonable cost. With Qdrant, Nyris can search through extensive datasets efficiently, making it a crucial part of their technology stack.
By hosting Qdrant on Google Cloud within their Kubernetes Cluster, Nyris benefits from the scalability and reliability essential for their demanding operations, ensuring a robust and efficient visual search solution.
##  [](https://qdrant.tech/blog/case-study-nyris/#why-pure-vector-search-is-the-future-for-product-search)Why Pure-Vector Search is the Future for Product Search
Nyris’s vision is to identify every single product and spare part within milliseconds, and Qdrant plays an integral role in this. When envisioning the future of product search, Lukasson is convinced that vector representations will be the key to advancing search capabilities. Unlike keyword searches, vector search can seamlessly integrate various modalities, such as text, images, as well as depth or audio. This holistic approach will transform product and spare part searches, allowing for a single vector representation that encompasses a product’s text, visual and geometric descriptions.
“While traditional algorithms like BM25 are fast and cheap and still have a place in the search stack, vectors will replace them in the coming years,” says Lukasson. “Today, we have separate spaces for text search, visual search, and other modalities, but we envision a future with a unified vector representation that encompasses all relevant item data. No matter what input you use for your query, the search results will be accurate. The days of scrolling through thousands of results or encountering ’no results’ pages will soon be over. Every search request will deliver the right product or spare part in milliseconds.”
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-nyris/)
                    ## 📄 `https-qdrant-tech-blog-case-study-qatech.md`
                    ```md
                    # https://qdrant.tech/blog/case-study-qatech/
# Empowering QA.tech’s Testing Agents with Real-Time Precision and Scale
Qdrant
·
November 21, 2024
![Empowering QA.tech’s Testing Agents with Real-Time Precision and Scale](https://qdrant.tech/blog/case-study-qatech/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Empowering QA.tech’s Testing Agents with Real-Time Precision and Scale
  *     * [What prompted QA.tech to use a vector database?](https://qdrant.tech/blog/case-study-qatech/#what-prompted-qatech-to-use-a-vector-database)
    * [Why QA.tech chose Qdrant for its AI Agent platform](https://qdrant.tech/blog/case-study-qatech/#why-qatech-chose-qdrant-for-its-ai-agent-platform)
    * [How QA.tech Overcame Key Challenges in AI Agent Development](https://qdrant.tech/blog/case-study-qatech/#how-qatech-overcame-key-challenges-in-ai-agent-development)
![qdrant-qatech-1](https://qdrant.tech/blog/case-study-qatech/qdrant-qatech-1.png)
**fully testing web applications, especially end-to-end, can be complex and time-consuming**. Unlike unit tests, end-to-end tests reveal what’s actually happening in the browser, often uncovering issues that other methods miss.
Traditional solutions like hard-coded tests are not only labor-intensive to set up but also challenging to maintain over time. Alternatively, hiring QA testers can be a solution, but for startups, it quickly becomes a bottleneck. With every release, more testers are needed, and if testing is outsourced, managing timelines and ensuring quality becomes even harder.
To address this, QA.tech has developed **testing agents** that perform tasks on the browser just like a user would - for example, purchasing a ticket on a travel app. These agents navigate the entire booking process, from searching for flights to completing the purchase, all while assessing their success. **They document errors, record the process, and flag issues for developers to review.** With access to console logs and network calls, developers can easily analyze each step, quickly understanding and debugging any issues that arise.
![qdrant-qatech-2](https://qdrant.tech/blog/case-study-qatech/qdrant-qatech-2.png)
_Output from a QA.tech AI agent_
##  [](https://qdrant.tech/blog/case-study-qatech/#what-prompted-qatech-to-use-a-vector-database)What prompted QA.tech to use a vector database?
QA.tech initially used **pgvector** for simpler vector use cases but encountered scalability limitations as their requirements grew, prompting them to adopt Qdrant. They needed a [vector database](https://qdrant.tech/qdrant-vector-database/) capable of handling high-velocity, real-time analysis to support their AI agents, which operate within an analysis layer that observes and interprets actions across web pages. This analysis layer relies heavily on multimodal models and substantial subprocessing to enable the AI agent to make informed, real-time decisions.
In some web interfaces, hundreds of actions can occur, and processing them in real time - especially with each click - can be slow. Dynamic web elements and changing identifiers further complicate this, making traditional methods unreliable. To address these challenges, QA.tech trained custom embeddings on specific actions, which significantly accelerates decision-making.
This setup requires frequent embedding lookups, generating a high volume of database calls for each interaction. As **Vilhelm von Ehrenheim from QA.tech** explained:
> “You get a lot of embeddings, a lot of calls, a lot of lookups towards the database for every click, and that needs to scale nicely.”
Qdrant’s fast, scalable [vector search](https://qdrant.tech/advanced-search/) enables QA.tech to handle these high-velocity lookups seamlessly, ensuring that the agent remains responsive and capable of making quick, accurate decisions in real time.
##  [](https://qdrant.tech/blog/case-study-qatech/#why-qatech-chose-qdrant-for-its-ai-agent-platform)Why QA.tech chose Qdrant for its AI Agent platform
QA.tech’s AI Agents handle high-velocity web actions, requiring efficient real-time operations and scalable infrastructure. The team faced challenges with managing network overhead, CPU load, and the need to store [multiple embeddings](https://qdrant.tech/documentation/concepts/vectors/#multivectors) for different use cases. Qdrant provided the solution to address these issues.
**Reducing Network Overhead with Batch Operations**
Handling hundreds of simultaneous actions on a web interface individually created significant network overhead. Von Ehrenheim explained that “doing all of those in separate calls creates a lot of network overhead.” Qdrant’s batch operations allowed QA.tech to process multiple actions at once, reducing network traffic and improving efficiency. This capability is essential for AI Agents, where real-time responsiveness is critical.
**Optimizing CPU Load for Embedding Processing**
PostgreSQL’s transaction guarantees resulted in high CPU usage when processing embeddings, especially at scale. Von Ehrenheim noted that adding many new embeddings “requires much more CPU,” which led to performance bottlenecks. Qdrant’s architecture efficiently handled large-scale embeddings, preventing CPU overload and ensuring smooth, uninterrupted performance, a key requirement for AI Agents.
**Managing Multiple Embeddings for Different Use Cases**
AI Agents need flexibility in handling both real-time actions and context-aware tasks. QA.tech required different embeddings for immediate action processing and deeper semantic searches. Von Ehrenheim mentioned, _“We use one embedding for high-velocity actions, but I also want to store other types of embeddings for analytical purposes.”_
> Qdrant’s ability to store multiple embeddings per data point allowed QA.tech to meet these diverse needs without added complexity.
##  [](https://qdrant.tech/blog/case-study-qatech/#how-qatech-overcame-key-challenges-in-ai-agent-development)How QA.tech Overcame Key Challenges in AI Agent Development
Building reliable AI agents presents unique complexities, particularly as workflows grow more multi-step and dynamic.
> “The more steps you ask an agent to take, the harder it becomes to ensure consistent performance,” Vilhelm von Ehrenheim, Co-Founder of QA.tech.
Each additional action adds layers of interdependent variables, creating pathways that can easily lead to errors if not managed carefully.
Von Ehrenheim also points out the limitations of current large language models (LLMs), noting that _“LLMs are getting more powerful, but they still struggle with multi-step reasoning and for example handling subtle visual changes like dark mode or adaptive UIs.”_ These challenges make it essential for agents to have precise planning capabilities and context awareness, which QA.tech has addressed by implementing custom embeddings and multimodal models.
_“This is where scalable, adaptable infrastructure becomes crucial,”_ von Ehrenheim adds. Qdrant has been instrumental for QA.tech, providing stable, high-performance vector search to support the demanding workflows. **“With Qdrant, we’re able to handle these complex, high-velocity tasks without compromising on reliability.”**
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-qatech/)
                    ## 📄 `https-qdrant-tech-blog-case-study-sprinklr.md`
                    ```md
                    # https://qdrant.tech/blog/case-study-sprinklr/
# How Sprinklr Leverages Qdrant to Enhance AI-Driven Customer Experience Solutions
Qdrant
·
October 17, 2024
![How Sprinklr Leverages Qdrant to Enhance AI-Driven Customer Experience Solutions](https://qdrant.tech/blog/case-study-sprinklr/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * How Sprinklr Leverages Qdrant to Enhance AI-Driven Customer Experience Solutions
  *     * [The Need for a Vector Database](https://qdrant.tech/blog/case-study-sprinklr/#the-need-for-a-vector-database)
      * [Why Qdrant?](https://qdrant.tech/blog/case-study-sprinklr/#why-qdrant)
    * [Implementation and Qdrant’s Performance](https://qdrant.tech/blog/case-study-sprinklr/#implementation-and-qdrants-performance)
      * [Key Outcomes with Qdrant](https://qdrant.tech/blog/case-study-sprinklr/#key-outcomes-with-qdrant)
    * [Outlook](https://qdrant.tech/blog/case-study-sprinklr/#outlook)
    * [Benchmarking Conclusion](https://qdrant.tech/blog/case-study-sprinklr/#benchmarking-conclusion)
![case-study-sprinklr-1](https://qdrant.tech/blog/case-study-sprinklr/image1.png)
Raghav Sonavane, Associate Director of Machine Learning Engineering at Sprinklr, leads the Applied AI team, focusing on Generative AI (GenAI) and Retrieval-Augmented Generation (RAG). His team is responsible for training and fine-tuning in-house models and deploying advanced retrieval and generation systems for customer-facing applications like FAQ bots and other 
![case-study-sprinklr-2](https://qdrant.tech/blog/case-study-sprinklr/image2.png)
_Figure:_ Sprinklr’s RAG architecture
Sprinklr’s platform is composed of four key product suites - Sprinklr Service, Sprinklr Marketing, Sprinklr Social, and Sprinklr Insights. Each suite is embedded with AI-first features such as assist agents, post-call analysis, and real-time analytics, which are crucial for managing large-scale contact center operations. “These AI-driven capabilities, supported by Qdrant’s advanced vector search, enhance Sprinklr’s customer-facing tools such as FAQ bots, transactional bots, conversational services, and product recommendation engines,” says Sonavane.
These self-serve applications rely heavily on advanced vector search to analyze and optimize community content and refine knowledge bases, ensuring efficient and relevant responses. For customers requiring further assistance, Sprinklr equips support agents with powerful search capabilities, enabling them to quickly access similar cases and draw from past interactions, enhancing the quality and speed of customer support.
##  [](https://qdrant.tech/blog/case-study-sprinklr/#the-need-for-a-vector-database)The Need for a Vector Database
To support various AI-driven applications, Sprinklr needed an efficient vector database. “The key challenge was to provide the highest quality and fastest search capabilities for retrieval tasks across the board,” explains Sonavane.
Last year, Sprinklr undertook a comprehensive evaluation of its existing search infrastructure. The goals were to identify current capability gaps, benchmark performance for speed and cost, and explore opportunities to improve the developer experience through enhanced scalability and stronger data privacy controls. It became clear that an advanced vector database was essential to meet these needs, and Qdrant emerged as the ideal solution.
###  [](https://qdrant.tech/blog/case-study-sprinklr/#why-qdrant)Why Qdrant?
After evaluating several options of vector DBs, including Pinecone, Weaviate, and ElasticSearch, Sprinklr chose Qdrant for its:
  * **Developer-Friendly Documentation:** “Qdrant’s clear [documentation](https://qdrant.tech/documentation/) enabled our team to integrate it quickly into our workflows,” notes Sonavane.
  * **High Customizability:** Qdrant provided Sprinklr with essential flexibility through high-level abstractions that allowed for extensive customizations. The diverse teams at Sprinklr, working on various GenAI applications, needed a solution that could adapt to different workloads. “The ability to fine-tune configurations at the collection level was crucial for our varied AI applications,” says Sonavane. Qdrant met this need by offering:
    * **Configuration for high-speed search** that fine-tunes settings for optimal performance.
    * [**Quantized vectors**](https://qdrant.tech/documentation/guides/quantization/) for high-dimensional data workloads
    * [**Memory map**](https://qdrant.tech/documentation/concepts/storage/#configuring-memmap-storage) for efficient search optimizing memory usage.
  * **Speed and Cost Efficiency:** Qdrant provided the best combination of speed and cost, making it the most viable solution for Sprinklr’s needs. “We needed a solution that wouldn’t just meet our performance requirements but also keep costs in check, and Qdrant delivered on both fronts,” says Sonavane.
  * **Enhanced Monitoring:** Qdrant’s monitoring tools further boosted system efficiency, allowing Sprinklr to maintain high performance across their platforms.
##  [](https://qdrant.tech/blog/case-study-sprinklr/#implementation-and-qdrants-performance)Implementation and Qdrant’s Performance
Sprinklr’s transition to Qdrant was carefully managed, starting with 10% of their workloads before gradually scaling up. The transition was seamless, thanks in part to Qdrant’s configurable [Web UI](https://qdrant.tech/documentation/interfaces/web-ui/), which allowed Sprinklr to fully utilize its capabilities within the existing infrastructure.
“Qdrant’s ability to index [multiple vectors](https://qdrant.tech/documentation/concepts/vectors/#multivectors) simultaneously and retrieve and re-rank with precision brought significant improvements to our workflow,” Sonavane remarks. This feature reduced the need for repeated retrieval processes, significantly improving efficiency. Additionally, Qdrant’s [quantization](https://qdrant.tech/documentation/guides/quantization/) and [memory mapping](https://qdrant.tech/documentation/concepts/storage/#configuring-memmap-storage) features enabled Sprinklr to reduce RAM usage, leading to substantial cost savings.
Qdrant now plays a key supportive role in enhancing Sprinklr’s vector search capabilities within its AI-driven applications, which is designed to be cloud- and LLM-agnostic. The platform supports various AI-driven tasks, from retrieval and re-ranking to serving advanced customer experiences. “Retrieval is the foundation of all our AI tasks, and Qdrant’s resilience and speed have made it an integral part of our system,” Sonavane emphasizes. Sprinklr operates [Qdrant as a managed service on AWS](https://qdrant.tech/cloud/), ensuring scalability, reliability, and ease of use.
###  [](https://qdrant.tech/blog/case-study-sprinklr/#key-outcomes-with-qdrant)Key Outcomes with Qdrant
After rigorous internal evaluation, Sprinklr achieved the following results with Qdrant:
  * **30% Cost Reduction** : Internal benchmarking showed Qdrant reduced Sprinklr’s retrieval infrastructure costs by 30%.
  * **Improved Developer Efficiency** : Qdrant’s user-friendly environment made it easier to maintain instances, enhancing overall efficiency.
The Sprinklr team conducted a thorough internal benchmark on applications requiring vector search across 10k to over 1M vectors with varying dimensions of vectors depending on the use case. The key results from these benchmarks include:
  * **Superior Write Performance** : Qdrant’s write performance excelled in Sprinklr’s benchmark tests, with incremental indexing time for 100k to 1M vectors being less than 10% of Elasticsearch’s, making it highly efficient for handling updates and append queries in high-ingestion use cases.
  * **Low Latency for Real-Time Applications:** In Sprinklr’s benchmark, Qdrant delivered a P99 latency of 20ms for searches on 1 million vectors, making it ideal for real-time use cases like live chat, where Elasticsearch and Milvus both exceeded 100ms.
  * **High Throughput for Heavy Query Loads** : In Sprinklr’s benchmark, Qdrant handled up to 250 requests per second (RPS) under similar configurations, significantly outperforming Elasticsearch’s 100 RPS, making it ideal for environments with heavy query loads.
“Qdrant is a very fast and high quality retrieval system,” Sonavane points out.
![case-study-sprinklr-3](https://qdrant.tech/blog/case-study-sprinklr/image3.png)
_Figure: P95 Query Time vs Mean Average Precision Benchmark Across Varying Index Sizes_
##  [](https://qdrant.tech/blog/case-study-sprinklr/#outlook)Outlook
Looking ahead, the Applied AI team at Sprinklr is focused on developing Sprinklr Digital Twin technology for companies, organizations, and employees, aiming to seamlessly integrate AI agents with human workers in business processes. Sprinklr Digital Twins are powered by a process engine that incorporates personas, skills, tasks, and activities, designed to optimize operational efficiency.
![case-study-sprinklr-4](https://qdrant.tech/blog/case-study-sprinklr/image4.png)
_Figure: Sprinklr Digital Twin_
Vector search will play a crucial role, as each AI agent will have its own knowledge base, skill set, and tool set, enabling precise and autonomous task execution. The integration of Qdrant further enhances the system’s ability to manage and utilize large volumes of data effectively.
##  [](https://qdrant.tech/blog/case-study-sprinklr/#benchmarking-conclusion)Benchmarking Conclusion
_**Configuration Details:**_
  * We benchmarked applications requiring search on different sizes ranging from 10k to 1M+ vectors, with varying dimensions of vectors depending on the usage. Our infrastructure mainly consisted of Elasticsearch and in-memory Faiss vector search.
Key Observations:
  1. **Indexing Speed** : Qdrant indexes vectors rapidly, making it suitable for applications that require quick data ingestion. Among the alternatives tried, milvus was on par with qdrant in terms of indexing time for a given precision. The latest versions of Elasticsearch offer much improvement compared to previous versions, though not as efficient as Qdrant.
     * **Write Performance:** For some of our use cases, update queries and append queries were significantly higher. For ES, an increase in the number of points had a severe impact on total upload time. For 100k to 1M vector index qdrant incremental indexing time was less than 10% of Elasticsearch.
  2. **Low Latency** : Tail latencies are very critical for real-time applications such as live chat, requiring low P95 and P99 latencies. For a workload requiring search on 1 million vectors, qdrant provided inference latency of 20ms P99 whereas ES and Milvus were more than 100ms.
  3. **High Throughput** : Qdrant handles a high number of requests per second, making it ideal for environments with heavy query loads. For similar configurations, Qdrant provided a throughput of 250 RPS whereas ES was around 100 RPS.
![case-study-sprinklr-5](https://qdrant.tech/blog/case-study-sprinklr/image3.png)
![case-study-sprinklr-6](https://qdrant.tech/blog/case-study-sprinklr/image6.png)
![case-study-sprinklr-7](https://qdrant.tech/blog/case-study-sprinklr/image7.png)
![case-study-sprinklr-8](https://qdrant.tech/blog/case-study-sprinklr/image8.png)
```
data = [
{'system': 'Qdrant', 'index_size': '1,000', 'MAP': 0.98, 'P95 Time': 0.22, 'Mean Time': 0.1, 'QPS': 280,
'Upload Time': 1},
{'system': 'Qdrant', 'index_size': '10,000', 'MAP': 0.99, 'P95 Time': 0.16, 'Mean Time': 0.09, 'QPS': 330,
'Upload Time': 5},
{'system': 'Qdrant', 'index_size': '100,000', 'MAP': 0.98, 'P95 Time': 0.3, 'Mean Time': 0.23, 'QPS': 145,
'Upload Time': 100},
{'system': 'Qdrant', 'index_size': '1,000,000', 'MAP': 0.99, 'P95 Time': 0.171, 'Mean Time': 0.162, 'QPS': 596,
'Upload Time': 220},
{'system': 'ElasticSearch', 'index_size': '1,000', 'MAP': 0.99, 'P95 Time': 0.42, 'Mean Time': 0.32, 'QPS': 95,
'Upload Time': 10},
{'system': 'ElasticSearch', 'index_size': '10,000', 'MAP': 0.98, 'P95 Time': 0.3, 'Mean Time': 0.24, 'QPS': 120,
'Upload Time': 50},
{'system': 'ElasticSearch', 'index_size': '100,000', 'MAP': 0.99, 'P95 Time': 0.48, 'Mean Time': 0.42, 'QPS': 80,
'Upload Time': 1100},
{'system': 'ElasticSearch', 'index_size': '1,000,000', 'MAP': 0.99, 'P95 Time': 0.37, 'Mean Time': 0.236,
'QPS': 348, 'Upload Time': 1150}
]

```
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-sprinklr/)
                    ## 📄 `https-qdrant-tech-blog-case-study-visua.md`
                    ```md
                    # https://qdrant.tech/blog/case-study-visua/
# Visua and Qdrant: Vector Search in Computer Vision
Manuel Meyer
·
May 01, 2024
![Visua and Qdrant: Vector Search in Computer Vision](https://qdrant.tech/blog/case-study-visua/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Visua and Qdrant: Vector Search in Computer Vision
  *     * [The Challenge](https://qdrant.tech/blog/case-study-visua/#the-challenge)
    * [The Solution](https://qdrant.tech/blog/case-study-visua/#the-solution)
    * [The Selection Process](https://qdrant.tech/blog/case-study-visua/#the-selection-process)
    * [Implementing Qdrant](https://qdrant.tech/blog/case-study-visua/#implementing-qdrant)
    * [The Results](https://qdrant.tech/blog/case-study-visua/#the-results)
![visua/image1.png](https://qdrant.tech/blog/case-study-visua/image1.png)
For over a decade, **Brandwatch** , cybersecurity like **Mimecast** , trademark protection like **Ebay** and several sports agencies like **Vision Insights** for sponsorship evaluation.
![visua/image3.png](https://qdrant.tech/blog/case-study-visua/image3.png)
##  [](https://qdrant.tech/blog/case-study-visua/#the-challenge)The Challenge
**Quality Control at Scale**
The accuracy of object detection within images is critical for VISUA ensuring that their algorithms are detecting objects in images correctly. With growing volumes of data processed for clients, the company was looking for a way to enhance its quality control and anomaly detection mechanisms to be more scalable and auditable.
The challenge was twofold. First, VISUA needed a method to rapidly and accurately identify images and the objects within them that were similar, to identify false negatives, or unclear outcomes and use them as inputs for reinforcement learning.
Second, the rapid growth in data volume challenged their previous quality control processes, which relied on a sampling method based on meta-information (like analyzing lower-confidence, smaller, or blurry images), which involved more manual reviews and was not as scalable as needed. In response, the team at VISUA explored vector databases as a solution.
##  [](https://qdrant.tech/blog/case-study-visua/#the-solution)The Solution
**Accelerating Anomaly Detection and Elevating Quality Control with Vector Search**
In addressing the challenge of scaling and enhancing its quality control processes, VISUA turned to vector databases, with Qdrant emerging as the solution of choice. This technological shift allowed VISUA to leverage vector databases for identifying similarities and deduplicating vast volumes of images, videos, and frames. By doing so, VISUA was able to automatically classify objects with a level of precision that was previously unattainable.
The introduction of vectors allowed VISUA to represent data uniquely and mark frames for closer examination by prioritizing the review of anomalies and data points with the highest variance. Consequently, this technology empowered Visia to scale its quality assurance and reinforcement learning processes tenfold.
> _“Using Qdrant as a vector database for our quality control allowed us to review 10x more data by exploiting repetitions and deduplicating samples and doing that at scale with having a query engine.”_ Alessandro Prest, Co-Founder at VISUA.
![visua/image2.jpg](https://qdrant.tech/blog/case-study-visua/image2.jpg)
##  [](https://qdrant.tech/blog/case-study-visua/#the-selection-process)The Selection Process
**Finding the Right Vector Database For Quality Analysis and Anomaly Detection**
Choosing the right vector database was a pivotal decision for VISUA, and the team conducted extensive benchmarks. They tested various solutions, including Weaviate, Pinecone, and Qdrant, focusing on the efficient handling of both vector and payload indexes. The objective was to identify a system that excels in managing hybrid queries that blend vector similarities with record attributes, crucial for enhancing their quality control and anomaly detection capabilities.
Qdrant distinguished itself through its:
  * **Hybrid Query Capability:** Qdrant enables the execution of hybrid queries that combine payload fields and vector data, allowing for comprehensive and nuanced searches. This functionality leverages the strengths of both payload attributes and vector similarities for detailed data analysis. Prest noted the importance of Qdrant’s hybrid approach, saying, “When talking with the founders of Qdrant, we realized that they put a lot of effort into this hybrid approach, which really resonated with us.”
  * **Performance Superiority** : Qdrant distinguished itself as the fastest engine for VISUA’s specific needs, significantly outpacing alternatives with query speeds up to 40 times faster for certain VISUA use cases. Alessandro Prest highlighted, “Qdrant was the fastest engine by a large margin for our use case,” underscoring its significant efficiency and scalability advantages.
  * **API Documentation** : The clarity, comprehensiveness, and user-friendliness of Qdrant’s API documentation and reference guides further solidified VISUA’s decision.
This strategic selection enabled VISUA to achieve a notable increase in operational efficiency and scalability in its quality control processes.
##  [](https://qdrant.tech/blog/case-study-visua/#implementing-qdrant)Implementing Qdrant
Upon selecting Qdrant as their vector database solution, VISUA undertook a methodical approach to integration. The process began in a controlled development environment, allowing VISUA to simulate real-world use cases and ensure that Qdrant met their operational requirements. This careful, phased approach ensured a smooth transition when moving Qdrant into their production environment, hosted on AWS clusters. VISUA is leveraging several specific Qdrant features in their production setup:
  1. **Support for Multiple Vectors per Record/Point** : This feature allows for a nuanced and multifaceted analysis of data, enabling VISUA to manage and query complex datasets more effectively.
  2. **Quantization** : Quantization optimizes storage and accelerates query processing, improving data handling efficiency and lowering memory use, essential for large-scale operations.
##  [](https://qdrant.tech/blog/case-study-visua/#the-results)The Results
Integrating Qdrant into VISUA’s quality control operations has delivered measurable outcomes when it comes to efficiency and scalability:
  * **40x Faster Query Processing** : Qdrant has drastically reduced the time needed for complex queries, enhancing workflow efficiency.
  * **10x Scalability Boost:** The efficiency of Qdrant enables VISUA to handle ten times more data in its quality assurance and learning processes, supporting growth without sacrificing quality.
  * **Increased Data Review Capacity:** The increased capacity to review the data allowed VISUA to enhance the accuracy of its algorithms through reinforcement learning.
####  [](https://qdrant.tech/blog/case-study-visua/#expanding-qdrants-use-beyond-anomaly-detection)Expanding Qdrant’s Use Beyond Anomaly Detection
While the primary application of Qdrant is focused on quality control, VISUA’s team is actively exploring additional use cases with Qdrant. VISUA’s use of Qdrant has inspired new opportunities, notably in content moderation. “The moment we started to experiment with Qdrant, opened up a lot of ideas within the team for new applications,” said Prest on the potential unlocked by Qdrant. For example, this has led them to actively explore the Qdrant [Discovery API](https://qdrant.tech/documentation/concepts/explore/?q=discovery#discovery-api), with an eye on enhancing content moderation processes.
Beyond content moderation, VISUA is set for significant growth by broadening its copyright infringement detection services. As the demand for detecting a wider range of infringements, like unauthorized use of popular characters on merchandise, increases, VISUA plans to expand its technology capabilities. Qdrant will be pivotal in this expansion, enabling VISUA to meet the complex and growing challenges of moderating copyrighted content effectively and ensuring comprehensive protection for brands and creators.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-visua/)
                    ## 📄 `https-qdrant-tech-blog-case-study-voiceflow.md`
                    ```md
                    # https://qdrant.tech/blog/case-study-voiceflow/
# Voiceflow & Qdrant: Powering No-Code AI Agent Creation with Scalable Vector Search
Qdrant
·
December 10, 2024
![Voiceflow & Qdrant: Powering No-Code AI Agent Creation with Scalable Vector Search](https://qdrant.tech/blog/case-study-voiceflow/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Voiceflow & Qdrant: Powering No-Code AI Agent Creation with Scalable Vector Search
  *     * [Evaluation Criteria](https://qdrant.tech/blog/case-study-voiceflow/#evaluation-criteria)
    * [Migration and Onboarding](https://qdrant.tech/blog/case-study-voiceflow/#migration-and-onboarding)
    * [RAG Pipeline Setup](https://qdrant.tech/blog/case-study-voiceflow/#rag-pipeline-setup)
    * [How Voiceflow Uses Qdrant](https://qdrant.tech/blog/case-study-voiceflow/#how-voiceflow-uses-qdrant)
    * [The Outcome](https://qdrant.tech/blog/case-study-voiceflow/#the-outcome)
    * [What’s Next](https://qdrant.tech/blog/case-study-voiceflow/#whats-next)
![voiceflow/image2.png](https://qdrant.tech/blog/case-study-voiceflow/image1.png)
##  [](https://qdrant.tech/blog/case-study-voiceflow/#evaluation-criteria)Evaluation Criteria
As part of this development, the Voiceflow engineering team was looking for a [vector database](https://qdrant.tech/qdrant-vector-database/) solution to power their RAG setup. They evaluated various vector databases based on several key factors:
  * **Performance** : The ability to [handle the scale](https://qdrant.tech/documentation/guides/distributed_deployment/) required by Voiceflow, supporting hundreds of thousands of projects efficiently.
  * **Metadata** : The capability to tag data and chunks and retrieve based on those values, essential for organizing and accessing specific information swiftly.
  * **Managed Solution** : The availability of a [managed service](https://qdrant.tech/documentation/cloud/) with automated maintenance, scaling, and security, freeing the team from infrastructure concerns.
_“We started with Pinecone but eventually switched to Qdrant,”_ Linkov noted. The reasons for the switch included:
  * **Scaling Capabilities** : Qdrant offers a robust multi-node setup with [horizontal scaling](https://qdrant.tech/documentation/cloud/cluster-scaling/), allowing clusters to grow by adding more nodes and distributing data and load among them. This ensures high performance and resilience, which is crucial for handling large-scale projects.
  * **Infrastructure** : “Qdrant provides robust infrastructure support, allowing integration with virtual private clouds on AWS using AWS Private Links and ensuring encryption with AWS KMS. This setup ensures high security and reliability,” says Portillo Edo.
  * **Responsive Qdrant Team** : “The Qdrant team is very responsive, ships features quickly and is a great partner to build with,” Linkov added.
##  [](https://qdrant.tech/blog/case-study-voiceflow/#migration-and-onboarding)Migration and Onboarding
Voiceflow began its migration to Qdrant by creating [backups](https://qdrant.tech/documentation/cloud/backups/) and ensuring data consistency through random checks and key customer verifications. “Once we were confident in the stability, we transitioned the primary database to Qdrant, completing the migration smoothly,” Linkov explained.
During onboarding, Voiceflow transitioned from namespaces to Qdrant’s collections, which offer enhanced flexibility and advanced vector search capabilities. They also implemented Quantization to enhance data processing efficiency. This comprehensive process ensured a seamless transition to Qdrant’s robust infrastructure.
##  [](https://qdrant.tech/blog/case-study-voiceflow/#rag-pipeline-setup)RAG Pipeline Setup
Voiceflow’s RAG pipeline setup provides a streamlined process for uploading and managing data from various sources, designed to offer flexibility and customization at each step.
  * **Data Upload** : Customers can upload data via API from sources such as URLs, PDFs, Word documents, and plain text formats. Integration with platforms like Zendesk is supported, and users can choose between single uploads or refresh-based uploads.
  * **Data Ingestion** : Once data is ingested, Voiceflow offers preset strategies for data checking. Users can utilize these strategies or opt for more customization through the API to tailor the ingestion process as needed.
  * **Metadata Tagging** : Metadata tags can be applied during the ingestion process, which helps organize and facilitate efficient data retrieval later on.
  * **Data Retrieval** : At retrieval time, Voiceflow provides prompts that can modify user questions by adding context, variables, or other modifications. This customization includes adding personas or structuring responses as markdown. Depending on the type of interaction (e.g., button, carousel with an image for image retrieval), these prompts are displayed to users in a structured format.
This comprehensive setup ensures that Voiceflow users can efficiently manage and customize their data workflows, providing a robust solution for building AI-driven applications.
##  [](https://qdrant.tech/blog/case-study-voiceflow/#how-voiceflow-uses-qdrant)How Voiceflow Uses Qdrant
Voiceflow leverages Qdrant’s robust features and infrastructure to optimize their AI assistant platform. Here’s a breakdown of how they utilize these capabilities:
_Database Features:_
  * **Quantization** : This feature helps Voiceflow to perform efficient data processing by reducing the size of vectors, making searches faster. The team uses [Product Quantization](https://qdrant.tech/articles/product-quantization/) in particular.
  * **Chunking Search** : Voiceflow uses chunking search to improve search efficiency by breaking down large datasets into manageable chunks, which allows for faster and more efficient data retrieval.
  * **Sparse Vector Search** : Although not yet implemented, this feature is being explored for more precise keyword searches. “This is an encouraging direction the Qdrant team is taking here as many users seek more exact keyword search,” said Linkov.
_Architecture:_
  * **Node Pool** : A large node pool is used for public cloud users, ensuring scalability, while several smaller, isolated instances cater to private cloud users, providing enhanced security.
_Infrastructure:_
  * **Private Link** : The ability to use Private Link connections across different instances is a significant advantage, requiring robust infrastructure support from Qdrant. “This setup was crucial for SOC2 compliance, and Qdrant’s support team made the process seamless by ensuring feasibility and aiding in the implementation,” Linkov explained.
By utilizing these features, Voiceflow ensures that its platform is scalable, secure, and efficient, meeting the diverse needs of its users.
##  [](https://qdrant.tech/blog/case-study-voiceflow/#the-outcome)The Outcome
Voiceflow achieved significant improvements and efficiencies by leveraging Qdrant’s capabilities:
  * **Enhanced Metadata Tagging** : Implemented robust metadata tagging, allowing for custom fields and tags that facilitate efficient search filtering.
  * **Optimized Performance** : Resolved concerns about retrieval times with a high number of tags by optimizing indexing strategies, achieving efficient performance.
  * **Minimal Operational Overhead** : Experienced minimal overhead, streamlining their operational processes.
  * **Future-Ready** : Anticipates further innovation in hybrid search with multi-token attention.
  * **Multitenancy Support** : Utilized Qdrant’s efficient and [isolated data management](https://qdrant.tech/documentation/guides/multiple-partitions/) to support diverse user needs.
Overall, Qdrant’s features and infrastructure provided Voiceflow with a stable, scalable, and efficient solution for their data processing and retrieval needs.
##  [](https://qdrant.tech/blog/case-study-voiceflow/#whats-next)What’s Next
Voiceflow plans to enhance its platform with more filtering and customization options, allowing developers to host and customize chatbot interfaces without building their own [RAG](https://qdrant.tech/rag/) pipeline.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-voiceflow/)
                    ## 📄 `https-qdrant-tech-blog-colpali-qdrant-optimization.md`
                    ```md
                    # https://qdrant.tech/blog/colpali-qdrant-optimization/
# Optimizing ColPali for Retrieval at Scale, 13x Faster Results
Evgeniya Sukhodolskaya, Sabrina Aquino
·
November 27, 2024
![Optimizing ColPali for Retrieval at Scale, 13x Faster Results](https://qdrant.tech/blog/colpali-qdrant-optimization/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Optimizing ColPali for Retrieval at Scale, 13x Faster Results
  *     * [The Scaling Dilemma](https://qdrant.tech/blog/colpali-qdrant-optimization/#the-scaling-dilemma)
    * [Two-Stage Retrieval Process](https://qdrant.tech/blog/colpali-qdrant-optimization/#two-stage-retrieval-process)
      * [Pooling](https://qdrant.tech/blog/colpali-qdrant-optimization/#pooling)
      * [The “ColPali as a Reranker” Experiment](https://qdrant.tech/blog/colpali-qdrant-optimization/#the-colpali-as-a-reranker-experiment)
      * [Implementation](https://qdrant.tech/blog/colpali-qdrant-optimization/#implementation)
      * [Experiment Setup](https://qdrant.tech/blog/colpali-qdrant-optimization/#experiment-setup)
    * [Results](https://qdrant.tech/blog/colpali-qdrant-optimization/#results)
      * [Metrics](https://qdrant.tech/blog/colpali-qdrant-optimization/#metrics)
    * [What’s Next?](https://qdrant.tech/blog/colpali-qdrant-optimization/#whats-next)
      * [Try It Yourself](https://qdrant.tech/blog/colpali-qdrant-optimization/#try-it-yourself)
ColPali is a fascinating leap in document retrieval. Its precision in handling visually rich PDFs is phenomenal, but scaling it to handle real-world datasets comes with its share of computational challenges.
Here’s how we solved these challenges to make ColPali 13x faster without sacrificing the precision it’s known for.
##  [](https://qdrant.tech/blog/colpali-qdrant-optimization/#the-scaling-dilemma)The Scaling Dilemma
ColPali generates **1,030 vectors for just one page of a PDF.** While this is manageable for small-scale tasks, in a real-world production setting where you may need to store hundreds od thousands of PDFs, the challenge of scaling becomes significant.
Consider this scenario:
  * **Dataset Size:** 20,000 PDF pages.
  * **Number of Vectors:** Each page generates ~1,000 vectors of 128 dimensions.
The total number of comparisons is calculated as:
1,000⋅1,000⋅20,000⋅128=2.56×1012 comparisons!
That’s trillions of comparisons needed to build the index. Even advanced indexing algorithms like **HNSW** struggle with this scale, as computational costs grow quadratically with amount of multivectors per page.
We turned to a hybrid optimization strategy combining **pooling** (to reduce computational overhead) and **reranking** (to preserve accuracy).
Before we go any deeper, watch our 
For those eager to explore, the 
##  [](https://qdrant.tech/blog/colpali-qdrant-optimization/#two-stage-retrieval-process)Two-Stage Retrieval Process
###  [](https://qdrant.tech/blog/colpali-qdrant-optimization/#pooling)Pooling
Pooling is well-known in machine learning as a way to compress data while keeping important information. For ColPali, we reduced 1,030 vectors per page to just 38 vectors by pooling rows in the document’s 32x32 grid.
![](https://qdrant.tech/blog/colpali-optimization/rows.png)
Max and mean pooling are the two most popular types, so we decided to test both approaches on the rows of the grid. Likewise, we could apply pooling on columns, which we plan to explore in the future.
  * **Mean Pooling:** Averages values across rows.
  * **Max Pooling:** Selects the maximum value for each feature.
32 vectors represent the pooled rows, while 6 vectors encode contextual information derived from ColPali’s special tokens (e.g., for the beginning of the sequence, and task-specific instructions like “Describe the image”).
For our experiments, we chose to preserve these 6 additional vectors.
###  [](https://qdrant.tech/blog/colpali-qdrant-optimization/#the-colpali-as-a-reranker-experiment)The “ColPali as a Reranker” Experiment
Pooling drastically reduces retrieval costs, but there’s a risk of losing fine-grained precision. To address this, we implemented a **two-stage retrieval system** , where embeddings generated with ColPali were max/mean pooled by grid rows to create lightweight vectors for the initial retrieval stage, followed by reranking with the original high-resolution embeddings:
  1. **Pooled Retrieval:** Quickly retrieves the top 200 candidates using lightweight pooled embeddings.
  2. **Full Reranking:** Refines these candidates using the original, high-resolution embeddings, delivering the final top 20 results.
###  [](https://qdrant.tech/blog/colpali-qdrant-optimization/#implementation)Implementation
We created a custom dataset with over 20,000 unique PDF pages by merging:
  * **ViDoRe Benchmark:** Designed for PDF documents retrieval evaluation.
  * **UFO Dataset:** Visually rich documents paired with synthetic queries 
  * **DocVQA Dataset:** A large set of document-derived Q&A pairs.
Each document was processed into 32x32 grids, generating both full-resolution and pooled embeddings. **Full-resolution** embeddings consisted of 1,030 vectors per page, while **pooled embeddings** included mean and max pooling variants.
All embeddings were were stored and kept in RAM to avoid caching effects during retrieval speed experiments.
###  [](https://qdrant.tech/blog/colpali-qdrant-optimization/#experiment-setup)Experiment Setup
We evaluated retrieval quality with 1,000 queries. First, pooled embeddings retrieved the top 200 candidates. Then, full-resolution embeddings reranked them to produce the final top 20 results.
To measure performance, we used:
  * **NDCG@20:** Measures ranking quality (how well the top results align with expectations).
  * **Recall@20:** Measures the overlap between this method and the original ColPali retrieval.
##  [](https://qdrant.tech/blog/colpali-qdrant-optimization/#results)Results
The experiment showed promising improvements in speed and accuracy. Retrieval time improved **13x** compared to using full-resolution embeddings alone.
###  [](https://qdrant.tech/blog/colpali-qdrant-optimization/#metrics)Metrics
Pooling Type | NDCG@20 | Recall@20  
---|---|---  
**Mean** | 0.952 | 0.917  
**Max** | 0.759 | 0.656  
Mean pooling preserved nearly identical quality to the original ColPali, with NDCG@20 = 0.952 and Recall@20 = 0.917. Max pooling did not perform well enough to be considered viable since it sacrificed significant accuracy without delivering a meaningful speed advantage.
##  [](https://qdrant.tech/blog/colpali-qdrant-optimization/#whats-next)What’s Next?
Future experiments could push these results even further:
  * Investigating column-wise pooling for additional compression.
  * Testing half-precision (float16) vectors to balance memory use and speed.
  * Skipping special multivectors during prefetch to streamline retrieval.
  * Combining quantization with oversampling for even faster search.
###  [](https://qdrant.tech/blog/colpali-qdrant-optimization/#try-it-yourself)Try It Yourself
Curious to see this in action? Explore the full codebase and experiment with ColPali optimizations:
  * **Demo Notebook:**
  * **Webinar Walkthrough:**
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/colpali-qdrant-optimization/)
                    ## 📄 `https-qdrant-tech-blog-dust-and-qdrant.md`
                    ```md
                    # https://qdrant.tech/blog/dust-and-qdrant/
# Dust and Qdrant: Using AI to Unlock Company Knowledge and Drive Employee Productivity
Manuel Meyer
·
February 06, 2024
![Dust and Qdrant: Using AI to Unlock Company Knowledge and Drive Employee Productivity](https://qdrant.tech/blog/dust-and-qdrant/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Dust and Qdrant: Using AI to Unlock Company Knowledge and Drive Employee Productivity
  *     * [Challenge](https://qdrant.tech/blog/dust-and-qdrant/#challenge)
    * [Solution](https://qdrant.tech/blog/dust-and-qdrant/#solution)
    * [Results](https://qdrant.tech/blog/dust-and-qdrant/#results)
    * [Outlook](https://qdrant.tech/blog/dust-and-qdrant/#outlook)
One of the major promises of artificial intelligence is its potential to accelerate efficiency and productivity within businesses, empowering employees and teams in their daily tasks. The French company 
##  [](https://qdrant.tech/blog/dust-and-qdrant/#challenge)Challenge
“The past year has shown that large language models (LLMs) are very useful but complicated to deploy,” Polu says, especially in the context of their application across business functions. This is why he believes that the goal of augmenting human productivity at scale is especially a product unlock and not only a research unlock, with the goal to identify the best way for companies to leverage these models. Therefore, Dust is creating a product that sits between humans and the large language models, with the focus on supporting the work of a team within the company to ultimately enhance employee productivity.
A major challenge in leveraging leading LLMs like OpenAI, Anthropic, or Mistral to their fullest for employees and teams lies in effectively addressing a company’s wide range of internal use cases. These use cases are typically very general and fluid in nature, requiring the use of very large language models. Due to the general nature of these use cases, it is very difficult to finetune the models - even if financial resources and access to the model weights are available. The main reason is that “the data that’s available in a company is a drop in the bucket compared to the data that is needed to finetune such big models accordingly,” Polu says, “which is why we believe that retrieval augmented generation is the way to go until we get much better at fine tuning”.
For successful retrieval augmented generation (RAG) in the context of employee productivity, it is important to get access to the company data and to be able to ingest the data that is considered ‘shared knowledge’ of the company. This data usually sits in various SaaS applications across the organization.
##  [](https://qdrant.tech/blog/dust-and-qdrant/#solution)Solution
Dust provides companies with the core platform to execute on their GenAI bet for their teams by deploying LLMs across the organization and providing context aware AI assistants through [RAG](https://qdrant.tech/rag/rag-evaluation-guide/) . Users can manage so-called data sources within Dust and upload files or directly connect to it via APIs to ingest data from tools like Notion, Google Drive, or Slack. Dust then handles the chunking strategy with the embeddings models and performs retrieval augmented generation.
![solution-laptop-screen](https://qdrant.tech/case-studies/dust/laptop-solutions.jpg)
For this, Dust required a vector database and evaluated different options including Pinecone and Weaviate, but ultimately decided on Qdrant as the solution of choice. “We particularly liked Qdrant because it is open-source, written in Rust, and it has a well-designed API,” Polu says. For example, Dust was looking for high control and visibility in the context of their rapidly scaling demand, which made the fact that Qdrant is open-source a key driver for selecting Qdrant. Also, Dust’s existing system which is interfacing with Qdrant, is written in Rust, which allowed Dust to create synergies with regards to library support.
When building their solution with Qdrant, Dust took a two step approach:
  1. **Get started quickly:** Initially, Dust wanted to get started quickly and opted for 
  2. **Scale and optimize:** As the load grew, Dust started to take advantage of Qdrant’s features to tune the setup for optimization and scale. They started to look into how they map and cache data, as well as applying some of Qdrant’s [built-in compression features](https://qdrant.tech/documentation/guides/quantization/). In particular, Dust leveraged the control of the [MMAP payload threshold](https://qdrant.tech/documentation/concepts/storage/#configuring-memmap-storage) as well as [Scalar Quantization](https://qdrant.tech/articles/scalar-quantization/), which enabled Dust to manage the balance between storing vectors on disk and keeping quantized vectors in RAM, more effectively. “This allowed us to scale smoothly from there,” Polu says.
##  [](https://qdrant.tech/blog/dust-and-qdrant/#results)Results
Dust has seen success in using Qdrant as their vector database of choice, as Polu acknowledges: “Qdrant’s ability to handle large-scale models and the flexibility it offers in terms of data management has been crucial for us. The observability features, such as historical graphs of RAM, Disk, and CPU, provided by Qdrant are also particularly useful, allowing us to plan our scaling strategy effectively.”
![“We were able to reduce the footprint of vectors in memory, which led to a significant cost reduction as
we don’t have to run lots of nodes in parallel. While being memory-bound, we were
able to push the same instances further with the help of quantization. While you
get pressure on MMAP in this case you maintain very good performance even if the
RAM is fully used. With this we were able to reduce our cost by 2x.” - Stanislas Polu, Co-Founder of Dust](https://qdrant.tech/case-studies/dust/Dust-Quote.jpg)
Dust was able to scale its application with Qdrant while maintaining low latency across hundreds of thousands of collections with retrieval only taking milliseconds, as well as maintaining high accuracy. Additionally, Polu highlights the efficiency gains Dust was able to unlock with Qdrant: “We were able to reduce the footprint of vectors in memory, which led to a significant cost reduction as we don’t have to run lots of nodes in parallel. While being memory-bound, we were able to push the same instances further with the help of quantization. While you get pressure on MMAP in this case you maintain very good performance even if the RAM is fully used. With this we were able to reduce our cost by 2x.”
##  [](https://qdrant.tech/blog/dust-and-qdrant/#outlook)Outlook
Dust will continue to build out their platform, aiming to be the platform of choice for companies to execute on their internal GenAI strategy, unlocking company knowledge and driving team productivity. Over the coming months, Dust will add more connections, such as Intercom, Jira, or Salesforce. Additionally, Dust will expand on its structured data capabilities.
To learn more about how Dust uses Qdrant to help employees in their day to day tasks, check out our 
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/dust-and-qdrant/)
                    ## 📄 `https-qdrant-tech-blog-enterprise-vector-search.md`
                    ```md
                    # https://qdrant.tech/blog/enterprise-vector-search/
# Introducing Qdrant Cloud’s New Enterprise-Ready Vector Search
Daniel Azoulai
·
March 04, 2025
![Introducing Qdrant Cloud’s New Enterprise-Ready Vector Search](https://qdrant.tech/blog/enterprise-vector-search/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Introducing Qdrant Cloud’s New Enterprise-Ready Vector Search
  *     * [Securely Scale Your AI Workloads](https://qdrant.tech/blog/enterprise-vector-search/#securely-scale-your-ai-workloads)
    * [Our New Qdrant Cloud Capabilities:](https://qdrant.tech/blog/enterprise-vector-search/#our-new-qdrant-cloud-capabilities)
    * [Ok, now for the good part…](https://qdrant.tech/blog/enterprise-vector-search/#ok-now-for-the-good-part)
      * [Cloud API for Simplified Management](https://qdrant.tech/blog/enterprise-vector-search/#cloud-api-for-simplified-management)
      * [Secure Access & Authentication - Control the Who and What](https://qdrant.tech/blog/enterprise-vector-search/#secure-access--authentication---control-the-who-and-what)
      * [Advanced Monitoring and Observability for Full Performance Insights](https://qdrant.tech/blog/enterprise-vector-search/#advanced-monitoring-and-observability-for-full-performance-insights)
    * [Simply put, Qdrant is Enterprise-Ready](https://qdrant.tech/blog/enterprise-vector-search/#simply-put-qdrant-is-enterprise-ready)
    * [Come Build with Us!](https://qdrant.tech/blog/enterprise-vector-search/#come-build-with-us)
At Qdrant, we enable developers to power AI workloads - not only securely, but at any scale. That’s why we are excited to introduce Qdrant Cloud’s new suite of enterprise-grade features. With **our Cloud API, Cloud RBAC** , **Single Sign-On (SSO)** , granular **Database API Keys** , and **Advanced Monitoring & Observability**, you now have the control and visibility needed to operate at scale.
##  [](https://qdrant.tech/blog/enterprise-vector-search/#securely-scale-your-ai-workloads)Securely Scale Your AI Workloads
Your enterprise-grade AI applications demand more than just a powerful vector database—they need to meet compliance, performance, and scalability requirements. To do that, you need simplified management, secure access & authentication, and real-time monitoring & observability. Now, Qdrant’s new enterprise-grade features address these needs, giving your team the tools to reduce operational overhead, simplify authentication, enforce access policies, and have deep visibility into performance.
##  [](https://qdrant.tech/blog/enterprise-vector-search/#our-new-qdrant-cloud-capabilities)Our New Qdrant Cloud Capabilities:
  * **Cloud API for Simplified Management →** Automate and scale with **API-driven control** and **Terraform support**.
  * **Secure Access & Authentication** → Control who gets in and what they can do with **Cloud RBAC** , **SSO** , and granular **Database API Keys**.
  * **Advanced Monitoring & Observability** → Stay ahead of issues with **Prometheus/OpenMetrics** , **Datadog** , **Grafana** , and other third-party integrations.
##  [](https://qdrant.tech/blog/enterprise-vector-search/#ok-now-for-the-good-part)Ok, now for the good part…
###  [](https://qdrant.tech/blog/enterprise-vector-search/#cloud-api-for-simplified-management)Cloud API for Simplified Management
Skip the UI—manage Qdrant entirely through code. The [**Qdrant Cloud API**](https://qdrant.tech/documentation/qdrant-cloud-api/) lets you automate cluster creation, updates, and scaling, ensuring repeatable, version-controlled deployments. You can also programmatically generate and revoke API keys, update configurations, and adapt infrastructure as workloads change.
You can manage the Qdrant Cloud lifecycle with Qdrant’s [**Terraform Provider**](https://qdrant.tech/documentation/cloud-tools/terraform/). With this support, you can define and automate cluster provisioning using Infrastructure-as-Code (IaC) best practices.
**Why it matters:** By automating cluster management and scaling, Qdrant helps you focus on building AI-powered applications, not maintaining infrastructure.
###  [](https://qdrant.tech/blog/enterprise-vector-search/#secure-access--authentication---control-the-who-and-what)Secure Access & Authentication - Control the Who and What
####  [](https://qdrant.tech/blog/enterprise-vector-search/#cloud-rbac-role-based-access-control---the-who)Cloud RBAC (Role-Based Access Control) - The Who
With **Cloud RBAC** , you can define precise **role-based permissions** for team members managing clusters, billing, and hybrid cloud deployments in Qdrant Cloud. Instead of granting broad, unrestricted access, teams can **assign permissions based on roles** , ensuring tighter security and compliance.
####  [](https://qdrant.tech/blog/enterprise-vector-search/#granular-database-api-keys---the-what)Granular Database API Keys - The What
**Database API Keys** let applications and services **directly interact with data inside Qdrant**. You can **grant API access at the cluster, collection, or even vector level** , specifying **read-only or read/write permissions** for each key.
Unlike **Cloud RBAC** , which governs **team permissions in the** , **Database API Keys** control how external applications access stored data. You can define **fine-grained API key permissions** , apply **Time-to-Live (TTL) expiration policies** , and revoke keys instantly—without requiring a database restart (**only available in Qdrant Cloud**).
To further refine access, **payload-based filters** allow you to restrict API keys to **only retrieve vectors that match specific metadata conditions**. Before finalizing an API key, you can **preview its access settings** to ensure it behaves as expected—reducing misconfigurations and improving security.
####  [](https://qdrant.tech/blog/enterprise-vector-search/#read-more-about-database-api-keyshttpsqdranttechdocumentationcloudauthentication)[Read more about Database API keys](https://qdrant.tech/documentation/cloud/authentication/).
####  [](https://qdrant.tech/blog/enterprise-vector-search/#single-sign-on-sso-for-simplified-authentication)Single Sign-On (SSO) for Simplified Authentication
**SSO** eliminates password sprawl by allowing users to log in through **Okta, Google Workspace, Azure AD (Entra ID), SAML, PingFederate, and more** —enforcing authentication policies while reducing IT overhead. Instead of managing separate credentials, users **simply enter their company email** and are redirected to their organization’s authentication system.
**SSO setup is fully supported** —to enable it for your company, **contact Qdrant support** , and our team will guide you through the setup process. SSO also works with **multi-factor authentication (MFA)** for additional security.
_SSO is only available for[Premium Tier](https://qdrant.tech/documentation/cloud/premium/) customers. [Learn more about SSO](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#enterprise-single-sign-on-sso)._
**Why it matters:** By integrating **Cloud RBAC** , granular **Database API Keys** and **SSO** , Qdrant Cloud helps your team have the right access at the right time—without unnecessary friction.
###  [](https://qdrant.tech/blog/enterprise-vector-search/#advanced-monitoring-and-observability-for-full-performance-insights)Advanced Monitoring and Observability for Full Performance Insights
Qdrant Cloud provides **real-time visibility into database performance** with built-in **Prometheus/OpenMetrics support**. You can monitor **CPU usage, memory usage, disk space, request volumes, and query latencies** directly in the **Qdrant Cloud Console** , giving you a **live overview of system health**.
For **deeper analytics** , Qdrant lets you **integrate with your existing monitoring stack** , including [Datadog](https://qdrant.tech/documentation/observability/datadog/)**,** [Grafana](https://qdrant.tech/documentation/cloud/cluster-monitoring/#grafana-dashboard)**,** and [other enterprise observability tools](https://qdrant.tech/documentation/observability/). Every Qdrant Cloud cluster includes a **metrics endpoint** , accessible via a **read-only API key** , providing **Prometheus and OpenTelemetry compatible data** for easy ingestion into Grafana Cloud or any other supported monitoring system.
Qdrant also provides a **ready-to-use** to help you **visualize key database metrics** , including historical performance data, cluster uptime, request latencies, backup schedules, and network I/O.
You can set up **customizable alerts** in [Grafana](https://qdrant.tech/documentation/cloud/cluster-monitoring/#grafana-dashboard), Prometheus, or [Datadog](https://qdrant.tech/documentation/observability/datadog/) to **track key performance indicators** such as **memory** , **storage** , and **query** **latency** thresholds.
For **historical performance tracking** , third-party integrations allow you to **analyze trends over time** , providing deeper insights into system performance and long-term optimization strategies.
**Why it matters:** With **detailed telemetry, automated alerts, and deep observability integrations** , you can troubleshoot issues faster, optimize database performance, and scale AI applications.
[Read more about advanced monitoring](https://qdrant.tech/documentation/cloud/cluster-monitoring/).
##  [](https://qdrant.tech/blog/enterprise-vector-search/#simply-put-qdrant-is-enterprise-ready)Simply put, Qdrant is Enterprise-Ready
Our high-performance vector search engine already handles billion-scale use cases. Through Qdrant Cloud, you get our Cloud API, authentication & access tools, and monitoring & observability integrations.
With this combination, you can simplify infrastructure management, implement secure access & authentication, and stay ahead of performance challenges. That’s why Qdrant is the enterprise vector database of choice—**no matter the scale**.
##  [](https://qdrant.tech/blog/enterprise-vector-search/#come-build-with-us)Come Build with Us!
[Contact Sales](https://qdrant.tech/contact-us/) to enable enterprise features for your team, or 
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/enterprise-vector-search/)
                    ## 📄 `https-qdrant-tech-blog-human-language-ai-models.md`
                    ```md
                    # https://qdrant.tech/blog/human-language-ai-models/
# When music just doesn't match our vibe, can AI help? - Filip Makraduli | Vector Space Talks
Demetrios Brinkmann
·
January 09, 2024
![When music just doesn't match our vibe, can AI help? - Filip Makraduli | Vector Space Talks](https://qdrant.tech/blog/human-language-ai-models/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * When music just doesn't match our vibe, can AI help? - Filip Makraduli | Vector Space Talks
  *     * [**Top Takeaways:**](https://qdrant.tech/blog/human-language-ai-models/#top-takeaways)
    * [Show Notes:](https://qdrant.tech/blog/human-language-ai-models/#show-notes)
    * [More Quotes from Filip:](https://qdrant.tech/blog/human-language-ai-models/#more-quotes-from-filip)
    * [Transcript:](https://qdrant.tech/blog/human-language-ai-models/#transcript)
> _“Was it possible to somehow maybe find a way to transfer this feeling that we have this vibe and get the help of AI to understand what exactly we need at that moment in terms of songs?”_  
>  – Filip Makraduli
Imagine if the recommendation system could understand spoken instructions or hummed melodies. This would greatly impact the user experience and accuracy of the recommendations.
Filip Makraduli, an electrical engineering graduate from Skopje, Macedonia, expanded his academic horizons with a Master’s in Biomedical Data Science from Imperial College London.
Currently a part of the Digital and Technology team at Marks and Spencer (M&S), he delves into retail data science, contributing to various ML and AI projects. His expertise spans causal ML, XGBoost models, NLP, and generative AI, with a current focus on improving outfit recommendation systems.
Filip is not only professionally engaged but also passionate about tech startups, entrepreneurship, and ML research, evident in his interest in Qdrant, a startup he admires.
_**Listen to the episode on**_
##  [](https://qdrant.tech/blog/human-language-ai-models/#top-takeaways)**Top Takeaways:**
Take a look at the song vibe recommender system created by Filip Makraduli. Find out how it works!
Filip discusses how AI can assist in finding the perfect songs for any mood. He takes us through his unique approach, using human language and AI models to capture the essence of a song and generate personalized recommendations.
Here are 5 key things you’ll learn from this video:
  1. How AI can help us understand and capture the vibe and feeling of a song
  2. The use of language to transfer the experience and feeling of a song
  3. The role of data sets and descriptions in building unconventional song recommendation systems
  4. The importance of encoding text and using sentence transformers to generate song embeddings
  5. How vector spaces and cosine similarity search are used to generate song recommendations
> Fun Fact: Filip actually created a Spotify playlist in real-time during the video, based on the vibe and mood Demetrios described, showing just how powerful and interactive this AI music recommendation system can be!
##  [](https://qdrant.tech/blog/human-language-ai-models/#show-notes)Show Notes:
01:25 Using AI to capture desired music vibes.  
06:17 Faster and accurate model.  
10:07 Sentence embedding model maps song descriptions.  
14:32 Improving recommendations, user personalization in music.  
15:49 Qdrant Python client creates user recommendations.  
21:26 Questions about getting better embeddings for songs.  
25:04 Contextual information for personalized walking recommendations.  
26:00 Need predictions, voice input, and music options.
##  [](https://qdrant.tech/blog/human-language-ai-models/#more-quotes-from-filip)More Quotes from Filip:
_“When you log in with Spotify, you could get recommendations related to your taste on Spotify or on whatever app you listen your music on.”_  
– Filip Makraduli
_“Once the user writes a query and the query mentions, like some kind of a mood, for example, I feel happy and it’s a sunny day and so on, you would get the similarity to the song that has this kind of language explanations and language intricacies in its description.”_  
– Filip Makraduli
_“I’ve explored Qdrant and as I said with Spotify web API there are a lot of things to be done with these specific user-created recommendations.”_  
– Filip Makraduli
##  [](https://qdrant.tech/blog/human-language-ai-models/#transcript)Transcript:
Demetrios: So for those who do not know, you are going to be talking to us about when the music we listen to does not match our vibe. And can we get AI to help us on that? And you’re currently working as a data scientist at Marks and Spencer. I know you got some slides to share, right? So I’ll let you share your screen. We can kick off the slides and then we’ll have a little presentation and I’ll be back on to answer some questions. And if Neil’s is still around at the end, which I don’t think he will be able to hang around, but we’ll see, we can pull him back on and have a little discussion at the end of the.
Filip Makraduli: That’s. That’s great. All right, cool. I’ll share my screen.
Demetrios: Right on.
Filip Makraduli: Yeah.
Demetrios: There we go.
Filip Makraduli: Yeah. So I had to use this slide because it was really well done as an introductory slide. Thank you. Yeah. Thank you also for making it so. Yeah, the idea was, and kind of the inspiration with music, we all listen to it. It’s part of our lives in many ways. Sometimes it’s like the gym.
Filip Makraduli: We’re ready to go, we’re all hyped up, ready to do a workout, and then we click play. But the music and the playlist we get, it’s just not what exactly we’re looking for at that point. Or if we try to work for a few hours and try to get concentrated and try to code for hours, we can do the same and then we click play, but it’s not what we’re looking for again. So my inspiration was here. Was it possible to somehow maybe find a way to transfer this feeling that we have this vibe and get the help of AI to understand what exactly we need at that moment in terms of songs. So the obvious first question is how do we even capture a vibe and feel of a song? So initially, one approach that’s popular and that works quite well is basically using a data set that has a lot of features. So Spotify has one data set like this and there are many others open source ones which include different features like loudness, key tempo, different kind of details related to the acoustics, the melody and so on. And this would work.
Filip Makraduli: And this is kind of a way that a lot of song recommendation systems are built. However, what I wanted to do was maybe try a different approach in a way. Try to have a more unconventional recommender system, let’s say. So what I did here was I tried to concentrate just on language. So my idea was, okay, is it possible to use human language to transfer this experience, this feeling that we have, and just use that and try to maybe encapsulate these features of songs. And instead of having a data set, just have descriptions of songs or sentences that explain different aspects of a song. So, as I said, this is a bit of a less traditional approach, and it’s more of kind of testing the waters, but it worked to a decent extent. So what I did was, first I created a data set where I queried a large language model.
Filip Makraduli: So I tried with llama and chat GPT, both. And the idea was to ask targeted questions, for example, like, what movie character does this song make you feel like? Or what’s the tempo like? So, different questions that would help us understand maybe in what situation we would listen to this song, how will it make us feel like? And so on. And the idea was, as I said, again, to only use song names as queries for this large language model. So not have the full data sets with multiple features, but just song name, and kind of use this pretrained ability of all these LLMs to get this info that I was looking for. So an example of the generated data was this. So this song called Deep Sea Creature. And we have, like, a small description of the song. So it says a heavy, dark, mysterious vibe.
Filip Makraduli: It will make you feel like you’re descending into the unknown and so on. So a bit of a darker choice here, but that’s the general idea. So trying to maybe do a bit of prompt engineering in a way to get the right features of a song, but through human language. So that was the first step. So the next step was how to encode this text. So all of this kind of querying reminds me of sentences. And this led me to sentence transformers and sentence Bird. And the usual issue with kind of doing this sentence similarity in the past was this, what I have highlighted here.
Filip Makraduli: So this is actually a quote from a paper that Nils published a few years ago. So, basically, the way that this similarity was done was using cross encoders in the past, and that worked well, but it was really slow and unscalable. So Nils and his colleague created this kind of model, which helped scale this and make this a lot quicker, but also keep a lot of the accuracy. So Bert and Roberta were used, but they were not, as I said, quite scalable or useful for larger applications. So that’s how sentence Bert was created. So the idea here was that there would be, like, a Siamese network that would train the model so that there could be, like, two bird models, and then the training would be done using this like zero, one and two tags, where kind of the sentences would be compared, whether there is entailment, neutrality or contradiction. So how similar these sentences are to each other. And by training a model like this and doing mean pooling, in the end, the model performed quite well and was able to kind of encapsulate this language intricacies of sentences.
Filip Makraduli: So I decided to use and try out sentence transformers for my use case, and that was the encoding bit. So we have the model, we encode the text, and we have the embedding. So now the question is, how do we actually generate the recommendations? How is the similarity performed? So the similarity was done using vector spaces and cosine similarity search here. There were multiple ways of doing this. First, I tried things with a flat index and I tried Qdrant and I tried FIS. So I’ve worked with both. And with the flat index, it was good. It works well.
Filip Makraduli: It’s quick for small number of examples, small number of songs, but there is an issue when scaling. So once the vector indices get bigger, there might be a problem. So one popular kind of index architecture is this one here on the left. So hierarchical, navigable, small world graphs. So the idea here is that you wouldn’t have to kind of go through all of the examples, but search through the examples in different layers, so that the search for similarities quicker. And this is a really popular approach. And Qdrant have done a really good customizable version of this, which is quite useful, I think, for very larger scales of application. And this graph here illustrates kind of well what the idea is.
Filip Makraduli: So there is the sentence in this example. It’s like a stripped striped blue shirt made from cotton, and then there is the network or the encoder. So in my case, this sentence is the song description, the neural network is the sentence transformer in my case. And then this embeddings are generated, which are then mapped into this vector space, and then this vector space is queryed and the cosine similarity is found, and the recommendations are generated in this way, so that once the user writes a query and the query mentions, like some kind of a mood, for example, I feel happy and it’s a sunny day and so on, you would get the similarity to the song that has this kind of language explanations and language intricacies in its description. And there are a lot of ways of doing this, as Nils mentioned, especially with different embedding models and doing context related search. So this is an interesting area for improvement, even in my use case. And the quick screenshot looks like this. So for example, the mood that the user wrote, it’s a bit rainy, but I feel like I need a long walk in London.
Filip Makraduli: And these are the top five suggested songs. This is also available on Streamlit. In the end I’ll share links of everything and also after that you can click create a Spotify playlist and this playlist will be saved in your Spotify account. As you can see here, it says playlist generated earlier today. So yeah, I tried this, it worked. I will try live demo bit later. Hopefully it works again. But this is in beta currently so you won’t be able to try it at home because Spotify needs to approve my app first and go through that process so that then I can do this part fully.
Filip Makraduli: And the front end bit, as I mentioned, was done in Streamlit. So why Streamlit? I like the caching bit. So of course this general part where it’s really easy and quick to do a lot of data dashboarding and data applications to test out models, that’s quite nice. But this caching options that they have help a lot with like loading models from hugging face or if you’re loading models from somewhere, or if you’re loading different databases. So if you’re combining models and data. In my case I had a binary file of the index and also the model. So it was quite useful and quick to do these things and to be able to try things out quickly. So this is kind of the step by step outline of everything I’ve mentioned and the whole project.
Filip Makraduli: So the first step is encoding this descriptions into embeddings. Then this vector embeddings are mapped into a vector space. Examples here with how I’ve used Qdrant for this, which was quite nice. I feel like the developer experience is really good for scalable purposes. It’s really useful. So if the number of songs keep increasing it’s quite good. And the query and more similar embeddings. The front is done with Streamlit and the Spotify API to save the playlists on the Spotify account.
Filip Makraduli: All of these steps can be improved and tweaked in certain ways and I will talk a bit about that too. So a lot more to be done. So now there are 2000 songs, but as I’ve mentioned, in this vector space, the more songs that are there, the more representative this recommendations would be. So this is something I’m currently exploring and doing, generating, filtering and user specific personalization. So once maybe you log in with Spotify, you could get recommendations related to your taste on Spotify or on whatever app you listen your music on. And referring to the talk that Niels had a lot of potential for better models and embeddings and embedding models. So also the contrastive learning bits or the contents aware querying, that could be useful too. And a vector database because currently I’m using a binary file.
Filip Makraduli: But I’ve explored Qdrant and as I said with Spotify web API there are a lot of things to be done with this specific user created recommendations. So with Qdrant, the Python client is quite good. The getting started helps a lot. So I wrote a bit of code. I think for production use cases it’s really great. So for my use case here, as you can see on the right, I just read the text from a column and then I encode with the model. So the sentence transformer is the model that I encode with. And there is this collections that they’re so called in Qdrant that are kind of like this vector spaces that you can create and you can also do different things with them, which I think one of the more helpful ones is the payload one and the batch one.
Filip Makraduli: So you can batch things in terms of how many vectors will go to the server per single request. And also the payload helps if you want to add extra context. So maybe I want to filter by genres. I can add useful information to the vector embedding. So this is quite a cool feature that I’m planning on using. And another potential way of doing this and kind of combining things is using audio waves too, lyrics and descriptions and combining all of this as embeddings and then going through the similar process. So that’s something that I’m looking to do also. And yeah, you also might have noticed that I’m a data scientist at Marks and Spencer and I just wanted to say that there are a lot of interesting ML and data related stuff going on there.
Filip Makraduli: So a lot of teams that work on very interesting use cases, like in recommender systems, personalization of offers different stuff about forecasting. There is a lot going on with causal ML and yeah, the digital and tech department is quite well developed and I think it’s a fun place to explore if you’re interested in retail data science use cases. So yeah, thank you for your attention. I’ll try the demo. So this is the QR code with the repo and all the useful links. You can contact me on LinkedIn. This is the screenshot of the repo and you have the link in the QR code. The name of the repo is song Vibe.
Filip Makraduli: A friend of mine said that that wasn’t a great name of a repo. Maybe he was right. But yeah, here we are. I’ll just try to do the demo quickly and then we can step back to the.
Demetrios: I love dude, I got to say, when you said you can just automatically create the Spotify playlist, that made me.
Filip Makraduli: Go like, oh, yes, let’s see if it works locally. Do you have any suggestion what mood are you in?
Demetrios: I was hoping you would ask me, man. I am in a bit of an esoteric mood and I want female kind of like Gaelic voices, but not Gaelic music, just Gaelic voices and lots of harmonies, heavy harmonies.
Filip Makraduli: Also.
Demetrios: You didn’t realize you’re asking a musician. Let’s see what we got.
Filip Makraduli: Let’s see if this works in 2000 songs. Okay, so these are the results. Okay, yeah, you’d have to playlist. Let’s see.
Demetrios: Yeah, can you make the playlist public and then I’ll just go find it right now. Here we go.
Filip Makraduli: Let’s see. Okay, yeah, open in. Spotify playlist created now. Okay, cool. I can also rename it. What do you want to name the playlist?
Demetrios: Esoteric Gaelic Harmonies. That’s what I think we got to go with AI. Well, I mean, maybe we could just put maybe in parenthes.
Filip Makraduli: Yeah. So I’ll share this later with you. Excellent. But yeah, basically that was it.
Demetrios: It worked. Ten out of ten for it. Working. That is also very cool.
Filip Makraduli: Live demo working. That’s good. So now doing the infinite screen, which I have stopped now.
Demetrios: Yeah, classic, dude. Well, I’ve got some questions coming through and the chat has been active too. So I’ll ask a few of the questions in the chat for a minute. But before I ask those questions in the chat, one thing that I was thinking about when you were talking about how to, like, the next step is getting better embeddings. And so was there a reason that you just went with the song title and then did you check, you said there was 2000 songs or how many songs? So did you do anything to check the output of the descriptions of these songs?
Filip Makraduli: Yeah, so I didn’t do like a systematic testing in terms of like, oh, yeah, the output is structured in this way. But yeah, I checked it roughly went through a few songs and they seemed like, I mean, of course you could add more info, but they seemed okay. So I was like, okay, let me try kind of whether this works. And, yeah, the descriptions were nice.
Demetrios: Awesome. Yeah. So that kind of goes into one of the questions that mornie’s asking. Let me see. Are you going to team this up with other methods, like collaborative filtering, content embeddings and stuff like that.
Filip Makraduli: Yeah, I was thinking about this different kind of styles, but I feel like I want to first try different things related to embeddings and language just because I feel like with the other things, with the other ways of doing these recommendations, other companies and other solutions have done a really great job there. So I wanted to try something different to see whether that could work as well or maybe to a similar degree. So that’s why I went towards this approach rather than collaborative filtering.
Demetrios: Yeah, it kind of felt like you wanted to test the boundaries and see if something like this, which seems a little far fetched, is actually possible. And it seems like I would give it a yes.
Filip Makraduli: It wasn’t that far fetched, actually, once you see it working.
Demetrios: Yeah, totally. Another question is coming through is asking, is it possible to merge the current mood so the vibe that you’re looking for with your musical preferences?
Filip Makraduli: Yeah. So I was thinking of that when we’re doing this, the playlist creation that I did for you, there is a way to get your top ten songs or your other playlists and so on from Spotify. So my idea of kind of capturing this added element was through Spotify like that. But of course it could be that you could enter that in your own profile in the app or so on. So one idea would be how would you capture that preferences of the user once you have the user there. So you’d need some data of the preferences of the user. So that’s the problem. But of course it is possible.
Demetrios: You know what I’d lOve? Like in your example, you put that, I feel like going for a walk or it’s raining, but I still feel like going through for a long walk in London. Right. You could probably just get that information from me, like what is the weather around me, where am I located? All that kind of stuff. So I don’t have to give you that context. You just add those kind of contextual things, especially weather. And I get the feeling that that would be another unlock too. Unless you’re like, you are the exact opposite of a sunny day on a sunny day. And it’s like, why does it keep playing this happy music? I told you I was sad.
Filip Makraduli: Yeah. You’re predicting not just the songs, but the mood also.
Demetrios: Yeah, totally.
Filip Makraduli: You don’t have to type anything, just open the website and you get everything.
Demetrios: Exactly. Yeah. Give me a few predictions just right off the bat and then maybe later we can figure it out. The other thing that I was thinking, could be a nice add on. I mean, the infinite feature request, I don’t think you realized you were going to get so many feature requests from me, but let it be known that if you come on here and I like your app, you’ll probably get some feature requests from me. So I was thinking about how it would be great if I could just talk to it instead of typing it in, right? And I could just explain my mood or explain my feeling and even top that off with a few melodies that are going on in my head, or a few singers or songwriters or songs that I really want, something like this, but not this song, and then also add that kind of thing, do the.
Filip Makraduli: Humming sound a bit and you play your melody and then you get.
Demetrios: Except I hum out of tune, so I don’t think that would work very well. I get a lot of random songs, that’s for sure. It would probably be just about as accurate as your recommendation engine is right now. Yeah. Well, this is awesome, man. I really appreciate you coming on here. I’m just going to make sure that there’s no other questions that came through the chat. No, looks like we’re good.
Demetrios: And for everyone out there that is listening, if you want to come on and talk about anything cool that you have built with Qdrant, or how you’re using Qdrant, or different ways that you would like Qdrant to be better, or things that you enjoy, whatever it may be, we’d love to have you on here. And I think that is it. We’re going to call it a day for the vector space talks, number two. We’ll see you all later. Philip, thanks so much for coming on. It’s.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/human-language-ai-models/)
                    ## 📄 `https-qdrant-tech-blog-iris-agent-qdrant.md`
                    ```md
                    # https://qdrant.tech/blog/iris-agent-qdrant/
# IrisAgent and Qdrant: Redefining Customer Support with AI
Manuel Meyer
·
March 06, 2024
![IrisAgent and Qdrant: Redefining Customer Support with AI](https://qdrant.tech/blog/iris-agent-qdrant/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * IrisAgent and Qdrant: Redefining Customer Support with AI
  *     * [The Challenge](https://qdrant.tech/blog/iris-agent-qdrant/#the-challenge)
    * [The Solution](https://qdrant.tech/blog/iris-agent-qdrant/#the-solution)
    * [Optimizing IrisAgent’s AI Pipeline: The Evaluation and Integration of Qdrant](https://qdrant.tech/blog/iris-agent-qdrant/#optimizing-irisagents-ai-pipeline-the-evaluation-and-integration-of-qdrant)
    * [Future of IrisAgent](https://qdrant.tech/blog/iris-agent-qdrant/#future-of-irisagent)
Artificial intelligence is evolving customer support, offering unprecedented capabilities for automating interactions, understanding user needs, and enhancing the overall customer experience. 
Bhatia describes IrisAgent as “the system of intelligence which sits on top of existing systems of records like support tickets, engineering bugs, sales data, or product data,” with the main objective of leveraging AI and generative AI, to automatically detect the intent and tags behind customer support tickets, reply to a large number of support tickets chats improve the time to resolution and increase the deflection rate of support teams. Ultimately, IrisAgent enables support teams to more with less and be more effective in helping customers.
##  [](https://qdrant.tech/blog/iris-agent-qdrant/#the-challenge)The Challenge
Throughout her career Bhatia noticed a lot of manual and inefficient processes in support teams paired with information silos between important functions like customer support, product management, engineering teams, and sales teams. These silos typically prevent support teams from accurately solving customers’ pain points, as they are only able to access a fraction of the internal knowledge and don’t get the relevant information and insights that other teams have.
IrisAgent is addressing these challenges with AI and GenAI by generating meaningful customer experience insights about what the root cause of specific customer escalations or churn. “The platform allows support teams to gather these cross-functional insights and connect them to a single view of customer problems,” Bhatia says. Additionally, IrisAgent facilitates the automation of mundane and repetitive support processes. In the past, these tasks were difficult to automate effectively due to the limitations of early AI technologies. Support functions often depended on rudimentary solutions like legacy decision trees, which suffered from a lack of scalability and robustness, primarily relying on simplistic keyword matching. However, advancements in AI and GenAI technologies have now enabled more sophisticated and efficient automation of these support processes.
##  [](https://qdrant.tech/blog/iris-agent-qdrant/#the-solution)The Solution
“IrisAgent provides a very holistic product profile, as we are the operating system for support teams,” Bhatia says. The platform includes features like omni-channel customer support automation, which integrates with other parts of the business, such as engineering or sales platforms, to really understand customer escalation points. Long before the advent of technologies such as ChatGPT, IrisAgeny had already been refining and advancing their AI and ML stack. This has enabled them to develop a comprehensive range of machine learning models, including both proprietary solutions and those built on cloud technologies. Through this advancement, IrisAgent was able to finetune on public and private customer data to achieve the level of accuracy that is needed to successfully deflect and resolve customer issues at scale.
![Iris GPT info](https://qdrant.tech/blog/iris-agent-qdrant/iris_gpt.png)
Since IrisAgent built out a lot of their AI related processes in-house with proprietary technology, they wanted to find ways to augment these capabilities with RAG technologies and vector databases. This strategic move was aimed at abstracting much of the technical complexity, thereby simplifying the process for engineers and data scientists on the team to interact with data and develop a variety of solutions built on top of it.
![Quote from CEO of IrisAgent](https://qdrant.tech/blog/iris-agent-qdrant/iris_ceo_quote.png)
“We were looking at a lot of vector databases in the market and one of our core requirements was that the solution needed to be open source because we have a strong emphasis on data privacy and security,” Bhatia says. Also, performance played a key role for IrisAgent during their evaluation as Bhatia mentions: “Despite it being a relatively new project at the time we tested Qdrant, the performance was really good.” Additional evaluation criteria were the ease of ability to deployment, future maintainability, and the quality of available documentation. Ultimately, IrisAgent decided to build with Qdrant as their vector database of choice, given these reasons:
  * **Open Source and Flexibility** : IrisAgent required a solution that was open source, to align with their data security needs and preference for self-hosting. Qdrant’s open-source nature allowed IrisAgent to deploy it on their cloud infrastructure seamlessly.
  * **Performance** : Early on, IrisAgent recognized Qdrant’s superior performance, despite its relative newness in the market. This performance aspect was crucial for handling large volumes of data efficiently.
  * **Ease of Use** : Qdrant’s user-friendly SDKs and compatibility with major programming languages like Go and Python made it an ideal choice for IrisAgent’s engineering team. Additionally, IrisAgent values Qdrant’s the solid documentation, which is easy to follow.
  * **Maintainability** : IrisAgent prioritized future maintainability in their choice of Qdrant, notably valuing the robustness and efficiency Rust provides, ensuring a scalable and future-ready solution.
##  [](https://qdrant.tech/blog/iris-agent-qdrant/#optimizing-irisagents-ai-pipeline-the-evaluation-and-integration-of-qdrant)Optimizing IrisAgent’s AI Pipeline: The Evaluation and Integration of Qdrant
IrisAgent utilizes comprehensive testing and sandbox environments, ensuring no customer data is used during the testing of new features. Initially, they deployed Qdrant in these environments to evaluate its performance, leveraging their own test data and employing Qdrant’s console and SDK features to conduct thorough data exploration and apply various filters. The primary languages used in these processes are Go, for its efficiency, and Python, for its strength in data science tasks.
After the successful testing, Qdrant’s outputs are now integrated into IrisAgent’s AI pipeline, enhancing a suite of proprietary AI models designed for tasks such as detecting hallucinations and similarities, and classifying customer intents. With Qdrant, IrisAgent saw significant performance and quality gains for their RAG use cases. Beyond this, IrisAgent also performs fine-tuning further in the development process.
Qdrant’s emphasis on open-source technology and support for main programming languages (Go and Python) ensures ease of use and compatibility with IrisAgent’s production environment. IrisAgent is deploying Qdrant on Google Cloud in order to fully leverage Google Cloud’s robust infrastructure and innovative offerings.
![Iris agent flow chart](https://qdrant.tech/blog/iris-agent-qdrant/iris_agent_flow_chart.png)
##  [](https://qdrant.tech/blog/iris-agent-qdrant/#future-of-irisagent)Future of IrisAgent
Looking ahead, IrisAgent is committed to pushing the boundaries of AI in customer support, with ambitious plans to evolve their product further. The cornerstone of this vision is a feature that will allow support teams to leverage historical support data more effectively, by automating the generation of knowledge base content to redefine how FAQs and product documentation are created. This strategic initiative aims not just to reduce manual effort but also to enrich the self-service capabilities of users. As IrisAgent continues to refine its AI algorithms and expand its training datasets, the goal is to significantly elevate the support experience, making it more seamless and intuitive for end-users.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/iris-agent-qdrant/)
                    ## 📄 `https-qdrant-tech-blog-metadata-deasy-labs.md`
                    ```md
                    # https://qdrant.tech/blog/metadata-deasy-labs/
# Metadata automation and optimization - Reece Griffiths | Vector Space Talks
Sabrina Aquino
·
February 24, 2025
![Metadata automation and optimization - Reece Griffiths | Vector Space Talks](https://qdrant.tech/blog/metadata-deasy-labs/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Metadata automation and optimization - Reece Griffiths | Vector Space Talks
  *     * [**Top takeaways:**](https://qdrant.tech/blog/metadata-deasy-labs/#top-takeaways)
    * [**Show notes:**](https://qdrant.tech/blog/metadata-deasy-labs/#show-notes)
    * [**More Quotes from Reece:**](https://qdrant.tech/blog/metadata-deasy-labs/#more-quotes-from-reece)
      * [**Try Deasy Labs 🚀**](https://qdrant.tech/blog/metadata-deasy-labs/#try-deasy-labs-)
> _“Metadata is one of the key unlocks to both segmentation and file organization, setting up the right knowledge base, and enriching it to hit that last mile of accuracy and speed.”_  
> **— Reece Griffiths**
##  [](https://qdrant.tech/blog/metadata-deasy-labs/#top-takeaways)**Top takeaways:**
Retrieval-augmented generation (RAG) and vector search are incomplete without high-quality metadata. In this episode of **Vector Space Talks** , Reece Griffiths explains how **metadata automation and optimization** can significantly enhance retrieval accuracy, filtering, and indexing efficiency.
Here are some key insights from this episode:
  1. **Why Metadata Matters in Vector Search:** Traditional approaches often focus on embedding models, but metadata can bridge the gap between mediocre and high-performance search systems.
  2. **Metadata for Segmentation vs. Enrichment:** Segmentation metadata helps filter and categorize data, while enrichment metadata provides additional context that improves retrieval accuracy.
  3. **Optimizing Hybrid Search with Metadata:** Reece explains how metadata can be embedded into sparse vectors for **hybrid search** , enhancing keyword and semantic search combinations.
  4. **Scaling Metadata Extraction:** Learn how Deasy Labs uses LLM-powered extraction methods to generate metadata dynamically and update taxonomies in real-time.
  5. **Metadata as an Access Control Layer:** Metadata can also be leveraged for **role-based access control (RBAC)** by defining data slices that different teams or users can access within a knowledge base.
> Fun Fact: Reece and his team at Deasy Labs experimented with **pure metadata embeddings** (without the original data) and found that hybrid search using metadata alone can yield strong retrieval performance.
##  [](https://qdrant.tech/blog/metadata-deasy-labs/#show-notes)**Show notes:**
00:00 Introduction to metadata automation and optimization.  
05:32 The role of metadata in retrieval-augmented generation (RAG).  
10:48 How Deasy Labs structures metadata extraction workflows.  
15:35 Implementing hybrid search with sparse metadata vectors.  
20:14 Automating metadata classification using LLMs.  
25:51 Best practices for maintaining metadata over time.  
30:18 Using metadata for segmentation and access control.  
35:43 Q&A and closing remarks.
##  [](https://qdrant.tech/blog/metadata-deasy-labs/#more-quotes-from-reece)**More Quotes from Reece:**
_“Going from 75% retrieval accuracy to 95%+ is hard. In many cases, 80% accuracy might as well be zero. Metadata is the key to getting that last mile.”_  
— Reece Griffiths
_“Metadata shouldn’t rely on manual tagging by business teams. With LLMs, we can auto-suggest domain-specific metadata dynamically and refine it over time.”_  
— Reece Griffiths
_“In a vector database, segmentation metadata helps you structure your knowledge base, while enrichment metadata boosts retrieval precision—both are critical.”_  
— Reece Griffiths
###  [](https://qdrant.tech/blog/metadata-deasy-labs/#try-deasy-labs-)**Try Deasy Labs 🚀**
Want to enhance your vector search performance with **automated metadata workflows**?
**Start now at**
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/metadata-deasy-labs/)
                    ## 📄 `https-qdrant-tech-blog-page-10.md`
                    ```md
                    # https://qdrant.tech/blog/page/10/
# Qdrant Blog
## Features and News
[![How Mixpeek Uses Qdrant for Efficient Multimodal Feature Stores](https://qdrant.tech/blog/case-study-mixpeek/preview/title.jpg) How Mixpeek Uses Qdrant for Efficient Multimodal Feature Stores Daniel Azoulai April 08, 2025 ](https://qdrant.tech/blog/case-study-mixpeek/)
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[!["Vector search and applications" by Andrey Vasnetsov, CTO at Qdrant](https://qdrant.tech/blog/vector-search-and-applications-record/preview/preview.jpg) "Vector search and applications" by Andrey Vasnetsov, CTO at Qdrant Andrey Vasnetsov, Co-founder and CTO at Qdrant has shared about vector search and applications with Learn NLP Academy.  Alyona Kavyerina December 11, 2023 ](https://qdrant.tech/blog/vector-search-and-applications-record/)[![From Content Quality to Compression: The Evolution of Embedding Models at Cohere with Nils Reimers](https://qdrant.tech/blog/cohere-embedding-v3/preview/preview.jpg) From Content Quality to Compression: The Evolution of Embedding Models at Cohere with Nils Reimers Nils Reimers head of machine learning at Cohere comes on the recent vector space talks to share details about their latest embedding V3 model. Demetrios Brinkmann November 19, 2023 ](https://qdrant.tech/blog/cohere-embedding-v3/)[![Powering Bloop semantic code search](https://qdrant.tech/blog/case-study-bloop/preview/preview.jpg) Powering Bloop semantic code search Bloop is a fast code-search engine that combines semantic search, regex search and precise code navigation Qdrant Team February 28, 2023 ](https://qdrant.tech/blog/case-study-bloop/)[![Pienso & Qdrant: Future Proofing Generative AI for Enterprise-Level Customers](https://qdrant.tech/blog/case-study-pienso/preview/preview.jpg) Pienso & Qdrant: Future Proofing Generative AI for Enterprise-Level Customers Why Pienso chose Qdrant as a cornerstone for building domain-specific foundation models. Qdrant Team February 28, 2023 ](https://qdrant.tech/blog/case-study-pienso/)[![Qdrant supports ARM architecture!](https://qdrant.tech/blog/qdrant-supports-arm-architecture/preview/preview.jpg) Qdrant supports ARM architecture! Qdrant's support for ARM architecture marks a pivotal step in enhancing accessibility and performance. This development optimizes data indexing and retrieval. Kacper Łukawski September 21, 2022 ](https://qdrant.tech/blog/qdrant-supports-arm-architecture/)[![Qdrant has joined NVIDIA Inception Program](https://qdrant.tech/blog/qdrant-joined-nvidia-inception-program/preview/preview.jpg) Qdrant has joined NVIDIA Inception Program Along with the various opportunities it gives, we are the most excited about GPU support since it is an essential feature in Qdrant's roadmap. Stay tuned for our new updates. Alyona Kavyerina April 04, 2022 ](https://qdrant.tech/blog/qdrant-joined-nvidia-inception-program/)[![Qdrant and Jina integration: storage backend support for DocArray](https://qdrant.tech/blog/qdrant-and-jina-integration/preview/preview.jpg) Qdrant and Jina integration: storage backend support for DocArray We are happy to announce that Jina.AI integrates Qdrant engine as a storage backend to their DocArray solution. Alyona Kavyerina March 15, 2022 ](https://qdrant.tech/blog/qdrant-and-jina-integration/)
  * [1](https://qdrant.tech/blog/)
  * [2](https://qdrant.tech/blog/page/2/)
  * [3](https://qdrant.tech/blog/page/3/)
  * [4](https://qdrant.tech/blog/page/4/)
  * [5](https://qdrant.tech/blog/page/5/)
  * [6](https://qdrant.tech/blog/page/6/)
  * [7](https://qdrant.tech/blog/page/7/)
  * [8](https://qdrant.tech/blog/page/8/)
  * [9](https://qdrant.tech/blog/page/9/)
  * [10](https://qdrant.tech/blog/page/10/)
  * [Newest](https://qdrant.tech/blog/)
### Get Started with Qdrant Free
![](https://qdrant.tech/img/rocket.svg)
###### Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/10/)
                    ## 📄 `https-qdrant-tech-blog-page-2.md`
                    ```md
                    # https://qdrant.tech/blog/page/2/
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Building a Facial Recognition System with Qdrant](https://qdrant.tech/blog/facial-recognition/preview/preview.jpg) Building a Facial Recognition System with Qdrant Build an AI app that uses facial recognition embeddings & vector search to match users with their celebrity look-alikes. David Myriel December 03, 2024 ](https://qdrant.tech/blog/facial-recognition/)[![Best Practices in RAG Evaluation: A Comprehensive Guide](https://qdrant.tech/blog/rag-evaluation-guide/preview/preview.jpg) Best Practices in RAG Evaluation: A Comprehensive Guide Explore best practices for evaluating Retrieval-Augmented Generation (RAG) systems. David Myriel November 24, 2024 ](https://qdrant.tech/blog/rag-evaluation-guide/)[![Empowering QA.tech’s Testing Agents with Real-Time Precision and Scale](https://qdrant.tech/blog/case-study-qatech/preview/preview.jpg) Empowering QA.tech’s Testing Agents with Real-Time Precision and Scale QA.tech uses Qdrant to power AI agents, enabling scalable, real-time web testing with custom embeddings and batch efficiency. Qdrant November 21, 2024 ](https://qdrant.tech/blog/case-study-qatech/)[![How Sprinklr Leverages Qdrant to Enhance AI-Driven Customer Experience Solutions](https://qdrant.tech/blog/case-study-sprinklr/preview/preview.jpg) How Sprinklr Leverages Qdrant to Enhance AI-Driven Customer Experience Solutions Learn how Sprinklr uses vector search to power AI tools for customer engagement. Qdrant October 17, 2024 ](https://qdrant.tech/blog/case-study-sprinklr/)[![New DeepLearning.AI Course on Retrieval Optimization: From Tokenization to Vector Quantization](https://qdrant.tech/blog/qdrant-deeplearning-ai-course/preview/preview.jpg) New DeepLearning.AI Course on Retrieval Optimization: From Tokenization to Vector Quantization Join Qdrant and DeepLearning.AI’s free, beginner-friendly course to learn retrieval optimization and boost search performance in machine learning. Qdrant October 06, 2024 ](https://qdrant.tech/blog/qdrant-deeplearning-ai-course/)[![Introducing Qdrant for Startups](https://qdrant.tech/blog/qdrant-for-startups-launch/preview/preview.jpg) Introducing Qdrant for Startups Enjoy special discounts from Qdrant, HuggingFace, LlamaIndex, and Airbyte, as well as expert support & tooling perks, and be the first to try new features. Qdrant October 02, 2024 ](https://qdrant.tech/blog/qdrant-for-startups-launch/)[![Qdrant and Shakudo: Secure & Performant Vector Search in VPC Environments](https://qdrant.tech/blog/case-study-shakudo/preview/preview.jpg) Qdrant and Shakudo: Secure & Performant Vector Search in VPC Environments Implementing vector search for enterprise AI via Qdrant's Hybrid Cloud integration into Shakudo’s virtual private cloud. Qdrant September 23, 2024 ](https://qdrant.tech/blog/case-study-shakudo/)[![Data-Driven RAG Evaluation: Testing Qdrant Apps with Relari AI](https://qdrant.tech/blog/qdrant-relari/preview/preview.jpg) Data-Driven RAG Evaluation: Testing Qdrant Apps with Relari AI Learn how Qdrant and Relari enhance RAG systems with vector search and data-driven RAG evaluation. Thierry Damiba, David Myriel & Yi Zhang September 16, 2024 ](https://qdrant.tech/blog/qdrant-relari/)[![Nyris & Qdrant: How Vectors are the Future of Visual Search](https://qdrant.tech/blog/case-study-nyris/preview/preview.jpg) Nyris & Qdrant: How Vectors are the Future of Visual Search Revolutionizing customer service in finance and insurance by leveraging vector search for faster responses and improved operational efficiency. Qdrant September 10, 2024 ](https://qdrant.tech/blog/case-study-nyris/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/2/)
                    ## 📄 `https-qdrant-tech-blog-page-3.md`
                    ```md
                    # https://qdrant.tech/blog/page/3/
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Kern AI & Qdrant: Precision AI Solutions for Finance and Insurance](https://qdrant.tech/blog/case-study-kern/preview/preview.jpg) Kern AI & Qdrant: Precision AI Solutions for Finance and Insurance Revolutionizing customer service in finance and insurance by leveraging vector search for faster responses and improved operational efficiency. Qdrant August 28, 2024 ](https://qdrant.tech/blog/case-study-kern/)[![Kairoswealth & Qdrant: Transforming Wealth Management with AI-Driven Insights and Scalable Vector Search](https://qdrant.tech/blog/case-study-kairoswealth/preview/preview.jpg) Kairoswealth & Qdrant: Transforming Wealth Management with AI-Driven Insights and Scalable Vector Search Enhancing wealth management using AI-driven insights and efficient vector search for improved recommendations and scalability. Qdrant July 10, 2024 ](https://qdrant.tech/blog/case-study-kairoswealth/)[![Qdrant 1.10 - Universal Query, Built-in IDF & ColBERT Support](https://qdrant.tech/blog/qdrant-1.10.x/preview/preview.jpg) Qdrant 1.10 - Universal Query, Built-in IDF & ColBERT Support Consolidated search API, built-in IDF, and native multivector support. David Myriel July 01, 2024 ](https://qdrant.tech/blog/qdrant-1.10.x/)[![Community Highlights #1](https://qdrant.tech/blog/community-highlights-1/preview/preview.jpg) Community Highlights #1 Celebrating top contributions and achievements in vector search, featuring standout projects, articles, and the Creator of the Month, Pavan Kumar! Sabrina Aquino June 20, 2024 ](https://qdrant.tech/blog/community-highlights-1/)[![Response to CVE-2024-3829: Arbitrary file upload vulnerability](https://qdrant.tech/blog/cve-2024-3829-response/preview/preview.jpg) Response to CVE-2024-3829: Arbitrary file upload vulnerability Upgrade your deployments to at least v1.9.0. Cloud deployments not materially affected. Mac Chaffee June 10, 2024 ](https://qdrant.tech/blog/cve-2024-3829-response/)[![Qdrant Attains SOC 2 Type II Audit Report](https://qdrant.tech/blog/qdrant-soc2-type2-audit/preview/preview.jpg) Qdrant Attains SOC 2 Type II Audit Report We're proud to announce achieving SOC 2 Type II compliance for Security, Availability, and Confidentiality. Sabrina Aquino May 23, 2024 ](https://qdrant.tech/blog/qdrant-soc2-type2-audit/)[![Introducing Qdrant Stars: Join Our Ambassador Program!](https://qdrant.tech/blog/qdrant-stars-announcement/preview/preview.jpg) Introducing Qdrant Stars: Join Our Ambassador Program! Say hello to the first Qdrant Stars and learn more about our new ambassador program! Sabrina Aquino May 19, 2024 ](https://qdrant.tech/blog/qdrant-stars-announcement/)[![Intel’s New CPU Powers Faster Vector Search](https://qdrant.tech/blog/qdrant-cpu-intel-benchmark/preview/preview.jpg) Intel’s New CPU Powers Faster Vector Search Intel’s 5th gen Xeon processor is made for enterprise-scale operations in vector space. David Myriel, Kumar Shivendu May 10, 2024 ](https://qdrant.tech/blog/qdrant-cpu-intel-benchmark/)[![QSoC 2024: Announcing Our Interns!](https://qdrant.tech/blog/qsoc24-interns-announcement/preview/preview.jpg) QSoC 2024: Announcing Our Interns! We are pleased to announce the selection of interns for the inaugural Qdrant Summer of Code (QSoC) program. Sabrina Aquino May 08, 2024 ](https://qdrant.tech/blog/qsoc24-interns-announcement/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/3/)
                    ## 📄 `https-qdrant-tech-blog-page-4.md`
                    ```md
                    # https://qdrant.tech/blog/page/4/
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Are You Vendor Locked?](https://qdrant.tech/blog/are-you-vendor-locked/preview/preview.jpg) Are You Vendor Locked? Redefining freedom in the age of Generative AI. We believe that vendor-dependency comes from hardware, not software. David Myriel May 05, 2024 ](https://qdrant.tech/blog/are-you-vendor-locked/)[![Visua and Qdrant: Vector Search in Computer Vision](https://qdrant.tech/blog/case-study-visua/preview/preview.jpg) Visua and Qdrant: Vector Search in Computer Vision How Visua uses Qdrant as a vector search engine for quality control and anomaly detection in their computer vision platform. Manuel Meyer May 01, 2024 ](https://qdrant.tech/blog/case-study-visua/)[![Qdrant 1.9.0 - Heighten Your Security With Role-Based Access Control Support](https://qdrant.tech/blog/qdrant-1.9.x/preview/preview.jpg) Qdrant 1.9.0 - Heighten Your Security With Role-Based Access Control Support New access control options for RBAC, a much faster shard transfer procedure, and direct support for byte embeddings. David Myriel April 24, 2024 ](https://qdrant.tech/blog/qdrant-1.9.x/)[![Qdrant's Trusted Partners for Hybrid Cloud Deployment](https://qdrant.tech/blog/hybrid-cloud-launch-partners/preview/preview.jpg) Qdrant's Trusted Partners for Hybrid Cloud Deployment With the launch of Qdrant Hybrid Cloud we provide developers the ability to deploy Qdrant as a managed vector database in any desired environment. Manuel Meyer April 15, 2024 ](https://qdrant.tech/blog/hybrid-cloud-launch-partners/)[![Developing Advanced RAG Systems with Qdrant Hybrid Cloud and LangChain ](https://qdrant.tech/blog/hybrid-cloud-langchain/preview/preview.jpg) Developing Advanced RAG Systems with Qdrant Hybrid Cloud and LangChain Empowering engineers and scientists globally to easily and securely develop and scale their GenAI applications. Qdrant April 14, 2024 ](https://qdrant.tech/blog/hybrid-cloud-langchain/)[![Advancements and Challenges in RAG Systems - Syed Asad | Vector Space Talks](https://qdrant.tech/blog/rag-advancements-challenges/preview/preview.jpg) Advancements and Challenges in RAG Systems - Syed Asad | Vector Space Talks Syed Asad unfolds the challenges of developing multimodal RAG systems at Kiwi Tech, detailing the balance between accuracy and cost-efficiency, and exploring various tools and approaches like GPT 4 and Mixtral to enhance family tree apps and financial chatbots while navigating the hurdles of data privacy and infrastructure demands. Demetrios Brinkmann April 11, 2024 ](https://qdrant.tech/blog/rag-advancements-challenges/)[![Building Search/RAG for an OpenAPI spec - Nick Khami | Vector Space Talks](https://qdrant.tech/blog/building-search-rag-open-api/preview/preview.jpg) Building Search/RAG for an OpenAPI spec - Nick Khami | Vector Space Talks Nick Khami discuss Trieve's work with Qdrant's Open API spec for creating powerful and simplified search and recommendation systems, touching on real-world applications, technical specifics, and the potential for improved user experiences. Demetrios Brinkmann April 11, 2024 ](https://qdrant.tech/blog/building-search-rag-open-api/)[![Iveta Lohovska on Gen AI and Vector Search | Qdrant](https://qdrant.tech/blog/gen-ai-and-vector-search/preview/preview.jpg) Iveta Lohovska on Gen AI and Vector Search | Qdrant Discover valuable insights on generative AI, vector search, and ethical AI implementation from Iveta Lohovska, Chief Technologist at HPE. Demetrios Brinkmann April 11, 2024 ](https://qdrant.tech/blog/gen-ai-and-vector-search/)[![Red Hat OpenShift and Qdrant Hybrid Cloud Offer Seamless and Scalable AI](https://qdrant.tech/blog/hybrid-cloud-red-hat-openshift/preview/preview.jpg) Red Hat OpenShift and Qdrant Hybrid Cloud Offer Seamless and Scalable AI Qdrant brings managed vector databases to Red Hat OpenShift for large-scale GenAI. Qdrant April 11, 2024 ](https://qdrant.tech/blog/hybrid-cloud-red-hat-openshift/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/4/)
                    ## 📄 `https-qdrant-tech-blog-page-5.md`
                    ```md
                    # https://qdrant.tech/blog/page/5/
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Qdrant Hybrid Cloud and DigitalOcean for Scalable and Secure AI Solutions](https://qdrant.tech/blog/hybrid-cloud-digitalocean/preview/preview.jpg) Qdrant Hybrid Cloud and DigitalOcean for Scalable and Secure AI Solutions Enabling developers to deploy a managed vector database in their DigitalOcean Environment. Qdrant April 11, 2024 ](https://qdrant.tech/blog/hybrid-cloud-digitalocean/)[![Enhance AI Data Sovereignty with Aleph Alpha and Qdrant Hybrid Cloud](https://qdrant.tech/blog/hybrid-cloud-aleph-alpha/preview/preview.jpg) Enhance AI Data Sovereignty with Aleph Alpha and Qdrant Hybrid Cloud Empowering the world’s best companies in their AI journey. Qdrant April 11, 2024 ](https://qdrant.tech/blog/hybrid-cloud-aleph-alpha/)[![Vultr and Qdrant Hybrid Cloud Support Next-Gen AI Projects](https://qdrant.tech/blog/hybrid-cloud-vultr/preview/preview.jpg) Vultr and Qdrant Hybrid Cloud Support Next-Gen AI Projects Providing a flexible platform for high-performance vector search in next-gen AI workloads. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-vultr/)[![STACKIT and Qdrant Hybrid Cloud for Best Data Privacy](https://qdrant.tech/blog/hybrid-cloud-stackit/preview/preview.jpg) STACKIT and Qdrant Hybrid Cloud for Best Data Privacy Empowering German AI development with a data privacy-first platform. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-stackit/)[![Qdrant Hybrid Cloud and Scaleway Empower GenAI](https://qdrant.tech/blog/hybrid-cloud-scaleway/preview/preview.jpg) Qdrant Hybrid Cloud and Scaleway Empower GenAI Supporting innovation in AI with the launch of a revolutionary managed database for startups and enterprises. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-scaleway/)[![Qdrant and OVHcloud Bring Vector Search to All Enterprises](https://qdrant.tech/blog/hybrid-cloud-ovhcloud/preview/preview.jpg) Qdrant and OVHcloud Bring Vector Search to All Enterprises Collaborating to support startups and enterprises in Europe with a strong focus on data control and privacy. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-ovhcloud/)[![New RAG Horizons with Qdrant Hybrid Cloud and LlamaIndex](https://qdrant.tech/blog/hybrid-cloud-llamaindex/preview/preview.jpg) New RAG Horizons with Qdrant Hybrid Cloud and LlamaIndex Unlock the most advanced RAG opportunities with Qdrant Hybrid Cloud and LlamaIndex. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-llamaindex/)[![Cutting-Edge GenAI with Jina AI and Qdrant Hybrid Cloud](https://qdrant.tech/blog/hybrid-cloud-jinaai/preview/preview.jpg) Cutting-Edge GenAI with Jina AI and Qdrant Hybrid Cloud Build your most successful app with Jina AI embeddings and on Qdrant Hybrid Cloud. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-jinaai/)[![Qdrant Hybrid Cloud and Haystack for Enterprise RAG](https://qdrant.tech/blog/hybrid-cloud-haystack/preview/preview.jpg) Qdrant Hybrid Cloud and Haystack for Enterprise RAG A winning combination for enterprise-scale RAG consists of a strong framework and a scalable database. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-haystack/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/5/)
                    ## 📄 `https-qdrant-tech-blog-page-6.md`
                    ```md
                    # https://qdrant.tech/blog/page/6/
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Elevate Your Data With Airbyte and Qdrant Hybrid Cloud](https://qdrant.tech/blog/hybrid-cloud-airbyte/preview/preview.jpg) Elevate Your Data With Airbyte and Qdrant Hybrid Cloud Leverage Airbyte and Qdrant Hybrid Cloud for best-in-class data performance. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-airbyte/)[![Teaching Vector Databases at Scale - Alfredo Deza | Vector Space Talks](https://qdrant.tech/blog/teaching-vector-db-at-scale/preview/preview.jpg) Teaching Vector Databases at Scale - Alfredo Deza | Vector Space Talks Alfredo Deza discusses the practicality of machine learning operations, highlighting how personal interest in topics like wine datasets enhances engagement, while reflecting on the synergies between his professional sportsman discipline and the persistent, straightforward approach required for effectively educating on vector databases and large language models. Demetrios Brinkmann April 09, 2024 ](https://qdrant.tech/blog/teaching-vector-db-at-scale/)[![How to meow on the long tail with Cheshire Cat AI? - Piero and Nicola | Vector Space Talks](https://qdrant.tech/blog/meow-with-cheshire-cat/preview/preview.jpg) How to meow on the long tail with Cheshire Cat AI? - Piero and Nicola | Vector Space Talks Cheshire Cat AI's Piero Savastano and Nicola Procopio discusses the framework's vector space complexities, community growth, and future cloud-based expansions. Demetrios Brinkmann April 09, 2024 ](https://qdrant.tech/blog/meow-with-cheshire-cat/)[![Response to CVE-2024-2221: Arbitrary file upload vulnerability](https://qdrant.tech/blog/cve-2024-2221-response/preview/preview.jpg) Response to CVE-2024-2221: Arbitrary file upload vulnerability Upgrade your deployments to at least v1.9.0. Cloud deployments not materially affected. Mike Jang April 05, 2024 ](https://qdrant.tech/blog/cve-2024-2221-response/)[![Introducing FastLLM: Qdrant’s Revolutionary LLM](https://qdrant.tech/blog/fastllm-announcement/preview/preview.jpg) Introducing FastLLM: Qdrant’s Revolutionary LLM Lightweight and open-source. Custom made for RAG and completely integrated with Qdrant. David Myriel April 01, 2024 ](https://qdrant.tech/blog/fastllm-announcement/)[![VirtualBrain: Best RAG to unleash the real power of AI - Guillaume Marquis | Vector Space Talks](https://qdrant.tech/blog/virtualbrain-best-rag/preview/preview.jpg) VirtualBrain: Best RAG to unleash the real power of AI - Guillaume Marquis | Vector Space Talks Guillaume Marquis, CTO & Co-Founder at VirtualBrain, reveals the mechanics of advanced document retrieval with RAG technology, discussing the challenges of scalability, up-to-date information, and navigating user feedback to enhance the productivity of knowledge workers. Demetrios Brinkmann March 27, 2024 ](https://qdrant.tech/blog/virtualbrain-best-rag/)[![Talk with YouTube without paying a cent - Francesco Saverio Zuppichini | Vector Space Talks](https://qdrant.tech/blog/youtube-without-paying-cent/preview/preview.jpg) Talk with YouTube without paying a cent - Francesco Saverio Zuppichini | Vector Space Talks Francesco Zuppichini outlines the process of converting YouTube video subtitles into searchable vector databases, leveraging tools like YouTube DL and Hugging Face, and addressing the challenges of coding without conventional frameworks in machine learning engineering. Demetrios Brinkmann March 27, 2024 ](https://qdrant.tech/blog/youtube-without-paying-cent/)[![Qdrant is Now Available on Azure Marketplace!](https://qdrant.tech/blog/azure-marketplace/preview/preview.jpg) Qdrant is Now Available on Azure Marketplace! Discover the power of Qdrant on Azure Marketplace! Get started today and streamline your operations with ease. David Myriel March 26, 2024 ](https://qdrant.tech/blog/azure-marketplace/)[![Production-scale RAG for Real-Time News Distillation - Robert Caulk | Vector Space Talks](https://qdrant.tech/blog/real-time-news-distillation-rag/preview/preview.jpg) Production-scale RAG for Real-Time News Distillation - Robert Caulk | Vector Space Talks Robert Caulk, founder of Emergent Methods, discusses the complexities of context engineering, the power of Newscatcher API for broader news access, and the sophisticated use of tools like Qdrant for improved recommendation systems, all while emphasizing the importance of efficiency and modularity in technology stacks for real-time data management. Demetrios Brinkmann March 25, 2024 ](https://qdrant.tech/blog/real-time-news-distillation-rag/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/6/)
                    ## 📄 `https-qdrant-tech-blog-page-7.md`
                    ```md
                    # https://qdrant.tech/blog/page/7/
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Insight Generation Platform for LifeScience Corporation - Hooman Sedghamiz | Vector Space Talks](https://qdrant.tech/blog/insight-generation-platform/preview/preview.jpg) Insight Generation Platform for LifeScience Corporation - Hooman Sedghamiz | Vector Space Talks Hooman Sedghamiz discloses the potential of AI in life sciences, from custom knowledge applications to improving crop yield predictions, while tearing apart the nuances of in-house AI deployment for multi-faceted enterprise efficiency. Demetrios Brinkmann March 25, 2024 ](https://qdrant.tech/blog/insight-generation-platform/)[![The challenges in using LLM-as-a-Judge - Sourabh Agrawal | Vector Space Talks](https://qdrant.tech/blog/llm-as-a-judge/preview/preview.jpg) The challenges in using LLM-as-a-Judge - Sourabh Agrawal | Vector Space Talks Everything you need to know about chatbots, Sourabh Agrawal goes in to detail on evaluating their performance, from real-time to post-feedback assessments, and introduces uptrendAI—an open-source tool for enhancing chatbot interactions through customized and logical evaluations. Demetrios Brinkmann March 19, 2024 ](https://qdrant.tech/blog/llm-as-a-judge/)[![Vector Search for Content-Based Video Recommendation - Gladys and Samuel from Dailymotion](https://qdrant.tech/blog/vector-search-vector-recommendation/preview/preview.jpg) Vector Search for Content-Based Video Recommendation - Gladys and Samuel from Dailymotion Gladys Roch and Samuel Leonardo Gracio from Dailymotion, discussed optimizing video recommendations using Qdrant's vector search alongside challenges and solutions in content-based recommender systems. Demetrios Brinkmann March 19, 2024 ](https://qdrant.tech/blog/vector-search-vector-recommendation/)[![IrisAgent and Qdrant: Redefining Customer Support with AI](https://qdrant.tech/blog/iris-agent-qdrant/preview/preview.jpg) IrisAgent and Qdrant: Redefining Customer Support with AI Learn how IrisAgent leverages Qdrant for RAG to automate support, and improve resolution times, transforming customer service Manuel Meyer March 06, 2024 ](https://qdrant.tech/blog/iris-agent-qdrant/)[![Dailymotion's Journey to Crafting the Ultimate Content-Driven Video Recommendation Engine with Qdrant Vector Database](https://qdrant.tech/blog/case-study-dailymotion/preview/preview.jpg) Dailymotion's Journey to Crafting the Ultimate Content-Driven Video Recommendation Engine with Qdrant Vector Database Dailymotion's Journey to Crafting the Ultimate Content-Driven Video Recommendation Engine with Qdrant Vector Database Atita Arora February 27, 2024 ](https://qdrant.tech/blog/case-study-dailymotion/)[![Qdrant vs Pinecone: Vector Databases for AI Apps](https://qdrant.tech/blog/comparing-qdrant-vs-pinecone-vector-databases/preview/preview.jpg) Qdrant vs Pinecone: Vector Databases for AI Apps In this detailed Qdrant vs Pinecone comparison, we share the top features to determine the best vector database for your AI applications. Qdrant Team February 25, 2024 ](https://qdrant.tech/blog/comparing-qdrant-vs-pinecone-vector-databases/)[![What is Vector Similarity? Understanding its Role in AI Applications.](https://qdrant.tech/blog/what-is-vector-similarity/preview/preview.jpg) What is Vector Similarity? Understanding its Role in AI Applications. Discover the significance of vector similarity in AI applications and how our vector database revolutionizes similarity search technology for enhanced performance and accuracy. Qdrant Team February 24, 2024 ](https://qdrant.tech/blog/what-is-vector-similarity/)[![DSPy vs LangChain: A Comprehensive Framework Comparison](https://qdrant.tech/blog/dspy-vs-langchain/preview/preview.jpg) DSPy vs LangChain: A Comprehensive Framework Comparison We dive deep into the capabilities of DSPy and LangChain and discuss scenarios where each of these frameworks shine. Qdrant Team February 23, 2024 ](https://qdrant.tech/blog/dspy-vs-langchain/)[![Qdrant Summer of Code 24](https://qdrant.tech/blog/qdrant-summer-of-code-24/preview/preview.jpg) Qdrant Summer of Code 24 Introducing Qdrant Summer of Code 2024 program. GSoC alternative. Andre Zayarni February 21, 2024 ](https://qdrant.tech/blog/qdrant-summer-of-code-24/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/7/)
                    ## 📄 `https-qdrant-tech-blog-page-8.md`
                    ```md
                    # https://qdrant.tech/blog/page/8/
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Dust and Qdrant: Using AI to Unlock Company Knowledge and Drive Employee Productivity](https://qdrant.tech/blog/dust-and-qdrant/preview/preview.jpg) Dust and Qdrant: Using AI to Unlock Company Knowledge and Drive Employee Productivity Using AI to Unlock Company Knowledge and Drive Employee Productivity Manuel Meyer February 06, 2024 ](https://qdrant.tech/blog/dust-and-qdrant/)[![The Bitter Lesson of Retrieval in Generative Language Model Workflows - Mikko Lehtimäki | Vector Space Talks](https://qdrant.tech/blog/bitter-lesson-generative-language-model/preview/preview.jpg) The Bitter Lesson of Retrieval in Generative Language Model Workflows - Mikko Lehtimäki | Vector Space Talks Mikko Lehtimäki delves into the intricate world of retrieval-augmented generation, discussing how Yokot AI manages vast diverse data inputs and how focusing on re-ranking can massively improve LLM workflows and output quality. Demetrios Brinkmann January 29, 2024 ](https://qdrant.tech/blog/bitter-lesson-generative-language-model/)[![Indexify Unveiled - Diptanu Gon Choudhury | Vector Space Talks](https://qdrant.tech/blog/indexify-content-extraction-engine/preview/preview.jpg) Indexify Unveiled - Diptanu Gon Choudhury | Vector Space Talks Diptanu Gon Choudhury shares insights on re-imaging Spark and data infrastructure while discussing his work on Indexify to enhance AI-driven workflows and knowledge bases. Demetrios Brinkmann January 26, 2024 ](https://qdrant.tech/blog/indexify-content-extraction-engine/)[![Unlocking AI Potential: Insights from Stanislas Polu](https://qdrant.tech/blog/qdrant-x-dust-vector-search/preview/preview.jpg) Unlocking AI Potential: Insights from Stanislas Polu Explore the dynamic discussion with Stanislas Polu on AI, ML, entrepreneurship, and product development. Gain valuable insights into AI's transformative power. Demetrios Brinkmann January 26, 2024 ](https://qdrant.tech/blog/qdrant-x-dust-vector-search/)[![Announcing Qdrant's $28M Series A Funding Round](https://qdrant.tech/blog/series-A-funding-round/preview/preview.jpg) Announcing Qdrant's $28M Series A Funding Round Andre Zayarni, CEO & Co-Founder January 23, 2024 ](https://qdrant.tech/blog/series-a-funding-round/)[![Introducing Qdrant Cloud on Microsoft Azure](https://qdrant.tech/blog/qdrant-cloud-on-microsoft-azure/preview/preview.jpg) Introducing Qdrant Cloud on Microsoft Azure Learn the benefits of Qdrant Cloud on Azure. Manuel Meyer January 17, 2024 ](https://qdrant.tech/blog/qdrant-cloud-on-microsoft-azure/)[![Qdrant Updated Benchmarks 2024](https://qdrant.tech/blog/qdrant-benchmarks-2024/preview/preview.jpg) Qdrant Updated Benchmarks 2024 We've compared how Qdrant performs against the other vector search engines to give you a thorough performance analysis Sabrina Aquino January 15, 2024 ](https://qdrant.tech/blog/qdrant-benchmarks-2024/)[![Navigating challenges and innovations in search technologies](https://qdrant.tech/blog/navigating-challenges-innovations/preview/preview.jpg) Navigating challenges and innovations in search technologies Podcast on search and LLM with Datatalk.club Atita Arora January 12, 2024 ](https://qdrant.tech/blog/navigating-challenges-innovations/)[![Optimizing an Open Source Vector Database with Andrey Vasnetsov](https://qdrant.tech/blog/open-source-vector-search-engine-vector-database/preview/preview.jpg) Optimizing an Open Source Vector Database with Andrey Vasnetsov Learn key strategies for optimizing vector search from Andrey Vasnetsov, CTO at Qdrant. Dive into techniques like efficient indexing for improved performance. Demetrios Brinkmann January 10, 2024 ](https://qdrant.tech/blog/open-source-vector-search-engine-vector-database/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/8/)
                    ## 📄 `https-qdrant-tech-blog-page-9.md`
                    ```md
                    # https://qdrant.tech/blog/page/9/
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Vector Search Complexities: Insights from Projects in Image Search and RAG - Noé Achache | Vector Space Talks](https://qdrant.tech/blog/vector-image-search-rag/preview/preview.jpg) Vector Search Complexities: Insights from Projects in Image Search and RAG - Noé Achache | Vector Space Talks Noé Achache shares insights on vector search complexities, discussing projects on image matching, document retrieval, and handling sensitive medical data with practical solutions and industry challenges. Demetrios Brinkmann January 09, 2024 ](https://qdrant.tech/blog/vector-image-search-rag/)[![How to Superpower Your Semantic Search Using a Vector Database Vector Space Talks](https://qdrant.tech/blog/semantic-search-vector-database/preview/preview.jpg) How to Superpower Your Semantic Search Using a Vector Database Vector Space Talks Unlock the secrets of supercharging semantic search with Nicolas Mauti's insights on leveraging vector databases. Discover advanced strategies. Demetrios Brinkmann January 09, 2024 ](https://qdrant.tech/blog/semantic-search-vector-database/)[![Building LLM Powered Applications in Production - Hamza Farooq | Vector Space Talks](https://qdrant.tech/blog/llm-complex-search-copilot/preview/preview.jpg) Building LLM Powered Applications in Production - Hamza Farooq | Vector Space Talks Hamza Farooq presents the future of large language models, complex search, and copilot, discussing real-world applications and the challenges of implementing these technologies in production. Demetrios Brinkmann January 09, 2024 ](https://qdrant.tech/blog/llm-complex-search-copilot/)[![Building a High-Performance Entity Matching Solution with Qdrant - Rishabh Bhardwaj | Vector Space Talks](https://qdrant.tech/blog/entity-matching-qdrant/preview/preview.jpg) Building a High-Performance Entity Matching Solution with Qdrant - Rishabh Bhardwaj | Vector Space Talks Rishabh Bhardwaj, a Data Engineer at HRS Group, discusses building a high-performance hotel matching solution with Qdrant, addressing data inconsistency, duplication, and real-time processing challenges. Demetrios Brinkmann January 09, 2024 ](https://qdrant.tech/blog/entity-matching-qdrant/)[![FastEmbed: Fast & Lightweight Embedding Generation - Nirant Kasliwal | Vector Space Talks](https://qdrant.tech/blog/fast-embed-models/preview/preview.jpg) FastEmbed: Fast & Lightweight Embedding Generation - Nirant Kasliwal | Vector Space Talks Nirant Kasliwal discusses the efficiency and optimization techniques of FastEmbed, a Python library designed for speedy, lightweight embedding generation in machine learning applications. Demetrios Brinkmann January 09, 2024 ](https://qdrant.tech/blog/fast-embed-models/)[![When music just doesn't match our vibe, can AI help? - Filip Makraduli | Vector Space Talks](https://qdrant.tech/blog/human-language-ai-models/preview/preview.jpg) When music just doesn't match our vibe, can AI help? - Filip Makraduli | Vector Space Talks Filip Makraduli discusses using human language and AI to capture music vibes, encoding text with sentence transformers, generating recommendations through vector spaces, integrating Streamlit and Spotify API, and future improvements for AI-powered music recommendations. Demetrios Brinkmann January 09, 2024 ](https://qdrant.tech/blog/human-language-ai-models/)[![Binary Quantization - Andrey Vasnetsov | Vector Space Talks](https://qdrant.tech/blog/binary-quantization/preview/preview.jpg) Binary Quantization - Andrey Vasnetsov | Vector Space Talks Andrey Vasnetsov, CTO of Qdrant, discusses the concept of binary quantization and its benefits in vector indexing, including the challenges and potential future developments of this technique. Demetrios Brinkmann January 09, 2024 ](https://qdrant.tech/blog/binary-quantization/)[![Loading Unstructured.io Data into Qdrant from the Terminal](https://qdrant.tech/blog/qdrant-unstructured/preview/preview.jpg) Loading Unstructured.io Data into Qdrant from the Terminal Learn how to simplify the process of loading unstructured data into Qdrant using the Qdrant Unstructured destination. Anush Shetty January 09, 2024 ](https://qdrant.tech/blog/qdrant-unstructured/)[![Chat with a codebase using Qdrant and N8N](https://qdrant.tech/blog/qdrant-n8n/preview/preview.jpg) Chat with a codebase using Qdrant and N8N Building a RAG-based chatbot using Qdrant and N8N to chat with a codebase on GitHub Anush Shetty January 06, 2024 ](https://qdrant.tech/blog/qdrant-n8n/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/9/)
                    ## 📄 `https-qdrant-tech-blog-qdrant-1-13-x.md`
                    ```md
                    # https://qdrant.tech/blog/qdrant-1.13.x/
# Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine
David Myriel
·
January 23, 2025
![Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine](https://qdrant.tech/blog/qdrant-1.13.x/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine
  *     * [GPU Accelerated Indexing](https://qdrant.tech/blog/qdrant-1.13.x/#gpu-accelerated-indexing)
      * [Benchmarks on Common GPUs](https://qdrant.tech/blog/qdrant-1.13.x/#benchmarks-on-common-gpus)
      * [](https://qdrant.tech/blog/qdrant-1.13.x/#instructions--documentationdocumentationguidesrunning-with-gpu)[Instructions & Documentation](https://qdrant.tech/documentation/guides/running-with-gpu/)
    * [Strict Mode for Operational Control](https://qdrant.tech/blog/qdrant-1.13.x/#strict-mode-for-operational-control)
      * [Enable Strict Mode](https://qdrant.tech/blog/qdrant-1.13.x/#enable-strict-mode)
    * [HNSW Graph Compression](https://qdrant.tech/blog/qdrant-1.13.x/#hnsw-graph-compression)
    * [Filter by Named Vectors](https://qdrant.tech/blog/qdrant-1.13.x/#filter-by-named-vectors)
      * [Create a Collection with Named Vectors](https://qdrant.tech/blog/qdrant-1.13.x/#create-a-collection-with-named-vectors)
      * [Sample Request](https://qdrant.tech/blog/qdrant-1.13.x/#sample-request)
    * [Custom Storage Engine](https://qdrant.tech/blog/qdrant-1.13.x/#custom-storage-engine)
      * [Our New Storage Architecture](https://qdrant.tech/blog/qdrant-1.13.x/#our-new-storage-architecture)
    * [Get Started with Qdrant](https://qdrant.tech/blog/qdrant-1.13.x/#get-started-with-qdrant)
**GPU Accelerated Indexing:** Fast HNSW indexing with architecture-free GPU support.  
**Strict Mode:** Enforce operation restrictions on collections for enhanced control.  
**HNSW Graph Compression:** Reduce storage use via HNSW Delta Encoding.  
**Named Vector Filtering:** New `has_vector` filtering condition for named vectors.  
**Custom Storage:** For constant-time reads/writes of payloads and sparse vectors.  
##  [](https://qdrant.tech/blog/qdrant-1.13.x/#gpu-accelerated-indexing)GPU Accelerated Indexing
![gpu-accelerated-indexing](https://qdrant.tech/blog/qdrant-1.13.x/image_6.png)
We are making it easier for you to handle even **the most demanding workloads**.
Qdrant now supports GPU-accelerated HNSW indexing **on all major GPU vendors, including NVIDIA, AMD and Intel**. This new feature reduces indexing times, making it a game-changer for projects where speed truly matters.
> Indexing over GPU now delivers speeds up to 10x faster than CPU-based methods for the equivalent hardware price.
Our custom implementation of GPU-accelerated HNSW indexing **is built entirely in-house**. Unlike solutions that depend on third-party libraries, our approach is vendor-agnostic, meaning it works seamlessly with any modern GPU that supports **Vulkan API**. This ensures broad compatibility and flexibility for a wide range of systems.
_Here is a picture of us, running Qdrant with GPU support on a SteamDeck (AMD Van Gogh GPU):_
![Qdrant on SteamDeck](https://qdrant.tech/blog/qdrant-1.13.x/gpu-test.jpg)
Qdrant on SteamDeck with integrated AMD GPU
This experiment didn’t require any changes to the codebase, and everything worked right out of the box with our AMD Docker image.
> As of right now this solution supports only on-premises deployments, but we will introduce support for Qdrant Cloud shortly.
###  [](https://qdrant.tech/blog/qdrant-1.13.x/#benchmarks-on-common-gpus)Benchmarks on Common GPUs
**Qdrant doesn’t require high-end GPUs** to achieve significant performance improvements. The table below compares indexing times and instance costs for 1 million vectors (1536-dimensional) across common GPU machines:
**Configuration** | **Indexing time (s)** | **Price per Instance (USD/month)**  
---|---|---  
AMD Radeon Pro V520 | 33.1 | $394.20 (CPU + GPU)  
Nvidia T4 | 19.1 |  $277.40 (CPU) + $255.50(GPU) = $532.90  
Nvidia L4 | 12.4 |  $214.32 (CPU) + $408.83(GPU) = $624.15  
8 CPU Cores | 97.5 | $195.67  
4 CPU Cores | 221.9 | $107.16  
_Quoted prices are from Google Cloud Platform (NVIDIA) and AWS (AMD)_
**Additional Benefits:**
  * **Multi-GPU Support:** Index segments concurrently to handle large-scale workloads.
  * **Hardware Flexibility:** Doesn’t require high-end GPUs to achieve significant performance improvements.
  * **Full Feature Support:** GPU indexing supports **all quantization options and datatypes** implemented in Qdrant.
  * **Large-Scale Benefits:** Fast indexing unlocks larger size of segments, which leads to **higher RPS on the same hardware**.
###  [](https://qdrant.tech/blog/qdrant-1.13.x/#instructions--documentationdocumentationguidesrunning-with-gpu)[Instructions & Documentation](https://qdrant.tech/documentation/guides/running-with-gpu/)
The setup is simple, with pre-configured Docker images 
> Note: Logs will clearly indicate GPU detection and usage for transparency.
_Read more about this feature in the[**GPU Indexing Documentation**](https://qdrant.tech/documentation/guides/running-with-gpu/)_
####  [](https://qdrant.tech/blog/qdrant-1.13.x/#interview-with-the-creator-of-gpu-indexing)Interview With the Creator of GPU Indexing
We interviewed **Qdrant’s own Ivan Pleshkov from the Core development team**. Ivan created the new GPU indexing feature with an innovative approach he brings from the gaming industry. Listen in to hear about his vision and challenges while building the feature.
##  [](https://qdrant.tech/blog/qdrant-1.13.x/#strict-mode-for-operational-control)Strict Mode for Operational Control
![strict-mode](https://qdrant.tech/blog/qdrant-1.13.x/image_2.png)
**Strict Mode** ensures consistent performance in distributed deployments by enforcing operational controls. It limits computationally intensive operations like unindexed filtering, batch sizes, and search parameters (`hnsw_ef`, `oversampling`) This prevents inefficient usage that could overload your system.
Additional safeguards, including limits on **payload sizes** , **filter conditions** , and **timeouts** , keep high-demand applications fast and reliable. This feature is configured via `strict_mode_config`, and it allows collection-level customization while maintaining backward compatibility.
> New collections will default to **Strict Mode** , ensuring compliance by design and balancing workloads across tenants.
This feature also enhances usability by providing **detailed error messages** when requests exceed defined limits. The system will give you clear guidance on resolution steps.
**Strict Mode** solves the “ _noisy neighbor_ ” problem and optimizes resource allocation, making multi-tenancy work nicely in serverless mode.
###  [](https://qdrant.tech/blog/qdrant-1.13.x/#enable-strict-mode)Enable Strict Mode
To configure **Strict Mode** , refer to the [**schema definitions**](https://api.qdrant.tech/api-reference/collections/create-collection#request.body.strict_mode_config) for all available `strict_mode_config` parameters.
When a defined limit is crossed, Qdrant responds with a client-side error that includes details about the specific limit exceeded. This can make troubleshooting much simpler.
> The `enabled` field in the configuration acts as a dynamic toggle, allowing you to activate or deactivate Strict Mode as needed.
In this example we enable **Strict Mode** when creating a collection to activate the `unindexed_filtering_retrieve` limit:
httpbashpythontypescriptrustjavacsharpgo
```
PUT /collections/{collection_name}
{
    "strict_mode_config": {
        "enabled": true,
        "unindexed_filtering_retrieve": true
    }
}

```
```
curl -X PUT http://localhost:6333/collections/{collection_name} \
'Content-Type: application/json' \
'{
    "strict_mode_config": {
        "enabled":" true,
        "unindexed_filtering_retrieve": true
    }
  }'

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.create_collection(
    collection_name="{collection_name}",
    strict_mode_config=models.SparseVectorParams{ enabled=True, unindexed_filtering_retrieve=True },
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.createCollection("{collection_name}", {
  strict_mode_config: {
    enabled: true,
    unindexed_filtering_retrieve: true,
  },
});

```
```
useqdrant_client::Qdrant;useqdrant_client::qdrant::{CreateCollectionBuilder,StrictModeConfigBuilder};letclient=Qdrant::from_url("http://localhost:6334").build()?;client.create_collection(CreateCollectionBuilder::new("{collection_name}").strict_config_mode(StrictModeConfigBuilder::default().enabled(true).unindexed_filtering_retrieve(true)),).await?;
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Collections.CreateCollection;importio.qdrant.client.grpc.Collections.StrictModeCOnfig;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.createCollectionAsync(CreateCollection.newBuilder().setCollectionName("{collection_name}").setStrictModeConfig(StrictModeConfig.newBuilder().setEnabled(true).setUnindexedFilteringRetrieve(true).build()).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.CreateCollectionAsync(
	collectionName: "{collection_name}",
	strictModeConfig: new StrictModeConfig { enabled = true, unindexed_filtering_retrieve = true }
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.CreateCollection(context.Background(), &qdrant.CreateCollection{
	CollectionName: "{collection_name}",
	StrictModeConfig: &qdrant.StrictModeConfig{
        Enabled: qdrant.PtrOf(true),
		IndexingThreshold: qdrant.PtrOf(true),
	},
})

```
> You may also use the `PATCH` request to enable Strict Mode on an existing collection.
_Read more about Strict Mode in the[**Database Administration Guide**](https://qdrant.tech/documentation/guides/administration/#strict-mode)_
##  [](https://qdrant.tech/blog/qdrant-1.13.x/#hnsw-graph-compression)HNSW Graph Compression
![hnsw-graph-compression](https://qdrant.tech/blog/qdrant-1.13.x/image_3.png)
We’re always looking for ways to make your search experience faster and more efficient. That’s why we are introducing a new optimization method for our HNSW graph technology: 
**Delta Encoding** is a clever way to compress data by storing only the differences (or “deltas”) between values. It’s commonly used in search engines (_for the classical inverted index_) to save space and improve performance. We’ve now 
In contrast with traditional compression algorithms, like gzip or lz4, **Delta Encoding** requires very little CPU overhead for decompression, which makes it a perfect fit for the HNSW graph links.
> Our experiments didn’t observe any measurable performance degradation. However, the memory footprint of the HNSW graph was **reduced by up to 30%**.
_For more general info, read about[**Indexing and Data Structures in Qdrant**](https://qdrant.tech/documentation/concepts/indexing/)_
##  [](https://qdrant.tech/blog/qdrant-1.13.x/#filter-by-named-vectors)Filter by Named Vectors
![filter-named-vectors](https://qdrant.tech/blog/qdrant-1.13.x/image_4.png)
In Qdrant, you can store multiple vectors of different sizes and types in a single data point. This is useful when you have to representing data with multiple embeddings, such as image, text, or video features.
> We previously introduced this feature as [**Named Vectors**](https://qdrant.tech/documentation/concepts/vectors/#named-vectors). Now, you can filter points by checking if a specific named vector exists.
This makes it easy to search for points based on the presence of specific vectors. For example, _if your collection includes image and text vectors, you can filter for points that only have the image vector defined_.
###  [](https://qdrant.tech/blog/qdrant-1.13.x/#create-a-collection-with-named-vectors)Create a Collection with Named Vectors
Upon collection [creation](https://qdrant.tech/documentation/concepts/collections/#collection-with-multiple-vectors), you define named vector types, such as `image` or `text`:
```
PUT /collections/{collection_name}
{
    "vectors": {
        "image": {
            "size": 4,
            "distance": "Dot"
        },
        "text": {
            "size": 8,
            "distance": "Cosine"
        }
    },
    "sparse_vectors": {
        "sparse-image": {},
        "sparse-text": {},
    },
}

```
###  [](https://qdrant.tech/blog/qdrant-1.13.x/#sample-request)Sample Request
Some points might include both **image** and **text** vectors, while others might include just one. With this new feature, you can easily filter for points that specifically have the **image** vector defined.
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/scroll
{
    "filter": {
        "must": [
            { "has_vector": "image" }
        ]
    }
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.scroll(
    collection_name="{collection_name}",
    scroll_filter=models.Filter(
        must=[
            models.HasVectorCondition(has_vector="image"),
        ],
    ),
)

```
```
client.scroll("{collection_name}", {
      filter: {
    must: [
      {
        has_vector: "image",
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,ScrollPointsBuilder};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.scroll(ScrollPointsBuilder::new("{collection_name}").filter(Filter::must([Condition::has_vector("image")])),).await?;
```
```
importjava.util.List;import staticio.qdrant.client.ConditionFactory.hasVector;import staticio.qdrant.client.PointIdFactory.id;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.ScrollPoints;client.scrollAsync(ScrollPoints.newBuilder().setCollectionName("{collection_name}").setFilter(Filter.newBuilder().addMust(hasVector("image")).build()).build()).get();
```
```
using Qdrant.Client;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.ScrollAsync(collectionName: "{collection_name}", filter: HasVector("image"));

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Scroll(context.Background(), &qdrant.ScrollPoints{
	CollectionName: "{collection_name}",
	Filter: &qdrant.Filter{
		Must: []*qdrant.Condition{
			qdrant.NewHasVector(
        "image",
			),
		},
	},
})

```
This feature makes it easier to manage and query collections with heterogeneous data. It will give you more flexibility and control over your vector search workflows.
_To dive deeper into filtering by named vectors, check out the[**Filtering Documentation**](https://qdrant.tech/documentation/concepts/filtering/#has-vector)_
##  [](https://qdrant.tech/blog/qdrant-1.13.x/#custom-storage-engine)Custom Storage Engine
![custom-storage-engine](https://qdrant.tech/blog/qdrant-1.13.x/image_5.png)
When Qdrant started, we used **RocksDB** as the storage backend for payloads and sparse vectors. RocksDB, known for its versatility and ability to handle random reads and writes, seemed like a solid choice. But as our needs evolved, its “ _general-purpose_ ” design began to show cracks.
> RocksDB is built to handle arbitrary keys and values of any size, but this flexibility comes at a cost.
A key example is compaction, a process that reorganizes data on disk to maintain performance. **Under heavy write loads, compaction can become a bottleneck** , causing significant slowdowns. For Qdrant, this meant huge latency spikes at random moments causing timeout errors during large uploads—a frustrating roadblock.
To solve this, we built a **custom storage backend** optimized for our specific use case. Unlike RocksDB, our system delivers consistent performance by ensuring reads and writes require a constant number of disk operations, regardless of data size. As a result, you will get faster and reliable performance - free from latency-spikes.
###  [](https://qdrant.tech/blog/qdrant-1.13.x/#our-new-storage-architecture)Our New Storage Architecture
There are four elements: the **Data Layer** , **Mask Layer** , **the Region** and **Tracker Layer**.
![Qdrant's New Storage Backend](https://qdrant.tech/blog/qdrant-1.13.x/storage.png)
Qdrant’s New Storage Backend
**The Data Layer** consists of fixed-size blocks that store the actual data. The block size is a configurable parameter that can be adjusted based on the workload. Each record occupies the required number of blocks. If the data size exceeds the block size, it is split into multiple blocks. If the data size is smaller than the block size, it still occupies an entire block.
**The Mask Layer** contains a bitmask that indicates which blocks are occupied and which are free. The size of the mask corresponds to the number of blocks in the Data Layer. For instance, if we have 64 blocks of 128 bytes each, the bitmask will allocate 1 bit for every block in the Data Layer resulting in 8 bytes. This results in an overhead of 1/1024 of the Data Layer size, because each byte in the mask covers 1024 bytes of blocked storage. The bitmask is stored on disk and does not need to be loaded into memory.
**The Region** is an additional structure which tracks gaps in regions of the bitmask. This is to get an even smaller overhead against the data, which can be loaded into memory easily. Each region summarizes 1KB of bits in the bitmask, which represents a millionth scale of the Data Layer size, or 6 KB of RAM per GB of data.
**The Tracker Layer** is in charge of fast lookups, it directly links the IDs of the points to the place where the data is located.
##  [](https://qdrant.tech/blog/qdrant-1.13.x/#get-started-with-qdrant)Get Started with Qdrant
![get-started](https://qdrant.tech/blog/qdrant-1.13.x/image_1.png)
The easiest way to reach that **Hello World** moment is to [**try vector search in a live cluster**](https://qdrant.tech/documentation/quickstart-cloud/). Our **interactive tutorial** will show you how to create a cluster, add data and try some filtering clauses.
**New features, like named vector filtering, can be tested in the Qdrant Dashboard:**
![qdrant-filtering-tutorial](https://qdrant.tech/articles_data/vector-search-filtering/qdrant-filtering-tutorial.png)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/qdrant-1.13.x/)
                    ## 📄 `https-qdrant-tech-blog-qdrant-n8n-beyond-simple-similarity-search.md`
                    ```md
                    # https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/
# Automating Business Processes with Qdrant and n8n: Use Cases Beyond Simple Similarity Search
Evgeniya Sukhodolskaya
·
April 04, 2025
![Automating Business Processes with Qdrant and n8n: Use Cases Beyond Simple Similarity Search](https://qdrant.tech/blog/qdrant-n8n-2/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Automating Business Processes with Qdrant and n8n: Use Cases Beyond Simple Similarity Search
  *     * [Setting Up Qdrant in n8n](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#setting-up-qdrant-in-n8n)
      * [Qdrant Cloud](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#qdrant-cloud)
      * [Local Mode](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#local-mode)
    * [Beyond Simple Similarity Search](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#beyond-simple-similarity-search)
      * [Recommendations](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#recommendations)
      * [Big Data Analysis](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#big-data-analysis)
    * [What’s Next?](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#whats-next)
Low-code automation tools make it easy to turn ideas into reality quickly. As AI becomes central to modern business, having low-code platforms with built-in AI capabilities is no longer optional—it’s essential. 
Vector search has become a key building block in modern AI systems. While it’s often used as memory or a knowledge base for generative AI, its potential goes much further.
In this blog, we explore combining a dedicated vector search engine like Qdrant with an AI automation platform like n8n, moving beyond basic Retrieval-Augmented Generation (RAG) use cases. We’ll show you how to use vector search for recommendations and big data analysis using ready-to-use n8n workflows.
##  [](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#setting-up-qdrant-in-n8n)Setting Up Qdrant in n8n
To start using Qdrant with n8n, you need to provide your Qdrant instance credentials in the `QdrantApi` from the list.
###  [](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#qdrant-cloud)Qdrant Cloud
To connect [Qdrant Cloud](https://qdrant.tech/documentation/cloud/) to n8n:
  1. Open the 
  2. From the **Cluster Details** , copy the `Endpoint` address—this will be used as the `Qdrant URL` in n8n.
  3. Navigate to the **API Keys** tab and copy your API key—this will be the `API Key` in n8n.
For a walkthrough, see this 
###  [](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#local-mode)Local Mode
For a fully local setup, a valuable option is n8n’s 
This kit includes a [local instance of Qdrant](https://qdrant.tech/documentation/quickstart/). To get started:
  1. Follow the instructions in the repository to install the AI Starter Kit.
  2. Use the values from the `docker-compose.yml` file to fill in the connection details.
Remember to update to the latest Qdrant Docker image using `docker-compose pull`.
The default Qdrant configuration in AI Starter Kit’s `docker-compose.yml` looks like this:
```
qdrant:image:qdrant/qdranthostname:qdrantcontainer_name:qdrantnetworks:['demo']restart:unless-stoppedports:6333:6333volumes:qdrant_storage:/qdrant/storage
```
From this configuration, the `Qdrant URL` in n8n Qdrant credentials is `http://qdrant:6333/`. To set up a local Qdrant API key, add the following lines to the YAML file:
```
qdrant:...volumes:qdrant_storage:/qdrant/storageenvironment:QDRANT_API_KEY=test
```
After saving the configuration and running the Starter Kit, use `QDRANT_API_KEY` value (e.g., `test`) as the `API Key` and `http://qdrant:6333/` as the `Qdrant URL`.
##  [](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#beyond-simple-similarity-search)Beyond Simple Similarity Search
Vector search’s ability to determine semantic similarity between objects is often used to address models’ hallucinations, powering the memory of Retrieval-Augmented Generation-based applications.
Yet there’s more to vector search than just a “knowledge base” role. **By exploring the concept of “dissimilarity,” we unlock new possibilities.** By measuring how similar data points are in a semantic vector space, we can also analyze their differences.
This combination of similarity and dissimilarity expands vector search to recommendations, discovery search, and large-scale unstructured data analysis.
###  [](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#recommendations)Recommendations
When searching for new music, films, books, or food, it can be difficult to articulate exactly what we want. Instead, we often rely on discovering new content through comparison to examples of what we like or dislike.
The [Qdrant Recommendation API](https://qdrant.tech/articles/new-recommendation-api/) is built to make these discovery searches possible by using positive and negative examples as anchors. It helps find new relevant results based on your preferences.
####  [](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#movie-recommendations)Movie Recommendations
Imagine a home cinema night—you’ve already watched Harry Potter 666 times and crave a new series featuring young wizards. Your favorite streaming service repetitively recommends all seven parts of the millennial saga. Frustrated, you turn to n8n to create an **Agentic Movie Recommendation tool**.
**Setup:**
  1. **Dataset** : We use movie descriptions from the 
  2. **Embedding Model** : We’ll use OpenAI `text-embedding-3-small`, but you can opt for any other suitable embedding model.
**Workflow:**
A 
  1. **Movie Data Uploader** : Embeds movie descriptions and uploads them to Qdrant using the 
  2. **AI Agent** : Uses the 
  3. **Recommendations Tool** : A `text-embedding-3-small` and uses the Qdrant Recommendation API to get movie recommendations, which are passed back to the agent.
To use Qdrant's functionality beyond [Qdrant API reference](https://api.qdrant.tech/api-reference) to n8n's 
Set it up, run a chat and ask for “ _something about wizards but not Harry Potter_.” What results do you get?
* * *
If you’d like a detailed walkthrough of building this workflow step-by-step, watch the video below:
This recommendation scenario is easily adaptable to any language or data type (images, audio, video).
###  [](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#big-data-analysis)Big Data Analysis
The ability to map data to a vector space that reflects items’ similarity and dissimilarity relationships provides a range of mathematical tools for data analysis.
Vector search dedicated solutions are built to handle billions of data points and quickly compute distances between them, simplifying clustering, classification, dissimilarity sampling, deduplication, interpolation, and anomaly detection at scale.
The combination of this vector search feature with automation tools like n8n creates production-level solutions capable of monitoring data temporal shifts, managing data drift, and discovering patterns in seemingly unstructured data.
A practical example is worth a thousand words. Let’s look at **Qdrant-based anomaly detection and classification tools** , which are designed to be used by the 
To make it more interesting, this time we’ll focus on image data.
####  [](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#anomaly-detection-tool)Anomaly Detection Tool
One definition of “anomaly” comes intuitively after projecting vector representations of data points into a 2D space—Qdrant webUI provides this functionality. Points that don’t belong to any clusters are more likely to be anomalous.
![anomalies-on-2D](https://qdrant.tech/blog/qdrant-n8n-2/anomalies-2D.png)
With that intuition comes the recipe for building an anomaly detection tool. We will demonstrate it on anomaly detection in agricultural crops. Qdrant will be used to:
  1. Store vectorized images.
  2. Identify a “center” (representative) for each crop cluster.
  3. Define the borders of each cluster.
  4. Check if new images fall within these boundaries. If an image does not fit within any cluster, it is flagged as anomalous. Alternatively, you can check if an image is anomalous to a specific cluster.
![anomaly-detection](https://qdrant.tech/blog/qdrant-n8n-2/anomaly-detection.png)
**Setup:**
  1. **Dataset** : We use the 
  2. **Embedding Model** : The 
**1. Uploading Images to Qdrant**
Since the 
**Workflow:**
_There are three workflows: (1) Uploading images to Qdrant (2) Setting up cluster centers and thresholds (3) Anomaly detection tool itself._
An 
  1. **Check Collection** : Verifies if a collection with the specified name exists in Qdrant. If not, it creates one.
  2. **Payload Index** : Adds a [payload index](https://qdrant.tech/documentation/concepts/indexing/#payload-index) on the `crop_name` payload (metadata) field. This field stores crop class labels, and indexing it improves the speed of filterable searches in Qdrant. It changes the way a vector index is constructed, adapting it for fast vector search under filtering constraints. For more details, refer to this [guide on filtering in Qdrant](https://qdrant.tech/articles/vector-search-filtering/).
  3. **Fetch Images** : Fetches images from Google Cloud Storage using the 
  4. **Generate IDs** : Assigns UUIDs to each data point.
  5. **Embed Images** : Embeds the images using the Voyage API.
  6. **Batch Upload** : Uploads the embeddings to Qdrant in batches.
**2. Defining a Cluster Representative**
We used two approaches (it’s not an exhaustive list) to defining a cluster representative, depending on the availability of labeled data:
Method | Description  
---|---  
**Medoids** | A point within the cluster that has the smallest total distance to all other cluster points. This approach needs labeled data for each cluster.  
**Perfect Representative** | A representative defined by a textual description of the ideal cluster member—the multimodality of Voyage AI embeddings allows for this trick. For example, for cherries: _“Small, glossy red fruits on a medium-sized tree with slender branches and serrated leaves.”_ The closest image to this description in the vector space is selected as the representative. This method requires experimentation to align descriptions with real data.  
![cluster-representative](https://qdrant.tech/blog/qdrant-n8n-2/cluster-representative.png)
**Workflow:**
Both methods are demonstrated in the 
**Method** | **Steps**  
---|---  
**Medoids** | 1. Sample labeled cluster points from Qdrant.  
2. Compute a **pairwise distance matrix** for the cluster using Qdrant’s [Distance Matrix API](https://qdrant.tech/documentation/concepts/explore/?q=distance+#distance-matrix). This API helps with scalable cluster analysis and data points relationship exploration. Learn more in [this article](https://qdrant.tech/articles/distance-based-exploration/).  
3. For each point, calculate the sum of its distances to all other points. The point with the smallest total distance (or highest similarity for COSINE distance metric) is the medoid.  
4. Mark this point as the cluster representative.  
**Perfect Representative** | 1. Define textual descriptions for each cluster (e.g., AI-generated).  
2. Embed these descriptions using Voyage.  
3. Find the image embedding closest to the description one.  
4. Mark this image as the cluster representative.  
**3. Defining the Cluster Border**
**Workflow:**
The approach demonstrated in 
  1. Within a cluster, identify the furthest data point from the cluster representative (it can also be the 2nd or Xth furthest point; the best way to define it is through experimentation—for us, the 5th furthest point worked well). Since we use COSINE similarity, this is equivalent to the most similar point to the 
  2. Save the distance between the representative and respective furthest point as the cluster border (threshold).
**4. Anomaly Detection Tool**
**Workflow:**
With the preparatory steps complete, you can set up the anomaly detection tool, demonstrated in the 
Steps:
  1. Choose the method of the cluster representative definition.
  2. Fetch all the clusters to compare the candidate image against.
  3. Using Voyage AI, embed the candidate image in the same vector space.
  4. Calculate the candidate’s similarity to each cluster representative. The image is flagged as anomalous if the similarity is below the threshold for all clusters (outside the cluster borders). Alternatively, you can check if it’s anomalous to a particular cluster, for example, the cherries one.
* * *
Anomaly detection in image data has diverse applications, including:
  * Moderation of advertisements.
  * Anomaly detection in vertical farming.
  * Quality control in the food industry, such as [detecting anomalies in coffee beans](https://qdrant.tech/articles/detecting-coffee-anomalies/).
  * Identifying anomalies in map tiles for tasks like automated map updates or ecological monitoring.
This tool is adaptable to these use cases and, when combined with n8n integrations, has the potential to become a production-level business solution.
####  [](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#classification-tool)Classification Tool
The anomaly detection tool can also be used for classification, but there’s a simpler approach: K-Nearest Neighbors (KNN) classification.
> “Show me your friends, and I will tell you who you are.”
![KNN-2D](https://qdrant.tech/blog/qdrant-n8n-2/KNN.png)
The KNN method labels a data point by analyzing its classified neighbors and assigning this point the majority class in the neighborhood. This approach doesn’t require all data points to be labeled—a subset of labeled examples can serve as anchors to propagate labels across the dataset. Qdrant is well-suited for this task, offering fast neighbor searches with filtering capabilities.
Let’s build a KNN-based image classification tool.
**Setup**
  1. **Dataset** : We’ll use the 
  2. **Embedding Model** : As for anomaly detection, we’ll use the 
Additionally, it’s good to have test and validation data to determine the optimal value of K for your dataset.
**Workflow:**
Uploading images to Qdrant can be done using the same workflow—
The 
  1. **Embed Image** : Embeds the candidate for classification using Voyage.
  2. **Fetch neighbors** : Retrieves the K closest labeled neighbors from Qdrant.
  3. **Majority Voting** : Determines the prevailing class in the neighborhood by simple majority voting.
  4. **Optional: Ties Resolving** : In case of ties, expands the neighborhood radius.
Of course, this is a simple solution, and there exist more advanced approaches with higher precision & no need for labeled data—for example, you could try [metric learning with Qdrant](https://qdrant.tech/articles/metric-learning-tips/).
Though classification seems like a task that was solved in machine learning decades ago, it’s not so trivial to deal with in production. Issues like data drift, shifting class definitions, mislabeled data, and fuzzy differences between classes create unexpected problems, which require continuous adjustments of classifiers. Vector Search can be an unusual but effective solution, interesting due to its scalability.
####  [](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#live-walkthrough)Live Walkthrough
To see how n8n agents use these tools in practice, and to revisit the main ideas of the “ _Big Data Analysis_ ” section, watch our integration webinar:
##  [](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#whats-next)What’s Next?
Vector search is not limited to similarity search or basic RAG. When combined with automation platforms like n8n, it becomes a powerful tool for building smarter systems. Think dynamic routing in customer support, content moderation based on user behavior, or AI-driven alerts in data monitoring dashboards.
This blog showed how to use Qdrant and n8n for AI-backed recommendations, classification, and anomaly detection. But that’s just the start—try vector search for:
  * **Deduplication**
  * **Dissimilarity search**
  * **Diverse sampling**
With Qdrant and n8n, there’s plenty of room to create something unique!
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/)
                    ## 📄 `https-qdrant-tech-blog-qdrant-soc2-type2-audit.md`
                    ```md
                    # https://qdrant.tech/blog/qdrant-soc2-type2-audit/
# Qdrant Attains SOC 2 Type II Audit Report
Sabrina Aquino
·
May 23, 2024
![Qdrant Attains SOC 2 Type II Audit Report](https://qdrant.tech/blog/qdrant-soc2-type2-audit/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Qdrant Attains SOC 2 Type II Audit Report
  *     * [SOC 2 Type II: What Is It?](https://qdrant.tech/blog/qdrant-soc2-type2-audit/#soc-2-type-ii-what-is-it)
    * [Key Audit Findings](https://qdrant.tech/blog/qdrant-soc2-type2-audit/#key-audit-findings)
    * [Future Compliance](https://qdrant.tech/blog/qdrant-soc2-type2-audit/#future-compliance)
    * [About Qdrant](https://qdrant.tech/blog/qdrant-soc2-type2-audit/#about-qdrant)
At Qdrant, we are happy to announce the successful completion our the SOC 2 Type II Audit. This achievement underscores our unwavering commitment to upholding the highest standards of security, availability, and confidentiality for our services and our customers’ data.
##  [](https://qdrant.tech/blog/qdrant-soc2-type2-audit/#soc-2-type-ii-what-is-it)SOC 2 Type II: What Is It?
SOC 2 Type II certification is an examination of an organization’s controls in reference to the American Institute of Certified Public Accountants 
##  [](https://qdrant.tech/blog/qdrant-soc2-type2-audit/#key-audit-findings)Key Audit Findings
The audit ensured with no exceptions noted the effectiveness of our systems and controls on the following Trust Service Criteria:
  * Security
  * Confidentiality
  * Availability
These certifications are available today and automatically apply to your existing workloads. The full SOC 2 Type II report is available to customers and stakeholders upon request through the 
##  [](https://qdrant.tech/blog/qdrant-soc2-type2-audit/#future-compliance)Future Compliance
Going forward, Qdrant will maintain SOC 2 Type II compliance by conducting continuous, annual audits to ensure our security practices remain aligned with industry standards and evolving risks.
Recognizing the critical importance of data security and the trust our clients place in us, achieving SOC 2 Type II compliance underscores our ongoing commitment to prioritize data protection with the utmost integrity and reliability.
##  [](https://qdrant.tech/blog/qdrant-soc2-type2-audit/#about-qdrant)About Qdrant
Qdrant is a vector database designed to handle large-scale, high-dimensional data efficiently. It allows for fast and accurate similarity searches in complex datasets. Qdrant strives to achieve seamless and scalable vector search capabilities for various applications.
For more information about Qdrant and our security practices, please visit our [website](http://qdrant.tech) or [reach out to our team directly](https://qdrant.tech/contact-us/).
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/qdrant-soc2-type2-audit/)
                    ## 📄 `https-qdrant-tech-blog-satellite-vector-broadcasting.md`
                    ```md
                    # https://qdrant.tech/blog/satellite-vector-broadcasting/
# Satellite Vector Broadcasting: Near-Zero Latency Retrieval from Space
Qdrant Team
·
April 01, 2025
![Satellite Vector Broadcasting: Near-Zero Latency Retrieval from Space](https://qdrant.tech/blog/satellite-vector-broadcasting/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Satellite Vector Broadcasting: Near-Zero Latency Retrieval from Space
  *     * [📡 Qdrant Launches Satellite Vector Broadcasting for Near-Zero Latency Retrieval](https://qdrant.tech/blog/satellite-vector-broadcasting/#-qdrant-launches-satellite-vector-broadcasting-for-near-zero-latency-retrieval)
      * [📊 Benchmark Results](https://qdrant.tech/blog/satellite-vector-broadcasting/#-benchmark-results)
      * [🛰 Key Features](https://qdrant.tech/blog/satellite-vector-broadcasting/#-key-features)
      * [💬 Field Reports](https://qdrant.tech/blog/satellite-vector-broadcasting/#-field-reports)
      * [🛸 Coming Soon](https://qdrant.tech/blog/satellite-vector-broadcasting/#-coming-soon)
      * [📡 Availability](https://qdrant.tech/blog/satellite-vector-broadcasting/#-availability)
##  [](https://qdrant.tech/blog/satellite-vector-broadcasting/#-qdrant-launches-satellite-vector-broadcasting-for-near-zero-latency-retrieval)📡 Qdrant Launches Satellite Vector Broadcasting for Near-Zero Latency Retrieval
**CAPE CANAVERAL, FL** — Qdrant today announced the successful deployment of **Satellite Vector Broadcasting** , an ambitious new system for high-speed vector search that uses **actual satellites** to transmit, shard, and retrieve embeddings — bypassing Earth entirely.
> “Cloud is old news. Space is the new infrastructure,” said orbital software lead Luna Hertz. “We’re proud to say we’ve finally untethered cosine similarity from the bonds of gravity and Wi-Fi.”
The system uses a **constellation of proprietary CubeSats** equipped with ultra-low-latency broadcasting gear to beam vector data across the planet — and eventually, the solar system — via **inter-satellite vector laser relays**. Think 5G, but with telescopes.
###  [](https://qdrant.tech/blog/satellite-vector-broadcasting/#-benchmark-results)📊 Benchmark Results
**Infrastructure Mode** | **Avg. Latency (ms)**  
---|---  
Earth Data Center | 34.00000  
Cloud Provider (Multi-region) | 22.00000  
LEO Satellite Mesh | 12.00000  
Geo-Sync Satellite Array | 8.00000  
CubeSat Swarm (Experimental) | 4.00000  
Quantum Uplink (Theoretical) | 0.00001 ✨  
> Latency inversely correlated with altitude and absurdity.
![](https://qdrant.tech/blog/satellite-vector-broadcasting/image2.png)
###  [](https://qdrant.tech/blog/satellite-vector-broadcasting/#-key-features)🛰 Key Features
  * **Broadcast-to-Index Protocol (BIP)** : Queries are bounced off satellites and resolved mid-transmission using onboard embeddings.
  * **Lagrange-Optimized Clustering** : Vector clusters are dynamically rearranged based on orbital positioning and cosmic vibes.
  * **Cosine Boosters** : Custom solar panels double as cosine angle amplifiers for peak similarity accuracy in space.
###  [](https://qdrant.tech/blog/satellite-vector-broadcasting/#-field-reports)💬 Field Reports
> “I queried from Antarctica and got results before I hit enter.”
> — FrozenSysAdmin01
> “The CubeSat talked to me. It said my vectors were beautiful.”
> — Beta Tester, now in therapy
###  [](https://qdrant.tech/blog/satellite-vector-broadcasting/#-coming-soon)🛸 Coming Soon
  * **PlutoEdge™** : Coldest-ever vector cache, temperature-stabilized by cosmic background radiation
  * **StarlinkGPT Embedding Sync** (requires 42 satellites and a lot of coffee)
  * **Mars Cluster Alpha** : Terraforming… for faster search
###  [](https://qdrant.tech/blog/satellite-vector-broadcasting/#-availability)📡 Availability
Satellite Vector Broadcasting is now available in limited orbit. Each query costs **one launch credit** (or barter in moon rocks). Commercial adoption expected Q3 2025, pending space traffic regulations.
Learn more at: [**Qdrant Vector Database**](https://qdrant.tech/qdrant-vector-database/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/satellite-vector-broadcasting/)
                    ## 📄 `https-qdrant-tech-blog-static-embeddings.md`
                    ```md
                    # https://qdrant.tech/blog/static-embeddings/
# Static Embeddings: should you pay attention?
Kacper Łukawski
·
January 17, 2025
![Static Embeddings: should you pay attention?](https://qdrant.tech/blog/static-embeddings/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Static Embeddings: should you pay attention?
  *     * [What makes static embeddings different?](https://qdrant.tech/blog/static-embeddings/#what-makes-static-embeddings-different)
    * [Static embeddings in Qdrant](https://qdrant.tech/blog/static-embeddings/#static-embeddings-in-qdrant)
    * [Quantization of the static embeddings](https://qdrant.tech/blog/static-embeddings/#quantization-of-the-static-embeddings)
    * [Who should use static embeddings?](https://qdrant.tech/blog/static-embeddings/#who-should-use-static-embeddings)
      * [Customization of the static embeddings](https://qdrant.tech/blog/static-embeddings/#customization-of-the-static-embeddings)
In the world of resource-constrained computing, a quiet revolution is taking place. While transformers dominate leaderboards with their impressive capabilities, static embeddings are making an unexpected comeback, offering remarkable speed improvements with surprisingly small quality trade-offs. **We evaluated how Qdrant users can benefit from this renaissance, and the results are promising**.
##  [](https://qdrant.tech/blog/static-embeddings/#what-makes-static-embeddings-different)What makes static embeddings different?
Transformers are often seen as the only way to go when it comes to embeddings. The use of attention mechanisms helps to capture the relationships between the input tokens, so each token gets a vector representation that is context-aware and defined not only by the token itself but also by the surrounding tokens. Transformer-based models easily beat the quality of the older methods, such as word2vec or GloVe, which could only create a single vector embedding per each word. As a result, the word “bank” would have identical representation in the context of “river bank” and “financial institution”.
![Static embeddings](https://qdrant.tech/blog/static-embeddings/financial-river-bank.png)
Transformer-based models would represent the word “bank” differently in each of the contexts. However, transformers come with a cost. They are computationally expensive and usually require a lot of memory, although the embeddings models usually have fewer parameters than the Large Language Models. Still, GPUs are preferred to be used, even for inference.
Static embeddings are still a thing, though! `static-retrieval-mrl-en-v1`.
##  [](https://qdrant.tech/blog/static-embeddings/#static-embeddings-in-qdrant)Static embeddings in Qdrant
From the vector database perspective, static embeddings are not different from any other embedding models. They are dense vectors after all, and you can simply store them in a Qdrant collection. Here is how you do it with the `sentence-transformers/static-retrieval-mrl-en-v1` model:
```
import uuid
from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient, models
# The model produces vectors of size 1024
model = SentenceTransformer(
    "sentence-transformers/static-retrieval-mrl-en-v1"
)
# Let's assume we have a collection "my_collection" 
# with a single vector called "static"
client = QdrantClient("http://localhost:6333")
# Calling the sentence transformer model to encode 
# the text is not different compared to any other model
client.upsert(
    "my_collection",
    points=[
        models.PointStruct(
            id=uuid.uuid4().hex,
            vector=model.encode("Hello, world!"),
            payload={"static": "Hello, world!"},
        )
    ]
)

```
The retrieval is not going to be any faster just because you use static embeddings. However, **you will experience a huge speedup in creating the vectors from your data** , what is usually a bottleneck. The Hugging Face blog post mentions that the model might be even up to 400x faster on a CPU than the state-of-the-art embedding model.
We didn’t perform any proper benchmarking of the encoding speed, but one of the experiments done on `TREC-COVID` dataset from **encode and fully index 171K documents in Qdrant in around 7.5 minutes**. All of it done on a consumer-grade laptop, without GPU acceleration.
##  [](https://qdrant.tech/blog/static-embeddings/#quantization-of-the-static-embeddings)Quantization of the static embeddings
What can actually make the retrieval faster is the use of Matryoshka Embeddings, as the `static-retrieval-mrl-en-v1` model was trained with that technique in mind. However, that’s not the only way to speed up search. Quantization methods are really popular among our users, and we were curious to check if they might be applied to the static embeddings with the same success.
We took the `static-retrieval-mrl-en-v1` model and tested it on various subsets of 
NDCG@10  
---  
Dataset | Original vectors | Binary Quantization, no rescoring  
SciFact | _0.59348_ | 0.54195  
TREC-COVID | _0.4428_ | 0.44185  
ArguAna | _0.44393_ | 0.42164  
NFCorpus | _0.30045_ | 0.28027  
Binary Quantization definitely speeds up the retrieval, and make it cheaper, but also seems not to affect the quality of the retrieval much in some cases. **However, that’s something you should carefully verify on your own data**. If you are a Qdrant user, then you can just enable quantization on an existing collection and [measure the impact on the retrieval quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/).
All the tests we did were performed using 
##  [](https://qdrant.tech/blog/static-embeddings/#who-should-use-static-embeddings)Who should use static embeddings?
Static embeddings seem to be a budget-friendly option for those who would like to use semantic search in their applications, but can’t afford hosting standard representation models, or cannot do it, i.e. due to hardware constraints. Some of the use cases might be:
  * **Mobile applications** - although many smartphones have powerful CPUs or even GPUs, the battery life is still a concern, and the static embeddings might be a good compromise between the quality and the power consumption. Moreover, the static embeddings can be used in the applications that require offline mode.
  * **Web browser extensions** - running a transformer-based model in a web browser is usually not quite an option, but static embeddings might be a good choice, as they have fewer parameters and are faster to encode.
  * **Embedded systems** - the static embeddings might be a good choice for the devices with limited computational power, such as IoT devices or microcontrollers.
If you are one of the above, then you should definitely give static embeddings a try. **However, if the search quality is not the top of your priorities, then you might consider using static embeddings even in the high-performance environments**. The speedup in the encoding process might be a game-changer for you.
###  [](https://qdrant.tech/blog/static-embeddings/#customization-of-the-static-embeddings)Customization of the static embeddings
Last, but not least. The training pipeline published by **you can adjust it the specifics of your data easily**. This training process will also be way faster than for a transformer-based model, so you can even retrain it more often. Recomputing the embeddings is a bottleneck of the semantic search systems, and the static embeddings might be a good solution to this problem. Whether a custom static embedding model can beat a general pre-trained model remains an open question, but it’s definitely worth trying.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/static-embeddings/)
                    ## 📄 `https-qdrant-tech-blog-webinar-crewai-qdrant-obsidian.md`
                    ```md
                    # https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/
# How to Build Intelligent Agentic RAG with CrewAI and Qdrant
Kacper Łukawski
·
January 24, 2025
![How to Build Intelligent Agentic RAG with CrewAI and Qdrant](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * How to Build Intelligent Agentic RAG with CrewAI and Qdrant
  *     * [Background agents](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#background-agents)
      * [The basic concepts of CrewAI](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#the-basic-concepts-of-crewai)
      * [Email automation with CrewAI, Qdrant, and Obsidian notes](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#email-automation-with-crewai-qdrant-and-obsidian-notes)
    * [Implementing the system](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#implementing-the-system)
      * [CrewAI <> Qdrant integration](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#crewai--qdrant-integration)
      * [Loading the Obsidian notes to Qdrant](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#loading-the-obsidian-notes-to-qdrant)
      * [Drafting emails in Gmail Inbox](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#drafting-emails-in-gmail-inbox)
      * [Working system](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#working-system)
    * [Results](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#results)
    * [Materials](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#materials)
In a recent live session, we teamed up with 
In this article, we’ll guide you through the process of setting up an AI-powered system that connects directly to your email inbox and knowledge base, enabling it to analyze incoming messages and existing content to generate contextually relevant response suggestions.
##  [](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#background-agents)Background agents
Although we got used to LLM-based apps that usually have a chat-like interface, even if it’s not a real UI but a CLI tool, plenty of day-to-day tasks can be automated in the background without explicit human action firing the process. This concept is also known as **ambient agents** , where the agent is always there, waiting for a trigger to act.
###  [](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#the-basic-concepts-of-crewai)The basic concepts of CrewAI
Thanks for Tony’s participation, we could learn more about CrewAI, and understand the basic concepts of the framework. He introduced the concepts of agents and crews, and how they can be used to build intelligent multi-agent applications. Moreover, Tony described different types of memory that CrewAI applications can use.
When it comes to Qdrant role in CrewAI applications, it can be used as short-term, or entity memory, as both components are based on RAG and vector embeddings. If you’d like to know more about memory in CrewAI, please visit the 
Tony made an interesting analogy. He compared crews to different departments in a company, where each department has its own responsibilities, but they all work together to achieve the company’s goals.
###  [](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#email-automation-with-crewai-qdrant-and-obsidian-notes)Email automation with CrewAI, Qdrant, and Obsidian notes
Our webinar focused on building an agentic RAG system that would semi-automate email communication. RAG is an essential component of such a system, as you don’t want to take responsibility for responses that cannot be grounded. The system would monitor your Gmail inbox, analyze the incoming emails, and prepare response drafts if it detects that the email is not spam, newsletter, or notification.
On the other hand, the system would also monitor the Obsidian notes, by watching any changes in the local file system. When a file is created, modified, or deleted, the system would automatically move these changes to the Qdrant collection, so the knowledge base is always up-to-date. Obsidian uses Markdown files to store notes, so complex parsing is not required.
Here is a simplified diagram presenting the target architecture of the system:
![Project architecture](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/project-architecture.png)
Qdrant acts as a knowledge base, storing the embeddings of the Obsidian notes.
##  [](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#implementing-the-system)Implementing the system
Since our system integrates with two external APIs - Gmail and filesystem. **We won’t go into details of how to work with these APIs** , as it’s out of the scope of this webinar. Instead, we will focus on the CrewAI and Qdrant integration, and CrewAI agents’ implementation.
###  [](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#crewai--qdrant-integration)CrewAI <> Qdrant integration
Since there is no official integration between CrewAI and Qdrant yet, we created a custom implementation of the `RAGStorage` class, which has a pretty straightforward interface.
```
from typing import Optional
from crewai.memory.storage.rag_storage import RAGStorage
class QdrantStorage(RAGStorage):
    """
    Extends Storage to handle embeddings for memory entries 
    using Qdrant.
    """
    ...
    def search(self,
        query: str,
        limit: int = 3,
        filter: Optional[dict] = None,
        score_threshold: float = 0,
    ) -> list[dict]:
        ...
    def reset(self) -> None:
        ...

```
Full implementation might be found in the 
```
from crewai import Crew, Process
from crewai.memory import EntityMemory, ShortTermMemory
from email_assistant.storage import QdrantStorage
qdrant_location= "http://localhost:6333"
qdrant_api_key = "your-secret-api-key"
embedder_config = {...}
crew = Crew(
    agents=[...],
    tasks=[...],  # Automatically created by the @task decorator
    process=Process.sequential,
    memory=True,
    entity_memory=EntityMemory(
        storage=QdrantStorage(
            type="entity-memory",
            embedder_config=embedder_config,
            qdrant_location=qdrant_location,
            qdrant_api_key=qdrant_api_key,
        ),
    ),
    short_term_memory=ShortTermMemory(
        storage=QdrantStorage(
            type="short-term-memory",
            embedder_config=embedder_config,
            qdrant_location=qdrant_location,
            qdrant_api_key=qdrant_api_key,
        ),
    ),
    embedder=embedder_config,
    verbose=True,
)

```
Both types of memory will use different collection names in Qdrant, so you can easily distinguish between them, and the data won’t be mixed up.
**We are planning to release a CrewAI tool for Qdrant integration in the near future** , so stay tuned!
###  [](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#loading-the-obsidian-notes-to-qdrant)Loading the Obsidian notes to Qdrant
For the sake of the demo, we decided to simply scrape the documentation of both CrewAI and Qdrant, and store it in the Obsidian notes. That’s easy with Obsidian Web Clipper, as it allows you to save the web page as a Markdown file.
![Obsidian notes](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/obsidian.png)
Assuming we detected a change in the Obsidian notes, such as new note creation or modification, we would like to load the changes to Qdrant. We could possibly use some chunking methods, starting from basic fixed-size chunks, or go straight to semantic chunking. However, LLMs are also well-known for their ability to divide the text into meaningful parts, so we decided to try them out. Moreover, standard chunking is enough in many cases, but we also wanted to test the 
It turns out, implementing such a crew in CrewAI is quite straightforward. There are two actors in the crew - one chunking the text and the other one generating the context. Both might be defined in YAML files like this:
```
chunks_extractor:role:>    Semantic chunks extractorgoal:>    Parse Markdown to extract digestible pieces of information which are
    semantically meaningful and can be easily understood by a human.backstory:>    You are a search expert building a search engine for Markdown files.
    Once you receive a Markdown file, you divide it into meaningful semantic
    chunks, so each chunk is about a certain topic or concept. You're known 
    for your ability to extract relevant information from large documents and 
    present it in a structured and easy-to-understand format, that increases
    the searchability of the content and results quality.contextualizer:role:>    Bringing context to the extracted chunksgoal:>    Add context to the extracted chunks to make them more meaningful and
    understandable. This context should help the reader understand the
    significance of the information and how it relates to the broader topic.backstory:>    You are a knowledge curator who specializes in making information more
    accessible and understandable. You take the extracted chunks and provide
    additional context to make them more meaningful by bringing in relevant
    information about the whole document or the topic at hand.
```
CrewAI makes it very easy to define such agents, and even a non-tech person can understand and modify the YAML files.
Another YAML file defines the tasks that the agents should perform:
```
extract_chunks:description:>    Review the document you got and extract the chunks from it. Each 
    chunk should be a separate piece of information that can be easily understood 
    by a human and is semantically meaningful. If there are two or more chunks that 
    are closely related, but not put next to each other, you can merge them into 
    a single chunk. It is important to cover all the important information in the
    document and make sure that the chunks are logically structured and coherent.
    <document>{document}</document>expected_output:>    A list of semantic chunks with succinct context of information extracted from 
    the document.agent:chunks_extractorcontextualize_chunks:description:>    You have the chunks we want to situate within the whole document.
    Please give a short succinct context to situate this chunk within the overall 
    document for the purposes of improving search retrieval of the chunk. Answer 
    only with the succinct context and nothing else.expected_output:>    A short succinct context to situate the chunk within the overall document, along
    with the chunk itself.agent:contextualizer
```
YAML is not enough to make the agents work, so we need to implement them in Python. The role, goal, and backstory of the agent, as well as the task description and expected output, are used to build a prompt sent to the LLM. However, the code defines which LLM to use, and some other parameters of the interaction, like structured output. We heavily rely on Pydantic models to define the output of the task, so the responses might be easily processed by the application, for example, to store them in Qdrant.
```
from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from email_assistant import models
...
@CrewBase
class KnowledgeOrganizingCrew(BaseCrew):
    """
    A crew responsible for processing raw text data and converting it into structured knowledge.
    """
    agents_config = "config/knowledge/agents.yaml"
    tasks_config = "config/knowledge/tasks.yaml"
    @agent
    def chunks_extractor(self) -> Agent:
        return Agent(
            config=self.agents_config["chunks_extractor"],
            verbose=True,
            llm="anthropic/claude-3-5-sonnet-20241022",
        )
    ...
    @task
    def contextualize_chunks(self) -> Task:
        # The task description is borrowed from the Anthropic Contextual Retrieval
        # See: https://www.anthropic.com/news/contextual-retrieval/
        return Task(
            config=self.tasks_config["contextualize_chunks"],
            output_pydantic=models.ContextualizedChunks,
        )
    ...
    @crew
    def crew(self) -> Crew:
        """Creates the KnowledgeOrganizingCrew crew"""
        return Crew(
            agents=self.agents,  # Automatically created by the @agent decorator
            tasks=self.tasks,  # Automatically created by the @task decorator
            process=Process.sequential,
            memory=True,
            entity_memory=self.entity_memory(),
            short_term_memory=self.short_term_memory(),
            embedder=self.embedder_config,
            verbose=True,
        )

```
Full implementation might again be found in the 
###  [](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#drafting-emails-in-gmail-inbox)Drafting emails in Gmail Inbox
At this point we already have our notes stored in Qdrant, and we can write emails in Gmail Inbox using the notes as a ground truth. The system would monitor the Gmail inbox, and if it detects an email that is not spam, newsletter, or notification, it would draft a response based on the knowledge base stored in Qdrant. Again, that means we need to use two agents - one for detecting the kind of the incoming email, and the other one for drafting the response.
The YAML files for these agents might look like this:
```
categorizer:role:>    Email threads categorizergoal:>    Automatically categorize email threads based on their content.backstory:>    You're a virtual assistant with a knack for organizing information.
    You're known for your ability to quickly and accurately categorize email
    threads, so that your clients know which ones are important to answer
    and which ones are spam, newsletters, or other types of messages that
    do not require attention.
    Available categories: QUESTION, NOTIFICATION, NEWSLETTER, SPAM. Do not make
    up new categories.response_writer:role:>    Email response writergoal:>    Write clear and concise responses to an email thread. Try to help the
    sender. Use the external knowledge base to provide relevant information.backstory:>    You are a professional writer with a talent for crafting concise and
    informative responses. You're known for your ability to quickly understand
    the context of an email thread and provide a helpful and relevant response
    that addresses the sender's needs. You always rely on your knowledge base
    to provide accurate and up-to-date information.
```
The set of categories is predefined, so the categorizer should not invent new categories. The task definitions are as follows:
```
categorization_task:description:>    Review the content of the following email thread and categorize it 
    into the appropriate category. There might be multiple categories that
    apply to the email thread.
    <messages>{messages}</messages>expected_output:>    A list of all the categories that the email threads can be classified into.agent:categorizerresponse_writing_task:description:>    Write a response to the following email thread. The response should be
    clear, concise, and helpful to the sender. Always rely on the Qdrant search
    tool, so you can get the most relevant information to craft your response.
    Please try to include the source URLs of the information you provide.
    Only focus on the real question asked by the sender and do not try to 
    address any other issues that are not directly related to the sender's needs.
    Do not try to provide a response if the context is not clear enough.
    <messages>{messages}</messages>expected_output:>    A well-crafted response to the email thread that addresses the sender's needs.
    Please use simple HTML formatting to make the response more readable.
    Do not include greetings or signatures in your response, but provide the footnotes
    with the source URLs of the information you used, if possible.
    If the provided context does not give you enough information to write a response,
    you must admit that you cannot provide a response and write "I cannot provide a response.".agent:response_writer
```
We specifically asked the agents to include the source URLs of the information they provide, so both the sender and the recipient can verify the information.
###  [](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#working-system)Working system
We have both crews defined, and the application is ready to run. The only thing left is to monitor the Gmail inbox and the Obsidian notes for changes. We use the `watchdog` library to monitor the filesystem, and the `google-api-python-client` to monitor the Gmail inbox, but we won’t go into details of how to use these libraries, as the integration code would make this blog post too long.
If you open the 
##  [](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#results)Results
The system is now ready to run, and it can semi-automate email communication, and keep the knowledge base up-to-date. If you set it up properly, you can expect the system to draft responses to emails that are not spam, newsletter, or notification, so your email inbox may look like this, even when you sleep:
![Drafted emails](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/gmail-inbox.png)
##  [](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#materials)Materials
As usual, we prepared a video recording of the webinar, so you can watch it at your convenience:
The source code of the demo is available on 
Are you building agentic RAG applications using CrewAI and Qdrant? Please join 
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/)
                    ## 📄 `https-qdrant-tech-blog-webinar-vibe-coding-rag.md`
                    ```md
                    # https://qdrant.tech/blog/webinar-vibe-coding-rag/
# Vibe Coding RAG with our MCP server
Kacper Łukawski
·
March 21, 2025
![Vibe Coding RAG with our MCP server](https://qdrant.tech/blog/webinar-vibe-coding-rag/preview/title.jpg)
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Vibe Coding RAG with our MCP server
  *     * [Vibe coding](https://qdrant.tech/blog/webinar-vibe-coding-rag/#vibe-coding)
    * [Understanding the Model Context Protocol (MCP)](https://qdrant.tech/blog/webinar-vibe-coding-rag/#understanding-the-model-context-protocol-mcp)
    * [AI coding assistants](https://qdrant.tech/blog/webinar-vibe-coding-rag/#ai-coding-assistants)
    * [Building the project](https://qdrant.tech/blog/webinar-vibe-coding-rag/#building-the-project)
      * [Setting up the MCP server](https://qdrant.tech/blog/webinar-vibe-coding-rag/#setting-up-the-mcp-server)
      * [Building the knowledge base of the DaisyUI components](https://qdrant.tech/blog/webinar-vibe-coding-rag/#building-the-knowledge-base-of-the-daisyui-components)
      * [Scoping the project: YouTube In-Video Search](https://qdrant.tech/blog/webinar-vibe-coding-rag/#scoping-the-project-youtube-in-video-search)
    * [The vibe coding session](https://qdrant.tech/blog/webinar-vibe-coding-rag/#the-vibe-coding-session)
Another month means another webinar! This time 
##  [](https://qdrant.tech/blog/webinar-vibe-coding-rag/#vibe-coding)Vibe coding
**Vibe coding** is a development approach introduced by Andrej Karpathy where developers surrender to intuition rather than control. It leverages AI coding assistants for implementation while developers focus on outcomes. Through voice interfaces and complete trust in AI suggestions, the process prioritizes results over code comprehension.
That sounds appealing, as code might be written by less technical people, and that’s what we wanted to achieve during our live vibe coding session to see if it’s really that easy.
**Disclaimer:** We couldn’t promise the application will even run at the very end of the webinar, but we gave it a try either way! It’s less than an hour, and even having somehow functional demo within that time can already be considered a great success.
##  [](https://qdrant.tech/blog/webinar-vibe-coding-rag/#understanding-the-model-context-protocol-mcp)Understanding the Model Context Protocol (MCP)
Before diving into the tools, it’s important to understand what powers our approach. The 
Our [Qdrant](https://qdrant.tech/). This combination allows AI agents to:
  1. Store and retrieve memories (code snippets, documentation, etc.)
  2. Perform semantic searches across your codebase
  3. Find the most relevant context for generating new code
The server provides two primary tools:
  * `qdrant-store`: Stores information with optional metadata in the Qdrant database
  * `qdrant-find`: Retrieves relevant information using semantic search
This architecture enables AI coding agents to maintain context awareness throughout your development process.
##  [](https://qdrant.tech/blog/webinar-vibe-coding-rag/#ai-coding-assistants)AI coding assistants
There isn’t a clear winner of the AI coding tools, and the choice depends on your preferences and requirements. We did some initial research and decided to test the following tools:
![Cursor](https://qdrant.tech/blog/webinar-vibe-coding-rag/cursor.png)
There’s been a lot of excitement around **Cursor** recently, and for good reason. It’s a powerful IDE-integrated tool built on Visual Studio Code that promises to transform how we code with AI assistance. But those of you who had a somewhat complicated relationship with VS Code, like me, may prefer to stick with the familiar tools where you’re most productive, e.g. JetBrains IDEs. A huge benefit of Cursor is that it can integrate with the **MCP servers** , such as `mcp-server-qdrant`, which allows you to provide your own context to the AI model.
![GitHub Copilot](https://qdrant.tech/blog/webinar-vibe-coding-rag/github-copilot.png)
GitHub Copilot might be an interesting option for you, especially if you are an open source contributor and qualify for the Pro plan at no cost. This is quite appealing, as the Pro plan comes without any usage limits. This is a significant advantage over Cursor, which does have certain usage limits. From a pure economics standpoint, Copilot would make a lot of sense if it delivered comparable results.
![Aider](https://qdrant.tech/blog/webinar-vibe-coding-rag/aider.png)
Another contender we considered was **Aider** - a terminal-based agent for coding. It is a terminal-based tools that works directly with your git repository, making edits across multiple files. What’s particularly compelling is its flexibility - you can connect it to almost any LLM of your choice, including local models if you’re concerned about privacy or working offline. And it’s fully open source, which might be a huge benefit!
![Claude Code](https://qdrant.tech/blog/webinar-vibe-coding-rag/claude-code.png)
Last but not least, we have **Claude Code** - another terminal AI coding assistant, but the only one tightly integrated with the specific model family - Claude models from Anthropic. Since it’s baked by the same team that created the models, it might be the most optimized for the task. The tool is still in beta preview, but the built-in support for the Model Context Protocol is a huge advantage, and we eventually decided to use it for our vibe coding session!
##  [](https://qdrant.tech/blog/webinar-vibe-coding-rag/#building-the-project)Building the project
The idea behind **vibe coding** is to let the AI do the heavy lifting while you focus on the outcome. However, real software development is more than just writing code. It’s about understanding the problem, designing a solution, and choosing the right tools and libraries. We don’t want the model to use an outdated version of the library it was possibly trained on, so we need to provide it with the right context. That’s why building an inline RAG (Retrieval Augmented Generation) for the AI coding agent may take it to the next level, as it can bring the context to the model when it needs it.
In our case, we really wanted to use **MCP server** to provide the context to the AI coding assistant.
###  [](https://qdrant.tech/blog/webinar-vibe-coding-rag/#setting-up-the-mcp-server)Setting up the MCP server
The Qdrant MCP server acts as a semantic memory layer that can:
  * Store code snippets, documentation, and implementation details using the `qdrant-store` tool
  * Retrieve the most relevant information based on natural language queries with the `qdrant-find` tool
For our live coding session, we configured Claude Code to work with this MCP server. When Claude needs to generate code, it can automatically search for relevant examples in our codebase and create new code based on the extracted examples. Moreover, when the assistant is done with generating the code, it can also store it in Qdrant for further reference. And if configured correctly, it will only do that when we accept the change.
The latest version of the `mcp-server-qdrant` allows to specify the instructions for the AI agent, so it can understand when to use which of the tools. This way, the MCP server can not only be used for coding but virtually to any semantic search task, where the context is crucial. This is how we did that during the webinar:
```
export TOOL_FIND_DESCRIPTION="Use this tool ALWAYS before generating any FRONTEND code. \
It lets you search for relevant code snippets based on natural language descriptions. \
The 'query' parameter should describe what you're looking for, and the tool will return the most relevant code \
snippets. If this tool finds something similar, then create your code so it is consistent. Reuse existing code \
as much as you can."
export TOOL_STORE_DESCRIPTION="Store reusable FRONTEND code snippets for later retrieval. \
The 'information' parameter should contain a natural language description of what the code does, while the actual \
code should be included in the 'metadata' parameter as a 'code' property. The value of 'metadata' is a Python \
dictionary with strings as keys. Use this always when you generate some code to store it for further reference."

```
Both descriptions might be configured while you run the server:
```
claude mcp add qdrant-code-search \
QDRANT_URL="http://localhost:6333" \
COLLECTION_NAME="mcp-server-qdrant-knowledge-base" \
TOOL_FIND_DESCRIPTION="$TOOL_FIND_DESCRIPTION" \
TOOL_STORE_DESCRIPTION="$TOOL_STORE_DESCRIPTION" \

```
The MCP server configuration is primarily done through environment variables. For those looking to set up their own instance, here are the key configuration options:
Name | Description | Default Value  
---|---|---  
`QDRANT_URL` | URL of the Qdrant server | None  
`QDRANT_API_KEY` | API key for the Qdrant server | None  
`COLLECTION_NAME` | Name of the collection to use | _Required_  
`QDRANT_LOCAL_PATH` | Path to the local Qdrant database (alternative to `QDRANT_URL`) | None  
`EMBEDDING_PROVIDER` | Embedding provider to use | `fastembed`  
`EMBEDDING_MODEL` | Name of the embedding model to use | `sentence-transformers/all-MiniLM-L6-v2`  
By default, the server uses the `sentence-transformers/all-MiniLM-L6-v2` embedding model from 
###  [](https://qdrant.tech/blog/webinar-vibe-coding-rag/#building-the-knowledge-base-of-the-daisyui-components)Building the knowledge base of the DaisyUI components
![DaisyUI](https://qdrant.tech/blog/webinar-vibe-coding-rag/daisyui.png)
That makes it really easy to extract all the code snippets with the corresponding meaning and store for the reference while we vibe code an app. This extraction process is easy with LLMs, but we will skip this part for now. 
###  [](https://qdrant.tech/blog/webinar-vibe-coding-rag/#scoping-the-project-youtube-in-video-search)Scoping the project: YouTube In-Video Search
When learning a new skill, YouTube videos can be a great resource. However, in-depth content is often lengthy and may assume no prior knowledge. What if you could have a smart assistant to help you navigate through videos and find exactly what you need? This project aims to create a search engine for video content, helping you skim through and focus on what matters specifically to you.
Would you like to recreate our vibe coded project? The 
##  [](https://qdrant.tech/blog/webinar-vibe-coding-rag/#the-vibe-coding-session)The vibe coding session
If you are interested to see how well Claude Code performed in action, you can watch the full webinar recording below:
No matter if you build an MVP, or want to build a more complex application with the help of AI, it’s key to give your agent a reliable source of information. That’s why we’ve built our MCP server, so you can easily connect your documentation and codebase to Claude Code, Cursor, Windsurf or any other AI agent that supports the Model Context Protocol.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/webinar-vibe-coding-rag/)
                    ## 📄 `https-qdrant-tech-blog.md`
                    ```md
                    # https://qdrant.tech/blog/
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Automating Business Processes with Qdrant and n8n: Use Cases Beyond Simple Similarity Search](https://qdrant.tech/blog/qdrant-n8n-2/preview/preview.jpg) Automating Business Processes with Qdrant and n8n: Use Cases Beyond Simple Similarity Search Build powerful agentic workflows for recommendations and large-scale data analysis with the combined capabilities of Qdrant and n8n. Evgeniya Sukhodolskaya April 04, 2025 ](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/)[![Satellite Vector Broadcasting: Near-Zero Latency Retrieval from Space](https://qdrant.tech/blog/satellite-vector-broadcasting/preview/preview.jpg) Satellite Vector Broadcasting: Near-Zero Latency Retrieval from Space The future of vector search, featuring a constellation of CubeSats for ultra-low-latency vector retrieval. Complete with benchmark results and field reports from our beta testers. Qdrant Team April 01, 2025 ](https://qdrant.tech/blog/satellite-vector-broadcasting/)[![Vibe Coding RAG with our MCP server](https://qdrant.tech/blog/webinar-vibe-coding-rag/preview/preview.jpg) Vibe Coding RAG with our MCP server Check out how the MCP server can give you more control over the quality of vibe coding with AI agents like Cursor, and Claude Code! Kacper Łukawski March 21, 2025 ](https://qdrant.tech/blog/webinar-vibe-coding-rag/)[![How Deutsche Telekom Built a Multi-Agent Enterprise Platform Leveraging Qdrant](https://qdrant.tech/blog/case-study-deutsche-telekom/preview/preview.jpg) How Deutsche Telekom Built a Multi-Agent Enterprise Platform Leveraging Qdrant Learn about Deutsche Telekom's requirements for scaling enterprise AI agents, key AI stack considerations, and how the team built a Platform as a Service (PaaS) - LMOS (Language Models Operating System) — a multi-agent PaaS designed for high scalability and modular AI agent deployment. Manuel Meyer March 07, 2025 ](https://qdrant.tech/blog/case-study-deutsche-telekom/)[![Introducing Qdrant Cloud’s New Enterprise-Ready Vector Search](https://qdrant.tech/blog/enterprise-vector-search/preview/preview.jpg) Introducing Qdrant Cloud’s New Enterprise-Ready Vector Search Discover Qdrant Cloud's enterprise features: RBAC, SSO, granular API keys, advanced monitoring/observability. Daniel Azoulai March 04, 2025 ](https://qdrant.tech/blog/enterprise-vector-search/)[![Metadata automation and optimization - Reece Griffiths | Vector Space Talks](https://qdrant.tech/blog/metadata-deasy-labs/preview/preview.jpg) Metadata automation and optimization - Reece Griffiths | Vector Space Talks Metadata plays a critical role in vector search accuracy, yet it’s often overlooked. In this episode of Vector Space Talks, Reece Griffiths, CEO of Deasy Labs, explains why metadata automation is essential for scalable AI systems. He walks us through how Deasy Labs orchestrates metadata extraction, classification, and enrichment to boost retrieval efficiency. Sabrina Aquino February 24, 2025 ](https://qdrant.tech/blog/metadata-deasy-labs/)[![How to Build Intelligent Agentic RAG with CrewAI and Qdrant](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/preview/preview.jpg) How to Build Intelligent Agentic RAG with CrewAI and Qdrant Learn how to build an agentic RAG system to semi-automate email communication with CrewAI, Qdrant, and Obsidian. Kacper Łukawski January 24, 2025 ](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/)[![Static Embeddings: should you pay attention?](https://qdrant.tech/blog/static-embeddings/preview/preview.jpg) Static Embeddings: should you pay attention? Static embeddings are a thing back! Is the encoding speedup worth a try? We checked that! Kacper Łukawski January 17, 2025 ](https://qdrant.tech/blog/static-embeddings/)[![Voiceflow & Qdrant: Powering No-Code AI Agent Creation with Scalable Vector Search](https://qdrant.tech/blog/case-study-voiceflow/preview/preview.jpg) Voiceflow & Qdrant: Powering No-Code AI Agent Creation with Scalable Vector Search Learn how Voiceflow builds scalable, customizable, no-code AI agent solutions for enterprises. Qdrant December 10, 2024 ](https://qdrant.tech/blog/case-study-voiceflow/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/)
                    ## 📄 `https-qdrant-tech-cloud.md`
                    ```md
                    # https://qdrant.tech/cloud/
### Qdrant Cloud
Qdrant Cloud provides optimal flexibility and offers a suite of features focused on efficient and scalable vector search - fully managed. Available on AWS, Google Cloud, and Azure.
[Talk to Sales](https://qdrant.tech/contact-us/)
##### Run Anywhere
Available on **AWS** , **Google Cloud** , and **Azure** regions globally for deployment flexibility and quick data access.
![Run anywhere graphic](https://qdrant.tech/img/qdrant-cloud-bento-cards/run-anywhere-graphic.png)
##### Simple Setup and Start Free
Deploying a cluster via the Qdrant Cloud Console takes only a few seconds and scales up as needed.
![Simple setup illustration](https://qdrant.tech/img/qdrant-cloud-bento-cards/simple-setup-illustration.png)
##### Efficient Resource Management
Dramatically reduce memory usage with built-in compression options and offload data to disk.
![Efficient resource management diagram](https://qdrant.tech/img/qdrant-cloud-bento-cards/efficient-resource-management.png)
##### Zero-downtime Upgrades
Uninterrupted service during scaling and model updates for continuous operation and deployment flexibility.
[Cluster Scaling](https://qdrant.tech/documentation/cloud/cluster-scaling/) ![Zero downtime upgrades illustration](https://qdrant.tech/img/qdrant-cloud-bento-cards/zero-downtime-upgrades.png)
##### Continuous Backups
Automated, configurable backups for data safety and easy restoration to previous states.
[Backups](https://qdrant.tech/documentation/cloud/backups/) ![Continuous backups illustration](https://qdrant.tech/img/qdrant-cloud-bento-cards/continuous-backups.png)
###### Learn more about all features that are supported on Qdrant Cloud.
[Qdrant Features](https://qdrant.tech/qdrant-vector-database/)
## Qdrant is also available on leading marketplaces
![AWS marketplace logo](https://qdrant.tech/img/marketplaces/aws-logo.png)
##### AWS Marketplace
![Google Cloud marketplace logo](https://qdrant.tech/img/marketplaces/google-cloud-logo.png)
##### Google Cloud Marketplace
![Microsoft Azure logo](https://qdrant.tech/img/marketplaces/microsoft-azure-logo.png)
##### Microsoft Azure
## Additional Resources
###### Documentation
Discover more about Qdrant by checking out our documentation for details on advanced features and functionalities.
[Read More ](https://qdrant.tech/documentation/)
###### Enterprise Solutions
For maximal control for production-ready applications Qdrant is available as a Hybrid Cloud and Private Cloud (Full On Premise) solution.
[Read More ](https://qdrant.tech/enterprise-solutions/)
###### Benchmarks
Learn how Qdrant is designed to deliver the fastest and most accurate results and how it compares to alternatives in our benchmarks.
[Compare ](https://qdrant.tech/benchmarks/)
###### Pricing
Visit our pricing page for more details on Qdrant’s free tier, managed cloud, and enterprise plans.
[Learn More ](https://qdrant.tech/pricing/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/cloud/)
                    ## 📄 `https-qdrant-tech-community.md`
                    ```md
                    # https://qdrant.tech/community/
![Community](https://qdrant.tech/img/community-hero.svg)
# Welcome to the Qdrant Community
Connect with over 30,000 community members, get access to educational resources, and stay up to date on all news and discussions about Qdrant and the vector database space.
![Community](https://qdrant.tech/img/mobile/community-hero.svg)
## Discover our Programs
###### Qdrant Stars
Qdrant Stars are our top contributors, organizers, and evangelists. Learn more about how you can become a Star.
[Learn More ](https://qdrant.tech/stars/)![Avatar](https://qdrant.tech/img/community-features/qdrant-stars.svg)
###### Discord
Chat in real-time with the Qdrant team and community members.
![Avatar](https://qdrant.tech/img/community-features/discord.svg)
###### Community Blog
Learn all the latest tips and tricks in the AI space through our community blog.
[Visit our Blog ](https://qdrant.tech/blog/)![Avatar](https://qdrant.tech/img/community-features/community-blog.svg)
###### Vector Space Talks
Weekly tech talks with Qdrant users and industry experts.
![Avatar](https://qdrant.tech/img/community-features/vector-space-talks.svg)
![Documentation](https://qdrant.tech/icons/outline/documentation-blue.svg)
###### Documentation
Docs carefully crafted to support developers and decision-makers learning about Qdrant features.
[Read More](https://qdrant.tech/documentation/)
![Guide](https://qdrant.tech/icons/outline/guide-blue.svg)
###### Contributors Guide
Whatever your strengths are, we got you covered. Learn more about how to contribute to Qdrant.
![Partners](https://qdrant.tech/icons/outline/handshake-blue.svg)
###### Partners
Technology partners and applications that support Qdrant.
[Learn More](https://qdrant.tech/partners/)
![News & Updates](https://qdrant.tech/icons/outline/mail-blue.svg)
###### News & Updates
Stay up to date on product news, technical articles, and more.
[Learn More](https://qdrant.tech/subscribe/)
## Love from our community
![Avatar](https://qdrant.tech/img/customers/owen-colegrove.svg)
Owen Colegrove
@ocolegro
qdrant has been amazing!
![Avatar](https://qdrant.tech/img/customers/darren.svg)
Darren
@darrenangle
qdrant is so fast I'm using Rust for all future projects goodnight everyone
![Avatar](https://qdrant.tech/img/customers/greg-schoeninger.svg)
Greg Schoeninger
@gregschoeninger
Indexing millions of embeddings into @qdrant_engine has been the smoothest experience I've had so far with a vector db. Team Rustacian all the way 🦀
![Avatar](https://qdrant.tech/img/customers/ifioravanti.svg)
Ifioravanti
@ivanfioravanti
@qdrant_engine is ultra super powerful! Combine it to @LangChainAI and you have a super productivity boost for your AI projects ⏩⏩⏩
![Avatar](https://qdrant.tech/img/customers/sengpt.svg)
sengpt
@sengpt
Thank you, Qdrant is awesome
![Avatar](https://qdrant.tech/img/customers/owen-colegrove.svg)
Owen Colegrove
@ocolegro
that sounds good to me, big fan of qdrant.
### Launch a new cluster today
![](https://qdrant.tech/img/database.svg)
Do you have further questions? We are happy to assist you.
[Contact us ](https://qdrant.tech/contact-us/)[Contact us](https://qdrant.tech/contact-us/)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/community/)
                    ## 📄 `https-qdrant-tech-contact-us.md`
                    ```md
                    # https://qdrant.tech/contact-us/
### Contact Qdrant
Let us know how we can help by filling out the form. We will respond within 48 business hours.
![Qdrant Cloud Support](https://qdrant.tech/icons/outline/comments-violet.svg)
###### Qdrant Cloud Support
For questions or issues with Qdrant Cloud, contact
![Developer Support](https://qdrant.tech/icons/outline/discord-blue.svg)
###### Developer Support
For developer questions about Qdrant usage, join our
###### Talk to our Team
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/contact-us/)
                    ## 📄 `https-qdrant-tech-customers.md`
                    ```md
                    # https://qdrant.tech/customers/
# Customers
Learn how Qdrant powers thousands of top AI solutions that require vector search with unparalleled efficiency, performance and massive-scale data processing.
![Logo](https://qdrant.tech/img/customers-case-studies/hubspot-logo.svg)
##### HubSpot & Qdrant: Scaling an Intelligent AI Assistant
HubSpot selected Qdrant because it significantly outperformed alternatives, ensuring that Breeze AI could quickly retrieve and rank relevant data. This was crucial for recommendation systems and contextual content retrieval, where speed and accuracy directly impact user engagement and satisfaction.
[Read Case Study](https://qdrant.tech/blog/case-study-hubspot/)
![Preview](https://qdrant.tech/img/customers-case-studies/case-study-hubspot.png)
“Qdrant powers our demanding recommendation and RAG applications. We chose it for its ease of deployment and high performance at scale, and have been consistently impressed with its results. The platform’s continuous feature enhancements and overall performance gains, coupled with their responsiveness, make Qdrant a reliable solution for our AI infrastructure.”
![Srubin Sethu Madhavan Avatar](https://qdrant.tech/img/customers/srubin-sethu-madhavan.svg)
Srubin Sethu Madhavan
Technical Lead II at Hubspot
![Logo](https://qdrant.tech/img/brands/hubspot.svg)
![Logo Deutsche Telekom](https://qdrant.tech/img/customers-case-studies/customer-logo0.svg)
##### How Deutsche Telekom Built a Multi-Agent Enterprise Platform Leveraging Qdrant
Deutsche Telekom leveraged Qdrant to build an AI Agent Platform powering their multi-agent PaaS (LMOS), enabling scalable AI deployment across 10 European subsidiaries, supporting over 2 million conversations, and reducing agent development time from 15 days to just 2.
[Read Case Study](https://qdrant.tech/blog/case-study-deutsche-telekom/)
![Preview](https://qdrant.tech/img/customers-case-studies/case-study0.png)
“We looked at all the big options out there right now for vector databases, with our focus on ease of use, performance, pricing, and communication. **Qdrant came out on top in each category...** ultimately, it wasn't much of a contest.”
![Alex Webb Avatar](https://qdrant.tech/img/customers/alex-webb.svg)
Alex Webb
Director of Engineering, CB Insights
![Logo](https://qdrant.tech/img/brands/cb-insights.svg)
![Logo Sprinklr](https://qdrant.tech/img/customers-case-studies/customer-logo1.svg)
##### How Sprinklr Leverages Qdrant to Enhance AI-Driven Customer Experience Solutions
Sprinklr uses Qdrant to enhance its AI-driven customer experience management platform, improving data retrieval speed, efficiency, and **reducing costs by 30%**. This integration has also boosted developer productivity and ensured superior search performance across their AI applications.
[Read Case Study](https://qdrant.tech/blog/case-study-sprinklr/)
![Preview](https://qdrant.tech/img/customers-case-studies/case-study1.png)
![Hands typing text on a laptop](https://qdrant.tech/img/customers-case-studies/case-study-image1.png) ![QA.Tech Logo](https://qdrant.tech/img/customers-case-studies/qa-tech.svg)
###### Empowering QA.tech’s Testing Agents with Real-Time Precision and Scale
[Read Story](https://qdrant.tech/blog/case-study-qatech/)
![Hand holding a smartphone](https://qdrant.tech/img/customers-case-studies/case-study-image2.png) ![Kairos Logo](https://qdrant.tech/img/customers-case-studies/kairos.svg)
###### Kairoswealth & Qdrant: Transforming Wealth Management with AI-Driven Insights and Scalable Vector Search
[Read Story](https://qdrant.tech/blog/case-study-kairoswealth/)
![A man looks at a laptop screen](https://qdrant.tech/img/customers-case-studies/case-study-image3.png) ![Kern AI Logo](https://qdrant.tech/img/customers-case-studies/kern-ai.svg)
###### Kern AI & Qdrant: Precision AI Solutions for Finance and Insurance
[Read Story](https://qdrant.tech/blog/case-study-kern/)
![Logo Voiceflow](https://qdrant.tech/img/customers-case-studies/customer-logo2.svg)
##### Voiceflow & Qdrant: Powering No-Code AI Agent Creation with Scalable Vector Search
Voiceflow enables enterprises to create AI agents in a no-code environment by designing workflows. Qdrant's features and infrastructure provided Voiceflow with a stable, scalable, and efficient solution for their data processing and retrieval needs.
[Read Case Study](https://qdrant.tech/blog/case-study-voiceflow/)
![Preview](https://qdrant.tech/img/customers-case-studies/case-study2.png)
“Vector stores are definitely here to stay, the objects in the world around us from image, sound, video and text become easily universal and searchable thanks to the embedding models and vector stores. I personally recommend Qdrant. We have been using it for a while and couldn’t be happier.”
![Hooman Sedghamiz Avatar](https://qdrant.tech/img/customers/hooman-sedghamiz.svg)
Hooman Sedghamiz
Director AI/ML, Bayer
![Logo](https://qdrant.tech/img/brands/bayer.svg)
![Logo Nyris](https://qdrant.tech/img/customers-case-studies/customer-logo3.svg)
##### Nyris & Qdrant: How Vectors are the Future of Visual Search
Nyris offers visual search solutions for various industries, using vector-based technology to quickly identify products. They selected Qdrant for its speed, accuracy, and scalability, advancing their vision of transforming product search with unified vector representations.
[Read Case Study](https://qdrant.tech/blog/case-study-nyris/)
![Preview](https://qdrant.tech/img/customers-case-studies/case-study3.png)
“We LOVE Qdrant! The exceptional engineering, strong business value, and outstanding team behind the product drove our choice. Thank you for your great contribution to the technology community!”
![Kyle Tobin Avatar](https://qdrant.tech/img/customers/kyle-tobin.png)
Kyle Tobin
Principal, Cognizant
![Cognizant Logo](https://qdrant.tech/img/brands/cognizant.svg)
![Logo Dailymotion](https://qdrant.tech/img/customers-case-studies/customer-logo4.svg)
##### Recommendation Engine with Qdrant Vector Database
Dailymotion leverages Qdrant to optimize its **video recommendation engine** , managing over 420 million videos and processing 13 million recommendations daily. With this, Dailymotion was able to **reduced content processing times from hours to minutes** and **increased user interactions and click-through rates by more than 3x.**
[Read Case Study](https://qdrant.tech/blog/case-study-dailymotion/)
![Preview](https://qdrant.tech/img/customers-case-studies/case-study4.png)
![The hands of a person in a medical gown holding a tablet against the background of a pharmacy shop](https://qdrant.tech/img/customers-case-studies/case-visua.png) ![Visua Logo](https://qdrant.tech/img/customers-case-studies/visua.svg)
###### VISUA improves quality control process for computer vision with anomaly detection by 10x.
[Read Story](https://qdrant.tech/blog/case-study-visua/)
![A man in a jeans shirt is holding a smartphone, only his hands are visible. In the foreground, there is an image of a robot surrounded by chat and sound waves.](https://qdrant.tech/img/customers-case-studies/case-dust.png) ![Dust Logo](https://qdrant.tech/img/customers-case-studies/dust.svg)
###### Dust uses Qdrant for RAG, achieving millisecond retrieval, reducing costs by 50%, and boosting scalability.
[Read Story](https://qdrant.tech/blog/dust-and-qdrant/)
![Hands holding a smartphone, styled smartphone interface visualisation in the foreground. First-person view](https://qdrant.tech/img/customers-case-studies/case-iris-agent.png) ![Logo](https://qdrant.tech/img/customers-case-studies/iris-agent.svg)
###### IrisAgent uses Qdrant for RAG to automate support, and improve resolution times, transforming customer service.
[Read Story](https://qdrant.tech/blog/iris-agent-qdrant/)
## Vector Space Wall
![Avatar](https://qdrant.tech/img/customers/jonathan-eisenzopf.svg)
Jonathan Eisenzopf
Chief Strategy and Research Officer at Talkmap
“With Qdrant, we found the missing piece to develop our own provider independent multimodal generative AI platform on enterprise scale.”
![Avatar](https://qdrant.tech/img/customers/angel-luis-almaraz-sanchez.svg)
Angel Luis Almaraz Sánchez
Full Stack | DevOps
Thank you, great work, Qdrant is my favorite option for similarity search.
![Avatar](https://qdrant.tech/img/customers/shubham-krishna.svg)
Shubham Krishna
ML Engineer @ ML6
Go ahead and checkout Qdrant. I plan to build a movie retrieval search where you can ask anything regarding a movie based on the vector embeddings generated by a LLM. It can also be used for getting recommendations.
![Avatar](https://qdrant.tech/img/customers/kwok-hing-leon.svg)
Kwok Hing LEON
Data Science
Check out qdrant for improving searches. Bye to non-semantic KM engines.
![Avatar](https://qdrant.tech/img/customers/ankur-s.svg)
Ankur S
Building
Quadrant is a great vector database. There is a real sense of thought behind the api!
![Avatar](https://qdrant.tech/img/customers/yasin-salimibeni-view-yasin-salimibeni.svg)
Yasin Salimibeni View Yasin Salimibeni’s profile
AI Evangelist | Generative AI Product Designer | Entrepreneur | Mentor
Great work. I just started testing Qdrant Azure and I was impressed by the efficiency and speed. Being deploy-ready on large cloud providers is a great plus. Way to go!
![Avatar](https://qdrant.tech/img/customers/marcel-coetzee.svg)
Marcel Coetzee
Data and AI Plumber
Using Qdrant as a blazing fact vector store for a stealth project of mine. It offers fantasic functionality for semantic search ✨
![Avatar](https://qdrant.tech/img/customers/andrew-rove.svg)
Andrew Rove
Principal Software Engineer
We have been using Qdrant in production now for over 6 months to store vectors for cosine similarity search and it is way more stable and faster than our old ElasticSearch vector index.  
No merging segments, no red indexes at random times. It just works and was super easy to deploy via docker to our cluster.  
It’s faster, cheaper to host, and more stable, and open source to boot!
![Avatar](https://qdrant.tech/img/customers/josh-lloyd.svg)
Josh Lloyd
ML Engineer
I'm using Qdrant to search through thousands of documents to find similar text phrases for question answering. Qdrant's awesome filtering allows me to slice along metadata while I'm at it! 🚀 and it's fast ⏩🔥
![Avatar](https://qdrant.tech/img/customers/leonard-puttmann.svg)
Leonard Püttmann
data scientist
Amidst the hype around vector databases, Qdrant is by far my favorite one. It's super fast (written in Rust) and open-source! At Kern AI we use Qdrant for fast document retrieval and to do quick similarity search for text data.
![Avatar](https://qdrant.tech/img/customers/stanislas-polu.svg)
Stanislas Polu
Software Engineer & Co-Founder, Dust
Qdrant's the best. By. Far.
![Avatar](https://qdrant.tech/img/customers/sivesh-sukumar.svg)
Sivesh Sukumar
Investor at Balderton
We're using Qdrant to help segment and source Europe's next wave of extraordinary companies!
![Avatar](https://qdrant.tech/img/customers/saksham-gupta.svg)
Saksham Gupta
AI Governance Machine Learning Engineer
Looking forward to using Qdrant vector similarity search in the clinical trial space! OpenAI Embeddings + Qdrant = Match made in heaven!
![Avatar](https://qdrant.tech/img/customers/rishav-dash.svg)
Rishav Dash
Data Scientist
awesome stuff 🔥
### Get started for free
Turn embeddings or neural network encoders into full-fledged applications for matching, searching, recommending, and more.
Do you have further questions? We are happy to assist you.
[Contact us ](https://qdrant.tech/contact-us/)[Contact us](https://qdrant.tech/contact-us/)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/customers/)
                    ## 📄 `https-qdrant-tech-data-analysis-anomaly-detection.md`
                    ```md
                    # https://qdrant.tech/data-analysis-anomaly-detection/
# Data Analysis and Anomaly Detection
Explore entity matching for deduplication and anomaly detection with Qdrant, leveraging neural networks while still being fast and affordable in your applications for insights hard to get in other ways.
[Contact Us](https://qdrant.tech/contact-us/)
![Anomaly Detection](https://qdrant.tech/img/vectors/vector-3.svg)
### Anomaly Detection with Qdrant
Qdrant optimizes anomaly detection by integrating vector embeddings for nuanced data analysis. It supports dissimilarity, diversity searches, and advanced anomaly detection techniques, enhancing applications from cybersecurity to finance with precise, efficient data insights.
![Anomaly detection](https://qdrant.tech/img/data-analysis-anomaly-detection/anomaly-detection.svg)
![Logo](https://qdrant.tech/img/data-analysis-anomaly-detection/customer-logo.svg)
##### Metric Learning for Anomaly Detection
Detecting Coffee Anomalies with Qdrant: Discover how Qdrant can be used for anomaly detection in green coffee quality control, transforming the industry's approach to sorting and classification.
[Read Case Study](https://qdrant.tech/articles/detecting-coffee-anomalies/)
![Preview](https://qdrant.tech/img/data-analysis-anomaly-detection/case-study.png)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/data-analysis-anomaly-detection/)
                    ## 📄 `https-qdrant-tech-demo.md`
                    ```md
                    # https://qdrant.tech/demo/
## Qdrant Demos and Tutorials
Experience firsthand how Qdrant powers intelligent search, anomaly detection, and personalized recommendations, showcasing the full capabilities of vector search to revolutionize data exploration and insights.
###### Semantic Search Demo - Startup Search
This demo leverages a pre-trained SentenceTransformer model to perform semantic searches on startup descriptions, transforming them into vectors for the Qdrant engine.
Enter a query to see how neural search compares to traditional full-text search, with the option to toggle neural search on and off for direct comparison.
###### Semantic Search and Recommendations Demo - Food Discovery
Explore personalized meal recommendations with our demo, using Delivery Service data. Like or dislike dish photos to refine suggestions based on visual appeal.
Filter options allow for restaurant selections within your delivery area, tailoring your dining experience to your preferences.
[View Demo](https://food-discovery.qdrant.tech/)
###### Categorization Demo -  
E-Commerce Products
Discover the power of vector databases in e-commerce through our demo. Simply input a product name and watch as our multi-language model intelligently categorizes it. The dots you see represent product clusters, highlighting our system's efficient categorization.
###### Code Search Demo -  
Explore Qdrant's Codebase
Semantic search isn't just for natural language. By combining results from two models, qdrant is able to locate relevant code snippets down to the exact line.
[View Demo](https://code-search.qdrant.tech/)
### Interactive Tutorials
Dive into the capabilities of Qdrant with our hands-on tutorials. Discover various methods to integrate vector search into your applications, enhancing functionality and user experience.
[View All Tutorials](https://qdrant.tech/documentation/tutorials/)
`...  
"hnsw_config": {  
"m": 64,  
"ef_construct": 512,  
"on_disk": true  
}  
...  
`
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/demo/)
                    ## 📄 `https-qdrant-tech-documentation-advanced-tutorials-code-search.md`
                    ```md
                    # https://qdrant.tech/documentation/advanced-tutorials/code-search/
### Getting Started
[What is Qdrant?](https://qdrant.tech/documentation/overview/)
  * [Understanding Vector Search in Qdrant](https://qdrant.tech/documentation/overview/vector-search/)
[Local Quickstart](https://qdrant.tech/documentation/quickstart/)
[API & SDKs](https://qdrant.tech/documentation/interfaces/)
[Qdrant Web UI](https://qdrant.tech/documentation/web-ui/)
### User Manual
[Concepts](https://qdrant.tech/documentation/concepts/)
  * [Collections](https://qdrant.tech/documentation/concepts/collections/)
  * [Points](https://qdrant.tech/documentation/concepts/points/)
  * [Vectors](https://qdrant.tech/documentation/concepts/vectors/)
  * [Payload](https://qdrant.tech/documentation/concepts/payload/)
  * [Search](https://qdrant.tech/documentation/concepts/search/)
  * [Explore](https://qdrant.tech/documentation/concepts/explore/)
  * [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/)
  * [Filtering](https://qdrant.tech/documentation/concepts/filtering/)
  * [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/)
  * [Storage](https://qdrant.tech/documentation/concepts/storage/)
  * [Indexing](https://qdrant.tech/documentation/concepts/indexing/)
  * [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)
[Guides](https://qdrant.tech/documentation/guides/installation/)
  * [Installation](https://qdrant.tech/documentation/guides/installation/)
  * [Administration](https://qdrant.tech/documentation/guides/administration/)
  * [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/)
  * [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/)
  * [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/)
  * [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/)
  * [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/)
  * [Quantization](https://qdrant.tech/documentation/guides/quantization/)
  * [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/)
  * [Configuration](https://qdrant.tech/documentation/guides/configuration/)
  * [Security](https://qdrant.tech/documentation/guides/security/)
  * [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/)
  * [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)
### Tutorials
[Vector Search Basics](https://qdrant.tech/documentation/beginner-tutorials/)
  * [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)
  * [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/)
  * [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)
  * [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)
[Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)
  * [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/)
  * [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/)
  * [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)
[Using the Database](https://qdrant.tech/documentation/database-tutorials/)
  * [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/)
  * [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/)
  * [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/)
  * [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/)
  * [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/)
  * [Automate filtering with LLMs](https://qdrant.tech/documentation/database-tutorials/automate-filtering-with-llms/)
### Support
[FAQ](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)
  * [Qdrant Fundamentals](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)
  * [Database Optimization](https://qdrant.tech/documentation/faq/database-optimization/)
# Qdrant Documentation
Qdrant is an AI-native vector database and a semantic search engine. You can use it to extract meaningful information from unstructured data.
[Cloud Quickstart ](https://qdrant.tech/documentation/quickstart-cloud/)[Local Quickstart](https://qdrant.tech/documentation/quickstart/)
## Ready to start developing?
Qdrant is open-source and can be self-hosted. However, the quickest way to get started is with our 
### Create your first Qdrant Cloud cluster today
![](https://qdrant.tech/img/rocket.svg)
## Optimize Qdrant's performance
Boost search speed, reduce latency, and improve the accuracy and memory usage of your Qdrant deployment.
[Learn More](https://qdrant.tech/documentation/guides/optimize/)
[ ![Documents](https://qdrant.tech/icons/outline/documentation-blue.svg) Documents Distributed Deployment Scale Qdrant beyond a single node and optimize for high availability, fault tolerance, and billion-scale performance. Read More](https://qdrant.tech/documentation/guides/distributed_deployment/)
[ ![Documents](https://qdrant.tech/icons/outline/documentation-blue.svg) Documents Multitenancy Build vector search apps that serve millions of users. Learn about data isolation, security, and performance tuning. Read More](https://qdrant.tech/documentation/guides/multiple-partitions/)
[ ![Blog](https://qdrant.tech/icons/outline/blog-purple.svg) Blog Vector Quantization Learn about cutting-edge techniques for vector quantization and how they can be used to improve search performance. Read More](https://qdrant.tech/articles/what-is-vector-quantization/)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/advanced-tutorials/code-search/)
                    ## 📄 `https-qdrant-tech-documentation-advanced-tutorials-collaborative-filtering.md`
                    ```md
                    # https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/)
                    ## 📄 `https-qdrant-tech-documentation-advanced-tutorials-pdf-retrieval-at-scale.md`
                    ```md
                    # https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)
                    ## 📄 `https-qdrant-tech-documentation-advanced-tutorials.md`
                    ```md
                    # https://qdrant.tech/documentation/advanced-tutorials/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/advanced-tutorials/)
                    ## 📄 `https-qdrant-tech-documentation-agentic-rag-crewai-zoom.md`
                    ```md
                    # https://qdrant.tech/documentation/agentic-rag-crewai-zoom/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)
                    ## 📄 `https-qdrant-tech-documentation-beginner-tutorials-hybrid-search-fastembed.md`
                    ```md
                    # https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)
                    ## 📄 `https-qdrant-tech-documentation-beginner-tutorials-neural-search.md`
                    ```md
                    # https://qdrant.tech/documentation/beginner-tutorials/neural-search/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/beginner-tutorials/neural-search/)
                    ## 📄 `https-qdrant-tech-documentation-beginner-tutorials-retrieval-quality.md`
                    ```md
                    # https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)
                    ## 📄 `https-qdrant-tech-documentation-beginner-tutorials-search-beginners.md`
                    ```md
                    # https://qdrant.tech/documentation/beginner-tutorials/search-beginners/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)
                    ## 📄 `https-qdrant-tech-documentation-beginner-tutorials.md`
                    ```md
                    # https://qdrant.tech/documentation/beginner-tutorials/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/beginner-tutorials/)
                    ## 📄 `https-qdrant-tech-documentation-cloud-authentication.md`
                    ```md
                    # https://qdrant.tech/documentation/cloud/authentication/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/cloud/authentication/)
                    ## 📄 `https-qdrant-tech-documentation-cloud-backups.md`
                    ```md
                    # https://qdrant.tech/documentation/cloud/backups/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/cloud/backups/)
                    ## 📄 `https-qdrant-tech-documentation-cloud-cluster-scaling.md`
                    ```md
                    # https://qdrant.tech/documentation/cloud/cluster-scaling/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/cloud/cluster-scaling/)
                    ## 📄 `https-qdrant-tech-documentation-cloud-qdrant-cloud-setup-enterprise-single-sign-on-sso.md`
                    ```md
                    # https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#enterprise-single-sign-on-sso
### Getting Started
[Cloud Quickstart](https://qdrant.tech/documentation/quickstart-cloud/)
### Managed Services
[Managed Cloud](https://qdrant.tech/documentation/cloud/)
  * [Getting Started](https://qdrant.tech/documentation/cloud/getting-started/)
  * [Account Setup](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/)
  * [Create a Cluster](https://qdrant.tech/documentation/cloud/create-cluster/)
  * [Authentication](https://qdrant.tech/documentation/cloud/authentication/)
  * [Cluster Access](https://qdrant.tech/documentation/cloud/cluster-access/)
  * [Scale Clusters](https://qdrant.tech/documentation/cloud/cluster-scaling/)
  * [Monitor Clusters](https://qdrant.tech/documentation/cloud/cluster-monitoring/)
  * [Upgrade Clusters](https://qdrant.tech/documentation/cloud/cluster-upgrades/)
  * [Backup Clusters](https://qdrant.tech/documentation/cloud/backups/)
  * [Billing & Payments](https://qdrant.tech/documentation/cloud/pricing-payments/)
  * [Premium Tier](https://qdrant.tech/documentation/cloud/premium/)
[Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/)
  * [Setup Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/hybrid-cloud-setup/)
  * [Create a Cluster](https://qdrant.tech/documentation/hybrid-cloud/hybrid-cloud-cluster-creation/)
  * [Configure the Qdrant Operator](https://qdrant.tech/documentation/hybrid-cloud/operator-configuration/)
  * [Networking, Logging & Monitoring](https://qdrant.tech/documentation/hybrid-cloud/networking-logging-monitoring/)
  * [Deployment Platforms](https://qdrant.tech/documentation/hybrid-cloud/platform-deployment-options/)
[Private Cloud](https://qdrant.tech/documentation/private-cloud/)
  * [Setup Private Cloud](https://qdrant.tech/documentation/private-cloud/private-cloud-setup/)
  * [Configuration](https://qdrant.tech/documentation/private-cloud/configuration/)
  * [Managing a Cluster](https://qdrant.tech/documentation/private-cloud/qdrant-cluster-management/)
  * [Backups](https://qdrant.tech/documentation/private-cloud/backups/)
  * [Logging & Monitoring](https://qdrant.tech/documentation/private-cloud/logging-monitoring/)
  * [API Reference](https://qdrant.tech/documentation/private-cloud/api-reference/)
  * [Changelog](https://qdrant.tech/documentation/private-cloud/changelog/)
[Cloud RBAC](https://qdrant.tech/documentation/cloud-rbac/)
  * [Role Management](https://qdrant.tech/documentation/cloud-rbac/role-management/)
  * [User Management](https://qdrant.tech/documentation/cloud-rbac/user-management/)
  * [Permission Reference](https://qdrant.tech/documentation/cloud-rbac/permission-reference/)
  * [Early Access FAQ](https://qdrant.tech/documentation/cloud-rbac/early-access-faq/)
### Interfaces & Tools
[Qdrant Cloud API](https://qdrant.tech/documentation/qdrant-cloud-api/)
[Infrastructure Tools](https://qdrant.tech/documentation/cloud-tools/)
  * [Pulumi](https://qdrant.tech/documentation/cloud-tools/pulumi/)
  * [Terraform](https://qdrant.tech/documentation/cloud-tools/terraform/)
### Support
[Support](https://qdrant.tech/documentation/support/)
  * [Documentation](https://qdrant.tech/documentation/)
  * [Cloud](https://qdrant.tech/documentation/cloud/)
  * Account Setup
#  [](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#setting-up-a-qdrant-cloud-account)Setting up a Qdrant Cloud Account
##  [](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#registration)Registration
There are different ways to register for a Qdrant Cloud account:
  * With an email address and passwordless login via email
  * With a Google account
  * With a GitHub account
  * By connection an enterprise SSO solution
Every account is tied to an email address. You can invite additional users to your account and manage their permissions.
###  [](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#email-registration)Email registration
  1. Register for a 
##  [](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#inviting-additional-users-to-an-account)Inviting additional users to an account
You can invite additional users to your account, and manage their permissions on the _Account Management_ page in the Qdrant Cloud Console.
![Invitations](https://qdrant.tech/documentation/cloud/invitations.png)
Invited users will receive an email with an invitation link to join Qdrant Cloud. Once they signed up, they can accept the invitation from the Overview page.
![Accepting invitation](https://qdrant.tech/documentation/cloud/accept-invitation.png)
##  [](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#switching-between-accounts)Switching between accounts
If you have access to multiple accounts, you can switch between accounts with the account switcher on the top menu bar of the Qdrant Cloud Console.
![Switching between accounts](https://qdrant.tech/documentation/cloud/account-switcher.png)
##  [](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#account-settings)Account settings
You can configure your account settings in the Qdrant Cloud Console, by clicking on your account picture in the top right corner, and selecting _Profile_.
The following functionality is available.
###  [](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#renaming-an-account)Renaming an account
If you use multiple accounts for different purposes, it is a good idea to give them descriptive names, for example _Development_ , _Production_ , _Testing_. You can also choose which account should be the default one, when you log in.
![Account management](https://qdrant.tech/documentation/cloud/account-management.png)
###  [](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#deleting-an-account)Deleting an account
When you delete an account, all database clusters and associated data will be deleted.
##  [](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#enterprise-single-sign-on-sso)Enterprise Single-Sign-On (SSO)
Qdrant Cloud supports Enterprise Single-Sign-On for Premium Tier customers. The following providers are supported:
  * Active Directory/LDAP
  * ADFS
  * Azure Active Directory Native
  * Google Workspace
  * OpenID Connect
  * Okta
  * PingFederate
  * SAML
  * Azure Active Directory
Enterprise Sign-On is available as an add-on for [Premium Tier](https://qdrant.tech/documentation/cloud/premium/) customers. If you are interested in using SSO, please [contact us](https://qdrant.tech/contact-us/).
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/cloud/qdrant-cloud-setup.md) this page on GitHub, or 
On this page:
  * [Setting up a Qdrant Cloud Account](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#setting-up-a-qdrant-cloud-account)
    * [Registration](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#registration)
      * [Email registration](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#email-registration)
    * [Inviting additional users to an account](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#inviting-additional-users-to-an-account)
    * [Switching between accounts](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#switching-between-accounts)
    * [Account settings](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#account-settings)
      * [Renaming an account](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#renaming-an-account)
      * [Deleting an account](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#deleting-an-account)
    * [Enterprise Single-Sign-On (SSO)](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#enterprise-single-sign-on-sso)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-collections.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/collections/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/collections/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-explore.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/explore/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/explore/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-filtering-full-text-match.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/filtering/#full-text-match
  * [Documentation](https://qdrant.tech/documentation/)
  * [Concepts](https://qdrant.tech/documentation/concepts/)
  * Filtering
#  [](https://qdrant.tech/documentation/concepts/filtering/#filtering)Filtering
With Qdrant, you can set conditions when searching or retrieving points. For example, you can impose conditions on both the [payload](https://qdrant.tech/documentation/concepts/payload/) and the `id` of the point.
Setting additional conditions is important when it is impossible to express all the features of the object in the embedding. Examples include a variety of business requirements: stock availability, user location, or desired price range.
##  [](https://qdrant.tech/documentation/concepts/filtering/#related-content)Related Content
[A Complete Guide to Filtering in Vector Search](https://qdrant.tech/articles/vector-search-filtering/) | Developer advice on proper usage and advanced practices.  
---|---  
##  [](https://qdrant.tech/documentation/concepts/filtering/#filtering-clauses)Filtering clauses
Qdrant allows you to combine conditions in clauses. Clauses are different logical operations, such as `OR`, `AND`, and `NOT`. Clauses can be recursively nested into each other so that you can reproduce an arbitrary boolean expression.
Let’s take a look at the clauses implemented in Qdrant.
Suppose we have a set of points with the following payload:
```
[
  { "id": 1, "city": "London", "color": "green" },
  { "id": 2, "city": "London", "color": "red" },
  { "id": 3, "city": "London", "color": "blue" },
  { "id": 4, "city": "Berlin", "color": "red" },
  { "id": 5, "city": "Moscow", "color": "green" },
  { "id": 6, "city": "Moscow", "color": "blue" }
]

```
###  [](https://qdrant.tech/documentation/concepts/filtering/#must)Must
Example:
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/scroll
{
    "filter": {
        "must": [
            { "key": "city", "match": { "value": "London" } },
            { "key": "color", "match": { "value": "red" } }
        ]
    }
    ...
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.scroll(
    collection_name="{collection_name}",
    scroll_filter=models.Filter(
        must=[
            models.FieldCondition(
                key="city",
                match=models.MatchValue(value="London"),
            ),
            models.FieldCondition(
                key="color",
                match=models.MatchValue(value="red"),
            ),
        ]
    ),
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.scroll("{collection_name}", {
  filter: {
    must: [
      {
        key: "city",
        match: { value: "London" },
      },
      {
        key: "color",
        match: { value: "red" },
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,ScrollPointsBuilder};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.scroll(ScrollPointsBuilder::new("{collection_name}").filter(Filter::must([Condition::matches("city","london".to_string()),Condition::matches("color","red".to_string()),])),).await?;
```
```
importjava.util.List;import staticio.qdrant.client.ConditionFactory.matchKeyword;importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.ScrollPoints;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.scrollAsync(ScrollPoints.newBuilder().setCollectionName("{collection_name}").setFilter(Filter.newBuilder().addAllMust(List.of(matchKeyword("city","London"),matchKeyword("color","red"))).build()).build()).get();
```
```
using Qdrant.Client;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
// & operator combines two conditions in an AND conjunction(must)
await client.ScrollAsync(
	collectionName: "{collection_name}",
	filter: MatchKeyword("city", "London") & MatchKeyword("color", "red")
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Scroll(context.Background(), &qdrant.ScrollPoints{
	CollectionName: "{collection_name}",
	Filter: &qdrant.Filter{
		Must: []*qdrant.Condition{
			qdrant.NewMatch("city", "London"),
			qdrant.NewMatch("color", "red"),
		},
	},
})

```
Filtered points would be:
```
[{ "id": 2, "city": "London", "color": "red" }]

```
When using `must`, the clause becomes `true` only if every condition listed inside `must` is satisfied. In this sense, `must` is equivalent to the operator `AND`.
###  [](https://qdrant.tech/documentation/concepts/filtering/#should)Should
Example:
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/scroll
{
    "filter": {
        "should": [
            { "key": "city", "match": { "value": "London" } },
            { "key": "color", "match": { "value": "red" } }
        ]
    }
}

```
```
client.scroll(
    collection_name="{collection_name}",
    scroll_filter=models.Filter(
        should=[
            models.FieldCondition(
                key="city",
                match=models.MatchValue(value="London"),
            ),
            models.FieldCondition(
                key="color",
                match=models.MatchValue(value="red"),
            ),
        ]
    ),
)

```
```
client.scroll("{collection_name}", {
  filter: {
    should: [
      {
        key: "city",
        match: { value: "London" },
      },
      {
        key: "color",
        match: { value: "red" },
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,ScrollPointsBuilder};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.scroll(ScrollPointsBuilder::new("{collection_name}").filter(Filter::should([Condition::matches("city","london".to_string()),Condition::matches("color","red".to_string()),])),).await?;
```
```
import staticio.qdrant.client.ConditionFactory.matchKeyword;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.ScrollPoints;importjava.util.List;client.scrollAsync(ScrollPoints.newBuilder().setCollectionName("{collection_name}").setFilter(Filter.newBuilder().addAllShould(List.of(matchKeyword("city","London"),matchKeyword("color","red"))).build()).build()).get();
```
```
using Qdrant.Client;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
// | operator combines two conditions in an OR disjunction(should)
await client.ScrollAsync(
	collectionName: "{collection_name}",
	filter: MatchKeyword("city", "London") | MatchKeyword("color", "red")
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Scroll(context.Background(), &qdrant.ScrollPoints{
	CollectionName: "{collection_name}",
	Filter: &qdrant.Filter{
		Should: []*qdrant.Condition{
			qdrant.NewMatch("city", "London"),
			qdrant.NewMatch("color", "red"),
		},
	},
})

```
```
[
  { "id": 1, "city": "London", "color": "green" },
  { "id": 2, "city": "London", "color": "red" },
  { "id": 3, "city": "London", "color": "blue" },
  { "id": 4, "city": "Berlin", "color": "red" }
]

```
When using `should`, the clause becomes `true` if at least one condition listed inside `should` is satisfied. In this sense, `should` is equivalent to the operator `OR`.
###  [](https://qdrant.tech/documentation/concepts/filtering/#must-not)Must Not
Example:
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/scroll
{
    "filter": {
        "must_not": [
            { "key": "city", "match": { "value": "London" } },
            { "key": "color", "match": { "value": "red" } }
        ]
    }
}

```
```
client.scroll(
    collection_name="{collection_name}",
    scroll_filter=models.Filter(
        must_not=[
            models.FieldCondition(key="city", match=models.MatchValue(value="London")),
            models.FieldCondition(key="color", match=models.MatchValue(value="red")),
        ]
    ),
)

```
```
client.scroll("{collection_name}", {
  filter: {
    must_not: [
      {
        key: "city",
        match: { value: "London" },
      },
      {
        key: "color",
        match: { value: "red" },
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,ScrollPointsBuilder};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.scroll(ScrollPointsBuilder::new("{collection_name}").filter(Filter::must_not([Condition::matches("city","london".to_string()),Condition::matches("color","red".to_string()),])),).await?;
```
```
importjava.util.List;import staticio.qdrant.client.ConditionFactory.matchKeyword;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.ScrollPoints;client.scrollAsync(ScrollPoints.newBuilder().setCollectionName("{collection_name}").setFilter(Filter.newBuilder().addAllMustNot(List.of(matchKeyword("city","London"),matchKeyword("color","red"))).build()).build()).get();
```
```
using Qdrant.Client;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
// The ! operator negates the condition(must not)
await client.ScrollAsync(
	collectionName: "{collection_name}",
	filter: !(MatchKeyword("city", "London") & MatchKeyword("color", "red"))
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Scroll(context.Background(), &qdrant.ScrollPoints{
	CollectionName: "{collection_name}",
	Filter: &qdrant.Filter{
		MustNot: []*qdrant.Condition{
			qdrant.NewMatch("city", "London"),
			qdrant.NewMatch("color", "red"),
		},
	},
})

```
```
[
  { "id": 5, "city": "Moscow", "color": "green" },
  { "id": 6, "city": "Moscow", "color": "blue" }
]

```
When using `must_not`, the clause becomes `true` if none of the conditions listed inside `should` is satisfied. In this sense, `must_not` is equivalent to the expression `(NOT A) AND (NOT B) AND (NOT C)`.
###  [](https://qdrant.tech/documentation/concepts/filtering/#clauses-combination)Clauses combination
It is also possible to use several clauses simultaneously:
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/scroll
{
    "filter": {
        "must": [
            { "key": "city", "match": { "value": "London" } }
        ],
        "must_not": [
            { "key": "color", "match": { "value": "red" } }
        ]
    }
}

```
```
client.scroll(
    collection_name="{collection_name}",
    scroll_filter=models.Filter(
        must=[
            models.FieldCondition(key="city", match=models.MatchValue(value="London")),
        ],
        must_not=[
            models.FieldCondition(key="color", match=models.MatchValue(value="red")),
        ],
    ),
)

```
```
client.scroll("{collection_name}", {
  filter: {
    must: [
      {
        key: "city",
        match: { value: "London" },
      },
    ],
    must_not: [
      {
        key: "color",
        match: { value: "red" },
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,ScrollPointsBuilder};client.scroll(ScrollPointsBuilder::new("{collection_name}").filter(Filter{must: vec![Condition::matches("city","London".to_string())],must_not: vec![Condition::matches("color","red".to_string())],..Default::default()}),).await?;
```
```
import staticio.qdrant.client.ConditionFactory.matchKeyword;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.ScrollPoints;client.scrollAsync(ScrollPoints.newBuilder().setCollectionName("{collection_name}").setFilter(Filter.newBuilder().addMust(matchKeyword("city","London")).addMustNot(matchKeyword("color","red")).build()).build()).get();
```
```
using Qdrant.Client;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.ScrollAsync(
	collectionName: "{collection_name}",
	filter: MatchKeyword("city", "London") & !MatchKeyword("color", "red")
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Scroll(context.Background(), &qdrant.ScrollPoints{
	CollectionName: "{collection_name}",
	Filter: &qdrant.Filter{
		Must: []*qdrant.Condition{
			qdrant.NewMatch("city", "London"),
		},
		MustNot: []*qdrant.Condition{
			qdrant.NewMatch("color", "red"),
		},
	},
})

```
```
[
  { "id": 1, "city": "London", "color": "green" },
  { "id": 3, "city": "London", "color": "blue" }
]

```
In this case, the conditions are combined by `AND`.
Also, the conditions could be recursively nested. Example:
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/scroll
{
    "filter": {
        "must_not": [
            {
                "must": [
                    { "key": "city", "match": { "value": "London" } },
                    { "key": "color", "match": { "value": "red" } }
                ]
            }
        ]
    }
}

```
```
client.scroll(
    collection_name="{collection_name}",
    scroll_filter=models.Filter(
        must_not=[
            models.Filter(
                must=[
                    models.FieldCondition(
                        key="city", match=models.MatchValue(value="London")
                    ),
                    models.FieldCondition(
                        key="color", match=models.MatchValue(value="red")
                    ),
                ],
            ),
        ],
    ),
)

```
```
client.scroll("{collection_name}", {
  filter: {
    must_not: [
      {
        must: [
          {
            key: "city",
            match: { value: "London" },
          },
          {
            key: "color",
            match: { value: "red" },
          },
        ],
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,ScrollPointsBuilder};client.scroll(ScrollPointsBuilder::new("{collection_name}").filter(Filter::must_not([Filter::must([Condition::matches("city","London".to_string()),Condition::matches("color","red".to_string()),],).into()])),).await?;
```
```
importjava.util.List;import staticio.qdrant.client.ConditionFactory.filter;import staticio.qdrant.client.ConditionFactory.matchKeyword;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.ScrollPoints;client.scrollAsync(ScrollPoints.newBuilder().setCollectionName("{collection_name}").setFilter(Filter.newBuilder().addMustNot(filter(Filter.newBuilder().addAllMust(List.of(matchKeyword("city","London"),matchKeyword("color","red"))).build())).build()).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.ScrollAsync(
	collectionName: "{collection_name}",
	filter: new Filter { MustNot = { MatchKeyword("city", "London") & MatchKeyword("color", "red") } }
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Scroll(context.Background(), &qdrant.ScrollPoints{
	CollectionName: "{collection_name}",
	Filter: &qdrant.Filter{
		MustNot: []*qdrant.Condition{
			qdrant.NewFilterAsCondition(&qdrant.Filter{
				Must: []*qdrant.Condition{
					qdrant.NewMatch("city", "London"),
					qdrant.NewMatch("color", "red"),
				},
			}),
		},
	},
})

```
```
[
  { "id": 1, "city": "London", "color": "green" },
  { "id": 3, "city": "London", "color": "blue" },
  { "id": 4, "city": "Berlin", "color": "red" },
  { "id": 5, "city": "Moscow", "color": "green" },
  { "id": 6, "city": "Moscow", "color": "blue" }
]

```
##  [](https://qdrant.tech/documentation/concepts/filtering/#filtering-conditions)Filtering conditions
Different types of values in payload correspond to different kinds of queries that we can apply to them. Let’s look at the existing condition variants and what types of data they apply to.
###  [](https://qdrant.tech/documentation/concepts/filtering/#match)Match
jsonpythontypescriptrustjavacsharpgo
```
{
  "key": "color",
  "match": {
    "value": "red"
  }
}

```
```
models.FieldCondition(
    key="color",
    match=models.MatchValue(value="red"),
)

```
```
{
    key: 'color', 
    match: {value: 'red'}
}

```
```
Condition::matches("color","red".to_string())
```
```
matchKeyword("color","red");
```
```
using static Qdrant.Client.Grpc.Conditions;
MatchKeyword("color", "red");

```
```
import "github.com/qdrant/go-client/qdrant"
qdrant.NewMatch("color", "red")

```
For the other types, the match condition will look exactly the same, except for the type used:
jsonpythontypescriptrustjavacsharpgo
```
{
  "key": "count",
  "match": {
    "value": 0
  }
}

```
```
models.FieldCondition(
    key="count",
    match=models.MatchValue(value=0),
)

```
```
{
    key: 'count',
    match: {value: 0}    
}

```
```
Condition::matches("count",0)
```
```
import staticio.qdrant.client.ConditionFactory.match;match("count",0);
```
```
using static Qdrant.Client.Grpc.Conditions;
Match("count", 0);

```
```
import "github.com/qdrant/go-client/qdrant"
qdrant.NewMatchInt("count", 0)

```
The simplest kind of condition is one that checks if the stored value equals the given one. If several values are stored, at least one of them should match the condition. You can apply it to [keyword](https://qdrant.tech/documentation/concepts/payload/#keyword), [integer](https://qdrant.tech/documentation/concepts/payload/#integer) and [bool](https://qdrant.tech/documentation/concepts/payload/#bool) payloads.
###  [](https://qdrant.tech/documentation/concepts/filtering/#match-any)Match Any
_Available as of v1.1.0_
In case you want to check if the stored value is one of multiple values, you can use the Match Any condition. Match Any works as a logical OR for the given values. It can also be described as a `IN` operator.
You can apply it to [keyword](https://qdrant.tech/documentation/concepts/payload/#keyword) and [integer](https://qdrant.tech/documentation/concepts/payload/#integer) payloads.
Example:
jsonpythontypescriptrustjavacsharpgo
```
{
  "key": "color",
  "match": {
    "any": ["black", "yellow"]
  }
}

```
```
models.FieldCondition(
    key="color",
    match=models.MatchAny(any=["black", "yellow"]),
)

```
```
{
    key: 'color',
    match: {any: ['black', 'yellow']}    
}

```
```
Condition::matches("color",vec!["black".to_string(),"yellow".to_string()])
```
```
import staticio.qdrant.client.ConditionFactory.matchKeywords;matchKeywords("color",List.of("black","yellow"));
```
```
using static Qdrant.Client.Grpc.Conditions;
Match("color", ["black", "yellow"]);

```
```
import "github.com/qdrant/go-client/qdrant"
qdrant.NewMatchKeywords("color", "black", "yellow")

```
In this example, the condition will be satisfied if the stored value is either `black` or `yellow`.
If the stored value is an array, it should have at least one value matching any of the given values. E.g. if the stored value is `["black", "green"]`, the condition will be satisfied, because `"black"` is in `["black", "yellow"]`.
###  [](https://qdrant.tech/documentation/concepts/filtering/#match-except)Match Except
_Available as of v1.2.0_
In case you want to check if the stored value is not one of multiple values, you can use the Match Except condition. Match Except works as a logical NOR for the given values. It can also be described as a `NOT IN` operator.
You can apply it to [keyword](https://qdrant.tech/documentation/concepts/payload/#keyword) and [integer](https://qdrant.tech/documentation/concepts/payload/#integer) payloads.
Example:
jsonpythontypescriptrustjavacsharpgo
```
{
  "key": "color",
  "match": {
    "except": ["black", "yellow"]
  }
}

```
```
models.FieldCondition(
    key="color",
    match=models.MatchExcept(**{"except": ["black", "yellow"]}),
)

```
```
{
    key: 'color',
    match: {except: ['black', 'yellow']}
}

```
```
useqdrant_client::qdrant::r#match::MatchValue;Condition::matches("color",!MatchValue::from(vec!["black".to_string(),"yellow".to_string()]),)
```
```
import staticio.qdrant.client.ConditionFactory.matchExceptKeywords;matchExceptKeywords("color",List.of("black","yellow"));
```
```
import "github.com/qdrant/go-client/qdrant"
qdrant.NewMatchExcept("color", "black", "yellow")

```
In this example, the condition will be satisfied if the stored value is neither `black` nor `yellow`.
If the stored value is an array, it should have at least one value not matching any of the given values. E.g. if the stored value is `["black", "green"]`, the condition will be satisfied, because `"green"` does not match `"black"` nor `"yellow"`.
###  [](https://qdrant.tech/documentation/concepts/filtering/#nested-key)Nested key
_Available as of v1.1.0_
Payloads being arbitrary JSON object, it is likely that you will need to filter on a nested field.
For convenience, we use a syntax similar to what can be found in the 
Suppose we have a set of points with the following payload:
```
[
  {
    "id": 1,
    "country": {
      "name": "Germany",
      "cities": [
        {
          "name": "Berlin",
          "population": 3.7,
          "sightseeing": ["Brandenburg Gate", "Reichstag"]
        },
        {
          "name": "Munich",
          "population": 1.5,
          "sightseeing": ["Marienplatz", "Olympiapark"]
        }
      ]
    }
  },
  {
    "id": 2,
    "country": {
      "name": "Japan",
      "cities": [
        {
          "name": "Tokyo",
          "population": 9.3,
          "sightseeing": ["Tokyo Tower", "Tokyo Skytree"]
        },
        {
          "name": "Osaka",
          "population": 2.7,
          "sightseeing": ["Osaka Castle", "Universal Studios Japan"]
        }
      ]
    }
  }
]

```
You can search on a nested field using a dot notation.
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/scroll
{
    "filter": {
        "should": [
            {
                "key": "country.name",
                "match": {
                    "value": "Germany"
                }
            }
        ]
    }
}

```
```
client.scroll(
    collection_name="{collection_name}",
    scroll_filter=models.Filter(
        should=[
            models.FieldCondition(
                key="country.name", match=models.MatchValue(value="Germany")
            ),
        ],
    ),
)

```
```
client.scroll("{collection_name}", {
  filter: {
    should: [
      {
        key: "country.name",
        match: { value: "Germany" },
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,ScrollPointsBuilder};client.scroll(ScrollPointsBuilder::new("{collection_name}").filter(Filter::should([Condition::matches("country.name","Germany".to_string()),])),).await?;
```
```
import staticio.qdrant.client.ConditionFactory.matchKeyword;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.ScrollPoints;client.scrollAsync(ScrollPoints.newBuilder().setCollectionName("{collection_name}").setFilter(Filter.newBuilder().addShould(matchKeyword("country.name","Germany")).build()).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.ScrollAsync(collectionName: "{collection_name}", filter: MatchKeyword("country.name", "Germany"));

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Scroll(context.Background(), &qdrant.ScrollPoints{
	CollectionName: "{collection_name}",
	Filter: &qdrant.Filter{
		Should: []*qdrant.Condition{
			qdrant.NewMatch("country.name", "Germany"),
		},
	},
})

```
You can also search through arrays by projecting inner values using the `[]` syntax.
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/scroll
{
    "filter": {
        "should": [
            {
                "key": "country.cities[].population",
                "range": {
                    "gte": 9.0,
                }
            }
        ]
    }
}

```
```
client.scroll(
    collection_name="{collection_name}",
    scroll_filter=models.Filter(
        should=[
            models.FieldCondition(
                key="country.cities[].population",
                range=models.Range(
                    gt=None,
                    gte=9.0,
                    lt=None,
                    lte=None,
                ),
            ),
        ],
    ),
)

```
```
client.scroll("{collection_name}", {
  filter: {
    should: [
      {
        key: "country.cities[].population",
        range: {
          gt: null,
          gte: 9.0,
          lt: null,
          lte: null,
        },
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,Range,ScrollPointsBuilder};client.scroll(ScrollPointsBuilder::new("{collection_name}").filter(Filter::should([Condition::range("country.cities[].population",Range{gte: Some(9.0),..Default::default()},),])),).await?;
```
```
import staticio.qdrant.client.ConditionFactory.range;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.Range;importio.qdrant.client.grpc.Points.ScrollPoints;client.scrollAsync(ScrollPoints.newBuilder().setCollectionName("{collection_name}").setFilter(Filter.newBuilder().addShould(range("country.cities[].population",Range.newBuilder().setGte(9.0).build())).build()).build()).get();
```
```
using Qdrant.Client;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.ScrollAsync(
	collectionName: "{collection_name}",
	filter: Range("country.cities[].population", new Qdrant.Client.Grpc.Range { Gte = 9.0 })
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Scroll(context.Background(), &qdrant.ScrollPoints{
	CollectionName: "{collection_name}",
	Filter: &qdrant.Filter{
		Should: []*qdrant.Condition{
			qdrant.NewRange("country.cities[].population", &qdrant.Range{
				Gte: qdrant.PtrOf(9.0),
			}),
		},
	},
})

```
This query would only output the point with id 2 as only Japan has a city with population greater than 9.0.
And the leaf nested field can also be an array.
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/scroll
{
    "filter": {
        "should": [
            {
                "key": "country.cities[].sightseeing",
                "match": {
                    "value": "Osaka Castle"
                }
            }
        ]
    }
}

```
```
client.scroll(
    collection_name="{collection_name}",
    scroll_filter=models.Filter(
        should=[
            models.FieldCondition(
                key="country.cities[].sightseeing",
                match=models.MatchValue(value="Osaka Castle"),
            ),
        ],
    ),
)

```
```
client.scroll("{collection_name}", {
  filter: {
    should: [
      {
        key: "country.cities[].sightseeing",
        match: { value: "Osaka Castle" },
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,ScrollPointsBuilder};client.scroll(ScrollPointsBuilder::new("{collection_name}").filter(Filter::should([Condition::matches("country.cities[].sightseeing","Osaka Castle".to_string()),])),).await?;
```
```
import staticio.qdrant.client.ConditionFactory.matchKeyword;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.ScrollPoints;client.scrollAsync(ScrollPoints.newBuilder().setCollectionName("{collection_name}").setFilter(Filter.newBuilder().addShould(matchKeyword("country.cities[].sightseeing","Germany")).build()).build()).get();
```
```
using Qdrant.Client;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.ScrollAsync(
	collectionName: "{collection_name}",
	filter: MatchKeyword("country.cities[].sightseeing", "Germany")
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Scroll(context.Background(), &qdrant.ScrollPoints{
	CollectionName: "{collection_name}",
	Filter: &qdrant.Filter{
		Should: []*qdrant.Condition{
			qdrant.NewMatch("country.cities[].sightseeing", "Germany"),
		},
	},
})

```
This query would only output the point with id 2 as only Japan has a city with the “Osaka castke” as part of the sightseeing.
###  [](https://qdrant.tech/documentation/concepts/filtering/#nested-object-filter)Nested object filter
_Available as of v1.2.0_
By default, the conditions are taking into account the entire payload of a point.
For instance, given two points with the following payload:
The following query would match both points:
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/scroll
{
    "filter": {
        "must": [
            {
                "key": "diet[].food",
                  "match": {
                    "value": "meat"
                }
            },
            {
                "key": "diet[].likes",
                  "match": {
                    "value": true
                }
            }
        ]
    }
}

```
```
client.scroll(
    collection_name="{collection_name}",
    scroll_filter=models.Filter(
        must=[
            models.FieldCondition(
                key="diet[].food", match=models.MatchValue(value="meat")
            ),
            models.FieldCondition(
                key="diet[].likes", match=models.MatchValue(value=True)
            ),
        ],
    ),
)

```
```
client.scroll("{collection_name}", {
  filter: {
    must: [
      {
        key: "diet[].food",
        match: { value: "meat" },
      },
      {
        key: "diet[].likes",
        match: { value: true },
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,ScrollPointsBuilder};client.scroll(ScrollPointsBuilder::new("{collection_name}").filter(Filter::must([Condition::matches("diet[].food","meat".to_string()),Condition::matches("diet[].likes",true),])),).await?;
```
```
importjava.util.List;import staticio.qdrant.client.ConditionFactory.match;import staticio.qdrant.client.ConditionFactory.matchKeyword;importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.ScrollPoints;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.scrollAsync(ScrollPoints.newBuilder().setCollectionName("{collection_name}").setFilter(Filter.newBuilder().addAllMust(List.of(matchKeyword("diet[].food","meat"),match("diet[].likes",true))).build()).build()).get();
```
```
using Qdrant.Client;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.ScrollAsync(
	collectionName: "{collection_name}",
	filter: MatchKeyword("diet[].food", "meat") & Match("diet[].likes", true)
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Scroll(context.Background(), &qdrant.ScrollPoints{
	CollectionName: "{collection_name}",
	Filter: &qdrant.Filter{
		Must: []*qdrant.Condition{
			qdrant.NewMatch("diet[].food", "meat"),
			qdrant.NewMatchBool("diet[].likes", true),
		},
	},
})

```
To retrieve only the points which are matching the conditions on an array element basis, that is the point with id 1 in this example, you would need to use a nested object filter.
Nested object filters allow arrays of objects to be queried independently of each other.
It is achieved by using the `nested` condition type formed by a payload key to focus on and a filter to apply.
The key should point to an array of objects and can be used with or without the bracket notation (“data” or “data[]”).
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/scroll
{
    "filter": {
        "must": [{
            "nested": {
                "key": "diet",
                "filter":{
                    "must": [
                        {
                            "key": "food",
                            "match": {
                                "value": "meat"
                            }
                        },
                        {
                            "key": "likes",
                            "match": {
                                "value": true
                            }
                        }
                    ]
                }
            }
        }]
    }
}

```
```
client.scroll(
    collection_name="{collection_name}",
    scroll_filter=models.Filter(
        must=[
            models.NestedCondition(
                nested=models.Nested(
                    key="diet",
                    filter=models.Filter(
                        must=[
                            models.FieldCondition(
                                key="food", match=models.MatchValue(value="meat")
                            ),
                            models.FieldCondition(
                                key="likes", match=models.MatchValue(value=True)
                            ),
                        ]
                    ),
                )
            )
        ],
    ),
)

```
```
client.scroll("{collection_name}", {
  filter: {
    must: [
      {
        nested: {
          key: "diet",
          filter: {
            must: [
              {
                key: "food",
                match: { value: "meat" },
              },
              {
                key: "likes",
                match: { value: true },
              },
            ],
          },
        },
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,NestedCondition,ScrollPointsBuilder};client.scroll(ScrollPointsBuilder::new("{collection_name}").filter(Filter::must([NestedCondition{key: "diet".to_string(),filter: Some(Filter::must([Condition::matches("food","meat".to_string()),Condition::matches("likes",true),])),}.into()])),).await?;
```
```
importjava.util.List;import staticio.qdrant.client.ConditionFactory.match;import staticio.qdrant.client.ConditionFactory.matchKeyword;import staticio.qdrant.client.ConditionFactory.nested;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.ScrollPoints;client.scrollAsync(ScrollPoints.newBuilder().setCollectionName("{collection_name}").setFilter(Filter.newBuilder().addMust(nested("diet",Filter.newBuilder().addAllMust(List.of(matchKeyword("food","meat"),match("likes",true))).build())).build()).build()).get();
```
```
using Qdrant.Client;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.ScrollAsync(
	collectionName: "{collection_name}",
	filter: Nested("diet", MatchKeyword("food", "meat") & Match("likes", true))
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Scroll(context.Background(), &qdrant.ScrollPoints{
	CollectionName: "{collection_name}",
	Filter: &qdrant.Filter{
		Must: []*qdrant.Condition{
			qdrant.NewNestedFilter("diet", &qdrant.Filter{
				Must: []*qdrant.Condition{
					qdrant.NewMatch("food", "meat"),
					qdrant.NewMatchBool("likes", true),
				},
			}),
		},
	},
})

```
The matching logic is modified to be applied at the level of an array element within the payload.
Nested filters work in the same way as if the nested filter was applied to a single element of the array at a time. Parent document is considered to match the condition if at least one element of the array matches the nested filter.
**Limitations**
The `has_id` condition is not supported within the nested object filter. If you need it, place it in an adjacent `must` clause.
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/scroll
{
   "filter":{
      "must":[
         {
            "nested":{
               "key":"diet",
               "filter":{
                  "must":[
                     {
                        "key":"food",
                        "match":{
                           "value":"meat"
                        }
                     },
                     {
                        "key":"likes",
                        "match":{
                           "value":true
                        }
                     }
                  ]
               }
            }
         },
         {
            "has_id":[
               1
            ]
         }
      ]
   }
}

```
```
client.scroll(
    collection_name="{collection_name}",
    scroll_filter=models.Filter(
        must=[
            models.NestedCondition(
                nested=models.Nested(
                    key="diet",
                    filter=models.Filter(
                        must=[
                            models.FieldCondition(
                                key="food", match=models.MatchValue(value="meat")
                            ),
                            models.FieldCondition(
                                key="likes", match=models.MatchValue(value=True)
                            ),
                        ]
                    ),
                )
            ),
            models.HasIdCondition(has_id=[1]),
        ],
    ),
)

```
```
client.scroll("{collection_name}", {
  filter: {
    must: [
      {
        nested: {
          key: "diet",
          filter: {
            must: [
              {
                key: "food",
                match: { value: "meat" },
              },
              {
                key: "likes",
                match: { value: true },
              },
            ],
          },
        },
      },
      {
        has_id: [1],
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,NestedCondition,ScrollPointsBuilder};client.scroll(ScrollPointsBuilder::new("{collection_name}").filter(Filter::must([NestedCondition{key: "diet".to_string(),filter: Some(Filter::must([Condition::matches("food","meat".to_string()),Condition::matches("likes",true),])),}.into(),Condition::has_id([1]),])),).await?;
```
```
importjava.util.List;import staticio.qdrant.client.ConditionFactory.hasId;import staticio.qdrant.client.ConditionFactory.match;import staticio.qdrant.client.ConditionFactory.matchKeyword;import staticio.qdrant.client.ConditionFactory.nested;import staticio.qdrant.client.PointIdFactory.id;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.ScrollPoints;client.scrollAsync(ScrollPoints.newBuilder().setCollectionName("{collection_name}").setFilter(Filter.newBuilder().addMust(nested("diet",Filter.newBuilder().addAllMust(List.of(matchKeyword("food","meat"),match("likes",true))).build())).addMust(hasId(id(1))).build()).build()).get();
```
```
using Qdrant.Client;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.ScrollAsync(
	collectionName: "{collection_name}",
	filter: Nested("diet", MatchKeyword("food", "meat") & Match("likes", true)) & HasId(1)
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Scroll(context.Background(), &qdrant.ScrollPoints{
	CollectionName: "{collection_name}",
	Filter: &qdrant.Filter{
		Must: []*qdrant.Condition{
			qdrant.NewNestedFilter("diet", &qdrant.Filter{
				Must: []*qdrant.Condition{
					qdrant.NewMatch("food", "meat"),
					qdrant.NewMatchBool("likes", true),
				},
			}),
			qdrant.NewHasID(qdrant.NewIDNum(1)),
		},
	},
})

```
###  [](https://qdrant.tech/documentation/concepts/filtering/#full-text-match)Full Text Match
_Available as of v0.10.0_
A special case of the `match` condition is the `text` match condition. It allows you to search for a specific substring, token or phrase within the text field.
Exact texts that will match the condition depend on full-text index configuration. Configuration is defined during the index creation and describe at [full-text index](https://qdrant.tech/documentation/concepts/indexing/#full-text-index).
If there is no full-text index for the field, the condition will work as exact substring match.
jsonpythontypescriptrustjavacsharpgo
```
{
  "key": "description",
  "match": {
    "text": "good cheap"
  }
}

```
```
models.FieldCondition(
    key="description",
    match=models.MatchText(text="good cheap"),
)

```
```
{
    key: 'description',
    match: {text: 'good cheap'}    
}

```
```
useqdrant_client::qdrant::Condition;Condition::matches_text("description","good cheap")
```
```
import staticio.qdrant.client.ConditionFactory.matchText;matchText("description","good cheap");
```
```
using static Qdrant.Client.Grpc.Conditions;
MatchText("description", "good cheap");

```
```
import "github.com/qdrant/go-client/qdrant"
qdrant.NewMatchText("description", "good cheap")

```
If the query has several words, then the condition will be satisfied only if all of them are present in the text.
###  [](https://qdrant.tech/documentation/concepts/filtering/#range)Range
jsonpythontypescriptrustjavacsharpgo
```
{
  "key": "price",
  "range": {
    "gt": null,
    "gte": 100.0,
    "lt": null,
    "lte": 450.0
  }
}

```
```
models.FieldCondition(
    key="price",
    range=models.Range(
        gt=None,
        gte=100.0,
        lt=None,
        lte=450.0,
    ),
)

```
```
{
    key: 'price',
    range: {
        gt: null,
        gte: 100.0,
        lt: null,
        lte: 450.0    
    }    
}

```
```
useqdrant_client::qdrant::{Condition,Range};Condition::range("price",Range{gt: None,gte: Some(100.0),lt: None,lte: Some(450.0),},)
```
```
import staticio.qdrant.client.ConditionFactory.range;importio.qdrant.client.grpc.Points.Range;range("price",Range.newBuilder().setGte(100.0).setLte(450).build());
```
```
using static Qdrant.Client.Grpc.Conditions;
Range("price", new Qdrant.Client.Grpc.Range { Gte = 100.0, Lte = 450 });

```
```
import "github.com/qdrant/go-client/qdrant"
qdrant.NewRange("price", &qdrant.Range{
	Gte: qdrant.PtrOf(100.0),
	Lte: qdrant.PtrOf(450.0),
})

```
The `range` condition sets the range of possible values for stored payload values. If several values are stored, at least one of them should match the condition.
Comparisons that can be used:
  * `gt` - greater than
  * `gte` - greater than or equal
  * `lt` - less than
  * `lte` - less than or equal
Can be applied to [float](https://qdrant.tech/documentation/concepts/payload/#float) and [integer](https://qdrant.tech/documentation/concepts/payload/#integer) payloads.
###  [](https://qdrant.tech/documentation/concepts/filtering/#datetime-range)Datetime Range
The datetime range is a unique range condition, used for [datetime](https://qdrant.tech/documentation/concepts/payload/#datetime) payloads, which supports RFC 3339 formats. You do not need to convert dates to UNIX timestaps. During comparison, timestamps are parsed and converted to UTC.
_Available as of v1.8.0_
jsonpythontypescriptrustjavacsharpgo
```
{
  "key": "date",
  "range": {
    "gt": "2023-02-08T10:49:00Z",
    "gte": null,
    "lt": null,
    "lte": "2024-01-31 10:14:31Z"
  }
}

```
```
models.FieldCondition(
    key="date",
    range=models.DatetimeRange(
        gt="2023-02-08T10:49:00Z",
        gte=None,
        lt=None,
        lte="2024-01-31T10:14:31Z",
    ),
)

```
```
{
    key: 'date',
    range: {
        gt: '2023-02-08T10:49:00Z',
        gte: null,
        lt: null,
        lte: '2024-01-31T10:14:31Z'
    }
}

```
```
useqdrant_client::qdrant::{Condition,DatetimeRange,Timestamp};Condition::datetime_range("date",DatetimeRange{gt: Some(Timestamp::date_time(2023,2,8,10,49,0).unwrap()),gte: None,lt: None,lte: Some(Timestamp::date_time(2024,1,31,10,14,31).unwrap()),},)
```
```
import staticio.qdrant.client.ConditionFactory.datetimeRange;importcom.google.protobuf.Timestamp;importio.qdrant.client.grpc.Points.DatetimeRange;importjava.time.Instant;longgt=Instant.parse("2023-02-08T10:49:00Z").getEpochSecond();longlte=Instant.parse("2024-01-31T10:14:31Z").getEpochSecond();datetimeRange("date",DatetimeRange.newBuilder().setGt(Timestamp.newBuilder().setSeconds(gt)).setLte(Timestamp.newBuilder().setSeconds(lte)).build());
```
```
using Qdrant.Client.Grpc;
Conditions.DatetimeRange(
    field: "date",
    gt: new DateTime(2023, 2, 8, 10, 49, 0, DateTimeKind.Utc),
    lte: new DateTime(2024, 1, 31, 10, 14, 31, DateTimeKind.Utc)
);

```
```
import (
	"time"
	"github.com/qdrant/go-client/qdrant"
	"google.golang.org/protobuf/types/known/timestamppb"
)
qdrant.NewDatetimeRange("date", &qdrant.DatetimeRange{
	Gt:  timestamppb.New(time.Date(2023, 2, 8, 10, 49, 0, 0, time.UTC)),
	Lte: timestamppb.New(time.Date(2024, 1, 31, 10, 14, 31, 0, time.UTC)),
})

```
###  [](https://qdrant.tech/documentation/concepts/filtering/#uuid-match)UUID Match
_Available as of v1.11.0_
Matching of UUID values works similarly to the regular `match` condition for strings. Functionally, it will work with `keyword` and `uuid` indexes exactly the same, but `uuid` index is more memory efficient.
jsonpythontypescriptrustjavacsharpgo
```
{
  "key": "uuid",
  "match": {
    "value": "f47ac10b-58cc-4372-a567-0e02b2c3d479"
  }
}

```
```
models.FieldCondition(
    key="uuid",
    match=models.MatchValue(value="f47ac10b-58cc-4372-a567-0e02b2c3d479"),
)

```
```
{
    key: 'uuid',
    match: {value: 'f47ac10b-58cc-4372-a567-0e02b2c3d479'}    
}

```
```
Condition::matches("uuid","f47ac10b-58cc-4372-a567-0e02b2c3d479".to_string())
```
```
matchKeyword("uuid","f47ac10b-58cc-4372-a567-0e02b2c3d479");
```
```
using static Qdrant.Client.Grpc.Conditions;
MatchKeyword("uuid", "f47ac10b-58cc-4372-a567-0e02b2c3d479");

```
```
import "github.com/qdrant/go-client/qdrant"
qdrant.NewMatch("uuid", "f47ac10b-58cc-4372-a567-0e02b2c3d479")

```
###  [](https://qdrant.tech/documentation/concepts/filtering/#geo)Geo
####  [](https://qdrant.tech/documentation/concepts/filtering/#geo-bounding-box)Geo Bounding Box
jsonpythontypescriptrustjavacsharpgo
```
{
  "key": "location",
  "geo_bounding_box": {
    "bottom_right": {
      "lon": 13.455868,
      "lat": 52.495862
    },
    "top_left": {
      "lon": 13.403683,
      "lat": 52.520711
    }
  }
}

```
```
models.FieldCondition(
    key="location",
    geo_bounding_box=models.GeoBoundingBox(
        bottom_right=models.GeoPoint(
            lon=13.455868,
            lat=52.495862,
        ),
        top_left=models.GeoPoint(
            lon=13.403683,
            lat=52.520711,
        ),
    ),
)

```
```
{
    key: 'location',
    geo_bounding_box: {
        bottom_right: {
            lon: 13.455868,
            lat: 52.495862
        },
        top_left: {
            lon: 13.403683,
            lat: 52.520711
        }
    }
}

```
```
useqdrant_client::qdrant::{Condition,GeoBoundingBox,GeoPoint};Condition::geo_bounding_box("location",GeoBoundingBox{bottom_right: Some(GeoPoint{lon: 13.455868,lat: 52.495862,}),top_left: Some(GeoPoint{lon: 13.403683,lat: 52.520711,}),},)
```
```
import staticio.qdrant.client.ConditionFactory.geoBoundingBox;geoBoundingBox("location",52.520711,13.403683,52.495862,13.455868);
```
```
using static Qdrant.Client.Grpc.Conditions;
GeoBoundingBox("location", 52.520711, 13.403683, 52.495862, 13.455868);

```
```
import "github.com/qdrant/go-client/qdrant"
qdrant.NewGeoBoundingBox("location", 52.520711, 13.403683, 52.495862, 13.455868)

```
It matches with `location`s inside a rectangle with the coordinates of the upper left corner in `bottom_right` and the coordinates of the lower right corner in `top_left`.
####  [](https://qdrant.tech/documentation/concepts/filtering/#geo-radius)Geo Radius
jsonpythontypescriptrustjavacsharpgo
```
{
  "key": "location",
  "geo_radius": {
    "center": {
      "lon": 13.403683,
      "lat": 52.520711
    },
    "radius": 1000.0
  }
}

```
```
models.FieldCondition(
    key="location",
    geo_radius=models.GeoRadius(
        center=models.GeoPoint(
            lon=13.403683,
            lat=52.520711,
        ),
        radius=1000.0,
    ),
)

```
```
{
    key: 'location',
    geo_radius: {
        center: {
            lon: 13.403683,
            lat: 52.520711
        },
        radius: 1000.0
    }    
}

```
```
useqdrant_client::qdrant::{Condition,GeoPoint,GeoRadius};Condition::geo_radius("location",GeoRadius{center: Some(GeoPoint{lon: 13.403683,lat: 52.520711,}),radius: 1000.0,},)
```
```
import staticio.qdrant.client.ConditionFactory.geoRadius;geoRadius("location",52.520711,13.403683,1000.0f);
```
```
using static Qdrant.Client.Grpc.Conditions;
GeoRadius("location", 52.520711, 13.403683, 1000.0f);

```
```
import "github.com/qdrant/go-client/qdrant"
qdrant.NewGeoRadius("location", 52.520711, 13.403683, 1000.0)

```
It matches with `location`s inside a circle with the `center` at the center and a radius of `radius` meters.
If several values are stored, at least one of them should match the condition. These conditions can only be applied to payloads that match the [geo-data format](https://qdrant.tech/documentation/concepts/payload/#geo).
####  [](https://qdrant.tech/documentation/concepts/filtering/#geo-polygon)Geo Polygon
Geo Polygons search is useful for when you want to find points inside an irregularly shaped area, for example a country boundary or a forest boundary. A polygon always has an exterior ring and may optionally include interior rings. A lake with an island would be an example of an interior ring. If you wanted to find points in the water but not on the island, you would make an interior ring for the island.
When defining a ring, you must pick either a clockwise or counterclockwise ordering for your points. The first and last point of the polygon must be the same.
Currently, we only support unprojected global coordinates (decimal degrees longitude and latitude) and we are datum agnostic.
jsonpythontypescriptrustjavacsharpgo
```
{
  "key": "location",
  "geo_polygon": {
    "exterior": {
      "points": [
        { "lon": -70.0, "lat": -70.0 },
        { "lon": 60.0, "lat": -70.0 },
        { "lon": 60.0, "lat": 60.0 },
        { "lon": -70.0, "lat": 60.0 },
        { "lon": -70.0, "lat": -70.0 }
      ]
    },
    "interiors": [
      {
        "points": [
          { "lon": -65.0, "lat": -65.0 },
          { "lon": 0.0, "lat": -65.0 },
          { "lon": 0.0, "lat": 0.0 },
          { "lon": -65.0, "lat": 0.0 },
          { "lon": -65.0, "lat": -65.0 }
        ]
      }
    ]
  }
}

```
```
models.FieldCondition(
    key="location",
    geo_polygon=models.GeoPolygon(
        exterior=models.GeoLineString(
            points=[
                models.GeoPoint(
                    lon=-70.0,
                    lat=-70.0,
                ),
                models.GeoPoint(
                    lon=60.0,
                    lat=-70.0,
                ),
                models.GeoPoint(
                    lon=60.0,
                    lat=60.0,
                ),
                models.GeoPoint(
                    lon=-70.0,
                    lat=60.0,
                ),
                models.GeoPoint(
                    lon=-70.0,
                    lat=-70.0,
                ),
            ]
        ),
        interiors=[
            models.GeoLineString(
                points=[
                    models.GeoPoint(
                        lon=-65.0,
                        lat=-65.0,
                    ),
                    models.GeoPoint(
                        lon=0.0,
                        lat=-65.0,
                    ),
                    models.GeoPoint(
                        lon=0.0,
                        lat=0.0,
                    ),
                    models.GeoPoint(
                        lon=-65.0,
                        lat=0.0,
                    ),
                    models.GeoPoint(
                        lon=-65.0,
                        lat=-65.0,
                    ),
                ]
            )
        ],
    ),
)

```
```
{
  key: "location",
  geo_polygon: {
    exterior: {
      points: [
        {
          lon: -70.0,
          lat: -70.0
        },
        {
          lon: 60.0,
          lat: -70.0
        },
        {
          lon: 60.0,
          lat: 60.0
        },
        {
          lon: -70.0,
          lat: 60.0
        },
        {
          lon: -70.0,
          lat: -70.0
        }
      ]
    },
    interiors: [
      {
        points: [
          {
            lon: -65.0,
            lat: -65.0
          },
          {
            lon: 0,
            lat: -65.0
          },
          {
            lon: 0,
            lat: 0
          },
          {
            lon: -65.0,
            lat: 0
          },
          {
            lon: -65.0,
            lat: -65.0
          }
        ]
      }
    ]
  }
}

```
```
useqdrant_client::qdrant::{Condition,GeoLineString,GeoPoint,GeoPolygon};Condition::geo_polygon("location",GeoPolygon{exterior: Some(GeoLineString{points: vec![GeoPoint{lon: -70.0,lat: -70.0,},GeoPoint{lon: 60.0,lat: -70.0,},GeoPoint{lon: 60.0,lat: 60.0,},GeoPoint{lon: -70.0,lat: 60.0,},GeoPoint{lon: -70.0,lat: -70.0,},],}),interiors: vec![GeoLineString{points: vec![GeoPoint{lon: -65.0,lat: -65.0,},GeoPoint{lon: 0.0,lat: -65.0,},GeoPoint{lon: 0.0,lat: 0.0},GeoPoint{lon: -65.0,lat: 0.0,},GeoPoint{lon: -65.0,lat: -65.0,},],}],},)
```
```
import staticio.qdrant.client.ConditionFactory.geoPolygon;importio.qdrant.client.grpc.Points.GeoLineString;importio.qdrant.client.grpc.Points.GeoPoint;geoPolygon("location",GeoLineString.newBuilder().addAllPoints(List.of(GeoPoint.newBuilder().setLon(-70.0).setLat(-70.0).build(),GeoPoint.newBuilder().setLon(60.0).setLat(-70.0).build(),GeoPoint.newBuilder().setLon(60.0).setLat(60.0).build(),GeoPoint.newBuilder().setLon(-70.0).setLat(60.0).build(),GeoPoint.newBuilder().setLon(-70.0).setLat(-70.0).build())).build(),List.of(GeoLineString.newBuilder().addAllPoints(List.of(GeoPoint.newBuilder().setLon(-65.0).setLat(-65.0).build(),GeoPoint.newBuilder().setLon(0.0).setLat(-65.0).build(),GeoPoint.newBuilder().setLon(0.0).setLat(0.0).build(),GeoPoint.newBuilder().setLon(-65.0).setLat(0.0).build(),GeoPoint.newBuilder().setLon(-65.0).setLat(-65.0).build())).build()));
```
```
using Qdrant.Client.Grpc;
using static Qdrant.Client.Grpc.Conditions;
GeoPolygon(
	field: "location",
	exterior: new GeoLineString
	{
		Points =
		{
			new GeoPoint { Lat = -70.0, Lon = -70.0 },
			new GeoPoint { Lat = 60.0, Lon = -70.0 },
			new GeoPoint { Lat = 60.0, Lon = 60.0 },
			new GeoPoint { Lat = -70.0, Lon = 60.0 },
			new GeoPoint { Lat = -70.0, Lon = -70.0 }
		}
	},
	interiors: [
		new()
		{
			Points =
			{
				new GeoPoint { Lat = -65.0, Lon = -65.0 },
				new GeoPoint { Lat = 0.0, Lon = -65.0 },
				new GeoPoint { Lat = 0.0, Lon = 0.0 },
				new GeoPoint { Lat = -65.0, Lon = 0.0 },
				new GeoPoint { Lat = -65.0, Lon = -65.0 }
			}
		}
	]
);

```
```
import "github.com/qdrant/go-client/qdrant"
qdrant.NewGeoPolygon("location",
	&qdrant.GeoLineString{
		Points: []*qdrant.GeoPoint{
			{Lat: -70, Lon: -70},
			{Lat: 60, Lon: -70},
			{Lat: 60, Lon: 60},
			{Lat: -70, Lon: 60},
			{Lat: -70, Lon: -70},
		},
	}, &qdrant.GeoLineString{
		Points: []*qdrant.GeoPoint{
			{Lat: -65, Lon: -65},
			{Lat: 0, Lon: -65},
			{Lat: 0, Lon: 0},
			{Lat: -65, Lon: 0},
			{Lat: -65, Lon: -65},
		},
	})

```
A match is considered any point location inside or on the boundaries of the given polygon’s exterior but not inside any interiors.
If several location values are stored for a point, then any of them matching will include that point as a candidate in the resultset. These conditions can only be applied to payloads that match the [geo-data format](https://qdrant.tech/documentation/concepts/payload/#geo).
###  [](https://qdrant.tech/documentation/concepts/filtering/#values-count)Values count
In addition to the direct value comparison, it is also possible to filter by the amount of values.
For example, given the data:
```
[
  { "id": 1, "name": "product A", "comments": ["Very good!", "Excellent"] },
  { "id": 2, "name": "product B", "comments": ["meh", "expected more", "ok"] }
]

```
We can perform the search only among the items with more than two comments:
jsonpythontypescriptrustjavacsharpgo
```
{
  "key": "comments",
  "values_count": {
    "gt": 2
  }
}

```
```
models.FieldCondition(
    key="comments",
    values_count=models.ValuesCount(gt=2),
)

```
```
{
    key: 'comments',
    values_count: {gt: 2}    
}

```
```
useqdrant_client::qdrant::{Condition,ValuesCount};Condition::values_count("comments",ValuesCount{gt: Some(2),..Default::default()},)
```
```
import staticio.qdrant.client.ConditionFactory.valuesCount;importio.qdrant.client.grpc.Points.ValuesCount;valuesCount("comments",ValuesCount.newBuilder().setGt(2).build());
```
```
using Qdrant.Client.Grpc;
using static Qdrant.Client.Grpc.Conditions;
ValuesCount("comments", new ValuesCount { Gt = 2 });

```
```
import "github.com/qdrant/go-client/qdrant"
qdrant.NewValuesCount("comments", &qdrant.ValuesCount{
	Gt: qdrant.PtrOf(uint64(2)),
})

```
The result would be:
```
[{ "id": 2, "name": "product B", "comments": ["meh", "expected more", "ok"] }]

```
If stored value is not an array - it is assumed that the amount of values is equals to 1.
###  [](https://qdrant.tech/documentation/concepts/filtering/#is-empty)Is Empty
Sometimes it is also useful to filter out records that are missing some value. The `IsEmpty` condition may help you with that:
jsonpythontypescriptrustjavacsharpgo
```
{
  "is_empty": {
    "key": "reports"
  }
}

```
```
models.IsEmptyCondition(
    is_empty=models.PayloadField(key="reports"),
)

```
```
{
  is_empty: {
    key: "reports"
  }
}

```
```
useqdrant_client::qdrant::Condition;Condition::is_empty("reports")
```
```
import staticio.qdrant.client.ConditionFactory.isEmpty;isEmpty("reports");
```
```
using Qdrant.Client.Grpc;
using static Qdrant.Client.Grpc.Conditions;
IsEmpty("reports");

```
```
import "github.com/qdrant/go-client/qdrant"
qdrant.NewIsEmpty("reports")

```
This condition will match all records where the field `reports` either does not exist, or has `null` or `[]` value.
The **IsEmpty** is often useful together with the logical negation **must_not**. In this case all non-empty values will be selected.
###  [](https://qdrant.tech/documentation/concepts/filtering/#is-null)Is Null
It is not possible to test for `NULL` values with the **match** condition. We have to use `IsNull` condition instead:
jsonpythontypescriptrustjavacsharpgo
```
{
    "is_null": {
        "key": "reports"
    }
}

```
```
models.IsNullCondition(
    is_null=models.PayloadField(key="reports"),
)

```
```
{
  is_null: {
    key: "reports"
  }
}

```
```
useqdrant_client::qdrant::Condition;Condition::is_null("reports")
```
```
import staticio.qdrant.client.ConditionFactory.isNull;isNull("reports");
```
```
using Qdrant.Client.Grpc;
using static Qdrant.Client.Grpc.Conditions;
IsNull("reports");

```
```
import "github.com/qdrant/go-client/qdrant"
qdrant.NewIsNull("reports")

```
This condition will match all records where the field `reports` exists and has `NULL` value.
###  [](https://qdrant.tech/documentation/concepts/filtering/#has-id)Has id
This type of query is not related to payload, but can be very useful in some situations. For example, the user could mark some specific search results as irrelevant, or we want to search only among the specified points.
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/scroll
{
    "filter": {
        "must": [
            { "has_id": [1,3,5,7,9,11] }
        ]
    }
    ...
}

```
```
client.scroll(
    collection_name="{collection_name}",
    scroll_filter=models.Filter(
        must=[
            models.HasIdCondition(has_id=[1, 3, 5, 7, 9, 11]),
        ],
    ),
)

```
```
client.scroll("{collection_name}", {
  filter: {
    must: [
      {
        has_id: [1, 3, 5, 7, 9, 11],
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,ScrollPointsBuilder};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.scroll(ScrollPointsBuilder::new("{collection_name}").filter(Filter::must([Condition::has_id([1,3,5,7,9,11])])),).await?;
```
```
importjava.util.List;import staticio.qdrant.client.ConditionFactory.hasId;import staticio.qdrant.client.PointIdFactory.id;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.ScrollPoints;client.scrollAsync(ScrollPoints.newBuilder().setCollectionName("{collection_name}").setFilter(Filter.newBuilder().addMust(hasId(List.of(id(1),id(3),id(5),id(7),id(9),id(11)))).build()).build()).get();
```
```
using Qdrant.Client;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.ScrollAsync(collectionName: "{collection_name}", filter: HasId([1, 3, 5, 7, 9, 11]));

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Scroll(context.Background(), &qdrant.ScrollPoints{
	CollectionName: "{collection_name}",
	Filter: &qdrant.Filter{
		Must: []*qdrant.Condition{
			qdrant.NewHasID(
				qdrant.NewIDNum(1),
				qdrant.NewIDNum(3),
				qdrant.NewIDNum(5),
				qdrant.NewIDNum(7),
				qdrant.NewIDNum(9),
				qdrant.NewIDNum(11),
			),
		},
	},
})

```
```
[
  { "id": 1, "city": "London", "color": "green" },
  { "id": 3, "city": "London", "color": "blue" },
  { "id": 5, "city": "Moscow", "color": "green" }
]

```
###  [](https://qdrant.tech/documentation/concepts/filtering/#has-vector)Has vector
_Available as of v1.13.0_
This condition enables filtering by the presence of a given named vector on a point.
For example, if we have two named vector in our collection.
Some points in the collection might have all vectors, some might have only a subset of them.
If your collection does not have named vectors, use an empty (`""`) name.
This is how you can search for points which have the dense `image` vector defined:
httppythontypescriptrustjavacsharpgo
```
client.scroll("{collection_name}", {
  filter: {
    must: [
      {
        has_vector: "image",
      },
    ],
  },
});

```
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/filtering.md) this page on GitHub, or 
On this page:
  * [Filtering](https://qdrant.tech/documentation/concepts/filtering/#filtering)
    * [Related Content](https://qdrant.tech/documentation/concepts/filtering/#related-content)
    * [Filtering clauses](https://qdrant.tech/documentation/concepts/filtering/#filtering-clauses)
      * [Must](https://qdrant.tech/documentation/concepts/filtering/#must)
      * [Should](https://qdrant.tech/documentation/concepts/filtering/#should)
      * [Must Not](https://qdrant.tech/documentation/concepts/filtering/#must-not)
      * [Clauses combination](https://qdrant.tech/documentation/concepts/filtering/#clauses-combination)
    * [Filtering conditions](https://qdrant.tech/documentation/concepts/filtering/#filtering-conditions)
      * [Match](https://qdrant.tech/documentation/concepts/filtering/#match)
      * [Match Any](https://qdrant.tech/documentation/concepts/filtering/#match-any)
      * [Match Except](https://qdrant.tech/documentation/concepts/filtering/#match-except)
      * [Nested key](https://qdrant.tech/documentation/concepts/filtering/#nested-key)
      * [Nested object filter](https://qdrant.tech/documentation/concepts/filtering/#nested-object-filter)
      * [Full Text Match](https://qdrant.tech/documentation/concepts/filtering/#full-text-match)
      * [Range](https://qdrant.tech/documentation/concepts/filtering/#range)
      * [Datetime Range](https://qdrant.tech/documentation/concepts/filtering/#datetime-range)
      * [UUID Match](https://qdrant.tech/documentation/concepts/filtering/#uuid-match)
      * [Geo](https://qdrant.tech/documentation/concepts/filtering/#geo)
      * [Values count](https://qdrant.tech/documentation/concepts/filtering/#values-count)
      * [Is Empty](https://qdrant.tech/documentation/concepts/filtering/#is-empty)
      * [Is Null](https://qdrant.tech/documentation/concepts/filtering/#is-null)
      * [Has id](https://qdrant.tech/documentation/concepts/filtering/#has-id)
      * [Has vector](https://qdrant.tech/documentation/concepts/filtering/#has-vector)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/filtering/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-filtering-geo-bounding-box.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/filtering/#geo-bounding-box
                    ## 📄 `https-qdrant-tech-documentation-concepts-filtering-geo-radius.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/filtering/#geo-radius
                    ## 📄 `https-qdrant-tech-documentation-concepts-filtering-match.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/filtering/#match
                    ## 📄 `https-qdrant-tech-documentation-concepts-filtering-nested-key.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/filtering/#nested-key
                    ## 📄 `https-qdrant-tech-documentation-concepts-filtering-range.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/filtering/#range
                    ## 📄 `https-qdrant-tech-documentation-concepts-filtering.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/filtering/
                    ## 📄 `https-qdrant-tech-documentation-concepts-hybrid-queries.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/hybrid-queries/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/hybrid-queries/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-indexing-filtrable-index.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/indexing/#filtrable-index
  * [Documentation](https://qdrant.tech/documentation/)
  * [Concepts](https://qdrant.tech/documentation/concepts/)
  * Indexing
#  [](https://qdrant.tech/documentation/concepts/indexing/#indexing)Indexing
A key feature of Qdrant is the effective combination of vector and traditional indexes. It is essential to have this because for vector search to work effectively with filters, having vector index only is not enough. In simpler terms, a vector index speeds up vector search, and payload indexes speed up filtering.
The indexes in the segments exist independently, but the parameters of the indexes themselves are configured for the whole collection.
Not all segments automatically have indexes. Their necessity is determined by the [optimizer](https://qdrant.tech/documentation/concepts/optimizer/) settings and depends, as a rule, on the number of stored points.
##  [](https://qdrant.tech/documentation/concepts/indexing/#payload-index)Payload Index
Payload index in Qdrant is similar to the index in conventional document-oriented databases. This index is built for a specific field and type, and is used for quick point requests by the corresponding filtering condition.
The index is also used to accurately estimate the filter cardinality, which helps the [query planning](https://qdrant.tech/documentation/concepts/search/#query-planning) choose a search strategy.
Creating an index requires additional computational resources and memory, so choosing fields to be indexed is essential. Qdrant does not make this choice but grants it to the user.
To mark a field as indexable, you can use the following:
httppythontypescriptrustjavacsharpgo
```
PUT /collections/{collection_name}/index
{
    "field_name": "name_of_the_field_to_index",
    "field_schema": "keyword"
}

```
```
client.create_payload_index(
    collection_name="{collection_name}",
    field_name="name_of_the_field_to_index",
    field_schema="keyword",
)

```
```
client.createPayloadIndex("{collection_name}", {
  field_name: "name_of_the_field_to_index",
  field_schema: "keyword",
});

```
```
useqdrant_client::qdrant::{CreateFieldIndexCollectionBuilder,FieldType};client.create_field_index(CreateFieldIndexCollectionBuilder::new("{collection_name}","name_of_the_field_to_index",FieldType::Keyword,).wait(true),).await?;
```
```
importio.qdrant.client.grpc.Collections.PayloadSchemaType;client.createPayloadIndexAsync("{collection_name}","name_of_the_field_to_index",PayloadSchemaType.Keyword,null,true,null,null);
```
```
using Qdrant.Client;
var client = new QdrantClient("localhost", 6334);
await client.CreatePayloadIndexAsync(
    collectionName: "{collection_name}",
    fieldName: "name_of_the_field_to_index"
);

```
```
import (
    "context"
    "github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
    Host: "localhost",
    Port: 6334,
})
client.CreateFieldIndex(context.Background(), &qdrant.CreateFieldIndexCollection{
    CollectionName: "{collection_name}",
    FieldName:      "name_of_the_field_to_index",
    FieldType:      qdrant.FieldType_FieldTypeKeyword.Enum(),
})

```
You can use dot notation to specify a nested field for indexing. Similar to specifying [nested filters](https://qdrant.tech/documentation/concepts/filtering/#nested-key).
Available field types are:
  * `keyword` - for [keyword](https://qdrant.tech/documentation/concepts/payload/#keyword) payload, affects [Match](https://qdrant.tech/documentation/concepts/filtering/#match) filtering conditions.
  * `integer` - for [integer](https://qdrant.tech/documentation/concepts/payload/#integer) payload, affects [Match](https://qdrant.tech/documentation/concepts/filtering/#match) and [Range](https://qdrant.tech/documentation/concepts/filtering/#range) filtering conditions.
  * `float` - for [float](https://qdrant.tech/documentation/concepts/payload/#float) payload, affects [Range](https://qdrant.tech/documentation/concepts/filtering/#range) filtering conditions.
  * `bool` - for [bool](https://qdrant.tech/documentation/concepts/payload/#bool) payload, affects [Match](https://qdrant.tech/documentation/concepts/filtering/#match) filtering conditions (available as of v1.4.0).
  * `geo` - for [geo](https://qdrant.tech/documentation/concepts/payload/#geo) payload, affects [Geo Bounding Box](https://qdrant.tech/documentation/concepts/filtering/#geo-bounding-box) and [Geo Radius](https://qdrant.tech/documentation/concepts/filtering/#geo-radius) filtering conditions.
  * `datetime` - for [datetime](https://qdrant.tech/documentation/concepts/payload/#datetime) payload, affects [Range](https://qdrant.tech/documentation/concepts/filtering/#range) filtering conditions (available as of v1.8.0).
  * `text` - a special kind of index, available for [keyword](https://qdrant.tech/documentation/concepts/payload/#keyword) / string payloads, affects [Full Text search](https://qdrant.tech/documentation/concepts/filtering/#full-text-match) filtering conditions.
  * `uuid` - a special type of index, similar to `keyword`, but optimized for [UUID values](https://qdrant.tech/documentation/concepts/payload/#uuid). Affects [Match](https://qdrant.tech/documentation/concepts/filtering/#match) filtering conditions. (available as of v1.11.0)
Payload index may occupy some additional memory, so it is recommended to only use index for those fields that are used in filtering conditions. If you need to filter by many fields and the memory limits does not allow to index all of them, it is recommended to choose the field that limits the search result the most. As a rule, the more different values a payload value has, the more efficiently the index will be used.
###  [](https://qdrant.tech/documentation/concepts/indexing/#full-text-index)Full-text index
_Available as of v0.10.0_
Qdrant supports full-text search for string payload. Full-text index allows you to filter points by the presence of a word or a phrase in the payload field.
Full-text index configuration is a bit more complex than other indexes, as you can specify the tokenization parameters. Tokenization is the process of splitting a string into tokens, which are then indexed in the inverted index.
To create a full-text index, you can use the following:
httppythontypescriptrustjavacsharpgo
```
PUT /collections/{collection_name}/index
{
    "field_name": "name_of_the_field_to_index",
    "field_schema": {
        "type": "text",
        "tokenizer": "word",
        "min_token_len": 2,
        "max_token_len": 20,
        "lowercase": true
    }
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.create_payload_index(
    collection_name="{collection_name}",
    field_name="name_of_the_field_to_index",
    field_schema=models.TextIndexParams(
        type="text",
        tokenizer=models.TokenizerType.WORD,
        min_token_len=2,
        max_token_len=15,
        lowercase=True,
    ),
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.createPayloadIndex("{collection_name}", {
  field_name: "name_of_the_field_to_index",
  field_schema: {
    type: "text",
    tokenizer: "word",
    min_token_len: 2,
    max_token_len: 15,
    lowercase: true,
  },
});

```
```
useqdrant_client::qdrant::{payload_index_params::IndexParams,CreateFieldIndexCollectionBuilder,FieldType,PayloadIndexParams,TextIndexParams,TokenizerType,};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.create_field_index(CreateFieldIndexCollectionBuilder::new("{collection_name}","name_of_the_field_to_index",FieldType::Text,).field_index_params(PayloadIndexParams{index_params: Some(IndexParams::TextIndexParams(TextIndexParams{tokenizer: TokenizerType::Wordasi32,min_token_len: Some(2),max_token_len: Some(10),lowercase: Some(true),})),}),).await?;
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Collections.PayloadIndexParams;importio.qdrant.client.grpc.Collections.PayloadSchemaType;importio.qdrant.client.grpc.Collections.TextIndexParams;importio.qdrant.client.grpc.Collections.TokenizerType;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.createPayloadIndexAsync("{collection_name}","name_of_the_field_to_index",PayloadSchemaType.Text,PayloadIndexParams.newBuilder().setTextIndexParams(TextIndexParams.newBuilder().setTokenizer(TokenizerType.Word).setMinTokenLen(2).setMaxTokenLen(10).setLowercase(true).build()).build(),null,null,null).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.CreatePayloadIndexAsync(
	collectionName: "{collection_name}",
	fieldName: "name_of_the_field_to_index",
	schemaType: PayloadSchemaType.Text,
	indexParams: new PayloadIndexParams
	{
		TextIndexParams = new TextIndexParams
		{
			Tokenizer = TokenizerType.Word,
			MinTokenLen = 2,
			MaxTokenLen = 10,
			Lowercase = true
		}
	}
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.CreateFieldIndex(context.Background(), &qdrant.CreateFieldIndexCollection{
	CollectionName: "{collection_name}",
	FieldName:      "name_of_the_field_to_index",
	FieldType:      qdrant.FieldType_FieldTypeText.Enum(),
	FieldIndexParams: qdrant.NewPayloadIndexParamsText(
		&qdrant.TextIndexParams{
			Tokenizer:   qdrant.TokenizerType_Whitespace,
			MinTokenLen: qdrant.PtrOf(uint64(2)),
			MaxTokenLen: qdrant.PtrOf(uint64(10)),
			Lowercase:   qdrant.PtrOf(true),
		}),
})

```
Available tokenizers are:
  * `word` - splits the string into words, separated by spaces, punctuation marks, and special characters.
  * `whitespace` - splits the string into words, separated by spaces.
  * `prefix` - splits the string into words, separated by spaces, punctuation marks, and special characters, and then creates a prefix index for each word. For example: `hello` will be indexed as `h`, `he`, `hel`, `hell`, `hello`.
  * `multilingual` - special type of tokenizer based on `--features multiling-chinese,multiling-japanese,multiling-korean` flags.
See [Full Text match](https://qdrant.tech/documentation/concepts/filtering/#full-text-match) for examples of querying with full-text index.
###  [](https://qdrant.tech/documentation/concepts/indexing/#parameterized-index)Parameterized index
_Available as of v1.8.0_
We’ve added a parameterized variant to the `integer` index, which allows you to fine-tune indexing and search performance.
Both the regular and parameterized `integer` indexes use the following flags:
  * `lookup`: enables support for direct lookup using [Match](https://qdrant.tech/documentation/concepts/filtering/#match) filters.
  * `range`: enables support for [Range](https://qdrant.tech/documentation/concepts/filtering/#range) filters.
The regular `integer` index assumes both `lookup` and `range` are `true`. In contrast, to configure a parameterized index, you would set only one of these filters to `true`:
`lookup` | `range` | Result  
---|---|---  
`true` | `true` | Regular integer index  
`true` | `false` | Parameterized integer index  
`false` | `true` | Parameterized integer index  
`false` | `false` | No integer index  
The parameterized index can enhance performance in collections with millions of points. We encourage you to try it out. If it does not enhance performance in your use case, you can always restore the regular `integer` index.
Note: If you set `"lookup": true` with a range filter, that may lead to significant performance issues.
For example, the following code sets up a parameterized integer index which supports only range filters:
httppythontypescriptrustjavacsharpgo
```
PUT /collections/{collection_name}/index
{
    "field_name": "name_of_the_field_to_index",
    "field_schema": {
        "type": "integer",
        "lookup": false,
        "range": true
    }
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.create_payload_index(
    collection_name="{collection_name}",
    field_name="name_of_the_field_to_index",
    field_schema=models.IntegerIndexParams(
        type=models.IntegerIndexType.INTEGER,
        lookup=False,
        range=True,
    ),
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.createPayloadIndex("{collection_name}", {
  field_name: "name_of_the_field_to_index",
  field_schema: {
    type: "integer",
    lookup: false,
    range: true,
  },
});

```
```
useqdrant_client::qdrant::{payload_index_params::IndexParams,CreateFieldIndexCollectionBuilder,FieldType,IntegerIndexParams,PayloadIndexParams,};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.create_field_index(CreateFieldIndexCollectionBuilder::new("{collection_name}","name_of_the_field_to_index",FieldType::Integer,).field_index_params(PayloadIndexParams{index_params: Some(IndexParams::IntegerIndexParams(IntegerIndexParams{lookup: false,range: true,})),}),).await?;
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Collections.IntegerIndexParams;importio.qdrant.client.grpc.Collections.PayloadIndexParams;importio.qdrant.client.grpc.Collections.PayloadSchemaType;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.createPayloadIndexAsync("{collection_name}","name_of_the_field_to_index",PayloadSchemaType.Integer,PayloadIndexParams.newBuilder().setIntegerIndexParams(IntegerIndexParams.newBuilder().setLookup(false).setRange(true).build()).build(),null,null,null).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.CreatePayloadIndexAsync(
    collectionName: "{collection_name}",
    fieldName: "name_of_the_field_to_index",
    schemaType: PayloadSchemaType.Integer,
    indexParams: new PayloadIndexParams
    {
	    IntegerIndexParams = new()
	    {
		    Lookup = false,
		    Range = true
	    }
    }
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.CreateFieldIndex(context.Background(), &qdrant.CreateFieldIndexCollection{
	CollectionName: "{collection_name}",
	FieldName:      "name_of_the_field_to_index",
	FieldType:      qdrant.FieldType_FieldTypeInteger.Enum(),
	FieldIndexParams: qdrant.NewPayloadIndexParamsInt(
		&qdrant.IntegerIndexParams{
			Lookup: false,
			Range:  true,
		}),
})

```
###  [](https://qdrant.tech/documentation/concepts/indexing/#on-disk-payload-index)On-disk payload index
_Available as of v1.11.0_
By default all payload-related structures are stored in memory. In this way, the vector index can quickly access payload values during search. As latency in this case is critical, it is recommended to keep hot payload indexes in memory.
There are, however, cases when payload indexes are too large or rarely used. In those cases, it is possible to store payload indexes on disk.
On-disk payload index might affect cold requests latency, as it requires additional disk I/O operations.
To configure on-disk payload index, you can use the following index parameters:
httppythontypescriptrustjavacsharpgo
```
PUT /collections/{collection_name}/index
{
    "field_name": "payload_field_name",
    "field_schema": {
        "type": "keyword",
        "on_disk": true
    }
}

```
```
client.create_payload_index(
    collection_name="{collection_name}",
    field_name="payload_field_name",
    field_schema=models.KeywordIndexParams(
        type=models.KeywordIndexType.KEYWORD,
        on_disk=True,
    ),
)

```
```
client.createPayloadIndex("{collection_name}", {
  field_name: "payload_field_name",
  field_schema: {
    type: "keyword",
    on_disk: true
  },
});

```
```
useqdrant_client::qdrant::{CreateFieldIndexCollectionBuilder,KeywordIndexParamsBuilder,FieldType};useqdrant_client::{Qdrant,QdrantError};letclient=Qdrant::from_url("http://localhost:6334").build()?;client.create_field_index(CreateFieldIndexCollectionBuilder::new("{collection_name}","payload_field_name",FieldType::Keyword,).field_index_params(KeywordIndexParamsBuilder::default().on_disk(true),),);
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Collections.PayloadIndexParams;importio.qdrant.client.grpc.Collections.PayloadSchemaType;importio.qdrant.client.grpc.Collections.KeywordIndexParams;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.createPayloadIndexAsync("{collection_name}","payload_field_name",PayloadSchemaType.Keyword,PayloadIndexParams.newBuilder().setKeywordIndexParams(KeywordIndexParams.newBuilder().setOnDisk(true).build()).build(),null,null,null).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.CreatePayloadIndexAsync(
 collectionName: "{collection_name}",
 fieldName: "payload_field_name",
 schemaType: PayloadSchemaType.Keyword,
 indexParams: new PayloadIndexParams
 {
  KeywordIndexParams = new KeywordIndexParams
  {
   OnDisk   = true
  }
 }
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.CreateFieldIndex(context.Background(), &qdrant.CreateFieldIndexCollection{
	CollectionName: "{collection_name}",
	FieldName:      "name_of_the_field_to_index",
	FieldType:      qdrant.FieldType_FieldTypeKeyword.Enum(),
	FieldIndexParams: qdrant.NewPayloadIndexParamsKeyword(
		&qdrant.KeywordIndexParams{
			OnDisk: qdrant.PtrOf(true),
		}),
})

```
Payload index on-disk is supported for following types:
  * `keyword`
  * `integer`
  * `float`
  * `datetime`
  * `uuid`
  * `text`
  * `geo`
The list will be extended in future versions.
###  [](https://qdrant.tech/documentation/concepts/indexing/#tenant-index)Tenant Index
_Available as of v1.11.0_
Many vector search use-cases require multitenancy. In a multi-tenant scenario the collection is expected to contain multiple subsets of data, where each subset belongs to a different tenant.
Qdrant supports efficient multi-tenant search by enabling [special configuration](https://qdrant.tech/documentation/guides/multiple-partitions/) vector index, which disables global search and only builds sub-indexes for each tenant.
In Qdrant, tenants are not necessarily non-overlapping. It is possible to have subsets of data that belong to multiple tenants.
However, knowing that the collection contains multiple tenants unlocks more opportunities for optimization. To optimize storage in Qdrant further, you can enable tenant indexing for payload fields.
This option will tell Qdrant which fields are used for tenant identification and will allow Qdrant to structure storage for faster search of tenant-specific data. One example of such optimization is localizing tenant-specific data closer on disk, which will reduce the number of disk reads during search.
To enable tenant index for a field, you can use the following index parameters:
httppythontypescriptrustjavacsharpgo
```
PUT /collections/{collection_name}/index
{
    "field_name": "payload_field_name",
    "field_schema": {
        "type": "keyword",
        "is_tenant": true
    }
}

```
```
client.create_payload_index(
    collection_name="{collection_name}",
    field_name="payload_field_name",
    field_schema=models.KeywordIndexParams(
        type=models.KeywordIndexType.KEYWORD,
        is_tenant=True,
    ),
)

```
```
client.createPayloadIndex("{collection_name}", {
  field_name: "payload_field_name",
  field_schema: {
    type: "keyword",
    is_tenant: true
  },
});

```
```
useqdrant_client::qdrant::{CreateFieldIndexCollectionBuilder,KeywordIndexParamsBuilder,FieldType};useqdrant_client::{Qdrant,QdrantError};letclient=Qdrant::from_url("http://localhost:6334").build()?;client.create_field_index(CreateFieldIndexCollectionBuilder::new("{collection_name}","payload_field_name",FieldType::Keyword,).field_index_params(KeywordIndexParamsBuilder::default().is_tenant(true),),);
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Collections.PayloadIndexParams;importio.qdrant.client.grpc.Collections.PayloadSchemaType;importio.qdrant.client.grpc.Collections.KeywordIndexParams;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.createPayloadIndexAsync("{collection_name}","payload_field_name",PayloadSchemaType.Keyword,PayloadIndexParams.newBuilder().setKeywordIndexParams(KeywordIndexParams.newBuilder().setIsTenant(true).build()).build(),null,null,null).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.CreatePayloadIndexAsync(
 collectionName: "{collection_name}",
 fieldName: "payload_field_name",
 schemaType: PayloadSchemaType.Keyword,
 indexParams: new PayloadIndexParams
 {
  KeywordIndexParams = new KeywordIndexParams
  {
   IsTenant = true
  }
 }
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.CreateFieldIndex(context.Background(), &qdrant.CreateFieldIndexCollection{
	CollectionName: "{collection_name}",
	FieldName:      "name_of_the_field_to_index",
	FieldType:      qdrant.FieldType_FieldTypeKeyword.Enum(),
	FieldIndexParams: qdrant.NewPayloadIndexParamsKeyword(
		&qdrant.KeywordIndexParams{
			IsTenant: qdrant.PtrOf(true),
		}),
})

```
Tenant optimization is supported for the following datatypes:
  * `keyword`
  * `uuid`
###  [](https://qdrant.tech/documentation/concepts/indexing/#principal-index)Principal Index
_Available as of v1.11.0_
Similar to the tenant index, the principal index is used to optimize storage for faster search, assuming that the search request is primarily filtered by the principal field.
A good example of a use case for the principal index is time-related data, where each point is associated with a timestamp. In this case, the principal index can be used to optimize storage for faster search with time-based filters.
httppythontypescriptrustjavacsharpgo
```
PUT /collections/{collection_name}/index
{
    "field_name": "timestamp",
    "field_schema": {
        "type": "integer",
        "is_principal": true
    }
}

```
```
client.create_payload_index(
    collection_name="{collection_name}",
    field_name="timestamp",
    field_schema=models.IntegerIndexParams(
        type=models.IntegerIndexType.INTEGER,
        is_principal=True,
    ),
)

```
```
client.createPayloadIndex("{collection_name}", {
  field_name: "timestamp",
  field_schema: {
    type: "integer",
    is_principal: true
  },
});

```
```
useqdrant_client::qdrant::{CreateFieldIndexCollectionBuilder,IntegerIndexParamsBuilder,FieldType};useqdrant_client::{Qdrant,QdrantError};letclient=Qdrant::from_url("http://localhost:6334").build()?;client.create_field_index(CreateFieldIndexCollectionBuilder::new("{collection_name}","timestamp",FieldType::Integer,).field_index_params(IntegerIndexParamsBuilder::default().is_principal(true),),);
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Collections.PayloadIndexParams;importio.qdrant.client.grpc.Collections.PayloadSchemaType;importio.qdrant.client.grpc.Collections.IntegerIndexParams;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.createPayloadIndexAsync("{collection_name}","timestamp",PayloadSchemaType.Integer,PayloadIndexParams.newBuilder().setIntegerIndexParams(KeywordIndexParams.newBuilder().setIsPrincipa(true).build()).build(),null,null,null).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.CreatePayloadIndexAsync(
 collectionName: "{collection_name}",
 fieldName: "timestamp",
 schemaType: PayloadSchemaType.Integer,
 indexParams: new PayloadIndexParams
 {
  IntegerIndexParams = new IntegerIndexParams
  {
   IsPrincipal = true
  }
 }
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.CreateFieldIndex(context.Background(), &qdrant.CreateFieldIndexCollection{
	CollectionName: "{collection_name}",
	FieldName:      "name_of_the_field_to_index",
	FieldType:      qdrant.FieldType_FieldTypeInteger.Enum(),
	FieldIndexParams: qdrant.NewPayloadIndexParamsInt(
		&qdrant.IntegerIndexParams{
			IsPrincipal: qdrant.PtrOf(true),
		}),
})

```
Principal optimization is supported for following types:
  * `integer`
  * `float`
  * `datetime`
##  [](https://qdrant.tech/documentation/concepts/indexing/#vector-index)Vector Index
A vector index is a data structure built on vectors through a specific mathematical model. Through the vector index, we can efficiently query several vectors similar to the target vector.
Qdrant currently only uses HNSW as a dense vector index.
In order to improve performance, HNSW limits the maximum degree of nodes on each layer of the graph to `m`. In addition, you can use `ef_construct` (when building index) or `ef` (when searching targets) to specify a search range.
The corresponding parameters could be configured in the configuration file:
```
storage:# Default parameters of HNSW Index. Could be overridden for each collection or named vector individuallyhnsw_index:# Number of edges per node in the index graph.# Larger the value - more accurate the search, more space required.m:16# Number of neighbours to consider during the index building.# Larger the value - more accurate the search, more time required to build index.ef_construct:100# Minimal size (in KiloBytes) of vectors for additional payload-based indexing.# If payload chunk is smaller than `full_scan_threshold_kb` additional indexing won't be used -# in this case full-scan search should be preferred by query planner and additional indexing is not required.# Note: 1Kb = 1 vector of size 256full_scan_threshold:10000
```
And so in the process of creating a [collection](https://qdrant.tech/documentation/concepts/collections/). The `ef` parameter is configured during [the search](https://qdrant.tech/documentation/concepts/search/) and by default is equal to `ef_construct`.
HNSW is chosen for several reasons. First, HNSW is well-compatible with the modification that allows Qdrant to use filters during a search. Second, it is one of the most accurate and fastest algorithms, according to 
_Available as of v1.1.1_
The HNSW parameters can also be configured on a collection and named vector level by setting [`hnsw_config`](https://qdrant.tech/documentation/concepts/indexing/#vector-index) to fine-tune search performance.
##  [](https://qdrant.tech/documentation/concepts/indexing/#sparse-vector-index)Sparse Vector Index
_Available as of v1.7.0_
Sparse vectors in Qdrant are indexed with a special data structure, which is optimized for vectors that have a high proportion of zeroes. In some ways, this indexing method is similar to the inverted index, which is used in text search engines.
  * A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms.
  * All sparse vectors added to the collection are immediately indexed in the mutable version of a sparse index.
With Qdrant, you can benefit from a more compact and efficient immutable sparse index, which is constructed during the same optimization process as the dense vector index.
This approach is particularly useful for collections storing both dense and sparse vectors.
To configure a sparse vector index, create a collection with the following parameters:
httppythontypescriptrustjavacsharpgo
```
PUT /collections/{collection_name}
{
    "sparse_vectors": {
        "text": {
            "index": {
                "on_disk": false
            }
        }
    }
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.create_collection(
    collection_name="{collection_name}",
    vectors_config={},
    sparse_vectors_config={
        "text": models.SparseVectorParams(
            index=models.SparseIndexParams(on_disk=False),
        )
    },
)

```
```
import { QdrantClient, Schemas } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.createCollection("{collection_name}", {
  sparse_vectors: {
    "splade-model-name": {
      index: {
        on_disk: false
      }
    }
  }
});

```
```
useqdrant_client::qdrant::{CreateCollectionBuilder,SparseIndexConfigBuilder,SparseVectorParamsBuilder,SparseVectorsConfigBuilder,};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;letmutsparse_vectors_config=SparseVectorsConfigBuilder::default();sparse_vectors_config.add_named_vector_params("splade-model-name",SparseVectorParamsBuilder::default().index(SparseIndexConfigBuilder::default().on_disk(true)),);client.create_collection(CreateCollectionBuilder::new("{collection_name}").sparse_vectors_config(sparse_vectors_config),).await?;
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Collections;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.createCollectionAsync(Collections.CreateCollection.newBuilder().setCollectionName("{collection_name}").setSparseVectorsConfig(Collections.SparseVectorConfig.newBuilder().putMap("splade-model-name",Collections.SparseVectorParams.newBuilder().setIndex(Collections.SparseIndexConfig.newBuilder().setOnDisk(false).build()).build()).build()).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.CreateCollectionAsync(
	collectionName: "{collection_name}",
	sparseVectorsConfig: ("splade-model-name", new SparseVectorParams{
        Index = new SparseIndexConfig {
            OnDisk = false,
        }
    })
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.CreateCollection(context.Background(), &qdrant.CreateCollection{
	CollectionName: "{collection_name}",
	SparseVectorsConfig: qdrant.NewSparseVectorsConfig(
		map[string]*qdrant.SparseVectorParams{
			"splade-model-name": {
				Index: &qdrant.SparseIndexConfig{
					OnDisk: qdrant.PtrOf(false),
				}},
		}),
})

```
`
The following parameters may affect performance:
  * `on_disk: true` - The index is stored on disk, which lets you save memory. This may slow down search performance.
  * `on_disk: false` - The index is still persisted on disk, but it is also loaded into memory for faster search.
Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It automatically adjusts to the size of the vectors added to the collection.
**Note:** A sparse vector index only supports dot-product similarity searches. It does not support other distance metrics.
###  [](https://qdrant.tech/documentation/concepts/indexing/#idf-modifier)IDF Modifier
_Available as of v1.10.0_
For many search algorithms, it is important to consider how often an item occurs in a collection. Intuitively speaking, the less frequently an item appears in a collection, the more important it is in a search.
This is also known as the Inverse Document Frequency (IDF). It is used in text search engines to rank search results based on the rarity of a word in a collection.
IDF depends on the currently stored documents and therefore can’t be pre-computed in the sparse vectors in streaming inference mode. In order to support IDF in the sparse vector index, Qdrant provides an option to modify the sparse vector query with the IDF statistics automatically.
The only requirement is to enable the IDF modifier in the collection configuration:
httppythontypescriptrustjavacsharpgo
```
PUT /collections/{collection_name}
{
    "sparse_vectors": {
        "text": {
            "modifier": "idf"
        }
    }
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.create_collection(
    collection_name="{collection_name}",
    vectors_config={},
    sparse_vectors_config={
        "text": models.SparseVectorParams(
            modifier=models.Modifier.IDF,
        ),
    },
)

```
```
import { QdrantClient, Schemas } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.createCollection("{collection_name}", {
  sparse_vectors: {
    "text": {
      modifier: "idf"
    }
  }
});

```
```
useqdrant_client::qdrant::{CreateCollectionBuilder,Modifier,SparseVectorParamsBuilder,SparseVectorsConfigBuilder,};useqdrant_client::{Qdrant,QdrantError};letclient=Qdrant::from_url("http://localhost:6334").build()?;letmutsparse_vectors_config=SparseVectorsConfigBuilder::default();sparse_vectors_config.add_named_vector_params("text",SparseVectorParamsBuilder::default().modifier(Modifier::Idf),);client.create_collection(CreateCollectionBuilder::new("{collection_name}").sparse_vectors_config(sparse_vectors_config),).await?;
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Collections.CreateCollection;importio.qdrant.client.grpc.Collections.Modifier;importio.qdrant.client.grpc.Collections.SparseVectorConfig;importio.qdrant.client.grpc.Collections.SparseVectorParams;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.createCollectionAsync(CreateCollection.newBuilder().setCollectionName("{collection_name}").setSparseVectorsConfig(SparseVectorConfig.newBuilder().putMap("text",SparseVectorParams.newBuilder().setModifier(Modifier.Idf).build())).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.CreateCollectionAsync(
  collectionName: "{collection_name}",
  sparseVectorsConfig: ("text", new SparseVectorParams {
    Modifier = Modifier.Idf,
  })
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.CreateCollection(context.Background(), &qdrant.CreateCollection{
	CollectionName: "{collection_name}",
	SparseVectorsConfig: qdrant.NewSparseVectorsConfig(
		map[string]*qdrant.SparseVectorParams{
			"text": {
				Modifier: qdrant.Modifier_Idf.Enum(),
			},
		}),
})

```
Qdrant uses the following formula to calculate the IDF modifier:
IDF(qi)=ln⁡(N−n(qi)+0.5n(qi)+0.5+1)
Where:
  * `N` is the total number of documents in the collection.
  * `n` is the number of documents containing non-zero values for the given vector element.
##  [](https://qdrant.tech/documentation/concepts/indexing/#filtrable-index)Filtrable Index
Separately, a payload index and a vector index cannot solve the problem of search using the filter completely.
In the case of weak filters, you can use the HNSW index as it is. In the case of stringent filters, you can use the payload index and complete rescore. However, for cases in the middle, this approach does not work well.
On the one hand, we cannot apply a full scan on too many vectors. On the other hand, the HNSW graph starts to fall apart when using too strict filters.
![HNSW fail](https://qdrant.tech/docs/precision_by_m.png)
![hnsw graph](https://qdrant.tech/docs/graph.gif)
You can find more information on why this happens in our 
Extra edges allow you to efficiently search for nearby vectors using the HNSW index and apply filters as you search in the graph.
This approach minimizes the overhead on condition checks since you only need to calculate the conditions for a small fraction of the points involved in the search.
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/indexing.md) this page on GitHub, or 
On this page:
  * [Indexing](https://qdrant.tech/documentation/concepts/indexing/#indexing)
    * [Payload Index](https://qdrant.tech/documentation/concepts/indexing/#payload-index)
      * [Full-text index](https://qdrant.tech/documentation/concepts/indexing/#full-text-index)
      * [Parameterized index](https://qdrant.tech/documentation/concepts/indexing/#parameterized-index)
      * [On-disk payload index](https://qdrant.tech/documentation/concepts/indexing/#on-disk-payload-index)
      * [Tenant Index](https://qdrant.tech/documentation/concepts/indexing/#tenant-index)
      * [Principal Index](https://qdrant.tech/documentation/concepts/indexing/#principal-index)
    * [Vector Index](https://qdrant.tech/documentation/concepts/indexing/#vector-index)
    * [Sparse Vector Index](https://qdrant.tech/documentation/concepts/indexing/#sparse-vector-index)
      * [IDF Modifier](https://qdrant.tech/documentation/concepts/indexing/#idf-modifier)
    * [Filtrable Index](https://qdrant.tech/documentation/concepts/indexing/#filtrable-index)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/indexing/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-indexing-full-text-index.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/indexing/#full-text-index
                    ## 📄 `https-qdrant-tech-documentation-concepts-indexing-idf-modifier.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/indexing/#idf-modifier
                    ## 📄 `https-qdrant-tech-documentation-concepts-indexing-indexing.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/indexing/#indexing
                    ## 📄 `https-qdrant-tech-documentation-concepts-indexing-on-disk-payload-index.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/indexing/#on-disk-payload-index
                    ## 📄 `https-qdrant-tech-documentation-concepts-indexing-parameterized-index.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/indexing/#parameterized-index
                    ## 📄 `https-qdrant-tech-documentation-concepts-indexing-payload-index.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/indexing/#payload-index
                    ## 📄 `https-qdrant-tech-documentation-concepts-indexing-principal-index.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/indexing/#principal-index
                    ## 📄 `https-qdrant-tech-documentation-concepts-indexing-sparse-vector-index.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/indexing/#sparse-vector-index
                    ## 📄 `https-qdrant-tech-documentation-concepts-indexing-tenant-index.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/indexing/#tenant-index
                    ## 📄 `https-qdrant-tech-documentation-concepts-indexing-vector-index.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/indexing/#vector-index
                    ## 📄 `https-qdrant-tech-documentation-concepts-indexing.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/indexing/
                    ## 📄 `https-qdrant-tech-documentation-concepts-optimizer.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/optimizer/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/optimizer/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-payload-bool.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/payload/#bool
  * [Documentation](https://qdrant.tech/documentation/)
  * [Concepts](https://qdrant.tech/documentation/concepts/)
  * Payload
#  [](https://qdrant.tech/documentation/concepts/payload/#payload)Payload
One of the significant features of Qdrant is the ability to store additional information along with vectors. This information is called `payload` in Qdrant terminology.
Qdrant allows you to store any information that can be represented using JSON.
Here is an example of a typical payload:
```
{
    "name": "jacket",
    "colors": ["red", "blue"],
    "count": 10,
    "price": 11.99,
    "locations": [
        {
            "lon": 52.5200, 
            "lat": 13.4050
        }
    ],
    "reviews": [
        {
            "user": "alice",
            "score": 4
        },
        {
            "user": "bob",
            "score": 5
        }
    ]
}

```
##  [](https://qdrant.tech/documentation/concepts/payload/#payload-types)Payload types
In addition to storing payloads, Qdrant also allows you search based on certain kinds of values. This feature is implemented as additional filters during the search and will enable you to incorporate custom logic on top of semantic similarity.
During the filtering, Qdrant will check the conditions over those values that match the type of the filtering condition. If the stored value type does not fit the filtering condition - it will be considered not satisfied.
For example, you will get an empty output if you apply the [range condition](https://qdrant.tech/documentation/concepts/filtering/#range) on the string data.
However, arrays (multiple values of the same type) are treated a little bit different. When we apply a filter to an array, it will succeed if at least one of the values inside the array meets the condition.
The filtering process is discussed in detail in the section [Filtering](https://qdrant.tech/documentation/concepts/filtering/).
Let’s look at the data types that Qdrant supports for searching:
###  [](https://qdrant.tech/documentation/concepts/payload/#integer)Integer
`integer` - 64-bit integer in the range from `-9223372036854775808` to `9223372036854775807`.
Example of single and multiple `integer` values:
```
{
    "count": 10,
    "sizes": [35, 36, 38]
}

```
###  [](https://qdrant.tech/documentation/concepts/payload/#float)Float
`float` - 64-bit floating point number.
Example of single and multiple `float` values:
```
{
    "price": 11.99,
    "ratings": [9.1, 9.2, 9.4]
}

```
###  [](https://qdrant.tech/documentation/concepts/payload/#bool)Bool
Bool - binary value. Equals to `true` or `false`.
Example of single and multiple `bool` values:
```
{
    "is_delivered": true,
    "responses": [false, false, true, false]
}

```
###  [](https://qdrant.tech/documentation/concepts/payload/#keyword)Keyword
`keyword` - string value.
Example of single and multiple `keyword` values:
```
{
    "name": "Alice",
    "friends": [
        "bob",
        "eva",
        "jack"
    ]
}

```
###  [](https://qdrant.tech/documentation/concepts/payload/#geo)Geo
`geo` is used to represent geographical coordinates.
Example of single and multiple `geo` values:
```
{
    "location": {
        "lon": 52.5200,
        "lat": 13.4050
    },
    "cities": [
        {
            "lon": 51.5072,
            "lat": 0.1276
        },
        {
            "lon": 40.7128,
            "lat": 74.0060
        }
    ]
}

```
Coordinate should be described as an object containing two fields: `lon` - for longitude, and `lat` - for latitude.
###  [](https://qdrant.tech/documentation/concepts/payload/#datetime)Datetime
_Available as of v1.8.0_
`datetime` - date and time in 
See the following examples of single and multiple `datetime` values:
```
{
    "created_at": "2023-02-08T10:49:00Z",
    "updated_at": [
        "2023-02-08T13:52:00Z",
        "2023-02-21T21:23:00Z"
    ]
}

```
The following formats are supported:
  * `"2023-02-08T10:49:00Z"` (
  * `"2023-02-08T11:49:00+01:00"` (
  * `"2023-02-08T10:49:00"` (without timezone, UTC is assumed)
  * `"2023-02-08T10:49"` (without timezone and seconds)
  * `"2023-02-08"` (only date, midnight is assumed)
Notes about the format:
  * `T` can be replaced with a space.
  * The `T` and `Z` symbols are case-insensitive.
  * UTC is always assumed when the timezone is not specified.
  * Timezone can have the following formats: `±HH:MM`, `±HHMM`, `±HH`, or `Z`.
  * Seconds can have up to 6 decimals, so the finest granularity for `datetime` is microseconds.
###  [](https://qdrant.tech/documentation/concepts/payload/#uuid)UUID
_Available as of v1.11.0_
In addition to the basic `keyword` type, Qdrant supports `uuid` type for storing UUID values. Functionally, it works the same as `keyword`, internally stores parsed UUID values.
```
{
    "uuid": "550e8400-e29b-41d4-a716-446655440000",
    "uuids": [
        "550e8400-e29b-41d4-a716-446655440000",
        "550e8400-e29b-41d4-a716-446655440001"
    ]
}

```
String representation of UUID (e.g. `550e8400-e29b-41d4-a716-446655440000`) occupies 36 bytes. But when numeric representation is used, it is only 128 bits (16 bytes).
Usage of `uuid` index type is recommended in payload-heavy collections to save RAM and improve search performance.
##  [](https://qdrant.tech/documentation/concepts/payload/#create-point-with-payload)Create point with payload
REST API ([Schema](https://api.qdrant.tech/api-reference/points/upsert-points))
httppythontypescriptrustjavacsharpgo
```
PUT /collections/{collection_name}/points
{
    "points": [
        {
            "id": 1,
            "vector": [0.05, 0.61, 0.76, 0.74],
            "payload": {"city": "Berlin", "price": 1.99}
        },
        {
            "id": 2,
            "vector": [0.19, 0.81, 0.75, 0.11],
            "payload": {"city": ["Berlin", "London"], "price": 1.99}
        },
        {
            "id": 3,
            "vector": [0.36, 0.55, 0.47, 0.94],
            "payload": {"city": ["Berlin", "Moscow"], "price": [1.99, 2.99]}
        }
    ]
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.upsert(
    collection_name="{collection_name}",
    points=[
        models.PointStruct(
            id=1,
            vector=[0.05, 0.61, 0.76, 0.74],
            payload={
                "city": "Berlin",
                "price": 1.99,
            },
        ),
        models.PointStruct(
            id=2,
            vector=[0.19, 0.81, 0.75, 0.11],
            payload={
                "city": ["Berlin", "London"],
                "price": 1.99,
            },
        ),
        models.PointStruct(
            id=3,
            vector=[0.36, 0.55, 0.47, 0.94],
            payload={
                "city": ["Berlin", "Moscow"],
                "price": [1.99, 2.99],
            },
        ),
    ],
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.upsert("{collection_name}", {
  points: [
    {
      id: 1,
      vector: [0.05, 0.61, 0.76, 0.74],
      payload: {
        city: "Berlin",
        price: 1.99,
      },
    },
    {
      id: 2,
      vector: [0.19, 0.81, 0.75, 0.11],
      payload: {
        city: ["Berlin", "London"],
        price: 1.99,
      },
    },
    {
      id: 3,
      vector: [0.36, 0.55, 0.47, 0.94],
      payload: {
        city: ["Berlin", "Moscow"],
        price: [1.99, 2.99],
      },
    },
  ],
});

```
```
useqdrant_client::qdrant::{PointStruct,UpsertPointsBuilder};useqdrant_client::{Payload,Qdrant,QdrantError};useserde_json::json;letclient=Qdrant::from_url("http://localhost:6334").build()?;letpoints=vec![PointStruct::new(1,vec![0.05,0.61,0.76,0.74],Payload::try_from(json!({"city": "Berlin","price": 1.99})).unwrap(),),PointStruct::new(2,vec![0.19,0.81,0.75,0.11],Payload::try_from(json!({"city": ["Berlin","London"]})).unwrap(),),PointStruct::new(3,vec![0.36,0.55,0.47,0.94],Payload::try_from(json!({"city": ["Berlin","Moscow"],"price": [1.99,2.99]})).unwrap(),),];client.upsert_points(UpsertPointsBuilder::new("{collection_name}",points).wait(true)).await?;
```
```
importjava.util.List;importjava.util.Map;import staticio.qdrant.client.PointIdFactory.id;import staticio.qdrant.client.ValueFactory.value;import staticio.qdrant.client.VectorsFactory.vectors;importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.PointStruct;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.upsertAsync("{collection_name}",List.of(PointStruct.newBuilder().setId(id(1)).setVectors(vectors(0.05f,0.61f,0.76f,0.74f)).putAllPayload(Map.of("city",value("Berlin"),"price",value(1.99))).build(),PointStruct.newBuilder().setId(id(2)).setVectors(vectors(0.19f,0.81f,0.75f,0.11f)).putAllPayload(Map.of("city",list(List.of(value("Berlin"),value("London"))))).build(),PointStruct.newBuilder().setId(id(3)).setVectors(vectors(0.36f,0.55f,0.47f,0.94f)).putAllPayload(Map.of("city",list(List.of(value("Berlin"),value("London"))),"price",list(List.of(value(1.99),value(2.99))))).build())).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.UpsertAsync(
    collectionName: "{collection_name}",
    points: new List<PointStruct>
    {
        new PointStruct
        {
            Id = 1,
            Vectors = new[] { 0.05f, 0.61f, 0.76f, 0.74f },
            Payload = { ["city"] = "Berlin", ["price"] = 1.99 }
        },
        new PointStruct
        {
            Id = 2,
            Vectors = new[] { 0.19f, 0.81f, 0.75f, 0.11f },
            Payload = { ["city"] = new[] { "Berlin", "London" } }
        },
        new PointStruct
        {
            Id = 3,
            Vectors = new[] { 0.36f, 0.55f, 0.47f, 0.94f },
            Payload =
            {
                ["city"] = new[] { "Berlin", "Moscow" },
                ["price"] = new Value
                {
                    ListValue = new ListValue { Values = { new Value[] { 1.99, 2.99 } } }
                }
            }
        }
    }
);

```
```
import (
    "context"
    "github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
    Host: "localhost",
    Port: 6334,
})
client.Upsert(context.Background(), &qdrant.UpsertPoints{
    CollectionName: "{collection_name}",
    Points: []*qdrant.PointStruct{
        {
            Id:      qdrant.NewIDNum(1),
            Vectors: qdrant.NewVectors(0.05, 0.61, 0.76, 0.74),
            Payload: qdrant.NewValueMap(map[string]any{
                "city": "Berlin", "price": 1.99}),
        },
        {
            Id:      qdrant.NewIDNum(2),
            Vectors: qdrant.NewVectors(0.19, 0.81, 0.75, 0.11),
            Payload: qdrant.NewValueMap(map[string]any{
                "city": []any{"Berlin", "London"}}),
        },
        {
            Id:      qdrant.NewIDNum(3),
            Vectors: qdrant.NewVectors(0.36, 0.55, 0.47, 0.94),
            Payload: qdrant.NewValueMap(map[string]any{
                "city":  []any{"Berlin", "London"},
                "price": []any{1.99, 2.99}}),
        },
    },
})

```
##  [](https://qdrant.tech/documentation/concepts/payload/#update-payload)Update payload
Updating payloads in Qdrant offers flexible methods to manage vector metadata. The **set payload** method updates specific fields while keeping others unchanged, while the **overwrite** method replaces the entire payload. Developers can also use **clear payload** to remove all metadata or delete fields to remove specific keys without affecting the rest. These options provide precise control for adapting to dynamic datasets.
###  [](https://qdrant.tech/documentation/concepts/payload/#set-payload)Set payload
Set only the given payload values on a point.
REST API ([Schema](https://api.qdrant.tech/api-reference/points/set-payload)):
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/payload
{
    "payload": {
        "property1": "string",
        "property2": "string"
    },
    "points": [
        0, 3, 100
    ]
}

```
```
client.set_payload(
    collection_name="{collection_name}",
    payload={
        "property1": "string",
        "property2": "string",
    },
    points=[0, 3, 10],
)

```
```
client.setPayload("{collection_name}", {
  payload: {
    property1: "string",
    property2: "string",
  },
  points: [0, 3, 10],
});

```
```
useqdrant_client::qdrant::{PointsIdsList,SetPayloadPointsBuilder,};useqdrant_client::Payload,;useserde_json::json;client.set_payload(SetPayloadPointsBuilder::new("{collection_name}",Payload::try_from(json!({"property1": "string","property2": "string",})).unwrap(),).points_selector(PointsIdsList{ids: vec![0.into(),3.into(),10.into()],}).wait(true),).await?;
```
```
importjava.util.List;importjava.util.Map;import staticio.qdrant.client.PointIdFactory.id;import staticio.qdrant.client.ValueFactory.value;client.setPayloadAsync("{collection_name}",Map.of("property1",value("string"),"property2",value("string")),List.of(id(0),id(3),id(10)),true,null,null).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.SetPayloadAsync(
    collectionName: "{collection_name}",
    payload: new Dictionary<string, Value> { { "property1", "string" }, { "property2", "string" } },
    ids: new ulong[] { 0, 3, 10 }
);

```
```
import (
    "context"
    "github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
    Host: "localhost",
    Port: 6334,
})
client.SetPayload(context.Background(), &qdrant.SetPayloadPoints{
    CollectionName: "{collection_name}",
    Payload: qdrant.NewValueMap(
        map[string]any{"property1": "string", "property2": "string"}),
    PointsSelector: qdrant.NewPointsSelector(
        qdrant.NewIDNum(0),
        qdrant.NewIDNum(3)),
})

```
You don’t need to know the ids of the points you want to modify. The alternative is to use filters.
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/payload
{
    "payload": {
        "property1": "string",
        "property2": "string"
    },
    "filter": {
        "must": [
            {
                "key": "color",
                "match": {
                    "value": "red"
                }
            }
        ]
    }
}

```
```
client.set_payload(
    collection_name="{collection_name}",
    payload={
        "property1": "string",
        "property2": "string",
    },
    points=models.Filter(
        must=[
            models.FieldCondition(
                key="color",
                match=models.MatchValue(value="red"),
            ),
        ],
    ),
)

```
```
client.setPayload("{collection_name}", {
  payload: {
    property1: "string",
    property2: "string",
  },
  filter: {
    must: [
      {
        key: "color",
        match: {
          value: "red",
        },
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,Filter,SetPayloadPointsBuilder};useqdrant_client::Payload;useserde_json::json;client.set_payload(SetPayloadPointsBuilder::new("{collection_name}",Payload::try_from(json!({"property1": "string","property2": "string",})).unwrap(),).points_selector(Filter::must([Condition::matches("color","red".to_string(),)])).wait(true),).await?;
```
```
importjava.util.Map;import staticio.qdrant.client.ConditionFactory.matchKeyword;import staticio.qdrant.client.ValueFactory.value;client.setPayloadAsync("{collection_name}",Map.of("property1",value("string"),"property2",value("string")),Filter.newBuilder().addMust(matchKeyword("color","red")).build(),true,null,null).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.SetPayloadAsync(
    collectionName: "{collection_name}",
    payload: new Dictionary<string, Value> { { "property1", "string" }, { "property2", "string" } },
    filter: MatchKeyword("color", "red")
);

```
```
import (
    "context"
    "github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
    Host: "localhost",
    Port: 6334,
})
client.SetPayload(context.Background(), &qdrant.SetPayloadPoints{
    CollectionName: "{collection_name}",
    Payload: qdrant.NewValueMap(
        map[string]any{"property1": "string", "property2": "string"}),
    PointsSelector: qdrant.NewPointsSelectorFilter(&qdrant.Filter{
        Must: []*qdrant.Condition{
            qdrant.NewMatch("color", "red"),
        },
    }),
})

```
_Available as of v1.8.0_
It is possible to modify only a specific key of the payload by using the `key` parameter.
For instance, given the following payload JSON object on a point:
```
{
    "property1": {
        "nested_property": "foo",
    },
    "property2": {
        "nested_property": "bar",
    }
}

```
You can modify the `nested_property` of `property1` with the following request:
```
POST /collections/{collection_name}/points/payload
{
    "payload": {
        "nested_property": "qux",
    },
    "key": "property1",
    "points": [1]
}

```
Resulting in the following payload:
```
{
    "property1": {
        "nested_property": "qux",
    },
    "property2": {
        "nested_property": "bar",
    }
}

```
###  [](https://qdrant.tech/documentation/concepts/payload/#overwrite-payload)Overwrite payload
Fully replace any existing payload with the given one.
REST API ([Schema](https://api.qdrant.tech/api-reference/points/overwrite-payload)):
httppythontypescriptrustjavacsharpgo
```
PUT /collections/{collection_name}/points/payload
{
    "payload": {
        "property1": "string",
        "property2": "string"
    },
    "points": [
        0, 3, 100
    ]
}

```
```
client.overwrite_payload(
    collection_name="{collection_name}",
    payload={
        "property1": "string",
        "property2": "string",
    },
    points=[0, 3, 10],
)

```
```
client.overwritePayload("{collection_name}", {
  payload: {
    property1: "string",
    property2: "string",
  },
  points: [0, 3, 10],
});

```
```
useqdrant_client::qdrant::{PointsIdsList,SetPayloadPointsBuilder};useqdrant_client::Payload;useserde_json::json;client.overwrite_payload(SetPayloadPointsBuilder::new("{collection_name}",Payload::try_from(json!({"property1": "string","property2": "string",})).unwrap(),).points_selector(PointsIdsList{ids: vec![0.into(),3.into(),10.into()],}).wait(true),).await?;
```
```
importjava.util.List;import staticio.qdrant.client.PointIdFactory.id;import staticio.qdrant.client.ValueFactory.value;client.overwritePayloadAsync("{collection_name}",Map.of("property1",value("string"),"property2",value("string")),List.of(id(0),id(3),id(10)),true,null,null).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.OverwritePayloadAsync(
    collectionName: "{collection_name}",
    payload: new Dictionary<string, Value> { { "property1", "string" }, { "property2", "string" } },
    ids: new ulong[] { 0, 3, 10 }
);

```
```
import (
    "context"
    "github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
    Host: "localhost",
    Port: 6334,
})
client.OverwritePayload(context.Background(), &qdrant.SetPayloadPoints{
    CollectionName: "{collection_name}",
    Payload: qdrant.NewValueMap(
        map[string]any{"property1": "string", "property2": "string"}),
    PointsSelector: qdrant.NewPointsSelector(
        qdrant.NewIDNum(0),
        qdrant.NewIDNum(3)),
})

```
Like [set payload](https://qdrant.tech/documentation/concepts/payload/#set-payload), you don’t need to know the ids of the points you want to modify. The alternative is to use filters.
###  [](https://qdrant.tech/documentation/concepts/payload/#clear-payload)Clear payload
This method removes all payload keys from specified points
REST API ([Schema](https://api.qdrant.tech/api-reference/points/clear-payload)):
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/payload/clear
{
    "points": [0, 3, 100]
}

```
```
client.clear_payload(
    collection_name="{collection_name}",
    points_selector=[0, 3, 100],
)

```
```
client.clearPayload("{collection_name}", {
  points: [0, 3, 100],
});

```
```
useqdrant_client::qdrant::{ClearPayloadPointsBuilder,PointsIdsList};client.clear_payload(ClearPayloadPointsBuilder::new("{collection_name}").points(PointsIdsList{ids: vec![0.into(),3.into(),10.into()],}).wait(true),).await?;
```
```
importjava.util.List;import staticio.qdrant.client.PointIdFactory.id;client.clearPayloadAsync("{collection_name}",List.of(id(0),id(3),id(100)),true,null,null).get();
```
```
using Qdrant.Client;
var client = new QdrantClient("localhost", 6334);
await client.ClearPayloadAsync(collectionName: "{collection_name}", ids: new ulong[] { 0, 3, 100 });

```
```
import (
    "context"
    "github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
    Host: "localhost",
    Port: 6334,
})
client.ClearPayload(context.Background(), &qdrant.ClearPayloadPoints{
    CollectionName: "{collection_name}",
    Points: qdrant.NewPointsSelector(
        qdrant.NewIDNum(0),
        qdrant.NewIDNum(3)),
})

```
You can also use `models.FilterSelector` to remove the points matching given filter criteria, instead of providing the ids.
###  [](https://qdrant.tech/documentation/concepts/payload/#delete-payload-keys)Delete payload keys
Delete specific payload keys from points.
REST API ([Schema](https://api.qdrant.tech/api-reference/points/delete-payload)):
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/payload/delete
{
    "keys": ["color", "price"],
    "points": [0, 3, 100]
}

```
```
client.delete_payload(
    collection_name="{collection_name}",
    keys=["color", "price"],
    points=[0, 3, 100],
)

```
```
client.deletePayload("{collection_name}", {
  keys: ["color", "price"],
  points: [0, 3, 100],
});

```
```
useqdrant_client::qdrant::{DeletePayloadPointsBuilder,PointsIdsList};client.delete_payload(DeletePayloadPointsBuilder::new("{collection_name}",vec!["color".to_string(),"price".to_string()],).points_selector(PointsIdsList{ids: vec![0.into(),3.into(),10.into()],}).wait(true),).await?;
```
```
importjava.util.List;import staticio.qdrant.client.PointIdFactory.id;client.deletePayloadAsync("{collection_name}",List.of("color","price"),List.of(id(0),id(3),id(100)),true,null,null).get();
```
```
using Qdrant.Client;
var client = new QdrantClient("localhost", 6334);
await client.DeletePayloadAsync(
    collectionName: "{collection_name}",
    keys: ["color", "price"],
    ids: new ulong[] { 0, 3, 100 }
);

```
```
import (
    "context"
    "github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
    Host: "localhost",
    Port: 6334,
})
client.DeletePayload(context.Background(), &qdrant.DeletePayloadPoints{
    CollectionName: "{collection_name}",
    Keys:           []string{"color", "price"},
    PointsSelector: qdrant.NewPointsSelector(
        qdrant.NewIDNum(0),
        qdrant.NewIDNum(3)),
})

```
Alternatively, you can use filters to delete payload keys from the points.
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/payload/delete
{
    "keys": ["color", "price"],
    "filter": {
        "must": [
            {
                "key": "color",
                "match": {
                    "value": "red"
                }
            }
        ]
    }
}

```
```
client.delete_payload(
    collection_name="{collection_name}",
    keys=["color", "price"],
    points=models.Filter(
        must=[
            models.FieldCondition(
                key="color",
                match=models.MatchValue(value="red"),
            ),
        ],
    ),
)

```
```
client.deletePayload("{collection_name}", {
  keys: ["color", "price"],
  filter: {
    must: [
      {
        key: "color",
        match: {
          value: "red",
        },
      },
    ],
  },
});

```
```
useqdrant_client::qdrant::{Condition,DeletePayloadPointsBuilder,Filter};client.delete_payload(DeletePayloadPointsBuilder::new("{collection_name}",vec!["color".to_string(),"price".to_string()],).points_selector(Filter::must([Condition::matches("color","red".to_string(),)])).wait(true),).await?;
```
```
importjava.util.List;import staticio.qdrant.client.ConditionFactory.matchKeyword;client.deletePayloadAsync("{collection_name}",List.of("color","price"),Filter.newBuilder().addMust(matchKeyword("color","red")).build(),true,null,null).get();
```
```
using Qdrant.Client;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.DeletePayloadAsync(
    collectionName: "{collection_name}",
    keys: ["color", "price"],
    filter: MatchKeyword("color", "red")
);

```
```
import (
    "context"
    "github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
    Host: "localhost",
    Port: 6334,
})
client.DeletePayload(context.Background(), &qdrant.DeletePayloadPoints{
    CollectionName: "{collection_name}",
    Keys:           []string{"color", "price"},
    PointsSelector: qdrant.NewPointsSelectorFilter(
        &qdrant.Filter{
            Must: []*qdrant.Condition{qdrant.NewMatch("color", "red")},
        },
    ),
})

```
##  [](https://qdrant.tech/documentation/concepts/payload/#payload-indexing)Payload indexing
To search more efficiently with filters, Qdrant allows you to create indexes for payload fields by specifying the name and type of field it is intended to be.
The indexed fields also affect the vector index. See [Indexing](https://qdrant.tech/documentation/concepts/indexing/) for details.
In practice, we recommend creating an index on those fields that could potentially constrain the results the most. For example, using an index for the object ID will be much more efficient, being unique for each record, than an index by its color, which has only a few possible values.
In compound queries involving multiple fields, Qdrant will attempt to use the most restrictive index first.
To create index for the field, you can use the following:
REST API ([Schema](https://api.qdrant.tech/api-reference/indexes/create-field-index))
httppythontypescriptrustjavacsharpgo
The index usage flag is displayed in the payload schema with the [collection info API](https://api.qdrant.tech/api-reference/collections/get-collection).
Payload schema example:
```
{
    "payload_schema": {
        "property1": {
            "data_type": "keyword"
        },
        "property2": {
            "data_type": "integer"
        }
    }
}

```
##  [](https://qdrant.tech/documentation/concepts/payload/#facet-counts)Facet counts
_Available as of v1.12.0_
Faceting is a special counting technique that can be used for various purposes:
  * Know which unique values exist for a payload key.
  * Know the number of points that contain each unique value.
  * Know how restrictive a filter would become by matching a specific value.
Specifically, it is a counting aggregation for the values in a field, akin to a `GROUP BY` with `COUNT(*)` commands in SQL.
These results for a specific field is called a “facet”. For example, when you look at an e-commerce search results page, you might see a list of brands on the sidebar, showing the number of products for each brand. This would be a facet for a `"brand"` field.
In Qdrant you can facet on a field **only** if you have created a field index that supports `MatchValue` conditions for it, like a `keyword` index.
To get the facet counts for a field, you can use the following:
By default, the number of `hits` returned is limited to 10. To change this, use the `limit` parameter. Keep this in mind when checking the number of unique values a payload field contains.
REST API ([Facet](https://api.qdrant.tech/v-1-13-x/api-reference/points/facet))
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/facet
{
    "key": "size",
    "filter": {
      "must": {
        "key": "color",
        "match": { "value": "red" }
      }
    }
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.facet(
    collection_name="{collection_name}",
    key="size",
    facet_filter=models.Filter(must=[models.Match("color", "red")]),
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.facet("{collection_name}", {
    filter: {
        must: [
            {
                key: "color",
                match: {
                    value: "red",
                },
            },
        ],
    },
    key: "size",
});

```
```
useqdrant_client::qdrant::{Condition,FacetCountsBuilder,Filter};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.facet(FacetCountsBuilder::new("{collection_name}","size").limit(10).filter(Filter::must(vec![Condition::matches("color","red".to_string(),)])),).await?;
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;import staticio.qdrant.client.ConditionFactory.matchKeyword;importio.qdrant.client.grpc.Points;importio.qdrant.client.grpc.Filter;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.facetAsync(Points.FacetCounts.newBuilder().setCollectionName(collection_name).setKey("size").setFilter(Filter.newBuilder().addMust(matchKeyword("color","red")).build()).build()).get();
```
```
using Qdrant.Client;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.FacetAsync(
    "{collection_name}",
    key: "size",
    filter: MatchKeyword("color", "red")
);

```
```
import (
    "context"
    "github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
    Host: "localhost",
    Port: 6334,
})
res, err := client.Facet(ctx, &qdrant.FacetCounts{
    CollectionName: "{collection_name}",
    Key:            "size",
        Filter: &qdrant.Filter{
        Must: []*qdrant.Condition{
            qdrant.NewMatch("color", "red"),
        },
    },
})

```
The response will contain the counts for each unique value in the field:
```
{
  "response": {
    "hits": [
      {"value": "L", "count": 19},
      {"value": "S", "count": 10},
      {"value": "M", "count": 5},
      {"value": "XL", "count": 1},
      {"value": "XXL", "count": 1}
    ]
  },
  "time": 0.0001
}

```
The results are sorted by the count in descending order, then by the value in ascending order. Only values with non-zero counts will be returned.
By default, the way Qdrant the counts for each value is approximate to achieve fast results. This should accurate enough for most cases, but if you need to debug your storage, you can use the `exact` parameter to get exact counts.
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/facet
{
    "key": "size",
    "exact": true
}

```
```
client.facet(
    collection_name="{collection_name}",
    key="size",
    exact=True,
)

```
```
client.facet("{collection_name}", {
    key: "size",
    exact: true,
});

```
```
useqdrant_client::qdrant::FacetCountsBuilder;client.facet(FacetCountsBuilder::new("{collection_name}","size").limit(10).exact(true),).await?;
```
```
client.facetAsync(Points.FacetCounts.newBuilder().setCollectionName(collection_name).setKey("foo").setExact(true).build()).get();
```
```
using Qdrant.Client;
await client.FacetAsync(
    "{collection_name}",
    key: "size",
    exact: true,
);

```
```
res, err := client.Facet(ctx, &qdrant.FacetCounts{
    CollectionName: "{collection_name}",
    Key:            "key",
    Exact:          true,
})

```
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/payload.md) this page on GitHub, or 
On this page:
  * [Payload](https://qdrant.tech/documentation/concepts/payload/#payload)
    * [Payload types](https://qdrant.tech/documentation/concepts/payload/#payload-types)
      * [Integer](https://qdrant.tech/documentation/concepts/payload/#integer)
      * [Float](https://qdrant.tech/documentation/concepts/payload/#float)
      * [Bool](https://qdrant.tech/documentation/concepts/payload/#bool)
      * [Keyword](https://qdrant.tech/documentation/concepts/payload/#keyword)
      * [Geo](https://qdrant.tech/documentation/concepts/payload/#geo)
      * [Datetime](https://qdrant.tech/documentation/concepts/payload/#datetime)
      * [UUID](https://qdrant.tech/documentation/concepts/payload/#uuid)
    * [Create point with payload](https://qdrant.tech/documentation/concepts/payload/#create-point-with-payload)
    * [Update payload](https://qdrant.tech/documentation/concepts/payload/#update-payload)
      * [Set payload](https://qdrant.tech/documentation/concepts/payload/#set-payload)
      * [Overwrite payload](https://qdrant.tech/documentation/concepts/payload/#overwrite-payload)
      * [Clear payload](https://qdrant.tech/documentation/concepts/payload/#clear-payload)
      * [Delete payload keys](https://qdrant.tech/documentation/concepts/payload/#delete-payload-keys)
    * [Payload indexing](https://qdrant.tech/documentation/concepts/payload/#payload-indexing)
    * [Facet counts](https://qdrant.tech/documentation/concepts/payload/#facet-counts)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/payload/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-payload-datetime.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/payload/#datetime
                    ## 📄 `https-qdrant-tech-documentation-concepts-payload-float.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/payload/#float
                    ## 📄 `https-qdrant-tech-documentation-concepts-payload-geo.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/payload/#geo
                    ## 📄 `https-qdrant-tech-documentation-concepts-payload-integer.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/payload/#integer
                    ## 📄 `https-qdrant-tech-documentation-concepts-payload-keyword.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/payload/#keyword
                    ## 📄 `https-qdrant-tech-documentation-concepts-payload-uuid.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/payload/#uuid
                    ## 📄 `https-qdrant-tech-documentation-concepts-payload.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/payload/
                    ## 📄 `https-qdrant-tech-documentation-concepts-points.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/points/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/points/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-search-query-planning.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/search/#query-planning
  * [Documentation](https://qdrant.tech/documentation/)
  * [Concepts](https://qdrant.tech/documentation/concepts/)
  * Search
#  [](https://qdrant.tech/documentation/concepts/search/#similarity-search)Similarity search
Searching for the nearest vectors is at the core of many representational learning applications. Modern neural networks are trained to transform objects into vectors so that objects close in the real world appear close in vector space. It could be, for example, texts with similar meanings, visually similar pictures, or songs of the same genre.
![This is how vector similarity works](https://qdrant.tech/docs/encoders.png)
This is how vector similarity works
##  [](https://qdrant.tech/documentation/concepts/search/#query-api)Query API
_Available as of v1.10.0_
Qdrant provides a single interface for all kinds of search and exploration requests - the `Query API`. Here is a reference list of what kind of queries you can perform with the `Query API` in Qdrant:
Depending on the `query` parameter, Qdrant might prefer different strategies for the search.
Nearest Neighbors Search | Vector Similarity Search, also known as k-NN  
---|---  
Search By Id | Search by an already stored vector - skip embedding model inference  
[Recommendations](https://qdrant.tech/documentation/concepts/explore/#recommendation-api) | Provide positive and negative examples  
[Discovery Search](https://qdrant.tech/documentation/concepts/explore/#discovery-api) | Guide the search using context as a one-shot training set  
[Scroll](https://qdrant.tech/documentation/concepts/points/#scroll-points) | Get all points with optional filtering  
[Grouping](https://qdrant.tech/documentation/concepts/search/#grouping-api) | Group results by a certain field  
[Order By](https://qdrant.tech/documentation/concepts/hybrid-queries/#re-ranking-with-stored-values) | Order points by payload key  
[Hybrid Search](https://qdrant.tech/documentation/concepts/hybrid-queries/#hybrid-search) | Combine multiple queries to get better results  
[Multi-Stage Search](https://qdrant.tech/documentation/concepts/hybrid-queries/#multi-stage-queries) | Optimize performance for large embeddings  
[Random Sampling](https://qdrant.tech/documentation/concepts/search/#random-sampling) | Get random points from the collection  
**Nearest Neighbors Search**
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query
{
    "query": [0.2, 0.1, 0.9, 0.7] // <--- Dense vector
}

```
```
client.query_points(
    collection_name="{collection_name}",
    query=[0.2, 0.1, 0.9, 0.7], # <--- Dense vector
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.query("{collection_name}", {
    query: [0.2, 0.1, 0.9, 0.7], // <--- Dense vector
});

```
```
useqdrant_client::Qdrant;useqdrant_client::qdrant::{Condition,Filter,Query,QueryPointsBuilder};letclient=Qdrant::from_url("http://localhost:6334").build()?;client.query(QueryPointsBuilder::new("{collection_name}").query(Query::new_nearest(vec![0.2,0.1,0.9,0.7]))).await?;
```
```
importjava.util.List;import staticio.qdrant.client.QueryFactory.nearest;importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.QueryPoints;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.queryAsync(QueryPoints.newBuilder().setCollectionName("{collectionName}").setQuery(nearest(List.of(0.2f,0.1f,0.9f,0.7f))).build()).get();
```
```
using Qdrant.Client;
var client = new QdrantClient("localhost", 6334);
await client.QueryAsync(
 collectionName: "{collection_name}",
 query: new float[] { 0.2f, 0.1f, 0.9f, 0.7f }
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Query(context.Background(), &qdrant.QueryPoints{
	CollectionName: "{collection_name}",
	Query:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7),
})

```
**Search By Id**
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query
{
    "query": "43cf51e2-8777-4f52-bc74-c2cbde0c8b04" // <--- point id
}

```
```
client.query_points(
    collection_name="{collection_name}",
    query="43cf51e2-8777-4f52-bc74-c2cbde0c8b04", # <--- point id
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.query("{collection_name}", {
    query: '43cf51e2-8777-4f52-bc74-c2cbde0c8b04', // <--- point id
});

```
```
useqdrant_client::Qdrant;useqdrant_client::qdrant::{Condition,Filter,PointId,Query,QueryPointsBuilder};letclient=Qdrant::from_url("http://localhost:6334").build()?;client.query(QueryPointsBuilder::new("{collection_name}").query(Query::new_nearest(PointId::new("43cf51e2-8777-4f52-bc74-c2cbde0c8b04")))).await?;
```
```
importjava.util.UUID;import staticio.qdrant.client.QueryFactory.nearest;importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.QueryPoints;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.queryAsync(QueryPoints.newBuilder().setCollectionName("{collectionName}").setQuery(nearest(UUID.fromString("43cf51e2-8777-4f52-bc74-c2cbde0c8b04"))).build()).get();
```
```
using Qdrant.Client;
var client = new QdrantClient("localhost", 6334);
await client.QueryAsync(
    collectionName: "{collection_name}",
    query: Guid.Parse("43cf51e2-8777-4f52-bc74-c2cbde0c8b04")
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Query(context.Background(), &qdrant.QueryPoints{
	CollectionName: "{collection_name}",
	Query:          qdrant.NewQueryID(qdrant.NewID("43cf51e2-8777-4f52-bc74-c2cbde0c8b04")),
})

```
##  [](https://qdrant.tech/documentation/concepts/search/#metrics)Metrics
There are many ways to estimate the similarity of vectors with each other. In Qdrant terms, these ways are called metrics. The choice of metric depends on the vectors obtained and, in particular, on the neural network encoder training method.
Qdrant supports these most popular types of metrics:
  * Dot product: `Dot` - 
  * Cosine similarity: `Cosine` - 
  * Euclidean distance: `Euclid` - 
  * Manhattan distance: `Manhattan`*- _*Available as of v1.7_
The most typical metric used in similarity learning models is the cosine metric.
![Embeddings](https://qdrant.tech/docs/cos.png)
Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step is to normalize the vector when adding it to the collection. It happens only once for each vector.
The second step is the comparison of vectors. In this case, it becomes equivalent to dot production - a very fast operation due to SIMD.
Depending on the query configuration, Qdrant might prefer different strategies for the search. Read more about it in the [query planning](https://qdrant.tech/documentation/concepts/search/#query-planning) section.
##  [](https://qdrant.tech/documentation/concepts/search/#search-api)Search API
Let’s look at an example of a search query.
REST API - API Schema definition is available [here](https://api.qdrant.tech/api-reference/search/query-points)
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query
{
    "query": [0.2, 0.1, 0.9, 0.79],
    "filter": {
        "must": [
            {
                "key": "city",
                "match": {
                    "value": "London"
                }
            }
        ]
    },
    "params": {
        "hnsw_ef": 128,
        "exact": false
    },
    "limit": 3
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.query_points(
    collection_name="{collection_name}",
    query=[0.2, 0.1, 0.9, 0.7],
    query_filter=models.Filter(
        must=[
            models.FieldCondition(
                key="city",
                match=models.MatchValue(
                    value="London",
                ),
            )
        ]
    ),
    search_params=models.SearchParams(hnsw_ef=128, exact=False),
    limit=3,
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.query("{collection_name}", {
    query: [0.2, 0.1, 0.9, 0.7],
    filter: {
        must: [
            {
                key: "city",
                match: {
                    value: "London",
                },
            },
        ],
    },
    params: {
        hnsw_ef: 128,
        exact: false,
    },
    limit: 3,
});

```
```
useqdrant_client::qdrant::{Condition,Filter,QueryPointsBuilder,SearchParamsBuilder};useqdrant_client::Qdrant;client.query(QueryPointsBuilder::new("{collection_name}").query(vec![0.2,0.1,0.9,0.7]).limit(3).filter(Filter::must([Condition::matches("city","London".to_string(),)])).params(SearchParamsBuilder::default().hnsw_ef(128).exact(false)),).await?;
```
```
importjava.util.List;import staticio.qdrant.client.ConditionFactory.matchKeyword;import staticio.qdrant.client.QueryFactory.nearest;importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.QueryPoints;importio.qdrant.client.grpc.Points.SearchParams;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.queryAsync(QueryPoints.newBuilder().setCollectionName("{collection_name}").setQuery(nearest(0.2f,0.1f,0.9f,0.7f)).setFilter(Filter.newBuilder().addMust(matchKeyword("city","London")).build()).setParams(SearchParams.newBuilder().setExact(false).setHnswEf(128).build()).setLimit(3).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
await client.QueryAsync(
    collectionName: "{collection_name}",
    query: new float[] { 0.2f, 0.1f, 0.9f, 0.7f },
    filter: MatchKeyword("city", "London"),
    searchParams: new SearchParams { Exact = false, HnswEf = 128 },
    limit: 3
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Query(context.Background(), &qdrant.QueryPoints{
	CollectionName: "{collection_name}",
	Query:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7),
	Filter: &qdrant.Filter{
		Must: []*qdrant.Condition{
			qdrant.NewMatch("city", "London"),
		},
	},
	Params: &qdrant.SearchParams{
		Exact:  qdrant.PtrOf(false),
		HnswEf: qdrant.PtrOf(uint64(128)),
	},
})

```
In this example, we are looking for vectors similar to vector `[0.2, 0.1, 0.9, 0.7]`. Parameter `limit` (or its alias - `top`) specifies the amount of most similar results we would like to retrieve.
Values under the key `params` specify custom parameters for the search. Currently, it could be:
  * `hnsw_ef` - value that specifies `ef` parameter of the HNSW algorithm.
  * `exact` - option to not use the approximate search (ANN). If set to true, the search may run for a long as it performs a full scan to retrieve exact results.
  * `indexed_only` - With this option you can disable the search in those segments where vector index is not built yet. This may be useful if you want to minimize the impact to the search performance whilst the collection is also being updated. Using this option may lead to a partial result if the collection is not fully indexed yet, consider using it only if eventual consistency is acceptable for your use case.
Since the `filter` parameter is specified, the search is performed only among those points that satisfy the filter condition. See details of possible filters and their work in the [filtering](https://qdrant.tech/documentation/concepts/filtering/) section.
Example result of this API would be
```
{
  "result": [
    { "id": 10, "score": 0.81 },
    { "id": 14, "score": 0.75 },
    { "id": 11, "score": 0.73 }
  ],
  "status": "ok",
  "time": 0.001
}

```
The `result` contains ordered by `score` list of found point ids.
Note that payload and vector data is missing in these results by default. See [payload and vector in the result](https://qdrant.tech/documentation/concepts/search/#payload-and-vector-in-the-result) on how to include it.
If the collection was created with multiple vectors, the name of the vector to use for searching should be provided:
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query
{
    "query": [0.2, 0.1, 0.9, 0.7],
    "using": "image",
    "limit": 3
}

```
```
from qdrant_client import QdrantClient
client = QdrantClient(url="http://localhost:6333")
client.query_points(
    collection_name="{collection_name}",
    query=[0.2, 0.1, 0.9, 0.7],
    using="image",
    limit=3,
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.query("{collection_name}", {
  query: [0.2, 0.1, 0.9, 0.7],
  using: "image",
  limit: 3,
});

```
```
useqdrant_client::qdrant::QueryPointsBuilder;useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.query(QueryPointsBuilder::new("{collection_name}").query(vec![0.2,0.1,0.9,0.7]).limit(3).using("image"),).await?;
```
```
importjava.util.List;importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.QueryPoints;import staticio.qdrant.client.QueryFactory.nearest;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.queryAsync(QueryPoints.newBuilder().setCollectionName("{collection_name}").setQuery(nearest(0.2f,0.1f,0.9f,0.7f)).setUsing("image").setLimit(3).build()).get();
```
```
using Qdrant.Client;
var client = new QdrantClient("localhost", 6334);
await client.QueryAsync(
	collectionName: "{collection_name}",
	query: new float[] { 0.2f, 0.1f, 0.9f, 0.7f },
	usingVector: "image",
	limit: 3
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Query(context.Background(), &qdrant.QueryPoints{
	CollectionName: "{collection_name}",
	Query:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7),
	Using:          qdrant.PtrOf("image"),
})

```
Search is processing only among vectors with the same name.
If the collection was created with sparse vectors, the name of the sparse vector to use for searching should be provided:
You can still use payload filtering and other features of the search API with sparse vectors.
There are however important differences between dense and sparse vector search:
Index | Sparse Query | Dense Query  
---|---|---  
Scoring Metric | Default is `Dot product`, no need to specify it |  `Distance` has supported metrics e.g. Dot, Cosine  
Search Type | Always exact in Qdrant | HNSW is an approximate NN  
Return Behaviour | Returns only vectors with non-zero values in the same indices as the query vector | Returns `limit` vectors  
In general, the speed of the search is proportional to the number of non-zero values in the query vector.
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query
{
    "query": {
        "indices": [1, 3, 5, 7],
        "values": [0.1, 0.2, 0.3, 0.4]
    },
    "using": "text"
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
result = client.query_points(
    collection_name="{collection_name}",
    query=models.SparseVector(indices=[1, 3, 5, 7], values=[0.1, 0.2, 0.3, 0.4]),
    using="text",
).points

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.query("{collection_name}", {
    query: {
        indices: [1, 3, 5, 7],
        values: [0.1, 0.2, 0.3, 0.4]
    },
    using: "text",
    limit: 3,
});

```
```
useqdrant_client::qdrant::QueryPointsBuilder;useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.query(QueryPointsBuilder::new("{collection_name}").query(vec![(1,0.2),(3,0.1),(5,0.9),(7,0.7)]).limit(10).using("text"),).await?;
```
```
importjava.util.List;importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.QueryPoints;import staticio.qdrant.client.QueryFactory.nearest;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.queryAsync(QueryPoints.newBuilder().setCollectionName("{collection_name}").setUsing("text").setQuery(nearest(List.of(0.1f,0.2f,0.3f,0.4f),List.of(1,3,5,7))).setLimit(3).build()).get();
```
```
using Qdrant.Client;
var client = new QdrantClient("localhost", 6334);
await client.QueryAsync(
  collectionName: "{collection_name}",
  query: new (float, uint)[] {(0.1f, 1), (0.2f, 3), (0.3f, 5), (0.4f, 7)},
  usingVector: "text",
  limit: 3
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Query(context.Background(), &qdrant.QueryPoints{
	CollectionName: "{collection_name}",
	Query: qdrant.NewQuerySparse(
		[]uint32{1, 3, 5, 7},
		[]float32{0.1, 0.2, 0.3, 0.4}),
	Using: qdrant.PtrOf("text"),
})

```
###  [](https://qdrant.tech/documentation/concepts/search/#filtering-results-by-score)Filtering results by score
In addition to payload filtering, it might be useful to filter out results with a low similarity score. For example, if you know the minimal acceptance score for your model and do not want any results which are less similar than the threshold. In this case, you can use `score_threshold` parameter of the search query. It will exclude all results with a score worse than the given.
This parameter may exclude lower or higher scores depending on the used metric. For example, higher scores of Euclidean metric are considered more distant and, therefore, will be excluded.
###  [](https://qdrant.tech/documentation/concepts/search/#payload-and-vector-in-the-result)Payload and vector in the result
By default, retrieval methods do not return any stored information such as payload and vectors. Additional parameters `with_vectors` and `with_payload` alter this behavior.
Example:
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query
{
    "query": [0.2, 0.1, 0.9, 0.7],
    "with_vectors": true,
    "with_payload": true
}

```
```
client.query_points(
    collection_name="{collection_name}",
    query=[0.2, 0.1, 0.9, 0.7],
    with_vectors=True,
    with_payload=True,
)

```
```
client.query("{collection_name}", {
  query: [0.2, 0.1, 0.9, 0.7],
  with_vector: true,
  with_payload: true,
});

```
```
useqdrant_client::qdrant::QueryPointsBuilder;useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.query(QueryPointsBuilder::new("{collection_name}").query(vec![0.2,0.1,0.9,0.7]).limit(3).with_payload(true).with_vectors(true),).await?;
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.WithVectorsSelectorFactory;importio.qdrant.client.grpc.Points.QueryPoints;import staticio.qdrant.client.QueryFactory.nearest;import staticio.qdrant.client.WithPayloadSelectorFactory.enable;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.queryAsync(QueryPoints.newBuilder().setCollectionName("{collection_name}").setQuery(nearest(0.2f,0.1f,0.9f,0.7f)).setWithPayload(enable(true)).setWithVectors(WithVectorsSelectorFactory.enable(true)).setLimit(3).build()).get();
```
```
using Qdrant.Client;
var client = new QdrantClient("localhost", 6334);
await client.QueryAsync(
	collectionName: "{collection_name}",
	query: new float[] { 0.2f, 0.1f, 0.9f, 0.7f },
	payloadSelector: true,
	vectorsSelector: true,
	limit: 3
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Query(context.Background(), &qdrant.QueryPoints{
	CollectionName: "{collection_name}",
	Query:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7),
	WithPayload:    qdrant.NewWithPayload(true),
	WithVectors:    qdrant.NewWithVectors(true),
})

```
You can use `with_payload` to scope to or filter a specific payload subset. You can even specify an array of items to include, such as `city`, `village`, and `town`:
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query
{
    "query": [0.2, 0.1, 0.9, 0.7],
    "with_payload": ["city", "village", "town"]
}

```
```
from qdrant_client import QdrantClient
client = QdrantClient(url="http://localhost:6333")
client.query_points(
    collection_name="{collection_name}",
    query=[0.2, 0.1, 0.9, 0.7],
    with_payload=["city", "village", "town"],
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.query("{collection_name}", {
  query: [0.2, 0.1, 0.9, 0.7],
  with_payload: ["city", "village", "town"],
});

```
```
useqdrant_client::qdrant::{with_payload_selector::SelectorOptions,QueryPointsBuilder};useqdrant_client::Qdrant;client.query(QueryPointsBuilder::new("{collection_name}").query(vec![0.2,0.1,0.9,0.7]).limit(3).with_payload(SelectorOptions::Include(vec!["city".to_string(),"village".to_string(),"town".to_string(),].into(),)).with_vectors(true),).await?;
```
```
importjava.util.List;importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.QueryPoints;import staticio.qdrant.client.QueryFactory.nearest;import staticio.qdrant.client.WithPayloadSelectorFactory.include;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.queryAsync(QueryPoints.newBuilder().setCollectionName("{collection_name}").setQuery(nearest(0.2f,0.1f,0.9f,0.7f)).setWithPayload(include(List.of("city","village","town"))).setLimit(3).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.QueryAsync(
    collectionName: "{collection_name}",
    query: new float[] { 0.2f, 0.1f, 0.9f, 0.7f },
    payloadSelector: new WithPayloadSelector
    {
        Include = new PayloadIncludeSelector
        {
            Fields = { new string[] { "city", "village", "town" } }
        }
    },
    limit: 3
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Query(context.Background(), &qdrant.QueryPoints{
	CollectionName: "{collection_name}",
	Query:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7),
	WithPayload:    qdrant.NewWithPayloadInclude("city", "village", "town"),
})

```
Or use `include` or `exclude` explicitly. For example, to exclude `city`:
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query
{
    "query": [0.2, 0.1, 0.9, 0.7],
    "with_payload": {
      "exclude": ["city"]
    }
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.query_points(
    collection_name="{collection_name}",
    query=[0.2, 0.1, 0.9, 0.7],
    with_payload=models.PayloadSelectorExclude(
        exclude=["city"],
    ),
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.query("{collection_name}", {
  query: [0.2, 0.1, 0.9, 0.7],
  with_payload: {
    exclude: ["city"],
  },
});

```
```
useqdrant_client::qdrant::{with_payload_selector::SelectorOptions,QueryPointsBuilder};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.query(QueryPointsBuilder::new("{collection_name}").query(vec![0.2,0.1,0.9,0.7]).limit(3).with_payload(SelectorOptions::Exclude(vec!["city".to_string()].into())).with_vectors(true),).await?;
```
```
importjava.util.List;importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.QueryPoints;import staticio.qdrant.client.QueryFactory.nearest;import staticio.qdrant.client.WithPayloadSelectorFactory.exclude;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.queryAsync(QueryPoints.newBuilder().setCollectionName("{collection_name}").setQuery(nearest(0.2f,0.1f,0.9f,0.7f)).setWithPayload(exclude(List.of("city"))).setLimit(3).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.QueryAsync(
	collectionName: "{collection_name}",
	query: new float[] { 0.2f, 0.1f, 0.9f, 0.7f },
	payloadSelector: new WithPayloadSelector
	{
		Exclude = new PayloadExcludeSelector { Fields = { new string[] { "city" } } }
	},
	limit: 3
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Query(context.Background(), &qdrant.QueryPoints{
	CollectionName: "{collection_name}",
	Query:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7),
	WithPayload:    qdrant.NewWithPayloadExclude("city"),
})

```
It is possible to target nested fields using a dot notation:
  * `payload.nested_field` - for a nested field
  * `payload.nested_array[].sub_field` - for projecting nested fields within an array
Accessing array elements by index is currently not supported.
##  [](https://qdrant.tech/documentation/concepts/search/#batch-search-api)Batch search API
The batch search API enables to perform multiple search requests via a single request.
Its semantic is straightforward, `n` batched search requests are equivalent to `n` singular search requests.
This approach has several advantages. Logically, fewer network connections are required which can be very beneficial on its own.
More importantly, batched requests will be efficiently processed via the query planner which can detect and optimize requests if they have the same `filter`.
This can have a great effect on latency for non trivial filters as the intermediary results can be shared among the request.
In order to use it, simply pack together your search requests. All the regular attributes of a search request are of course available.
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query/batch
{
    "searches": [
        {
            "query": [0.2, 0.1, 0.9, 0.7],
            "filter": {
                "must": [
                    {
                        "key": "city",
                        "match": {
                            "value": "London"
                        }
                    }
                ]
            },
            "limit": 3
        },
        {
            "query": [0.5, 0.3, 0.2, 0.3],
            "filter": {
                "must": [
                    {
                        "key": "city",
                        "match": {
                            "value": "London"
                        }
                    }
                ]
            },
            "limit": 3
        }
    ]
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
filter_ = models.Filter(
    must=[
        models.FieldCondition(
            key="city",
            match=models.MatchValue(
                value="London",
            ),
        )
    ]
)
search_queries = [
    models.QueryRequest(query=[0.2, 0.1, 0.9, 0.7], filter=filter_, limit=3),
    models.QueryRequest(query=[0.5, 0.3, 0.2, 0.3], filter=filter_, limit=3),
]
client.query_batch_points(collection_name="{collection_name}", requests=search_queries)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
const filter = {
    must: [
        {
            key: "city",
            match: {
                value: "London",
            },
        },
    ],
};
const searches = [
    {
        query: [0.2, 0.1, 0.9, 0.7],
        filter,
        limit: 3,
    },
    {
        query: [0.5, 0.3, 0.2, 0.3],
        filter,
        limit: 3,
    },
];
client.queryBatch("{collection_name}", {
    searches,
});

```
```
useqdrant_client::qdrant::{Condition,Filter,QueryBatchPointsBuilder,QueryPointsBuilder};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;letfilter=Filter::must([Condition::matches("city","London".to_string())]);letsearches=vec![QueryPointsBuilder::new("{collection_name}").query(vec![0.1,0.2,0.3,0.4]).limit(3).filter(filter.clone()).build(),QueryPointsBuilder::new("{collection_name}").query(vec![0.5,0.3,0.2,0.3]).limit(3).filter(filter).build(),];client.query_batch(QueryBatchPointsBuilder::new("{collection_name}",searches)).await?;
```
```
importjava.util.List;importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.Filter;importio.qdrant.client.grpc.Points.QueryPoints;import staticio.qdrant.client.QueryFactory.nearest;import staticio.qdrant.client.ConditionFactory.matchKeyword;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());Filterfilter=Filter.newBuilder().addMust(matchKeyword("city","London")).build();List<QueryPoints>searches=List.of(QueryPoints.newBuilder().setQuery(nearest(0.2f,0.1f,0.9f,0.7f)).setFilter(filter).setLimit(3).build(),QueryPoints.newBuilder().setQuery(nearest(0.2f,0.1f,0.9f,0.7f)).setFilter(filter).setLimit(3).build());client.queryBatchAsync("{collection_name}",searches).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
using static Qdrant.Client.Grpc.Conditions;
var client = new QdrantClient("localhost", 6334);
var filter = MatchKeyword("city", "London");
var queries = new List<QueryPoints>
{
    new()
    {
        CollectionName = "{collection_name}",
        Query = new float[] { 0.2f, 0.1f, 0.9f, 0.7f },
        Filter = filter,
        Limit = 3
    },
    new()
    {
        CollectionName = "{collection_name}",
        Query = new float[] { 0.5f, 0.3f, 0.2f, 0.3f },
        Filter = filter,
        Limit = 3
    }
};
await client.QueryBatchAsync(collectionName: "{collection_name}", queries: queries);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
filter := qdrant.Filter{
	Must: []*qdrant.Condition{
		qdrant.NewMatch("city", "London"),
	},
}
client.QueryBatch(context.Background(), &qdrant.QueryBatchPoints{
	CollectionName: "{collection_name}",
	QueryPoints: []*qdrant.QueryPoints{
		{
			CollectionName: "{collection_name}",
			Query:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7),
			Filter:         &filter,
		},
		{
			CollectionName: "{collection_name}",
			Query:          qdrant.NewQuery(0.5, 0.3, 0.2, 0.3),
			Filter:         &filter,
		},
	},
})

```
The result of this API contains one array per search requests.
```
{
  "result": [
    [
        { "id": 10, "score": 0.81 },
        { "id": 14, "score": 0.75 },
        { "id": 11, "score": 0.73 }
    ],
    [
        { "id": 1, "score": 0.92 },
        { "id": 3, "score": 0.89 },
        { "id": 9, "score": 0.75 }
    ]
  ],
  "status": "ok",
  "time": 0.001
}

```
##  [](https://qdrant.tech/documentation/concepts/search/#query-by-id)Query by ID
Whenever you need to use a vector as an input, you can always use a [point ID](https://qdrant.tech/documentation/concepts/points/#point-ids) instead.
httppythontypescriptrustjavacsharpgo
The above example will fetch the default vector from the point with this id, and use it as the query vector.
If the `using` parameter is also specified, Qdrant will use the vector with that name.
It is also possible to reference an ID from a different collection, by setting the `lookup_from` parameter.
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query
{
    "query": "43cf51e2-8777-4f52-bc74-c2cbde0c8b04", // <--- point id
    "using": "512d-vector"
    "lookup_from": {
        "collection": "another_collection", // <--- other collection name
        "vector": "image-512" // <--- vector name in the other collection
    }
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.query_points(
    collection_name="{collection_name}",
    query="43cf51e2-8777-4f52-bc74-c2cbde0c8b04",  # <--- point id
    using="512d-vector",
    lookup_from=models.LookupLocation(
        collection="another_collection",  # <--- other collection name
        vector="image-512",  # <--- vector name in the other collection
    )
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.query("{collection_name}", {
    query: '43cf51e2-8777-4f52-bc74-c2cbde0c8b04', // <--- point id
using: '512d-vector',
    lookup_from: {
        collection: 'another_collection', // <--- other collection name
vector: 'image-512', // <--- vector name in the other collection
}
});

```
```
useqdrant_client::Qdrant;useqdrant_client::qdrant::{LookupLocationBuilder,PointId,Query,QueryPointsBuilder};letclient=Qdrant::from_url("http://localhost:6334").build()?;client.query(QueryPointsBuilder::new("{collection_name}").query(Query::new_nearest("43cf51e2-8777-4f52-bc74-c2cbde0c8b04")).using("512d-vector").lookup_from(LookupLocationBuilder::new("another_collection").vector_name("image-512"))).await?;
```
```
import staticio.qdrant.client.QueryFactory.nearest;importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.LookupLocation;importio.qdrant.client.grpc.Points.QueryPoints;importjava.util.UUID;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.queryAsync(QueryPoints.newBuilder().setCollectionName("{collection_name}").setQuery(nearest(UUID.fromString("43cf51e2-8777-4f52-bc74-c2cbde0c8b04"))).setUsing("512d-vector").setLookupFrom(LookupLocation.newBuilder().setCollectionName("another_collection").setVectorName("image-512").build()).build()).get();
```
```
using Qdrant.Client;
var client = new QdrantClient("localhost", 6334);
await client.QueryAsync(
  collectionName: "{collection_name}",
  query: Guid.Parse("43cf51e2-8777-4f52-bc74-c2cbde0c8b04"), // <--- point id
  usingVector: "512d-vector",
  lookupFrom: new() {
    CollectionName = "another_collection", // <--- other collection name
      VectorName = "image-512" // <--- vector name in the other collection
  }
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Query(context.Background(), &qdrant.QueryPoints{
	CollectionName: "{collection_name}",
	Query:          qdrant.NewQueryID(qdrant.NewID("43cf51e2-8777-4f52-bc74-c2cbde0c8b04")),
	Using:          qdrant.PtrOf("512d-vector"),
	LookupFrom: &qdrant.LookupLocation{
		CollectionName: "another_collection",
		VectorName:     qdrant.PtrOf("image-512"),
	},
})

```
In the case above, Qdrant will fetch the `"image-512"` vector from the specified point id in the collection `another_collection`.
The fetched vector(s) must match the characteristics of the `using` vector, otherwise, an error will be returned.
##  [](https://qdrant.tech/documentation/concepts/search/#pagination)Pagination
Search and [recommendation](https://qdrant.tech/documentation/concepts/explore/#recommendation-api) APIs allow to skip first results of the search and return only the result starting from some specified offset:
Example:
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query
{
    "query": [0.2, 0.1, 0.9, 0.7],
    "with_vectors": true,
    "with_payload": true,
    "limit": 10,
    "offset": 100
}

```
```
from qdrant_client import QdrantClient
client = QdrantClient(url="http://localhost:6333")
client.query_points(
    collection_name="{collection_name}",
    query=[0.2, 0.1, 0.9, 0.7],
    with_vectors=True,
    with_payload=True,
    limit=10,
    offset=100,
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.query("{collection_name}", {
  query: [0.2, 0.1, 0.9, 0.7],
  with_vector: true,
  with_payload: true,
  limit: 10,
  offset: 100,
});

```
```
useqdrant_client::qdrant::QueryPointsBuilder;useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.query(QueryPointsBuilder::new("{collection_name}").query(vec![0.2,0.1,0.9,0.7]).with_payload(true).with_vectors(true).limit(10).offset(100),).await?;
```
```
importjava.util.List;importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.WithVectorsSelectorFactory;importio.qdrant.client.grpc.Points.QueryPoints;import staticio.qdrant.client.QueryFactory.nearest;import staticio.qdrant.client.WithPayloadSelectorFactory.enable;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.queryAsync(QueryPoints.newBuilder().setCollectionName("{collection_name}").setQuery(nearest(0.2f,0.1f,0.9f,0.7f)).setWithPayload(enable(true)).setWithVectors(WithVectorsSelectorFactory.enable(true)).setLimit(10).setOffset(100).build()).get();
```
```
using Qdrant.Client;
var client = new QdrantClient("localhost", 6334);
await client.QueryAsync(
    collectionName: "{collection_name}",
    query: new float[] { 0.2f, 0.1f, 0.9f, 0.7f },
    payloadSelector: true,
    vectorsSelector: true,
    limit: 10,
    offset: 100
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Query(context.Background(), &qdrant.QueryPoints{
	CollectionName: "{collection_name}",
	Query:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7),
	WithPayload:    qdrant.NewWithPayload(true),
	WithVectors:    qdrant.NewWithVectors(true),
	Offset:         qdrant.PtrOf(uint64(100)),
})

```
Is equivalent to retrieving the 11th page with 10 records per page.
Large offset values may cause performance issues
Vector-based retrieval in general and HNSW index in particular, are not designed to be paginated. It is impossible to retrieve Nth closest vector without retrieving the first N vectors first.
However, using the offset parameter saves the resources by reducing network traffic and the number of times the storage is accessed.
Using an `offset` parameter, will require to internally retrieve `offset + limit` points, but only access payload and vector from the storage those points which are going to be actually returned.
##  [](https://qdrant.tech/documentation/concepts/search/#grouping-api)Grouping API
It is possible to group results by a certain field. This is useful when you have multiple points for the same item, and you want to avoid redundancy of the same item in the results.
For example, if you have a large document split into multiple chunks, and you want to search or [recommend](https://qdrant.tech/documentation/concepts/explore/#recommendation-api) on a per-document basis, you can group the results by the document ID.
Consider having points with the following payloads:
```
[
    {
        "id": 0,
        "payload": {
            "chunk_part": 0, 
            "document_id": "a"
        },
        "vector": [0.91]
    },
    {
        "id": 1,
        "payload": {
            "chunk_part": 1, 
            "document_id": ["a", "b"]
        },
        "vector": [0.8]
    },
    {
        "id": 2,
        "payload": {
            "chunk_part": 2, 
            "document_id": "a"
        },
        "vector": [0.2]
    },
    {
        "id": 3,
        "payload": {
            "chunk_part": 0, 
            "document_id": 123
        },
        "vector": [0.79]
    },
    {
        "id": 4,
        "payload": {
            "chunk_part": 1, 
            "document_id": 123
        },
        "vector": [0.75]
    },
    {
        "id": 5,
        "payload": {
            "chunk_part": 0, 
            "document_id": -10
        },
        "vector": [0.6]
    }
]

```
With the _**groups**_ API, you will be able to get the best _N_ points for each document, assuming that the payload of the points contains the document ID. Of course there will be times where the best _N_ points cannot be fulfilled due to lack of points or a big distance with respect to the query. In every case, the `group_size` is a best-effort parameter, akin to the `limit` parameter.
###  [](https://qdrant.tech/documentation/concepts/search/#search-groups)Search groups
REST API ([Schema](https://api.qdrant.tech/api-reference/search/query-points-groups)):
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query/groups
{
    // Same as in the regular query API
    "query": [1.1],
    // Grouping parameters
    "group_by": "document_id",  // Path of the field to group by
    "limit": 4,                 // Max amount of groups
    "group_size": 2            // Max amount of points per group
}

```
```
client.query_points_groups(
    collection_name="{collection_name}",
    # Same as in the regular query_points() API
    query=[1.1],
    # Grouping parameters
    group_by="document_id",  # Path of the field to group by
    limit=4,  # Max amount of groups
    group_size=2,  # Max amount of points per group
)

```
```
client.queryGroups("{collection_name}", {
    query: [1.1],
    group_by: "document_id",
    limit: 4,
    group_size: 2,
});

```
```
useqdrant_client::qdrant::QueryPointGroupsBuilder;client.query_groups(QueryPointGroupsBuilder::new("{collection_name}","document_id").query(vec![0.2,0.1,0.9,0.7]).group_size(2u64).with_payload(true).with_vectors(true).limit(4u64),).await?;
```
```
importjava.util.List;importio.qdrant.client.grpc.Points.SearchPointGroups;client.queryGroupsAsync(QueryPointGroups.newBuilder().setCollectionName("{collection_name}").setQuery(nearest(0.2f,0.1f,0.9f,0.7f)).setGroupBy("document_id").setLimit(4).setGroupSize(2).build()).get();
```
```
using Qdrant.Client;
var client = new QdrantClient("localhost", 6334);
await client.QueryGroupsAsync(
    collectionName: "{collection_name}",
    query: new float[] { 0.2f, 0.1f, 0.9f, 0.7f },
    groupBy: "document_id",
    limit: 4,
    groupSize: 2
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.QueryGroups(context.Background(), &qdrant.QueryPointGroups{
	CollectionName: "{collection_name}",
	Query:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7),
	GroupBy:        "document_id",
	GroupSize:      qdrant.PtrOf(uint64(2)),
})

```
The output of a _**groups**_ call looks like this:
```
{
    "result": {
        "groups": [
            {
                "id": "a",
                "hits": [
                    { "id": 0, "score": 0.91 },
                    { "id": 1, "score": 0.85 }
                ]
            },
            {
                "id": "b",
                "hits": [
                    { "id": 1, "score": 0.85 }
                ]
            },
            {
                "id": 123,
                "hits": [
                    { "id": 3, "score": 0.79 },
                    { "id": 4, "score": 0.75 }
                ]
            },
            {
                "id": -10,
                "hits": [
                    { "id": 5, "score": 0.6 }
                ]
            }
        ]
    },
    "status": "ok",
    "time": 0.001
}

```
The groups are ordered by the score of the top point in the group. Inside each group the points are sorted too.
If the `group_by` field of a point is an array (e.g. `"document_id": ["a", "b"]`), the point can be included in multiple groups (e.g. `"document_id": "a"` and `document_id: "b"`).
This feature relies heavily on the `group_by` key provided. To improve performance, make sure to create a dedicated index for it.
**Limitations** :
  * Only [keyword](https://qdrant.tech/documentation/concepts/payload/#keyword) and [integer](https://qdrant.tech/documentation/concepts/payload/#integer) payload values are supported for the `group_by` parameter. Payload values with other types will be ignored.
  * At the moment, pagination is not enabled when using **groups** , so the `offset` parameter is not allowed.
###  [](https://qdrant.tech/documentation/concepts/search/#lookup-in-groups)Lookup in groups
Having multiple points for parts of the same item often introduces redundancy in the stored data. Which may be fine if the information shared by the points is small, but it can become a problem if the payload is large, because it multiplies the storage space needed to store the points by a factor of the amount of points we have per group.
One way of optimizing storage when using groups is to store the information shared by the points with the same group id in a single point in another collection. Then, when using the [**groups** API](https://qdrant.tech/documentation/concepts/search/#grouping-api), add the `with_lookup` parameter to bring the information from those points into each group.
![Group id matches point id](https://qdrant.tech/docs/lookup_id_linking.png)
Store only document-level metadata (e.g., titles, abstracts) in the lookup collection, not chunks or duplicated data.
This has the extra benefit of having a single point to update when the information shared by the points in a group changes.
For example, if you have a collection of documents, you may want to chunk them and store the points for the chunks in a separate collection, making sure that you store the point id from the document it belongs in the payload of the chunk point.
In this case, to bring the information from the documents into the chunks grouped by the document id, you can use the `with_lookup` parameter:
httppythontypescriptrustjavacsharpgo
```
POST /collections/chunks/points/query/groups
{
    // Same as in the regular query API
    "query": [1.1],
    // Grouping parameters
    "group_by": "document_id",
    "limit": 2,
    "group_size": 2,
    // Lookup parameters
    "with_lookup": {
        // Name of the collection to look up points in
        "collection": "documents",
        // Options for specifying what to bring from the payload 
        // of the looked up point, true by default
        "with_payload": ["title", "text"],
        // Options for specifying what to bring from the vector(s) 
        // of the looked up point, true by default
        "with_vectors": false
    }
}

```
```
client.query_points_groups(
    collection_name="chunks",
    # Same as in the regular search() API
    query=[1.1],
    # Grouping parameters
    group_by="document_id",  # Path of the field to group by
    limit=2,  # Max amount of groups
    group_size=2,  # Max amount of points per group
    # Lookup parameters
    with_lookup=models.WithLookup(
        # Name of the collection to look up points in
        collection="documents",
        # Options for specifying what to bring from the payload
        # of the looked up point, True by default
        with_payload=["title", "text"],
        # Options for specifying what to bring from the vector(s)
        # of the looked up point, True by default
        with_vectors=False,
    ),
)

```
```
client.queryGroups("{collection_name}", {
    query: [1.1],
    group_by: "document_id",
    limit: 2,
    group_size: 2,
    with_lookup: {
        collection: "documents",
        with_payload: ["title", "text"],
        with_vectors: false,
    },
});

```
```
useqdrant_client::qdrant::{with_payload_selector::SelectorOptions,QueryPointGroupsBuilder,WithLookupBuilder};client.query_groups(QueryPointGroupsBuilder::new("{collection_name}","document_id").query(vec![0.2,0.1,0.9,0.7]).limit(2u64).limit(2u64).with_lookup(WithLookupBuilder::new("documents").with_payload(SelectorOptions::Include(vec!["title".to_string(),"text".to_string()].into(),)).with_vectors(false),),).await?;
```
```
importjava.util.List;importio.qdrant.client.grpc.Points.QueryPointGroups;importio.qdrant.client.grpc.Points.WithLookup;import staticio.qdrant.client.QueryFactory.nearest;import staticio.qdrant.client.WithVectorsSelectorFactory.enable;import staticio.qdrant.client.WithPayloadSelectorFactory.include;client.queryGroupsAsync(QueryPointGroups.newBuilder().setCollectionName("{collection_name}").setQuery(nearest(0.2f,0.1f,0.9f,0.7f)).setGroupBy("document_id").setLimit(2).setGroupSize(2).setWithLookup(WithLookup.newBuilder().setCollection("documents").setWithPayload(include(List.of("title","text"))).setWithVectors(enable(false)).build()).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.SearchGroupsAsync(
    collectionName: "{collection_name}",
    vector: new float[] { 0.2f, 0.1f, 0.9f, 0.7f},
    groupBy: "document_id",
    limit: 2,
    groupSize: 2,
    withLookup: new WithLookup
    {
        Collection = "documents",
        WithPayload = new WithPayloadSelector
        {
            Include = new PayloadIncludeSelector { Fields = { new string[] { "title", "text" } } }
        },
        WithVectors = false
    }
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.QueryGroups(context.Background(), &qdrant.QueryPointGroups{
	CollectionName: "{collection_name}",
	Query:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7),
	GroupBy:        "document_id",
	GroupSize:      qdrant.PtrOf(uint64(2)),
	WithLookup: &qdrant.WithLookup{
		Collection:  "documents",
		WithPayload: qdrant.NewWithPayloadInclude("title", "text"),
	},
})

```
For the `with_lookup` parameter, you can also use the shorthand `with_lookup="documents"` to bring the whole payload and vector(s) without explicitly specifying it.
The looked up result will show up under `lookup` in each group.
```
{
    "result": {
        "groups": [
            {
                "id": 1,
                "hits": [
                    { "id": 0, "score": 0.91 },
                    { "id": 1, "score": 0.85 }
                ],
                "lookup": {
                    "id": 1,
                    "payload": {
                        "title": "Document A",
                        "text": "This is document A"
                    }
                }
            },
            {
                "id": 2,
                "hits": [
                    { "id": 1, "score": 0.85 }
                ],
                "lookup": {
                    "id": 2,
                    "payload": {
                        "title": "Document B",
                        "text": "This is document B"
                    }
                }
            }
        ]
    },
    "status": "ok",
    "time": 0.001
}

```
Since the lookup is done by matching directly with the point id, the lookup collection must be pre-populated with points where the `id` matches the `group_by` value (e.g., document_id) from your primary collection.
Any group id that is not an existing (and valid) point id in the lookup collection will be ignored, and the `lookup` field will be empty.
##  [](https://qdrant.tech/documentation/concepts/search/#random-sampling)Random Sampling
_Available as of v1.11.0_
In some cases it might be useful to retrieve a random sample of points from the collection. This can be useful for debugging, testing, or for providing entry points for exploration.
Random sampling API is a part of [Universal Query API](https://qdrant.tech/documentation/concepts/search/#query-api) and can be used in the same way as regular search API.
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query
{
    "query": {
        "sample": "random"
    }
}

```
```
from qdrant_client import QdrantClient, models
sampled = client.query_points(
    collection_name="{collection_name}",
    query=models.SampleQuery(sample=models.Sample.RANDOM)
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
const sampled = await client.query("{collection_name}", {
  query: {
    sample: "random",
  },
});

```
```
useqdrant_client::Qdrant;useqdrant_client::qdrant::{Query,QueryPointsBuilder};letclient=Qdrant::from_url("http://localhost:6334").build()?;letsampled=client.query(QueryPointsBuilder::new("{collection_name}").query(Query::new_sample(Sample::Random))).await?;
```
```
import staticio.qdrant.client.QueryFactory.sample;importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.QueryPoints;importio.qdrant.client.grpc.Points.Sample;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.queryAsync(QueryPoints.newBuilder().setCollectionName("{collection_name}").setQuery(sample(Sample.Random)).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.QueryAsync(collectionName: "{collection_name}", query: Sample.Random);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.QueryGroups(context.Background(), &qdrant.QueryPointGroups{
	CollectionName: "{collection_name}",
	Query:          qdrant.NewQuerySample(qdrant.Sample_Random),
})

```
##  [](https://qdrant.tech/documentation/concepts/search/#query-planning)Query planning
Depending on the filter used in the search - there are several possible scenarios for query execution. Qdrant chooses one of the query execution options depending on the available indexes, the complexity of the conditions and the cardinality of the filtering result. This process is called query planning.
The strategy selection process relies heavily on heuristics and can vary from release to release. However, the general principles are:
  * planning is performed for each segment independently (see [storage](https://qdrant.tech/documentation/concepts/storage/) for more information about segments)
  * prefer a full scan if the amount of points is below a threshold
  * estimate the cardinality of a filtered result before selecting a strategy
  * retrieve points using payload index (see [indexing](https://qdrant.tech/documentation/concepts/indexing/)) if cardinality is below threshold
  * use filterable vector index if the cardinality is above a threshold
You can adjust the threshold using a 
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/search.md) this page on GitHub, or 
On this page:
  * [Similarity search](https://qdrant.tech/documentation/concepts/search/#similarity-search)
    * [Query API](https://qdrant.tech/documentation/concepts/search/#query-api)
    * [Metrics](https://qdrant.tech/documentation/concepts/search/#metrics)
    * [Search API](https://qdrant.tech/documentation/concepts/search/#search-api)
      * [Filtering results by score](https://qdrant.tech/documentation/concepts/search/#filtering-results-by-score)
      * [Payload and vector in the result](https://qdrant.tech/documentation/concepts/search/#payload-and-vector-in-the-result)
    * [Batch search API](https://qdrant.tech/documentation/concepts/search/#batch-search-api)
    * [Query by ID](https://qdrant.tech/documentation/concepts/search/#query-by-id)
    * [Pagination](https://qdrant.tech/documentation/concepts/search/#pagination)
    * [Grouping API](https://qdrant.tech/documentation/concepts/search/#grouping-api)
      * [Search groups](https://qdrant.tech/documentation/concepts/search/#search-groups)
      * [Lookup in groups](https://qdrant.tech/documentation/concepts/search/#lookup-in-groups)
    * [Random Sampling](https://qdrant.tech/documentation/concepts/search/#random-sampling)
    * [Query planning](https://qdrant.tech/documentation/concepts/search/#query-planning)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/search/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-search.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/search/
                    ## 📄 `https-qdrant-tech-documentation-concepts-snapshots.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/snapshots/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/snapshots/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-storage.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/storage/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/storage/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-vectors.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/vectors/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/vectors/)
                    ## 📄 `https-qdrant-tech-documentation-concepts.md`
                    ```md
                    # https://qdrant.tech/documentation/concepts/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/)
                    ## 📄 `https-qdrant-tech-documentation-database-tutorials-async-api.md`
                    ```md
                    # https://qdrant.tech/documentation/database-tutorials/async-api/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/database-tutorials/async-api/)
                    ## 📄 `https-qdrant-tech-documentation-database-tutorials-automate-filtering-with-llms.md`
                    ```md
                    # https://qdrant.tech/documentation/database-tutorials/automate-filtering-with-llms/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/database-tutorials/automate-filtering-with-llms/)
                    ## 📄 `https-qdrant-tech-documentation-database-tutorials-bulk-upload.md`
                    ```md
                    # https://qdrant.tech/documentation/database-tutorials/bulk-upload/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/database-tutorials/bulk-upload/)
                    ## 📄 `https-qdrant-tech-documentation-database-tutorials-create-snapshot.md`
                    ```md
                    # https://qdrant.tech/documentation/database-tutorials/create-snapshot/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/database-tutorials/create-snapshot/)
                    ## 📄 `https-qdrant-tech-documentation-database-tutorials-huggingface-datasets.md`
                    ```md
                    # https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/)
                    ## 📄 `https-qdrant-tech-documentation-database-tutorials-large-scale-search.md`
                    ```md
                    # https://qdrant.tech/documentation/database-tutorials/large-scale-search/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/database-tutorials/large-scale-search/)
                    ## 📄 `https-qdrant-tech-documentation-database-tutorials.md`
                    ```md
                    # https://qdrant.tech/documentation/database-tutorials/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/database-tutorials/)
                    ## 📄 `https-qdrant-tech-documentation-embeddings.md`
                    ```md
                    # https://qdrant.tech/documentation/embeddings/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/embeddings/)
                    ## 📄 `https-qdrant-tech-documentation-faq-database-optimization.md`
                    ```md
                    # https://qdrant.tech/documentation/faq/database-optimization/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/faq/database-optimization/)
                    ## 📄 `https-qdrant-tech-documentation-faq-qdrant-fundamentals.md`
                    ```md
                    # https://qdrant.tech/documentation/faq/qdrant-fundamentals/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)
                    ## 📄 `https-qdrant-tech-documentation-frameworks-autogen.md`
                    ```md
                    # https://qdrant.tech/documentation/frameworks/autogen/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/frameworks/autogen/)
                    ## 📄 `https-qdrant-tech-documentation-frameworks-crewai.md`
                    ```md
                    # https://qdrant.tech/documentation/frameworks/crewai/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/frameworks/crewai/)
                    ## 📄 `https-qdrant-tech-documentation-frameworks-langgraph.md`
                    ```md
                    # https://qdrant.tech/documentation/frameworks/langgraph/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/frameworks/langgraph/)
                    ## 📄 `https-qdrant-tech-documentation-frameworks-swarm.md`
                    ```md
                    # https://qdrant.tech/documentation/frameworks/swarm/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/frameworks/swarm/)
                    ## 📄 `https-qdrant-tech-documentation-frameworks.md`
                    ```md
                    # https://qdrant.tech/documentation/frameworks/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/frameworks/)
                    ## 📄 `https-qdrant-tech-documentation-guides-administration.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/administration/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/administration/)
                    ## 📄 `https-qdrant-tech-documentation-guides-capacity-planning.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/capacity-planning/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/capacity-planning/)
                    ## 📄 `https-qdrant-tech-documentation-guides-common-errors.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/common-errors/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/common-errors/)
                    ## 📄 `https-qdrant-tech-documentation-guides-configuration.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/configuration/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/configuration/)
                    ## 📄 `https-qdrant-tech-documentation-guides-distributed-deployment.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/distributed_deployment/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/distributed_deployment/)
                    ## 📄 `https-qdrant-tech-documentation-guides-installation.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/installation/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/installation/)
                    ## 📄 `https-qdrant-tech-documentation-guides-monitoring.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/monitoring/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/monitoring/)
                    ## 📄 `https-qdrant-tech-documentation-guides-multiple-partitions.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/multiple-partitions/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/multiple-partitions/)
                    ## 📄 `https-qdrant-tech-documentation-guides-optimize.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/optimize/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/optimize/)
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-accuracy-tuning.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/quantization/#accuracy-tuning
  * [Documentation](https://qdrant.tech/documentation/)
  * [Guides](https://qdrant.tech/documentation/guides/)
  * Quantization
#  [](https://qdrant.tech/documentation/guides/quantization/#quantization)Quantization
Quantization is an optional feature in Qdrant that enables efficient storage and search of high-dimensional vectors. By transforming original vectors into a new representations, quantization compresses data while preserving close to original relative distances between vectors. Different quantization methods have different mechanics and tradeoffs. We will cover them in this section.
Quantization is primarily used to reduce the memory footprint and accelerate the search process in high-dimensional vector spaces. In the context of the Qdrant, quantization allows you to optimize the search engine for specific use cases, striking a balance between accuracy, storage efficiency, and search speed.
There are tradeoffs associated with quantization. On the one hand, quantization allows for significant reductions in storage requirements and faster search times. This can be particularly beneficial in large-scale applications where minimizing the use of resources is a top priority. On the other hand, quantization introduces an approximation error, which can lead to a slight decrease in search quality. The level of this tradeoff depends on the quantization method and its parameters, as well as the characteristics of the data.
##  [](https://qdrant.tech/documentation/guides/quantization/#scalar-quantization)Scalar Quantization
_Available as of v1.1.0_
Scalar quantization, in the context of vector search engines, is a compression technique that compresses vectors by reducing the number of bits used to represent each vector component.
For instance, Qdrant uses 32-bit floating numbers to represent the original vector components. Scalar quantization allows you to reduce the number of bits used to 8. In other words, Qdrant performs `float32 -> uint8` conversion for each vector component. Effectively, this means that the amount of memory required to store a vector is reduced by a factor of 4.
In addition to reducing the memory footprint, scalar quantization also speeds up the search process. Qdrant uses a special SIMD CPU instruction to perform fast vector comparison. This instruction works with 8-bit integers, so the conversion to `uint8` allows Qdrant to perform the comparison faster.
The main drawback of scalar quantization is the loss of accuracy. The `float32 -> uint8` conversion introduces an error that can lead to a slight decrease in search quality. However, this error is usually negligible, and tends to be less significant for high-dimensional vectors. In our experiments, we found that the error introduced by scalar quantization is usually less than 1%.
However, this value depends on the data and the quantization parameters. Please refer to the [Quantization Tips](https://qdrant.tech/documentation/guides/quantization/#quantization-tips) section for more information on how to optimize the quantization parameters for your use case.
##  [](https://qdrant.tech/documentation/guides/quantization/#binary-quantization)Binary Quantization
_Available as of v1.5.0_
Binary quantization is an extreme case of scalar quantization. This feature lets you represent each vector component as a single bit, effectively reducing the memory footprint by a **factor of 32**.
This is the fastest quantization method, since it lets you perform a vector comparison with a few CPU instructions.
Binary quantization can achieve up to a **40x** speedup compared to the original vectors.
However, binary quantization is only efficient for high-dimensional vectors and require a centered distribution of vector components.
At the moment, binary quantization shows good accuracy results with the following models:
  * OpenAI `text-embedding-ada-002` - 1536d tested with 
  * Cohere AI `embed-english-v2.0` - 4096d tested on Wikipedia embeddings - 0.98 recall@50 with 2x oversampling
Models with a lower dimensionality or a different distribution of vector components may require additional experiments to find the optimal quantization parameters.
We recommend using binary quantization only with rescoring enabled, as it can significantly improve the search quality with just a minor performance impact. Additionally, oversampling can be used to tune the tradeoff between search speed and search quality in the query time.
###  [](https://qdrant.tech/documentation/guides/quantization/#binary-quantization-as-hamming-distance)Binary Quantization as Hamming Distance
The additional benefit of this method is that you can efficiently emulate Hamming distance with dot product.
Specifically, if original vectors contain `{-1, 1}` as possible values, then the dot product of two vectors is equal to the Hamming distance by simply replacing `-1` with `0` and `1` with `1`.
**Sample truth table**
Vector 1 | Vector 2 | Dot product  
---|---|---  
1 | 1 | 1  
1 | -1 | -1  
-1 | 1 | -1  
-1 | -1 | 1  
Vector 1 | Vector 2 | Hamming distance  
---|---|---  
1 | 1 | 0  
1 | 0 | 1  
0 | 1 | 1  
0 | 0 | 0  
As you can see, both functions are equal up to a constant factor, which makes similarity search equivalent. Binary quantization makes it efficient to compare vectors using this representation.
##  [](https://qdrant.tech/documentation/guides/quantization/#product-quantization)Product Quantization
_Available as of v1.2.0_
Product quantization is a method of compressing vectors to minimize their memory usage by dividing them into chunks and quantizing each segment individually. Each chunk is approximated by a centroid index that represents the original vector component. The positions of the centroids are determined through the utilization of a clustering algorithm such as k-means. For now, Qdrant uses only 256 centroids, so each centroid index can be represented by a single byte.
Product quantization can compress by a more prominent factor than a scalar one. But there are some tradeoffs. Product quantization distance calculations are not SIMD-friendly, so it is slower than scalar quantization. Also, product quantization has a loss of accuracy, so it is recommended to use it only for high-dimensional vectors.
Please refer to the [Quantization Tips](https://qdrant.tech/documentation/guides/quantization/#quantization-tips) section for more information on how to optimize the quantization parameters for your use case.
##  [](https://qdrant.tech/documentation/guides/quantization/#how-to-choose-the-right-quantization-method)How to choose the right quantization method
Here is a brief table of the pros and cons of each quantization method:
Quantization method | Accuracy | Speed | Compression  
---|---|---|---  
Scalar | 0.99 | up to x2 | 4  
Product | 0.7 | 0.5 | up to 64  
Binary | 0.95* | up to x40 | 32  
`*` - for compatible models
  * **Binary Quantization** is the fastest method and the most memory-efficient, but it requires a centered distribution of vector components. It is recommended to use with tested models only.
  * **Scalar Quantization** is the most universal method, as it provides a good balance between accuracy, speed, and compression. It is recommended as default quantization if binary quantization is not applicable.
  * **Product Quantization** may provide a better compression ratio, but it has a significant loss of accuracy and is slower than scalar quantization. It is recommended if the memory footprint is the top priority and the search speed is not critical.
##  [](https://qdrant.tech/documentation/guides/quantization/#setting-up-quantization-in-qdrant)Setting up Quantization in Qdrant
You can configure quantization for a collection by specifying the quantization parameters in the `quantization_config` section of the collection configuration.
Quantization will be automatically applied to all vectors during the indexation process. Quantized vectors are stored alongside the original vectors in the collection, so you will still have access to the original vectors if you need them.
_Available as of v1.1.1_
The `quantization_config` can also be set on a per vector basis by specifying it in a named vector.
###  [](https://qdrant.tech/documentation/guides/quantization/#setting-up-scalar-quantization)Setting up Scalar Quantization
To enable scalar quantization, you need to specify the quantization parameters in the `quantization_config` section of the collection configuration.
When enabling scalar quantization on an existing collection, use a PATCH request or the corresponding `update_collection` method and omit the vector configuration, as it’s already defined.
httppythontypescriptrustjavacsharpgo
```
PUT /collections/{collection_name}
{
    "vectors": {
      "size": 768,
      "distance": "Cosine"
    },
    "quantization_config": {
        "scalar": {
            "type": "int8",
            "quantile": 0.99,
            "always_ram": true
        }
    }
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.create_collection(
    collection_name="{collection_name}",
    vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE),
    quantization_config=models.ScalarQuantization(
        scalar=models.ScalarQuantizationConfig(
            type=models.ScalarType.INT8,
            quantile=0.99,
            always_ram=True,
        ),
    ),
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.createCollection("{collection_name}", {
  vectors: {
    size: 768,
    distance: "Cosine",
  },
  quantization_config: {
    scalar: {
      type: "int8",
      quantile: 0.99,
      always_ram: true,
    },
  },
});

```
```
useqdrant_client::qdrant::{CreateCollectionBuilder,Distance,QuantizationType,ScalarQuantizationBuilder,VectorParamsBuilder,};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.create_collection(CreateCollectionBuilder::new("{collection_name}").vectors_config(VectorParamsBuilder::new(768,Distance::Cosine)).quantization_config(ScalarQuantizationBuilder::default().r#type(QuantizationType::Int8.into()).quantile(0.99).always_ram(true),),).await?;
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Collections.CreateCollection;importio.qdrant.client.grpc.Collections.Distance;importio.qdrant.client.grpc.Collections.QuantizationConfig;importio.qdrant.client.grpc.Collections.QuantizationType;importio.qdrant.client.grpc.Collections.ScalarQuantization;importio.qdrant.client.grpc.Collections.VectorParams;importio.qdrant.client.grpc.Collections.VectorsConfig;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.createCollectionAsync(CreateCollection.newBuilder().setCollectionName("{collection_name}").setVectorsConfig(VectorsConfig.newBuilder().setParams(VectorParams.newBuilder().setSize(768).setDistance(Distance.Cosine).build()).build()).setQuantizationConfig(QuantizationConfig.newBuilder().setScalar(ScalarQuantization.newBuilder().setType(QuantizationType.Int8).setQuantile(0.99f).setAlwaysRam(true).build()).build()).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.CreateCollectionAsync(
 collectionName: "{collection_name}",
 vectorsConfig: new VectorParams { Size = 768, Distance = Distance.Cosine },
 quantizationConfig: new QuantizationConfig
 {
  Scalar = new ScalarQuantization
  {
   Type = QuantizationType.Int8,
   Quantile = 0.99f,
   AlwaysRam = true
  }
 }
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.CreateCollection(context.Background(), &qdrant.CreateCollection{
	CollectionName: "{collection_name}",
	VectorsConfig: qdrant.NewVectorsConfig(&qdrant.VectorParams{
		Size:     768,
		Distance: qdrant.Distance_Cosine,
	}),
	QuantizationConfig: qdrant.NewQuantizationScalar(
		&qdrant.ScalarQuantization{
            Type:      qdrant.QuantizationType_Int8,
			Quantile:  qdrant.PtrOf(float32(0.99)),
			AlwaysRam: qdrant.PtrOf(true),
		},
	),
})

```
There are 3 parameters that you can specify in the `quantization_config` section:
`type` - the type of the quantized vector components. Currently, Qdrant supports only `int8`.
`quantile` - the quantile of the quantized vector components. The quantile is used to calculate the quantization bounds. For instance, if you specify `0.99` as the quantile, 1% of extreme values will be excluded from the quantization bounds.
Using quantiles lower than `1.0` might be useful if there are outliers in your vector components. This parameter only affects the resulting precision and not the memory footprint. It might be worth tuning this parameter if you experience a significant decrease in search quality.
`always_ram` - whether to keep quantized vectors always cached in RAM or not. By default, quantized vectors are loaded in the same way as the original vectors. However, in some setups you might want to keep quantized vectors in RAM to speed up the search process.
In this case, you can set `always_ram` to `true` to store quantized vectors in RAM.
###  [](https://qdrant.tech/documentation/guides/quantization/#setting-up-binary-quantization)Setting up Binary Quantization
To enable binary quantization, you need to specify the quantization parameters in the `quantization_config` section of the collection configuration.
When enabling binary quantization on an existing collection, use a PATCH request or the corresponding `update_collection` method and omit the vector configuration, as it’s already defined.
httppythontypescriptrustjavacsharpgo
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.create_collection(
    collection_name="{collection_name}",
    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE),
    quantization_config=models.BinaryQuantization(
        binary=models.BinaryQuantizationConfig(
            always_ram=True,
        ),
    ),
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.createCollection("{collection_name}", {
  vectors: {
    size: 1536,
    distance: "Cosine",
  },
  quantization_config: {
    binary: {
      always_ram: true,
    },
  },
});

```
```
useqdrant_client::qdrant::{BinaryQuantizationBuilder,CreateCollectionBuilder,Distance,VectorParamsBuilder,};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.create_collection(CreateCollectionBuilder::new("{collection_name}").vectors_config(VectorParamsBuilder::new(1536,Distance::Cosine)).quantization_config(BinaryQuantizationBuilder::new(true)),).await?;
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Collections.BinaryQuantization;importio.qdrant.client.grpc.Collections.CreateCollection;importio.qdrant.client.grpc.Collections.Distance;importio.qdrant.client.grpc.Collections.QuantizationConfig;importio.qdrant.client.grpc.Collections.VectorParams;importio.qdrant.client.grpc.Collections.VectorsConfig;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.createCollectionAsync(CreateCollection.newBuilder().setCollectionName("{collection_name}").setVectorsConfig(VectorsConfig.newBuilder().setParams(VectorParams.newBuilder().setSize(1536).setDistance(Distance.Cosine).build()).build()).setQuantizationConfig(QuantizationConfig.newBuilder().setBinary(BinaryQuantization.newBuilder().setAlwaysRam(true).build()).build()).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.CreateCollectionAsync(
 collectionName: "{collection_name}",
 vectorsConfig: new VectorParams { Size = 1536, Distance = Distance.Cosine },
 quantizationConfig: new QuantizationConfig
 {
  Binary = new BinaryQuantization { AlwaysRam = true }
 }
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.CreateCollection(context.Background(), &qdrant.CreateCollection{
	CollectionName: "{collection_name}",
	VectorsConfig: qdrant.NewVectorsConfig(&qdrant.VectorParams{
		Size:     1536,
		Distance: qdrant.Distance_Cosine,
	}),
	QuantizationConfig: qdrant.NewQuantizationBinary(
		&qdrant.BinaryQuantization{
			AlwaysRam: qdrant.PtrOf(true),
		},
	),
})

```
`always_ram` - whether to keep quantized vectors always cached in RAM or not. By default, quantized vectors are loaded in the same way as the original vectors. However, in some setups you might want to keep quantized vectors in RAM to speed up the search process.
In this case, you can set `always_ram` to `true` to store quantized vectors in RAM.
###  [](https://qdrant.tech/documentation/guides/quantization/#setting-up-product-quantization)Setting up Product Quantization
To enable product quantization, you need to specify the quantization parameters in the `quantization_config` section of the collection configuration.
When enabling product quantization on an existing collection, use a PATCH request or the corresponding `update_collection` method and omit the vector configuration, as it’s already defined.
httppythontypescriptrustjavacsharpgo
```
PUT /collections/{collection_name}
{
    "vectors": {
      "size": 768,
      "distance": "Cosine"
    },
    "quantization_config": {
        "product": {
            "compression": "x16",
            "always_ram": true
        }
    }
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.create_collection(
    collection_name="{collection_name}",
    vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE),
    quantization_config=models.ProductQuantization(
        product=models.ProductQuantizationConfig(
            compression=models.CompressionRatio.X16,
            always_ram=True,
        ),
    ),
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.createCollection("{collection_name}", {
  vectors: {
    size: 768,
    distance: "Cosine",
  },
  quantization_config: {
    product: {
      compression: "x16",
      always_ram: true,
    },
  },
});

```
```
useqdrant_client::qdrant::{CompressionRatio,CreateCollectionBuilder,Distance,ProductQuantizationBuilder,VectorParamsBuilder,};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.create_collection(CreateCollectionBuilder::new("{collection_name}").vectors_config(VectorParamsBuilder::new(768,Distance::Cosine)).quantization_config(ProductQuantizationBuilder::new(CompressionRatio::X16.into()).always_ram(true),),).await?;
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Collections.CompressionRatio;importio.qdrant.client.grpc.Collections.CreateCollection;importio.qdrant.client.grpc.Collections.Distance;importio.qdrant.client.grpc.Collections.ProductQuantization;importio.qdrant.client.grpc.Collections.QuantizationConfig;importio.qdrant.client.grpc.Collections.VectorParams;importio.qdrant.client.grpc.Collections.VectorsConfig;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.createCollectionAsync(CreateCollection.newBuilder().setCollectionName("{collection_name}").setVectorsConfig(VectorsConfig.newBuilder().setParams(VectorParams.newBuilder().setSize(768).setDistance(Distance.Cosine).build()).build()).setQuantizationConfig(QuantizationConfig.newBuilder().setProduct(ProductQuantization.newBuilder().setCompression(CompressionRatio.x16).setAlwaysRam(true).build()).build()).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.CreateCollectionAsync(
 collectionName: "{collection_name}",
 vectorsConfig: new VectorParams { Size = 768, Distance = Distance.Cosine },
 quantizationConfig: new QuantizationConfig
 {
  Product = new ProductQuantization { Compression = CompressionRatio.X16, AlwaysRam = true }
 }
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.CreateCollection(context.Background(), &qdrant.CreateCollection{
	CollectionName: "{collection_name}",
	VectorsConfig: qdrant.NewVectorsConfig(&qdrant.VectorParams{
		Size:     768,
		Distance: qdrant.Distance_Cosine,
	}),
	QuantizationConfig: qdrant.NewQuantizationProduct(
		&qdrant.ProductQuantization{
			Compression: qdrant.CompressionRatio_x16,
			AlwaysRam:   qdrant.PtrOf(true),
		},
	),
})

```
There are two parameters that you can specify in the `quantization_config` section:
`compression` - compression ratio. Compression ratio represents the size of the quantized vector in bytes divided by the size of the original vector in bytes. In this case, the quantized vector will be 16 times smaller than the original vector.
`always_ram` - whether to keep quantized vectors always cached in RAM or not. By default, quantized vectors are loaded in the same way as the original vectors. However, in some setups you might want to keep quantized vectors in RAM to speed up the search process. Then set `always_ram` to `true`.
###  [](https://qdrant.tech/documentation/guides/quantization/#searching-with-quantization)Searching with Quantization
Once you have configured quantization for a collection, you don’t need to do anything extra to search with quantization. Qdrant will automatically use quantized vectors if they are available.
However, there are a few options that you can use to control the search process:
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query
{
    "query": [0.2, 0.1, 0.9, 0.7],
    "params": {
        "quantization": {
            "ignore": false,
            "rescore": true,
            "oversampling": 2.0
        }
    },
    "limit": 10
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.query_points(
    collection_name="{collection_name}",
    query=[0.2, 0.1, 0.9, 0.7],
    search_params=models.SearchParams(
        quantization=models.QuantizationSearchParams(
            ignore=False,
            rescore=True,
            oversampling=2.0,
        )
    ),
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.query("{collection_name}", {
    query: [0.2, 0.1, 0.9, 0.7],
    params: {
        quantization: {
            ignore: false,
            rescore: true,
            oversampling: 2.0,
        },
    },
    limit: 10,
});

```
```
useqdrant_client::qdrant::{QuantizationSearchParamsBuilder,QueryPointsBuilder,SearchParamsBuilder,};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.query(QueryPointsBuilder::new("{collection_name}").query(vec![0.2,0.1,0.9,0.7]).limit(10).params(SearchParamsBuilder::default().quantization(QuantizationSearchParamsBuilder::default().ignore(false).rescore(true).oversampling(2.0),),),).await?;
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.QuantizationSearchParams;importio.qdrant.client.grpc.Points.QueryPoints;importio.qdrant.client.grpc.Points.SearchParams;import staticio.qdrant.client.QueryFactory.nearest;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.queryAsync(QueryPoints.newBuilder().setCollectionName("{collection_name}").setQuery(nearest(0.2f,0.1f,0.9f,0.7f)).setParams(SearchParams.newBuilder().setQuantization(QuantizationSearchParams.newBuilder().setIgnore(false).setRescore(true).setOversampling(2.0).build()).build()).setLimit(10).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.QueryAsync(
	collectionName: "{collection_name}",
	query: new float[] { 0.2f, 0.1f, 0.9f, 0.7f },
	searchParams: new SearchParams
	{
		Quantization = new QuantizationSearchParams
		{
			Ignore = false,
			Rescore = true,
			Oversampling = 2.0
		}
	},
	limit: 10
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Query(context.Background(), &qdrant.QueryPoints{
	CollectionName: "{collection_name}",
	Query:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7),
	Params: &qdrant.SearchParams{
		Quantization: &qdrant.QuantizationSearchParams{
			Ignore:       qdrant.PtrOf(false),
			Rescore:      qdrant.PtrOf(true),
			Oversampling: qdrant.PtrOf(2.0),
		},
	},
})

```
`ignore` - Toggle whether to ignore quantized vectors during the search process. By default, Qdrant will use quantized vectors if they are available.
`rescore` - Having the original vectors available, Qdrant can re-evaluate top-k search results using the original vectors. This can improve the search quality, but may slightly decrease the search speed, compared to the search without rescore. It is recommended to disable rescore only if the original vectors are stored on a slow storage (e.g. HDD or network storage). By default, rescore is enabled.
**Available as of v1.3.0**
`oversampling` - Defines how many extra vectors should be pre-selected using quantized index, and then re-scored using original vectors. For example, if oversampling is 2.4 and limit is 100, then 240 vectors will be pre-selected using quantized index, and then top-100 will be returned after re-scoring. Oversampling is useful if you want to tune the tradeoff between search speed and search quality in the query time.
##  [](https://qdrant.tech/documentation/guides/quantization/#quantization-tips)Quantization tips
####  [](https://qdrant.tech/documentation/guides/quantization/#accuracy-tuning)Accuracy tuning
In this section, we will discuss how to tune the search precision. The fastest way to understand the impact of quantization on the search quality is to compare the search results with and without quantization.
In order to disable quantization, you can set `ignore` to `true` in the search request:
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query
{
    "query": [0.2, 0.1, 0.9, 0.7],
    "params": {
        "quantization": {
            "ignore": true
        }
    },
    "limit": 10
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.query_points(
    collection_name="{collection_name}",
    query=[0.2, 0.1, 0.9, 0.7],
    search_params=models.SearchParams(
        quantization=models.QuantizationSearchParams(
            ignore=True,
        )
    ),
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.query("{collection_name}", {
    query: [0.2, 0.1, 0.9, 0.7],
    params: {
        quantization: {
            ignore: true,
        },
    },
});

```
```
useqdrant_client::qdrant::{QuantizationSearchParamsBuilder,QueryPointsBuilder,SearchParamsBuilder,};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.query(QueryPointsBuilder::new("{collection_name}").query(vec![0.2,0.1,0.9,0.7]).limit(3).params(SearchParamsBuilder::default().quantization(QuantizationSearchParamsBuilder::default().ignore(true)),),).await?;
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.QuantizationSearchParams;importio.qdrant.client.grpc.Points.QueryPoints;importio.qdrant.client.grpc.Points.SearchParams;import staticio.qdrant.client.QueryFactory.nearest;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.queryAsync(QueryPoints.newBuilder().setCollectionName("{collection_name}").setQuery(nearest(0.2f,0.1f,0.9f,0.7f)).setParams(SearchParams.newBuilder().setQuantization(QuantizationSearchParams.newBuilder().setIgnore(true).build()).build()).setLimit(10).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.QueryAsync(
	collectionName: "{collection_name}",
	query: new float[] { 0.2f, 0.1f, 0.9f, 0.7f },
	searchParams: new SearchParams
	{
		Quantization = new QuantizationSearchParams { Ignore = true }
	},
	limit: 10
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Query(context.Background(), &qdrant.QueryPoints{
	CollectionName: "{collection_name}",
	Query:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7),
	Params: &qdrant.SearchParams{
		Quantization: &qdrant.QuantizationSearchParams{
			Ignore: qdrant.PtrOf(false),
		},
	},
})

```
  * **Adjust the quantile parameter** : The quantile parameter in scalar quantization determines the quantization bounds. By setting it to a value lower than 1.0, you can exclude extreme values (outliers) from the quantization bounds. For example, if you set the quantile to 0.99, 1% of the extreme values will be excluded. By adjusting the quantile, you find an optimal value that will provide the best search quality for your collection.
  * **Enable rescore** : Having the original vectors available, Qdrant can re-evaluate top-k search results using the original vectors. On large collections, this can improve the search quality, with just minor performance impact.
####  [](https://qdrant.tech/documentation/guides/quantization/#memory-and-speed-tuning)Memory and speed tuning
In this section, we will discuss how to tune the memory and speed of the search process with quantization.
There are 3 possible modes to place storage of vectors within the qdrant collection:
  * **All in RAM** - all vector, original and quantized, are loaded and kept in RAM. This is the fastest mode, but requires a lot of RAM. Enabled by default.
  * **Original on Disk, quantized in RAM** - this is a hybrid mode, allows to obtain a good balance between speed and memory usage. Recommended scenario if you are aiming to shrink the memory footprint while keeping the search speed.
This mode is enabled by setting `always_ram` to `true` in the quantization config while using memmap storage:
httppythontypescriptrustjavacsharpgo
```
PUT /collections/{collection_name}
{
    "vectors": {
        "size": 768,
        "distance": "Cosine",
        "on_disk": true
    },
    "quantization_config": {
        "scalar": {
            "type": "int8",
            "always_ram": true
        }
    }
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.create_collection(
    collection_name="{collection_name}",
    vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE, on_disk=True),
    quantization_config=models.ScalarQuantization(
        scalar=models.ScalarQuantizationConfig(
            type=models.ScalarType.INT8,
            always_ram=True,
        ),
    ),
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.createCollection("{collection_name}", {
  vectors: {
    size: 768,
    distance: "Cosine",
    on_disk: true,
  },
  quantization_config: {
    scalar: {
      type: "int8",
      always_ram: true,
    },
  },
});

```
```
useqdrant_client::qdrant::{CreateCollectionBuilder,Distance,QuantizationType,ScalarQuantizationBuilder,VectorParamsBuilder,};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.create_collection(CreateCollectionBuilder::new("{collection_name}").vectors_config(VectorParamsBuilder::new(768,Distance::Cosine)).quantization_config(ScalarQuantizationBuilder::default().r#type(QuantizationType::Int8.into()).always_ram(true),),).await?;
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Collections.CreateCollection;importio.qdrant.client.grpc.Collections.Distance;importio.qdrant.client.grpc.Collections.OptimizersConfigDiff;importio.qdrant.client.grpc.Collections.QuantizationConfig;importio.qdrant.client.grpc.Collections.QuantizationType;importio.qdrant.client.grpc.Collections.ScalarQuantization;importio.qdrant.client.grpc.Collections.VectorParams;importio.qdrant.client.grpc.Collections.VectorsConfig;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.createCollectionAsync(CreateCollection.newBuilder().setCollectionName("{collection_name}").setVectorsConfig(VectorsConfig.newBuilder().setParams(VectorParams.newBuilder().setSize(768).setDistance(Distance.Cosine).setOnDisk(true).build()).build()).setQuantizationConfig(QuantizationConfig.newBuilder().setScalar(ScalarQuantization.newBuilder().setType(QuantizationType.Int8).setAlwaysRam(true).build()).build()).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.CreateCollectionAsync(
	collectionName: "{collection_name}",
	vectorsConfig: new VectorParams { Size = 768, Distance = Distance.Cosine, OnDisk = true },
	quantizationConfig: new QuantizationConfig
	{
		Scalar = new ScalarQuantization { Type = QuantizationType.Int8, AlwaysRam = true }
	}
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.CreateCollection(context.Background(), &qdrant.CreateCollection{
	CollectionName: "{collection_name}",
	VectorsConfig: qdrant.NewVectorsConfig(&qdrant.VectorParams{
		Size:     768,
		Distance: qdrant.Distance_Cosine,
		OnDisk:   qdrant.PtrOf(true),
	}),
	QuantizationConfig: qdrant.NewQuantizationScalar(&qdrant.ScalarQuantization{
		Type:      qdrant.QuantizationType_Int8,
		AlwaysRam: qdrant.PtrOf(true),
	}),
})

```
In this scenario, the number of disk reads may play a significant role in the search speed. In a system with high disk latency, the re-scoring step may become a bottleneck.
Consider disabling `rescore` to improve the search speed:
httppythontypescriptrustjavacsharpgo
```
POST /collections/{collection_name}/points/query
{
    "query": [0.2, 0.1, 0.9, 0.7],
    "params": {
        "quantization": {
            "rescore": false
        }
    },
    "limit": 10
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.query_points(
    collection_name="{collection_name}",
    query=[0.2, 0.1, 0.9, 0.7],
    search_params=models.SearchParams(
        quantization=models.QuantizationSearchParams(rescore=False)
    ),
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.query("{collection_name}", {
    query: [0.2, 0.1, 0.9, 0.7],
    params: {
        quantization: {
            rescore: false,
        },
    },
});

```
```
useqdrant_client::qdrant::{QuantizationSearchParamsBuilder,QueryPointsBuilder,SearchParamsBuilder,};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.query(QueryPointsBuilder::new("{collection_name}").query(vec![0.2,0.1,0.9,0.7]).limit(3).params(SearchParamsBuilder::default().quantization(QuantizationSearchParamsBuilder::default().rescore(false)),),).await?;
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Points.QuantizationSearchParams;importio.qdrant.client.grpc.Points.QueryPoints;importio.qdrant.client.grpc.Points.SearchParams;import staticio.qdrant.client.QueryFactory.nearest;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.queryAsync(QueryPoints.newBuilder().setCollectionName("{collection_name}").setQuery(nearest(0.2f,0.1f,0.9f,0.7f)).setParams(SearchParams.newBuilder().setQuantization(QuantizationSearchParams.newBuilder().setRescore(false).build()).build()).setLimit(3).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.QueryAsync(
	collectionName: "{collection_name}",
	query: new float[] { 0.2f, 0.1f, 0.9f, 0.7f },
	searchParams: new SearchParams
	{
		Quantization = new QuantizationSearchParams { Rescore = false }
	},
	limit: 3
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.Query(context.Background(), &qdrant.QueryPoints{
	CollectionName: "{collection_name}",
	Query:          qdrant.NewQuery(0.2, 0.1, 0.9, 0.7),
	Params: &qdrant.SearchParams{
		Quantization: &qdrant.QuantizationSearchParams{
			Rescore: qdrant.PtrOf(false),
		},
	},
})

```
  * **All on Disk** - all vectors, original and quantized, are stored on disk. This mode allows to achieve the smallest memory footprint, but at the cost of the search speed.
It is recommended to use this mode if you have a large collection and fast storage (e.g. SSD or NVMe).
This mode is enabled by setting `always_ram` to `false` in the quantization config while using mmap storage:
httppythontypescriptrustjavacsharpgo
```
PUT /collections/{collection_name}
{
    "vectors": {
      "size": 768,
      "distance": "Cosine",
      "on_disk": true
    },
    "quantization_config": {
        "scalar": {
            "type": "int8",
            "always_ram": false
        }
    }
}

```
```
from qdrant_client import QdrantClient, models
client = QdrantClient(url="http://localhost:6333")
client.create_collection(
    collection_name="{collection_name}",
    vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE, on_disk=True),
    quantization_config=models.ScalarQuantization(
        scalar=models.ScalarQuantizationConfig(
            type=models.ScalarType.INT8,
            always_ram=False,
        ),
    ),
)

```
```
import { QdrantClient } from "@qdrant/js-client-rest";
const client = new QdrantClient({ host: "localhost", port: 6333 });
client.createCollection("{collection_name}", {
  vectors: {
    size: 768,
    distance: "Cosine",
    on_disk: true,
  },
  quantization_config: {
    scalar: {
      type: "int8",
      always_ram: false,
    },
  },
});

```
```
useqdrant_client::qdrant::{CreateCollectionBuilder,Distance,QuantizationType,ScalarQuantizationBuilder,VectorParamsBuilder,};useqdrant_client::Qdrant;letclient=Qdrant::from_url("http://localhost:6334").build()?;client.create_collection(CreateCollectionBuilder::new("{collection_name}").vectors_config(VectorParamsBuilder::new(768,Distance::Cosine).on_disk(true)).quantization_config(ScalarQuantizationBuilder::default().r#type(QuantizationType::Int8.into()).always_ram(false),),).await?;
```
```
importio.qdrant.client.QdrantClient;importio.qdrant.client.QdrantGrpcClient;importio.qdrant.client.grpc.Collections.CreateCollection;importio.qdrant.client.grpc.Collections.Distance;importio.qdrant.client.grpc.Collections.OptimizersConfigDiff;importio.qdrant.client.grpc.Collections.QuantizationConfig;importio.qdrant.client.grpc.Collections.QuantizationType;importio.qdrant.client.grpc.Collections.ScalarQuantization;importio.qdrant.client.grpc.Collections.VectorParams;importio.qdrant.client.grpc.Collections.VectorsConfig;QdrantClientclient=newQdrantClient(QdrantGrpcClient.newBuilder("localhost",6334,false).build());client.createCollectionAsync(CreateCollection.newBuilder().setCollectionName("{collection_name}").setVectorsConfig(VectorsConfig.newBuilder().setParams(VectorParams.newBuilder().setSize(768).setDistance(Distance.Cosine).setOnDisk(true).build()).build()).setQuantizationConfig(QuantizationConfig.newBuilder().setScalar(ScalarQuantization.newBuilder().setType(QuantizationType.Int8).setAlwaysRam(false).build()).build()).build()).get();
```
```
using Qdrant.Client;
using Qdrant.Client.Grpc;
var client = new QdrantClient("localhost", 6334);
await client.CreateCollectionAsync(
 collectionName: "{collection_name}",
 vectorsConfig: new VectorParams { Size = 768, Distance = Distance.Cosine, OnDisk = true},
 quantizationConfig: new QuantizationConfig
 {
  Scalar = new ScalarQuantization { Type = QuantizationType.Int8, AlwaysRam = false }
 }
);

```
```
import (
	"context"
	"github.com/qdrant/go-client/qdrant"
)
client, err := qdrant.NewClient(&qdrant.Config{
	Host: "localhost",
	Port: 6334,
})
client.CreateCollection(context.Background(), &qdrant.CreateCollection{
	CollectionName: "{collection_name}",
	VectorsConfig: qdrant.NewVectorsConfig(&qdrant.VectorParams{
		Size:     768,
		Distance: qdrant.Distance_Cosine,
		OnDisk:   qdrant.PtrOf(true),
	}),
	QuantizationConfig: qdrant.NewQuantizationScalar(
		&qdrant.ScalarQuantization{
			Type:      qdrant.QuantizationType_Int8,
			AlwaysRam: qdrant.PtrOf(false),
		},
	),
})

```
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/quantization.md) this page on GitHub, or 
On this page:
  * [Quantization](https://qdrant.tech/documentation/guides/quantization/#quantization)
    * [Scalar Quantization](https://qdrant.tech/documentation/guides/quantization/#scalar-quantization)
    * [Binary Quantization](https://qdrant.tech/documentation/guides/quantization/#binary-quantization)
      * [Binary Quantization as Hamming Distance](https://qdrant.tech/documentation/guides/quantization/#binary-quantization-as-hamming-distance)
    * [Product Quantization](https://qdrant.tech/documentation/guides/quantization/#product-quantization)
    * [How to choose the right quantization method](https://qdrant.tech/documentation/guides/quantization/#how-to-choose-the-right-quantization-method)
    * [Setting up Quantization in Qdrant](https://qdrant.tech/documentation/guides/quantization/#setting-up-quantization-in-qdrant)
      * [Setting up Scalar Quantization](https://qdrant.tech/documentation/guides/quantization/#setting-up-scalar-quantization)
      * [Setting up Binary Quantization](https://qdrant.tech/documentation/guides/quantization/#setting-up-binary-quantization)
      * [Setting up Product Quantization](https://qdrant.tech/documentation/guides/quantization/#setting-up-product-quantization)
      * [Searching with Quantization](https://qdrant.tech/documentation/guides/quantization/#searching-with-quantization)
    * [Quantization tips](https://qdrant.tech/documentation/guides/quantization/#quantization-tips)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/quantization/)
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-binary-quantization-as-hamming-distance.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/quantization/#binary-quantization-as-hamming-distance
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-binary-quantization.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/quantization/#binary-quantization
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-how-to-choose-the-right-quantization-method.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/quantization/#how-to-choose-the-right-quantization-method
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-memory-and-speed-tuning.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/quantization/#memory-and-speed-tuning
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-product-quantization.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/quantization/#product-quantization
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-quantization-tips.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/quantization/#quantization-tips
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-quantization.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/quantization/#quantization
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-scalar-quantization.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/quantization/#scalar-quantization
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-searching-with-quantization.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/quantization/#searching-with-quantization
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-setting-up-binary-quantization.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/quantization/#setting-up-binary-quantization
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-setting-up-product-quantization.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/quantization/#setting-up-product-quantization
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-setting-up-quantization-in-qdrant.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/quantization/#setting-up-quantization-in-qdrant
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-setting-up-scalar-quantization.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/quantization/#setting-up-scalar-quantization
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/quantization/
                    ## 📄 `https-qdrant-tech-documentation-guides-running-with-gpu.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/running-with-gpu/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/running-with-gpu/)
                    ## 📄 `https-qdrant-tech-documentation-guides-security.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/security/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/security/)
                    ## 📄 `https-qdrant-tech-documentation-guides-usage-statistics.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/usage-statistics/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/usage-statistics/)
                    ## 📄 `https-qdrant-tech-documentation-guides.md`
                    ```md
                    # https://qdrant.tech/documentation/guides/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/)
                    ## 📄 `https-qdrant-tech-documentation-hybrid-cloud.md`
                    ```md
                    # https://qdrant.tech/documentation/hybrid-cloud/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/hybrid-cloud/)
                    ## 📄 `https-qdrant-tech-documentation-interfaces-api-reference.md`
                    ```md
                    # https://qdrant.tech/documentation/interfaces/#api-reference
  * [Documentation](https://qdrant.tech/documentation/)
  * API & SDKs
#  [](https://qdrant.tech/documentation/interfaces/#interfaces)Interfaces
Qdrant supports these “official” clients.
> **Note:** If you are using a language that is not listed here, you can use the REST API directly or generate a client for your language using 
##  [](https://qdrant.tech/documentation/interfaces/#client-libraries)Client Libraries
Client Repository | Installation | Version  
---|---|---  
[![python](https://qdrant.tech/docs/misc/python.webp)](https://python-client.qdrant.tech/) | **[(Client Docs)](https://python-client.qdrant.tech/)** | `pip install qdrant-client[fastembed]`  
![typescript](https://qdrant.tech/docs/misc/ts.webp) | `npm install @qdrant/js-client-rest`  
![rust](https://qdrant.tech/docs/misc/rust.png) | `cargo add qdrant-client`  
![golang](https://qdrant.tech/docs/misc/go.webp) | `go get github.com/qdrant/go-client`  
![.net](https://qdrant.tech/docs/misc/dotnet.webp) | `dotnet add package Qdrant.Client`  
![java](https://qdrant.tech/docs/misc/java.webp)  
##  [](https://qdrant.tech/documentation/interfaces/#api-reference)API Reference
All interaction with Qdrant takes place via the REST API. We recommend using REST API if you are using Qdrant for the first time or if you are working on a prototype.
API | Documentation  
---|---  
REST API | [OpenAPI Specification](https://api.qdrant.tech/api-reference)  
gRPC API  
###  [](https://qdrant.tech/documentation/interfaces/#grpc-interface)gRPC Interface
The gRPC methods follow the same principles as REST. For each REST endpoint, there is a corresponding gRPC method.
As per the 
```
service:grpc_port:6334
```
If you decide to use gRPC, you must expose the port when starting Qdrant.
Running the service inside of Docker will look like this:
```
docker run -p 6333:6333 -p 6334:6334 \
$(pwd)/qdrant_storage:/qdrant/storage:z \

```
**When to use gRPC:** The choice between gRPC and the REST API is a trade-off between convenience and speed. gRPC is a binary protocol and can be more challenging to debug. We recommend using gRPC if you are already familiar with Qdrant and are trying to optimize the performance of your application.
##### Was this page useful?
![Thumb up icon](https://qdrant.tech/icons/outline/thumb-up.svg) Yes  ![Thumb down icon](https://qdrant.tech/icons/outline/thumb-down.svg) No
Thank you for your feedback! 🙏
We are sorry to hear that. 😔 You can [edit](https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/interfaces.md) this page on GitHub, or 
On this page:
  * [Interfaces](https://qdrant.tech/documentation/interfaces/#interfaces)
    * [Client Libraries](https://qdrant.tech/documentation/interfaces/#client-libraries)
    * [API Reference](https://qdrant.tech/documentation/interfaces/#api-reference)
      * [gRPC Interface](https://qdrant.tech/documentation/interfaces/#grpc-interface)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/interfaces/)
                    ## 📄 `https-qdrant-tech-documentation-interfaces.md`
                    ```md
                    # https://qdrant.tech/documentation/interfaces/
                    ## 📄 `https-qdrant-tech-documentation-overview-vector-search.md`
                    ```md
                    # https://qdrant.tech/documentation/overview/vector-search/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/overview/vector-search/)
                    ## 📄 `https-qdrant-tech-documentation-overview.md`
                    ```md
                    # https://qdrant.tech/documentation/overview/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/overview/)
                    ## 📄 `https-qdrant-tech-documentation-quantization-setting-up-quantization-in-qdrant.md`
                    ```md
                    # https://qdrant.tech/documentation/quantization/#setting-up-quantization-in-qdrant
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/quantization/)
                    ## 📄 `https-qdrant-tech-documentation-quick-start.md`
                    ```md
                    # https://qdrant.tech/documentation/quick-start/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/quick-start/)
                    ## 📄 `https-qdrant-tech-documentation-quickstart-cloud.md`
                    ```md
                    # https://qdrant.tech/documentation/quickstart-cloud/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/quickstart-cloud/)
                    ## 📄 `https-qdrant-tech-documentation-quickstart.md`
                    ```md
                    # https://qdrant.tech/documentation/quickstart/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/quickstart/)
                    ## 📄 `https-qdrant-tech-documentation-search-query-planning.md`
                    ```md
                    # https://qdrant.tech/documentation/search/#query-planning
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/search/)
                    ## 📄 `https-qdrant-tech-documentation-tutorials-multimodal-search-fastembed.md`
                    ```md
                    # https://qdrant.tech/documentation/tutorials/multimodal-search-fastembed/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/tutorials/multimodal-search-fastembed/)
                    ## 📄 `https-qdrant-tech-documentation-tutorials.md`
                    ```md
                    # https://qdrant.tech/documentation/tutorials/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/tutorials/)
                    ## 📄 `https-qdrant-tech-documentation-web-ui.md`
                    ```md
                    # https://qdrant.tech/documentation/web-ui/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/web-ui/)
                    ## 📄 `https-qdrant-tech-documentation.md`
                    ```md
                    # https://qdrant.tech/documentation/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/)
                    ## 📄 `https-qdrant-tech-enterprise-solutions.md`
                    ```md
                    # https://qdrant.tech/enterprise-solutions/
### Enterprise-Grade Vector Search
Qdrant’s enterprise-grade features give you deployment flexibility (Managed, Hybrid or Private Cloud), streamline authentication (SSO), improve access control (RBAC), enhance monitoring, and simplify infrastructure management. All for billion+ vector scale.
[Talk to Sales](https://qdrant.tech/contact-us/)
![Enterprise-solutions](https://qdrant.tech/img/enterprise-solutions-hero.png)
## Deploy the Way you Need
### Managed Cloud
Qdrant Cloud provides optimal flexibility and offers a suite of features focused on efficient and scalable vector search - fully managed. Available on AWS, Google Cloud, and Azure.
[Learn More](https://qdrant.tech/cloud/)
![Managed Cloud](https://qdrant.tech/img/enterprise-solutions-use-cases/managed-cloud.png)
### Hybrid Cloud
Bring your own Kubernetes clusters from any cloud provider, on-premise infrastructure, or edge locations and connect them to the managed cloud.
[Learn More](https://qdrant.tech/hybrid-cloud/)
![Hybrid Cloud](https://qdrant.tech/img/enterprise-solutions-use-cases/hybrid-cloud.svg)
### Private Cloud
Experience maximum control and security by deploying Qdrant in your own infrastructure or edge locations.
[Learn More](https://qdrant.tech/private-cloud/)
![Private Cloud](https://qdrant.tech/img/enterprise-solutions-use-cases/private-cloud.svg)
“Qdrant powers our demanding recommendation and RAG applications. We chose it for its ease of deployment and high performance at scale, and have been consistently impressed with its results. The platform’s continuous feature enhancements and overall performance gains, coupled with their responsiveness, make Qdrant a reliable solution for our AI infrastructure.”
![Srubin Sethu Madhavan Avatar](https://qdrant.tech/img/customers/srubin-sethu-madhavan.svg)
Srubin Sethu Madhavan
Technical Lead II at Hubspot
![Logo](https://qdrant.tech/img/brands/hubspot.svg)
## Effectively Scale your Enterprise AI Applications
###### Flexible deployment options. Compliance ready.
Ensure customer trust by safeguarding their data with top-tier security measures. We provide SOC2 Type 2 Certification, Hybrid Cloud deployments for highly regulated environments, and Private Cloud options to give you complete control and ensure data sovereignty.
[Learn More](https://qdrant.tech/blog/qdrant-soc2-type2-audit/)
![Compliance ready](https://qdrant.tech/img/enterprise-solutions-capabilities/enabling-compliance.svg)
###### Secure Access & Authentication
Control who gets in and what they can do with Cloud RBAC, SSO, and granular  
Database API Keys.
[Learn More](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/#enterprise-single-sign-on-sso)
![Secure Access & Authentication](https://qdrant.tech/img/enterprise-solutions-capabilities/identity-and-access-management.svg)
###### Cloud API for Simplified Management
Automate and scale with API-driven control and Terraform support.
[Learn More](https://qdrant.tech/documentation/cloud/authentication/)
![Cloud API](https://qdrant.tech/img/enterprise-solutions-capabilities/api.svg)
###### Advanced Monitoring & Observability
Stay ahead of issues with Prometheus/OpenMetrics, Datadog, Grafana, and other third-party integrations.
[Learn More](https://qdrant.tech/documentation/guides/monitoring/)
![Advanced Monitoring & Observability](https://qdrant.tech/img/enterprise-solutions-capabilities/observability.svg)
## Enterprises Face Challenges in Scaling AI Applications
![Security & Compliance Risks](https://qdrant.tech/img/enterprise-solutions-challenges/icon1.svg)
##### Security & Compliance Risks
Enterprises need granular control over who accesses what data. Without robust **security frameworks, role-based access control (RBAC),** and **single sign-on (SSO)** integrations, managing compliance with regulations like **GDPR** becomes a complex challenge.
![Lack of Performance Visibility](https://qdrant.tech/img/enterprise-solutions-challenges/icon2.svg)
##### Lack of Performance Visibility
Scaling AI applications demands insights into system performance. Without **real-time monitoring and observability** into query latency, resource usage, and infrastructure health, teams face operational blind spots, slowing down optimization efforts and impacting performance.
![Credential Chaos & Access Management Bottlenecks](https://qdrant.tech/img/enterprise-solutions-challenges/icon3.svg)
##### Credential Chaos & Access Management Bottlenecks
Growing teams often juggle multiple authentication systems and struggle with **credential sprawl**. Without a unified access management solution, onboarding and enforcing policies become time-consuming, leading to **unauthorized access risks** and inefficient workflows.
![Manual Infrastructure Management Overhead](https://qdrant.tech/img/enterprise-solutions-challenges/icon4.svg)
##### Manual Infrastructure Management Overhead
Enterprises often struggle to keep up with scaling demands. **Manual cluster provisioning and management** lead to slow deployments, human errors, and high operational costs.
Enterprises like Bosch use Qdrant for unparalleled performance and massive-scale vector search. “With Qdrant, we found the missing piece to develop our own provider independent multimodal generative AI platform at enterprise scale.”
![Jeremy Teichmann Avatar](https://qdrant.tech/img/customers/jeremy-t-daly-singh.svg)
Jeremy Teichmann & Daly Singh
Generative AI Expert & Product Owner
![Logo](https://qdrant.tech/img/brands/bosch.svg)
“Vector stores are definitely here to stay, the objects in the world around us from image, sound, video and text become easily universal and searchable thanks to the embedding models and vector stores. I personally recommend Qdrant. We have been using it for a while and couldn’t be happier.”
![Hooman Sedghamiz Avatar](https://qdrant.tech/img/customers/hooman-sedghamiz.svg)
Hooman Sedghamiz
Director AI/ML, Bayer
![Logo](https://qdrant.tech/img/brands/bayer.svg)
Do you have further questions? We are happy to assist you.
[Contact us ](https://qdrant.tech/contact-us/)[Contact us](https://qdrant.tech/contact-us/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/enterprise-solutions/)
                    ## 📄 `https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-articles-product-quantization-md.md`
                    ```md
                    # https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/product-quantization.md
![Galaxy](https://qdrant.tech/img/404-galaxy.svg) ![Galaxy](https://qdrant.tech/img/404-galaxy-mobile.svg)
Oops! We can't find the page you were looking for.
[Go to Home ](https://qdrant.tech/)
                    ## 📄 `https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-articles-scalar-quantization-md.md`
                    ```md
                    # https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/scalar-quantization.md
                    ## 📄 `https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-articles-what-is-quantization-md.md`
                    ```md
                    # https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/articles/what-is-quantization.md
                    ## 📄 `https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-documentation-concepts-indexing-md.md`
                    ```md
                    # https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/indexing.md
                    ## 📄 `https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-documentation-guides-quantization-md.md`
                    ```md
                    # https://qdrant.tech/github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/quantization.md
                    ## 📄 `https-qdrant-tech-guides-distributed-deployment.md`
                    ```md
                    # https://qdrant.tech/guides/distributed_deployment/
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/guides/distributed_deployment/)
                    ## 📄 `https-qdrant-tech-hybrid-cloud.md`
                    ```md
                    # https://qdrant.tech/hybrid-cloud/
# Qdrant Hybrid Cloud
![Privacy and Data Sovereignty](https://qdrant.tech/icons/fill/cloud-system-purple.svg)
Privacy and Data Sovereignty
![Flexible Deployment](https://qdrant.tech/icons/fill/separate-blue.svg)
Flexible Deployment
![Minimum Cost](https://qdrant.tech/icons/fill/money-growth-green.svg)
Minimum Cost
Seamlessly deploy and manage the vector database across diverse environments, ensuring performance, security, and cost efficiency for AI-driven applications.
[Talk to sales](https://qdrant.tech/contact-us/)
![Enterprise-solutions](https://qdrant.tech/img/hybrid-cloud-graphic.svg)
# Seamless Kubernetes Integration
Qdrant Hybrid Cloud integrates Kubernetes clusters from any setting - cloud, on-premises, or edge - into a unified, enterprise-grade managed service.
It ensures data privacy, deployment flexibility, low latency, and delivers cost savings, elevating standards for vector search and AI applications.
![Qdrant Kubernetes integration](https://qdrant.tech/img/kubernetes-clusters.svg)
![Separate](https://qdrant.tech/icons/outline/separate-blue.svg)
### Deployment Flexibility
Use your existing infrastructure, whether it be on cloud platforms, on-premise setups, or even at edge locations.
![Money growth](https://qdrant.tech/icons/outline/money-growth-blue.svg)
### Unmatched Cost Advantage
Maximum deployment flexibility to leverage the best available resources, in the cloud or on-premise.
![Speedometer](https://qdrant.tech/icons/outline/speedometer-blue.svg)
### Ultra-Low Latency
On-premise deployment for lightning-fast, low-latency access.
![Cloud system](https://qdrant.tech/icons/outline/cloud-system-blue.svg)
### Data Privacy & Sovereignty
Keep your sensitive data with your secure premises, while enjoying the benefits of a managed cloud.
![Switches](https://qdrant.tech/icons/outline/switches-blue.svg)
### Transparent Control
Fully managed experience for your Qdrant clusters, while your data remains exclusively yours.
## How it Works
1
###### Integration
Qdrant Hybrid Cloud allows you to deploy managed Qdrant clusters on any cloud platform or on-premise infrastructure, ensuring your data stays private by separating the data and control layers.
2
###### Management
A straightforward Kubernetes operator installation allows for hands-off cluster management, including scaling operations, zero-downtime upgrades and disaster recovery.
3
###### Privacy and Security
The architecture guarantees database isolation. The Qdrant Cloud only receives telemetry through an outgoing connection. No access to databases or your Kubernetes API is necessary to maintain the highest level of data security and privacy.
![How it works scheme](https://qdrant.tech/img/how-it-works-scheme.svg)
### Learn how Qdrant Hybrid Cloud works:
### Qdrant Hybrid Cloud Features
![Server rack](https://qdrant.tech/icons/outline/server-rack-blue.svg)
Run clusters in your own infrastructure, incl. your own cloud, infrastructure, or edge
![Cloud check](https://qdrant.tech/icons/outline/cloud-check-blue.svg)
All benefits of Qdrant Cloud
![Cloud connections](https://qdrant.tech/icons/outline/cloud-connections-blue.svg)
Use the Managed Cloud Central Cluster Management
![Headphones-blue](https://qdrant.tech/icons/outline/headphones-blue.svg)
Premium support plan option available
Learn more about Qdrant Hybrid Cloud in our documentation.
[See Documentation](https://qdrant.tech/documentation/hybrid-cloud/)
##### Seamlessly connect Qdrant with a wide array of cloud providers and infrastructure platforms, including but not limited to these options:
![AWS logo](https://qdrant.tech/img/cloud-provider-logos/aws-logo.svg)
AWS
![Google Cloud logo](https://qdrant.tech/img/cloud-provider-logos/google-cloud-logo.svg)
Google Cloud
![Digital Ocean logo](https://qdrant.tech/img/cloud-provider-logos/digital-ocean-logo.svg)
Digital Ocean
![Oracle Cloud logo](https://qdrant.tech/img/cloud-provider-logos/oracle-cloud-logo.svg)
Oracle Cloud
![Linode logo](https://qdrant.tech/img/cloud-provider-logos/linode-logo.svg)
Linode
![AWS logo](https://qdrant.tech/img/cloud-provider-logos/aws-logo.svg)
AWS
![Google Cloud logo](https://qdrant.tech/img/cloud-provider-logos/google-cloud-logo.svg)
Google Cloud
![Digital Ocean logo](https://qdrant.tech/img/cloud-provider-logos/digital-ocean-logo.svg)
Digital Ocean
![Oracle Cloud logo](https://qdrant.tech/img/cloud-provider-logos/oracle-cloud-logo.svg)
Oracle Cloud
![Linode logo](https://qdrant.tech/img/cloud-provider-logos/linode-logo.svg)
Linode
![AWS logo](https://qdrant.tech/img/cloud-provider-logos/aws-logo.svg)
AWS
![Google Cloud logo](https://qdrant.tech/img/cloud-provider-logos/google-cloud-logo.svg)
Google Cloud
![Digital Ocean logo](https://qdrant.tech/img/cloud-provider-logos/digital-ocean-logo.svg)
Digital Ocean
![Oracle Cloud logo](https://qdrant.tech/img/cloud-provider-logos/oracle-cloud-logo.svg)
Oracle Cloud
![Linode logo](https://qdrant.tech/img/cloud-provider-logos/linode-logo.svg)
Linode
![AWS logo](https://qdrant.tech/img/cloud-provider-logos/aws-logo.svg)
AWS
![Google Cloud logo](https://qdrant.tech/img/cloud-provider-logos/google-cloud-logo.svg)
Google Cloud
![Digital Ocean logo](https://qdrant.tech/img/cloud-provider-logos/digital-ocean-logo.svg)
Digital Ocean
![Oracle Cloud logo](https://qdrant.tech/img/cloud-provider-logos/oracle-cloud-logo.svg)
Oracle Cloud
![Linode logo](https://qdrant.tech/img/cloud-provider-logos/linode-logo.svg)
Linode
![AWS logo](https://qdrant.tech/img/cloud-provider-logos/aws-logo.svg)
AWS
![Google Cloud logo](https://qdrant.tech/img/cloud-provider-logos/google-cloud-logo.svg)
Google Cloud
![Digital Ocean logo](https://qdrant.tech/img/cloud-provider-logos/digital-ocean-logo.svg)
Digital Ocean
![Oracle Cloud logo](https://qdrant.tech/img/cloud-provider-logos/oracle-cloud-logo.svg)
Oracle Cloud
![Linode logo](https://qdrant.tech/img/cloud-provider-logos/linode-logo.svg)
Linode
![AWS logo](https://qdrant.tech/img/cloud-provider-logos/aws-logo.svg)
AWS
![Google Cloud logo](https://qdrant.tech/img/cloud-provider-logos/google-cloud-logo.svg)
Google Cloud
![Digital Ocean logo](https://qdrant.tech/img/cloud-provider-logos/digital-ocean-logo.svg)
Digital Ocean
![Oracle Cloud logo](https://qdrant.tech/img/cloud-provider-logos/oracle-cloud-logo.svg)
Oracle Cloud
![Linode logo](https://qdrant.tech/img/cloud-provider-logos/linode-logo.svg)
Linode
![AWS logo](https://qdrant.tech/img/cloud-provider-logos/aws-logo.svg)
AWS
![Google Cloud logo](https://qdrant.tech/img/cloud-provider-logos/google-cloud-logo.svg)
Google Cloud
![Digital Ocean logo](https://qdrant.tech/img/cloud-provider-logos/digital-ocean-logo.svg)
Digital Ocean
![Oracle Cloud logo](https://qdrant.tech/img/cloud-provider-logos/oracle-cloud-logo.svg)
Oracle Cloud
![Linode logo](https://qdrant.tech/img/cloud-provider-logos/linode-logo.svg)
Linode
![AWS logo](https://qdrant.tech/img/cloud-provider-logos/aws-logo.svg)
AWS
![Google Cloud logo](https://qdrant.tech/img/cloud-provider-logos/google-cloud-logo.svg)
Google Cloud
![Digital Ocean logo](https://qdrant.tech/img/cloud-provider-logos/digital-ocean-logo.svg)
Digital Ocean
![Oracle Cloud logo](https://qdrant.tech/img/cloud-provider-logos/oracle-cloud-logo.svg)
Oracle Cloud
![Linode logo](https://qdrant.tech/img/cloud-provider-logos/linode-logo.svg)
Linode
![Rancher logo](https://qdrant.tech/img/cloud-provider-logos/rancher-logo.svg)
Rancher
![Azure logo](https://qdrant.tech/img/cloud-provider-logos/azure-logo.svg)
Azure
![VMWare Tanzu logo](https://qdrant.tech/img/cloud-provider-logos/vmware-tanzu-logo.svg)
VMWare Tanzu
![Openshift logo](https://qdrant.tech/img/cloud-provider-logos/openshift-logo.svg)
Openshift
![Scaleway logo](https://qdrant.tech/img/cloud-provider-logos/scaleway-logo.svg)
Scaleway
![Rancher logo](https://qdrant.tech/img/cloud-provider-logos/rancher-logo.svg)
Rancher
![Azure logo](https://qdrant.tech/img/cloud-provider-logos/azure-logo.svg)
Azure
![VMWare Tanzu logo](https://qdrant.tech/img/cloud-provider-logos/vmware-tanzu-logo.svg)
VMWare Tanzu
![Openshift logo](https://qdrant.tech/img/cloud-provider-logos/openshift-logo.svg)
Openshift
![Scaleway logo](https://qdrant.tech/img/cloud-provider-logos/scaleway-logo.svg)
Scaleway
![Rancher logo](https://qdrant.tech/img/cloud-provider-logos/rancher-logo.svg)
Rancher
![Azure logo](https://qdrant.tech/img/cloud-provider-logos/azure-logo.svg)
Azure
![VMWare Tanzu logo](https://qdrant.tech/img/cloud-provider-logos/vmware-tanzu-logo.svg)
VMWare Tanzu
![Openshift logo](https://qdrant.tech/img/cloud-provider-logos/openshift-logo.svg)
Openshift
![Scaleway logo](https://qdrant.tech/img/cloud-provider-logos/scaleway-logo.svg)
Scaleway
![Rancher logo](https://qdrant.tech/img/cloud-provider-logos/rancher-logo.svg)
Rancher
![Azure logo](https://qdrant.tech/img/cloud-provider-logos/azure-logo.svg)
Azure
![VMWare Tanzu logo](https://qdrant.tech/img/cloud-provider-logos/vmware-tanzu-logo.svg)
VMWare Tanzu
![Openshift logo](https://qdrant.tech/img/cloud-provider-logos/openshift-logo.svg)
Openshift
![Scaleway logo](https://qdrant.tech/img/cloud-provider-logos/scaleway-logo.svg)
Scaleway
![Rancher logo](https://qdrant.tech/img/cloud-provider-logos/rancher-logo.svg)
Rancher
![Azure logo](https://qdrant.tech/img/cloud-provider-logos/azure-logo.svg)
Azure
![VMWare Tanzu logo](https://qdrant.tech/img/cloud-provider-logos/vmware-tanzu-logo.svg)
VMWare Tanzu
![Openshift logo](https://qdrant.tech/img/cloud-provider-logos/openshift-logo.svg)
Openshift
![Scaleway logo](https://qdrant.tech/img/cloud-provider-logos/scaleway-logo.svg)
Scaleway
![Rancher logo](https://qdrant.tech/img/cloud-provider-logos/rancher-logo.svg)
Rancher
![Azure logo](https://qdrant.tech/img/cloud-provider-logos/azure-logo.svg)
Azure
![VMWare Tanzu logo](https://qdrant.tech/img/cloud-provider-logos/vmware-tanzu-logo.svg)
VMWare Tanzu
![Openshift logo](https://qdrant.tech/img/cloud-provider-logos/openshift-logo.svg)
Openshift
![Scaleway logo](https://qdrant.tech/img/cloud-provider-logos/scaleway-logo.svg)
Scaleway
![Rancher logo](https://qdrant.tech/img/cloud-provider-logos/rancher-logo.svg)
Rancher
![Azure logo](https://qdrant.tech/img/cloud-provider-logos/azure-logo.svg)
Azure
![VMWare Tanzu logo](https://qdrant.tech/img/cloud-provider-logos/vmware-tanzu-logo.svg)
VMWare Tanzu
![Openshift logo](https://qdrant.tech/img/cloud-provider-logos/openshift-logo.svg)
Openshift
![Scaleway logo](https://qdrant.tech/img/cloud-provider-logos/scaleway-logo.svg)
Scaleway
![Rancher logo](https://qdrant.tech/img/cloud-provider-logos/rancher-logo.svg)
Rancher
![Azure logo](https://qdrant.tech/img/cloud-provider-logos/azure-logo.svg)
Azure
![VMWare Tanzu logo](https://qdrant.tech/img/cloud-provider-logos/vmware-tanzu-logo.svg)
VMWare Tanzu
![Openshift logo](https://qdrant.tech/img/cloud-provider-logos/openshift-logo.svg)
Openshift
![Scaleway logo](https://qdrant.tech/img/cloud-provider-logos/scaleway-logo.svg)
Scaleway
Do you have further questions? We are happy to assist you.
[Contact us ](https://qdrant.tech/contact-us/)[Contact us](https://qdrant.tech/contact-us/)
### Get started today
Turn embeddings or neural network encoders into full-fledged applications for matching, searching, recommending, and more.
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/hybrid-cloud/)
                    ## 📄 `https-qdrant-tech-legal-impressum.md`
                    ```md
                    # https://qdrant.tech/legal/impressum/
# Impressum
Angaben gemäß § 5 TMG
Qdrant Solutions GmbH
Chausseestraße 86  
10115 Berlin
#### Vertreten durch:
André Zayarni
#### Kontakt:
Telefon: +49 30 120 201 01
E-Mail: 
#### Registereintrag:
Eintragung im Registergericht: Berlin Charlottenburg  
Registernummer: HRB 235335 B
#### Umsatzsteuer-ID:
Umsatzsteuer-Identifikationsnummer gemäß §27a Umsatzsteuergesetz: DE347779324
### Verantwortlich für den Inhalt nach § 55 Abs. 2 RStV:
André Zayarni  
Chausseestraße 86  
10115 Berlin
## Haftungsausschluss:
### Haftung für Inhalte
Die Inhalte unserer Seiten wurden mit größter Sorgfalt erstellt. Für die Richtigkeit, Vollständigkeit und Aktualität der Inhalte können wir jedoch keine Gewähr übernehmen. Als Diensteanbieter sind wir gemäß § 7 Abs.1 TMG für eigene Inhalte auf diesen Seiten nach den allgemeinen Gesetzen verantwortlich. Nach §§ 8 bis 10 TMG sind wir als Diensteanbieter jedoch nicht verpflichtet, übermittelte oder gespeicherte fremde Informationen zu überwachen oder nach Umständen zu forschen, die auf eine rechtswidrige Tätigkeit hinweisen. Verpflichtungen zur Entfernung oder Sperrung der Nutzung von Informationen nach den allgemeinen Gesetzen bleiben hiervon unberührt. Eine diesbezügliche Haftung ist jedoch erst ab dem Zeitpunkt der Kenntnis einer konkreten Rechtsverletzung möglich. Bei Bekanntwerden von entsprechenden Rechtsverletzungen werden wir diese Inhalte umgehend entfernen.
### Haftung für Links
Unser Angebot enthält Links zu externen Webseiten Dritter, auf deren Inhalte wir keinen Einfluss haben. Deshalb können wir für diese fremden Inhalte auch keine Gewähr übernehmen. Für die Inhalte der verlinkten Seiten ist stets der jeweilige Anbieter oder Betreiber der Seiten verantwortlich. Die verlinkten Seiten wurden zum Zeitpunkt der Verlinkung auf mögliche Rechtsverstöße überprüft. Rechtswidrige Inhalte waren zum Zeitpunkt der Verlinkung nicht erkennbar. Eine permanente inhaltliche Kontrolle der verlinkten Seiten ist jedoch ohne konkrete Anhaltspunkte einer Rechtsverletzung nicht zumutbar. Bei Bekanntwerden von Rechtsverletzungen werden wir derartige Links umgehend entfernen.
### Datenschutz
Die Nutzung unserer Webseite ist in der Regel ohne Angabe personenbezogener Daten möglich. Soweit auf unseren Seiten personenbezogene Daten (beispielsweise Name, Anschrift oder eMail-Adressen) erhoben werden, erfolgt dies, soweit möglich, stets auf freiwilliger Basis. Diese Daten werden ohne Ihre ausdrückliche Zustimmung nicht an Dritte weitergegeben. Wir weisen darauf hin, dass die Datenübertragung im Internet (z.B. bei der Kommunikation per E-Mail) Sicherheitslücken aufweisen kann. Ein lückenloser Schutz der Daten vor dem Zugriff durch Dritte ist nicht möglich. Der Nutzung von im Rahmen der Impressumspflicht veröffentlichten Kontaktdaten durch Dritte zur Übersendung von nicht ausdrücklich angeforderter Werbung und Informationsmaterialien wird hiermit ausdrücklich widersprochen. Die Betreiber der Seiten behalten sich ausdrücklich rechtliche Schritte im Falle der unverlangten Zusendung von Werbeinformationen, etwa durch Spam-Mails, vor.
### Google Analytics
Diese Website benutzt Google Analytics, einen Webanalysedienst der Google Inc. (‘‘Google’’). Google Analytics verwendet sog. ‘‘Cookies’’, Textdateien, die auf Ihrem Computer gespeichert werden und die eine Analyse der Benutzung der Website durch Sie ermöglicht. Die durch den Cookie erzeugten Informationen über Ihre Benutzung dieser Website (einschließlich Ihrer IP-Adresse) wird an einen Server von Google in den USA übertragen und dort gespeichert. Google wird diese Informationen benutzen, um Ihre Nutzung der Website auszuwerten, um Reports über die Websiteaktivitäten für die Websitebetreiber zusammenzustellen und um weitere mit der Websitenutzung und der Internetnutzung verbundene Dienstleistungen zu erbringen. Auch wird Google diese Informationen gegebenenfalls an Dritte übertragen, sofern dies gesetzlich vorgeschrieben oder soweit Dritte diese Daten im Auftrag von Google verarbeiten. Google wird in keinem Fall Ihre IP-Adresse mit anderen Daten der Google in Verbindung bringen. Sie können die Installation der Cookies durch eine entsprechende Einstellung Ihrer Browser Software verhindern; wir weisen Sie jedoch darauf hin, dass Sie in diesem Fall gegebenenfalls nicht sämtliche Funktionen dieser Website voll umfänglich nutzen können. Durch die Nutzung dieser Website erklären Sie sich mit der Bearbeitung der über Sie erhobenen Daten durch Google in der zuvor beschriebenen Art und Weise und zu dem zuvor benannten Zweck einverstanden.
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/legal/impressum/)
                    ## 📄 `https-qdrant-tech-legal-privacy-policy.md`
                    ```md
                    # https://qdrant.tech/legal/privacy-policy/
# Privacy Policy
At qdrant.tech, accessible from qdrant.tech, qdrant.co, qdrant.com, qdrant.io, one of our main priorities is the privacy of our visitors. This Privacy Policy document contains types of information that is collected and recorded by qdrant.tech and how we use it.
If you have additional questions or require more information about our Privacy Policy, do not hesitate to contact us. Our Privacy Policy was generated with the help of 
## General Data Protection Regulation (GDPR)
We are a Data Controller of your information.
Qdrant legal basis for collecting and using the personal information described in this Privacy Policy depends on the Personal Information we collect and the specific context in which we collect the information:
  * Qdrant needs to perform a contract with you
  * You have given Qdrant permission to do so
  * Processing your personal information is in Qdrant legitimate interests
  * Qdrant needs to comply with the law
Qdrant will retain your personal information only for as long as is necessary for the purposes set out in this Privacy Policy. We will retain and use your information to the extent necessary to comply with our legal obligations, resolve disputes, and enforce our policies.
If you are a resident of the European Economic Area (EEA), you have certain data protection rights. If you wish to be informed what Personal Information we hold about you and if you want it to be removed from our systems, please contact us. In certain circumstances, you have the following data protection rights:
  * The right to access, update or to delete the information we have on you.
  * The right of rectification.
  * The right to object.
  * The right of restriction.
  * The right to data portability
  * The right to withdraw consent
## Log Files
qdrant.tech follows a standard procedure of using log files. These files log visitors when they visit websites. All hosting companies do this and a part of hosting services’ analytics. The information collected by log files include internet protocol (IP) addresses, browser type, Internet Service Provider (ISP), date and time stamp, referring/exit pages, and possibly the number of clicks. These are not linked to any information that is personally identifiable. The purpose of the information is for analyzing trends, administering the site, tracking users’ movement on the website, and gathering demographic information.
## Cookies and Web Beacons
Like any other website, qdrant.tech uses ‘cookies’. These cookies are used to store information including visitors’ preferences, and the pages on the website that the visitor accessed or visited. The information is used to optimize the users’ experience by customizing our web page content based on visitors’ browser type and/or other information.
For more general information on cookies, please read 
## Privacy Policies
You may consult this list to find the Privacy Policy for each of the advertising partners of qdrant.tech.
Third-party ad servers or ad networks uses technologies like cookies, JavaScript, or Web Beacons that are used in their respective advertisements and links that appear on qdrant.tech, which are sent directly to users’ browser. They automatically receive your IP address when this occurs. These technologies are used to measure the effectiveness of their advertising campaigns and/or to personalize the advertising content that you see on websites that you visit.
Note that qdrant.tech has no access to or control over these cookies that are used by third-party advertisers.
## Third Party Privacy Policies
qdrant.tech’s Privacy Policy does not apply to other advertisers or websites. Thus, we are advising you to consult the respective Privacy Policies of these third-party ad servers for more detailed information. It may include their practices and instructions about how to opt-out of certain options.
You can choose to disable cookies through your individual browser options. To know more detailed information about cookie management with specific web browsers, it can be found at the browsers’ respective websites.
## Children’s Information
Another part of our priority is adding protection for children while using the internet. We encourage parents and guardians to observe, participate in, and/or monitor and guide their online activity.
qdrant.tech does not knowingly collect any Personal Identifiable Information from children under the age of 13. If you think that your child provided this kind of information on our website, we strongly encourage you to contact us immediately and we will do our best efforts to promptly remove such information from our records.
## Online Privacy Policy Only
Our Privacy Policy applies only to our online activities and is valid for visitors to our website with regards to the information that they shared and/or collect in qdrant.tech. This policy is not applicable to any information collected offline or via channels other than this website.
## Consent
By using our website, you hereby consent to our Privacy Policy and agree to its terms.
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/legal/privacy-policy/)
                    ## 📄 `https-qdrant-tech-legal-terms-and-conditions.md`
                    ```md
                    # https://qdrant.tech/legal/terms_and_conditions/
## Terms and Conditions
Last updated: December 10, 2021
Please read these terms and conditions carefully before using Our Service.
### Interpretation and Definitions
#### Interpretation
The words of which the initial letter is capitalized have meanings defined under the following conditions. The following definitions shall have the same meaning regardless of whether they appear in singular or in plural.
#### Definitions
For the purposes of these Terms and Conditions:
  * **Affiliate** means an entity that controls, is controlled by or is under common control with a party, where “control” means ownership of 50% or more of the shares, equity interest or other securities entitled to vote for election of directors or other managing authority.
  * **Country** refers to: Berlin, Germany
  * **Company** (referred to as either “the Company”, “We”, “Us” or “Our” in this Agreement) refers to Qdrant Solutions GmbH, Chausseestraße 86, 10115 Berlin.
  * **Device** means any device that can access the Service such as a computer, a cellphone or a digital tablet.
  * **Service** refers to the Website.
  * **Terms and Conditions** (also referred as “Terms”) mean these Terms and Conditions that form the entire agreement between You and the Company regarding the use of the Service. This Terms and Conditions agreement has been created with the help of the Terms and Conditions Generator.
  * **Third-party Social Media Service** means any services or content (including data, information, products or services) provided by a third-party that may be displayed, included or made available by the Service.
  * **Website** refers to Qdrant, accessible from <https://qdrant.tech>
  * **You** means the individual accessing or using the Service, or the company, or other legal entity on behalf of which such individual is accessing or using the Service, as applicable.
### Acknowledgment
These are the Terms and Conditions governing the use of this Service and the agreement that operates between You and the Company. These Terms and Conditions set out the rights and obligations of all users regarding the use of the Service.
Your access to and use of the Service is conditioned on Your acceptance of and compliance with these Terms and Conditions. These Terms and Conditions apply to all visitors, users and others who access or use the Service.
By accessing or using the Service You agree to be bound by these Terms and Conditions. If You disagree with any part of these Terms and Conditions then You may not access the Service.
You represent that you are over the age of 18. The Company does not permit those under 18 to use the Service.
Your access to and use of the Service is also conditioned on Your acceptance of and compliance with the Privacy Policy of the Company. Our Privacy Policy describes Our policies and procedures on the collection, use and disclosure of Your personal information when You use the Application or the Website and tells You about Your privacy rights and how the law protects You. Please read Our Privacy Policy carefully before using Our Service.
### Links to Other Websites
Our Service may contain links to third-party web sites or services that are not owned or controlled by the Company.
The Company has no control over, and assumes no responsibility for, the content, privacy policies, or practices of any third party web sites or services. You further acknowledge and agree that the Company shall not be responsible or liable, directly or indirectly, for any damage or loss caused or alleged to be caused by or in connection with the use of or reliance on any such content, goods or services available on or through any such web sites or services.
We strongly advise You to read the terms and conditions and privacy policies of any third-party web sites or services that You visit.
### Termination
We may terminate or suspend Your access immediately, without prior notice or liability, for any reason whatsoever, including without limitation if You breach these Terms and Conditions.
Upon termination, Your right to use the Service will cease immediately.
### Limitation of Liability
Notwithstanding any damages that You might incur, the entire liability of the Company and any of its suppliers under any provision of this Terms and Your exclusive remedy for all of the foregoing shall be limited to the amount actually paid by You through the Service or 100 USD if You haven’t purchased anything through the Service.
To the maximum extent permitted by applicable law, in no event shall the Company or its suppliers be liable for any special, incidental, indirect, or consequential damages whatsoever (including, but not limited to, damages for loss of profits, loss of data or other information, for business interruption, for personal injury, loss of privacy arising out of or in any way related to the use of or inability to use the Service, third-party software and/or third-party hardware used with the Service, or otherwise in connection with any provision of this Terms), even if the Company or any supplier has been advised of the possibility of such damages and even if the remedy fails of its essential purpose.
Some states do not allow the exclusion of implied warranties or limitation of liability for incidental or consequential damages, which means that some of the above limitations may not apply. In these states, each party’s liability will be limited to the greatest extent permitted by law.
### “AS IS” and “AS AVAILABLE” Disclaimer
The Service is provided to You “AS IS” and “AS AVAILABLE” and with all faults and defects without warranty of any kind. To the maximum extent permitted under applicable law, the Company, on its own behalf and on behalf of its Affiliates and its and their respective licensors and service providers, expressly disclaims all warranties, whether express, implied, statutory or otherwise, with respect to the Service, including all implied warranties of merchantability, fitness for a particular purpose, title and non-infringement, and warranties that may arise out of course of dealing, course of performance, usage or trade practice. Without limitation to the foregoing, the Company provides no warranty or undertaking, and makes no representation of any kind that the Service will meet Your requirements, achieve any intended results, be compatible or work with any other software, applications, systems or services, operate without interruption, meet any performance or reliability standards or be error free or that any errors or defects can or will be corrected.
Without limiting the foregoing, neither the Company nor any of the company’s provider makes any representation or warranty of any kind, express or implied: (i) as to the operation or availability of the Service, or the information, content, and materials or products included thereon; (ii) that the Service will be uninterrupted or error-free; (iii) as to the accuracy, reliability, or currency of any information or content provided through the Service; or (iv) that the Service, its servers, the content, or e-mails sent from or on behalf of the Company are free of viruses, scripts, trojan horses, worms, malware, timebombs or other harmful components.
Some jurisdictions do not allow the exclusion of certain types of warranties or limitations on applicable statutory rights of a consumer, so some or all of the above exclusions and limitations may not apply to You. But in such a case the exclusions and limitations set forth in this section shall be applied to the greatest extent enforceable under applicable law.
### Governing Law
The laws of the Country, excluding its conflicts of law rules, shall govern this Terms and Your use of the Service. Your use of the Application may also be subject to other local, state, national, or international laws.
### Disputes Resolution
If You have any concern or dispute about the Service, You agree to first try to resolve the dispute informally by contacting the Company.
### For European Union (EU) Users
If You are a European Union consumer, you will benefit from any mandatory provisions of the law of the country in which you are resident in.
### United States Legal Compliance
You represent and warrant that (i) You are not located in a country that is subject to the United States government embargo, or that has been designated by the United States government as a “terrorist supporting” country, and (ii) You are not listed on any United States government list of prohibited or restricted parties.
### Severability and Waiver
#### Severability
If any provision of these Terms is held to be unenforceable or invalid, such provision will be changed and interpreted to accomplish the objectives of such provision to the greatest extent possible under applicable law and the remaining provisions will continue in full force and effect.
#### Waiver
Except as provided herein, the failure to exercise a right or to require performance of an obligation under this Terms shall not effect a party’s ability to exercise such right or require such performance at any time thereafter nor shall the waiver of a breach constitute a waiver of any subsequent breach.
Translation Interpretation These Terms and Conditions may have been translated if We have made them available to You on our Service. You agree that the original English text shall prevail in the case of a dispute.
### Changes to These Terms and Conditions
We reserve the right, at Our sole discretion, to modify or replace these Terms at any time. If a revision is material We will make reasonable efforts to provide at least 30 days’ notice prior to any new terms taking effect. What constitutes a material change will be determined at Our sole discretion.
By continuing to access or use Our Service after those revisions become effective, You agree to be bound by the revised terms. If You do not agree to the new terms, in whole or in part, please stop using the website and the Service.
### Contact Us
If you have any questions about these Terms and Conditions, You can contact us:
By email: 
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/legal/terms_and_conditions/)
                    ## 📄 `https-qdrant-tech-misc-qdrant-security-public-key-asc.md`
                    ```md
                    # https://qdrant.tech/misc/qdrant-security-public-key.asc
```
-----BEGIN PGP PUBLIC KEY BLOCK-----
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=9HbW
-----END PGP PUBLIC KEY BLOCK-----

```
                    ## 📄 `https-qdrant-tech-partners.md`
                    ```md
                    # https://qdrant.tech/partners/
### Global Partners & Integrations
Benefit from our collaboration with top cloud platforms, state-of-the-art AI embeddings, and dynamic frameworks.
![Partners logos](https://qdrant.tech/img/partners-hero-logos.svg) ![Partners logos](https://qdrant.tech/img/mobile/partners-hero-logos.svg)
## Cloud Partners
Qdrant Cloud seamlessly integrates with top cloud platforms and is available on leading marketplaces.
##### Microsoft Azure
“With the landscape of AI being complex for most customers, Qdrant's ease of use provides an easy approach for customers' implementation of RAG patterns for Generative AI solutions and additional choices in selecting AI components on Azure.”
![Tara Walker Avatar](https://qdrant.tech/img/customers/tara-walker.svg)
Tara Walker
Principal Software Engineer at Microsoft
![Logo](https://qdrant.tech/img/brands/microsoft.svg)
#### Embeddings Integrations
Qdrant’s integrations allow you to bring state-of-the-art AI and machine learning capabilities, and to enrich data analysis and search precision.
[See All Embeddings](https://qdrant.tech/documentation/embeddings/)
![Cohere logo](https://qdrant.tech/img/integrations/integration-cohere.svg)
###### Cohere
Integrate Qdrant with Cohere's co.embed API and Python SDK.
![Gemini logo](https://qdrant.tech/img/integrations/integration-gemini.svg)
###### Gemini
Connect Qdrant with Google's Gemini Embedding Model API seamlessly.
![OpenAI logo](https://qdrant.tech/img/integrations/integration-open-ai.svg)
###### OpenAI
Easily integrate OpenAI embeddings with Qdrant using the official Python SDK.
![Aleph Alpha logo](https://qdrant.tech/img/integrations/integration-aleph-alpha.svg)
###### Aleph Alpha
Integrate Qdrant with Aleph Alpha's multimodal, multilingual embeddings.
![Jina logo](https://qdrant.tech/img/integrations/integration-jina.svg)
###### Jina AI
Easily integrate Qdrant with Jina AI's embeddings API.
![AWS logo](https://qdrant.tech/img/integrations/integration-aws.svg)
###### AWS Bedrock
Utilize AWS Bedrock's embedding models with Qdrant seamlessly.
###### Qdrant stands out in handling embeddings by consistently achieving the lowest latency, ensuring quicker response times in data retrieval:
[See Our Benchmarks Report](https://qdrant.tech/benchmarks/)
![1M-Open-AI-Embeddings](https://qdrant.tech/img/partners-embeddings.svg) ![1M-Open-AI-Embeddings](https://qdrant.tech/img/mobile/partners-embeddings.svg)
#### Frameworks
Qdrant supports leading frameworks so you can streamline natural language processing, enhance large-scale data retrieval, integrate diverse data sources,and automate complex tasks.
[See All Frameworks](https://qdrant.tech/documentation/frameworks/)
![LangChain logo](https://qdrant.tech/img/integrations/integration-lang-chain.svg)
###### LangChain
Qdrant seamlessly integrates with LangChain for LLM development.
![LlamaIndex logo](https://qdrant.tech/img/integrations/integration-llama-index.svg)
###### LlamaIndex
Qdrant integrates with LlamaIndex for efficient data indexing in LLMs.
![Airbyte logo](https://qdrant.tech/img/integrations/integration-airbyte.svg)
###### Airbyte
Qdrant integrates with Airbyte to build robust data pipelines for efficient data management.
![Unstructured logo](https://qdrant.tech/img/integrations/integration-unstructured.svg)
###### Unstructured
Qdrant integrates with Unstructured for effective preprocessing and handling of unstructured data.
![DocArray logo](https://qdrant.tech/img/integrations/integration-doc-array.svg)
###### DocArray
Qdrant integrates natively with DocArray for efficient handling and processing of multi-modal data.
![AutoGen logo](https://qdrant.tech/img/integrations/integration-auto-gen.svg)
###### AutoGen
Qdrant integrates with Autogen to enhance the development of automated LLM applications.
### Certified Solution Partners
Qdrant has an ecosystem of solution partners who help you with the implementation and integration of your vector search applications.
![Traversaal.ai logo](https://qdrant.tech/img/partners-solution-logos/traversaal-ai-logo.svg)
![Domino logo](https://qdrant.tech/img/partners-solution-logos/domino-logo.svg)
![Revelry logo](https://qdrant.tech/img/partners-solution-logos/revelry-logo.svg)
![Softlandia logo](https://qdrant.tech/img/partners-solution-logos/softlandia-logo.svg)
![Traversaal.ai logo](https://qdrant.tech/img/partners-solution-logos/traversaal-ai-logo.svg)
![Domino logo](https://qdrant.tech/img/partners-solution-logos/domino-logo.svg)
![Revelry logo](https://qdrant.tech/img/partners-solution-logos/revelry-logo.svg)
![Softlandia logo](https://qdrant.tech/img/partners-solution-logos/softlandia-logo.svg)
![Traversaal.ai logo](https://qdrant.tech/img/partners-solution-logos/traversaal-ai-logo.svg)
![Domino logo](https://qdrant.tech/img/partners-solution-logos/domino-logo.svg)
![Revelry logo](https://qdrant.tech/img/partners-solution-logos/revelry-logo.svg)
![Softlandia logo](https://qdrant.tech/img/partners-solution-logos/softlandia-logo.svg)
![Traversaal.ai logo](https://qdrant.tech/img/partners-solution-logos/traversaal-ai-logo.svg)
![Domino logo](https://qdrant.tech/img/partners-solution-logos/domino-logo.svg)
![Revelry logo](https://qdrant.tech/img/partners-solution-logos/revelry-logo.svg)
![Softlandia logo](https://qdrant.tech/img/partners-solution-logos/softlandia-logo.svg)
### Become a Certified Solutions Partner
We partner with industry leaders to deliver innovative solutions and an exceptional customer experience.
[Become a Partner](https://qdrant.tech/contact-us/)
![](https://qdrant.tech/img/partner-banner.svg)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/partners/)
                    ## 📄 `https-qdrant-tech-pricing.md`
                    ```md
                    # https://qdrant.tech/pricing/
### Qdrant Pricing
##### Cloud & Enterprise solutions
Choose the deployment option for your application and explore our transparent pricing plans.
popular
###### Managed Cloud
##### Starting at $0
Starts with 1GB free cluster, no credit card required.
Scale your production solutions without deployment and upkeep. 
1GB free forever cluster. No credit card required.
Fully managed with central cluster management
Multiple cloud providers and regions (AWS, GCP, Azure)
Horizontal & vertical scaling
Central monitoring, log management and alerting
High availability, auto-healing
Backup & disaster recovery
Zero-downtime upgrades
Unlimited users
Standard support and uptime SLAs, can be upgraded to Premium
###### Hybrid Cloud
##### $0.014
Starting price per hour.
Bring your own cluster from any cloud provider, on-premise infrastructure, or edge locations and connect them to the managed cloud.
All the benefits of Qdrant Cloud
Security, data isolation, optimal latency
Use the Managed Cloud Central Cluster Management
Standard support and uptime SLAs, can be upgraded to Premium
###### Private Cloud
##### Custom
Price on request.
[Contact Sales](https://qdrant.tech/contact-us/)
Deploy Qdrant fully on premise for maximum control and data sovereignty.
All the benefits of Hybrid Cloud
Security, data isolation, optimal latency
Manage Qdrant database clusters on your infrastructure, in the cloud, on-premise at the edge, even fully air-gapped without a connection to Qdrant Cloud
Premium Support Plan
Not sure which plan is right for you?
Check out our pricing calculator.
### Launch a new cluster today
![](https://qdrant.tech/img/database.svg)
##### Microsoft Azure
Do you have further questions? We are happy to assist you.
[Contact us ](https://qdrant.tech/contact-us/)[Contact us](https://qdrant.tech/contact-us/)
### Deploy Qdrant locally with Docker
Get started with our [Quick Start Guide](https://qdrant.tech/documentation/quick-start/), or our main 
`1 docker pull qdrant/qdrant  
2 docker run -p 6333:6333 qdrant/qdrant  
`
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/pricing/)
                    ## 📄 `https-qdrant-tech-private-cloud.md`
                    ```md
                    # https://qdrant.tech/private-cloud/
### Qdrant Private Cloud. Run Qdrant On-Premise.
Effortlessly deploy and manage your enterprise-ready vector database fully on-premise, enhancing security for AI-driven applications.
[Contact us](https://qdrant.tech/contact-us/)
###### Qdrant Private Cloud offers a dedicated, on-premise solution that guarantees supreme data privacy and sovereignty.
![Private cloud data privacy](https://qdrant.tech/img/private-cloud-data-privacy.svg)
Designed for enterprise-grade demands, it provides a seamless management experience for your vector database, ensuring optimal performance and security for vector search and AI applications.
To learn more about Qdrant Private Cloud, please contact our team.
[Contact us ](https://qdrant.tech/contact-us/)[Contact us](https://qdrant.tech/contact-us/)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/private-cloud/)
                    ## 📄 `https-qdrant-tech-qdrant-for-startups-form.md`
                    ```md
                    # https://qdrant.tech/qdrant-for-startups/#form
# Qdrant for Startups
Qdrant for Startups is committed to being the catalyst for the next generation of AI innovators.  
Our program is specifically designed to provide AI-focused startups with the right resources to scale. If AI is at the heart of your startup, you're in the right place.
[Apply Now](https://qdrant.tech/qdrant-for-startups/#form)
![Qdrant for Startups](https://qdrant.tech/img/startups-program.svg)
#### Why join Qdrant for Startups?
#### Discount for Qdrant Cloud
Enjoy a 20% discount on 
![Qdrant Discount for Startups](https://qdrant.tech/img/qdrant-for-startups-benefits/card1.png)
##### Expert Technical Advice
Get access to one-on-one sessions with experts for personalized technical advice.
![Expert Technical Advice](https://qdrant.tech/img/qdrant-for-startups-benefits/card2.svg)
##### Partner Perks
Receive exclusive perks from Hugging Face, LlamaIndex, and Airbyte, ensuring you have access to key tools and resources for AI-driven applications.
![Co-Marketing Opportunities](https://qdrant.tech/img/qdrant-for-startups-benefits/card3.svg)
[Apply Now](https://qdrant.tech/qdrant-for-startups/#form)
## Apply Now
###### Join our Startup Program
## Program FAQ
###### What are the eligibility requirements?
You must meet all of the following:
  * New user of Qdrant Cloud.
  * Pre-seed, Seed, or Series A startups (under five years old) and less than $5M in funding.
  * Have not previously participated in the Qdrant for Startups program
  * Building an AI-driven product or services (agencies or devshops are not eligible)
  * Provide a link to a live, functional website
  * Billing will be done directly with Qdrant (not through a marketplace)
###### How can I apply to the Qdrant Startup Program?
Apply through our online form by providing details about your startup and plans for using Qdrant. Applications are reviewed within 7-10 business days, with selections based on innovation potential and alignment with our capabilities.
###### What criteria are used to select startups for the program?
We evaluate applications based on the innovation potential of the tech or AI-driven products or services and their alignment with Qdrant’s capabilities. Startups that demonstrate a clear vision and potential for impactful use of our platform are more likely to be selected.
###### How long is the discount valid, and what are the conditions?
The discount is valid for 12 months from the date of acceptance and applies exclusively to our Cloud services billed through Qdrant (via Stripe). Participants must add credit card details to their Qdrant account to utilize the discount. Billing can not be through a marketplace. For details on pricing, please visit qdrant.tech/pricing.
###### How can I maximize the co-marketing opportunities offered by the program?
Engage actively with our marketing team for features on social media, possible appearances in Discord talks or webinars, and case studies to maximize your startup's visibility and showcase your innovative use of Qdrant.
###### Can existing Qdrant customers apply for the Startup Program?
Yes, existing Qdrant customers are eligible to apply for the Startup Program if their cloud account was created within the last 30 days from the date of application. This opportunity is designed to ensure startups at the early stages of using our platform can still benefit from the additional support and resources offered.
###### Can I reapply if my application is initially rejected?
Yes, we welcome reapplications from startups whose circumstances have changed or who can provide additional information that might have been overlooked in the initial review. You must wait 2 months to re-apply.
###### Who can I contact for more information about the program?
After reading these FAQs in full, if you need more details or assistance, please contact 
[Apply Now](https://qdrant.tech/qdrant-for-startups/#form)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/qdrant-for-startups/)
                    ## 📄 `https-qdrant-tech-qdrant-for-startups.md`
                    ```md
                    # https://qdrant.tech/qdrant-for-startups/
                    ## 📄 `https-qdrant-tech-qdrant-vector-database.md`
                    ```md
                    # https://qdrant.tech/qdrant-vector-database/
### Qdrant. Efficient, Scalable, Fast.
Qdrant is the most advanced vector database with highest RPS, minimal latency, fast indexing, high control with accuracy, and so much more.
[Talk to Sales](https://qdrant.tech/contact-us/)
![Qdrant Vector Database](https://qdrant.tech/img/qdrant-vector-database-hero.svg) ![Qdrant Vector Database](https://qdrant.tech/img/mobile/qdrant-vector-database-hero.svg)
### Built for Performance
With up to 4x RPS, Qdrant excels in delivering high-speed, efficient data processing, setting new benchmarks in vector database performance.
[Benchmarks](https://qdrant.tech/benchmarks/)
![Benchmark](https://qdrant.tech/img/qdrant-vector-database-use-cases/built-for-performance.svg)
### Fully Managed
Experience seamless scalability and minimal operational overhead with Qdrant Cloud, designed for ease-of-use and reliability.
[Qdrant Cloud](https://qdrant.tech/cloud/)
![Qdrant Cloud](https://qdrant.tech/img/qdrant-vector-database-use-cases/fully-managed.svg)
### Run Anywhere
Qdrant’s Hybrid Cloud and Private Cloud solutions offer flexible deployment options for top-tier data protection.
[Enterprise Solutions](https://qdrant.tech/enterprise-solutions/)
![Enterprise Solutions](https://qdrant.tech/img/qdrant-vector-database-use-cases/run-anywhere.svg)
### Feature Overview
Built as a dedicated similarity search engine, Qdrant provides unique features to provide unparalleled performance and efficiency in managing your vector data workloads.
![Speedometer](https://qdrant.tech/icons/outline/speedometer-blue.svg)
##### Advanced Compression
Scalar, Product, and unique Binary Quantization features significantly reduce memory usage and improve search performance (40x) for high-dimensional vectors.
[Quantization](https://qdrant.tech/articles/binary-quantization/)
![Cloud-Managed](https://qdrant.tech/icons/outline/cloud-managed-blue.svg)
##### Distributed, Cloud-Native Design
Managed cloud services on AWS, GCP, and Azure for scalable, maintenance-free vector search. [Advanced sharding](https://qdrant.tech/guides/distributed_deployment/) available.
[Cloud Options](https://qdrant.tech/cloud/)
![Rocket](https://qdrant.tech/icons/outline/rocket-blue.svg)
##### Easy to Use API
Offers OpenAPI v3 specification for generating client libraries in almost any programming language.
[Learn More](https://qdrant.tech/documentation/interfaces/#api-reference)
![Enterprise](https://qdrant.tech/icons/outline/enterprise-blue.svg)
##### Enterprise-grade Security
Includes robust access management, backup options, and disaster recovery. Dedicated Enterprise Solutions available.
[Enterprise Solutions](https://qdrant.tech/enterprise-solutions/)
![Integration](https://qdrant.tech/icons/outline/integration-blue.svg)
##### Integrations
Qdrant supports a wide range of integrations for all leading embeddings and frameworks.
[See Integrations](https://qdrant.tech/documentation/frameworks/)
![Multitenancy](https://qdrant.tech/icons/outline/multitenancy-blue.svg)
##### Multitenancy Support
Ability to segment a single collection for organized and efficient retrieval, data isolation, and privacy. Vital for applications needing distinct vector dataset management.
[Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/)
![Disk-Storage](https://qdrant.tech/icons/outline/disk-storage-blue.svg)
##### Memory Maps and IO Uring
Effective on-disk storage options and low level hardware optimization.
[Learn More](https://qdrant.tech/articles/io_uring/)
![Matching](https://qdrant.tech/icons/outline/matching-blue.svg)
##### Fast and Precise Matching
Unparalleled speed and accuracy, powered by a bespoke modification of the HNSW algorithm for Approximate Nearest Neighbor Search.
[Learn More](https://qdrant.tech/documentation/concepts/search/)
![Filter](https://qdrant.tech/icons/outline/filter-blue.svg)
##### Payloads & Advanced Filtering
Vector payload supports a large variety of data types and query conditions, including string matching, numerical ranges, geo-locations, and more.
[Learn More](https://qdrant.tech/documentation/concepts/payload/)
![Vectors](https://qdrant.tech/icons/outline/vectors-blue.svg)
##### Sparse Vector Support
Efficient handling of sparse vectors for enhanced text retrieval and memory-efficient data representation for high-dimensional data sets.
[Learn More](https://qdrant.tech/articles/sparse-vectors/)
### Qdrant Cloud is the fastest way to get started with Qdrant.
![](https://qdrant.tech/img/rocket.svg)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/qdrant-vector-database/)
                    ## 📄 `https-qdrant-tech-rag-rag-evaluation-guide.md`
                    ```md
                    # https://qdrant.tech/rag/rag-evaluation-guide/
A Comprehensive Guide
# Best Practices in RAG Evaluation
Learn how to assess, calibrate, and optimize your RAG applications for long-term success.
[Download the Guide ](https://qdrant.tech/rag/rag-evaluation-guide/#form)[Learn More](https://qdrant.tech/rag/)
![RAG-Evaluation](https://qdrant.tech/img/rag-evaluation-guide/rag-evaluation.svg)
## What you will learn
The guide covers:
  * Recommended frameworks for comprehensive RAG assessment
  * How to identify and solve common RAG performance issues
  * Techniques for working with custom datasets
  * Essential metrics to monitor during testing, and more.
###### Download the guide
![Stages](https://qdrant.tech/img/rag-evaluation-guide/stages.svg)
## How to evaluate a RAG system
This guide will teach you how to evaluate a RAG system for both accuracy and quality.
###### Stages prone to errors
You will learn to maintain RAG performance by testing for:
  * Search precision
  * Recall
  * Contextual relevance
  * Response accuracy.
![Search text](https://qdrant.tech/icons/outline/search-text-blue.svg)
###### Information retrieval
This stage involves searching and fetching relevant information from a knowledge base or external sources.
![Integration](https://qdrant.tech/icons/outline/integration-blue.svg)
###### Information augmentation
In this stage, the retrieved information is processed and combined with the original query
![Vectors](https://qdrant.tech/icons/outline/vectors-blue.svg)
###### Generating responses
Using the augmented information, the language model generates a response to the original query.
[Download the Guide](https://qdrant.tech/rag/rag-evaluation-guide/#form)
### Why evaluate your RAG application?
The guide will outline both common issues, as well as recommendations to avoid these pitfalls.
![Maximize search](https://qdrant.tech/img/rag-evaluation-guide/integrations/maximize-search.svg)
Lack of Precision
![Enrich context](https://qdrant.tech/img/rag-evaluation-guide/integrations/enrich-context.svg)
Poor recall
![Avoid hallucinations](https://qdrant.tech/img/rag-evaluation-guide/integrations/avoid-hallucinations.svg)
“Lost in the middle”
### Recommended evaluation frameworks
In the guide, we explore three popular frameworks that can help simplify your evaluation process.
![Ragas logo](https://qdrant.tech/img/rag-evaluation-guide/integrations/ragas.svg)
Ragas is an open-source framework for evaluating retrieval augmented generation systems.
![Quotient AI logo](https://qdrant.tech/img/rag-evaluation-guide/integrations/quotient.svg)
Quotient AI is a platform that focuses on building and deploying RAG systems.
![Arize logo](https://qdrant.tech/img/rag-evaluation-guide/integrations/arize.svg)
Arize Phoenix is a tool designed for monitoring and observability in AI systems, including RAG pipelines.
# Learn More
Learn how to test RAG with questions and answers, evaluate RAG pipelines with custom datasets, and visually deconstruct response generation by reading the guide.
[Download the Guide](https://qdrant.tech/rag/rag-evaluation-guide/#form)
![Qdrant Kubernetes integration](https://qdrant.tech/img/rag-evaluation-guide/kubernetes-clusters.png)
### Read Qdrant’s Best Practices in RAG Evaluation guide for a deep dive into:
![Case study](https://qdrant.tech/icons/outline/case-study-blue.svg)
Why RAG evaluation is crucial for your AI's success
![Similarity](https://qdrant.tech/icons/outline/similarity-blue.svg)
Recommended frameworks for comprehensive assessment
![Bug](https://qdrant.tech/icons/outline/bug-blue.svg)
How to identify and solve common RAG performance issues
![Cloud connections](https://qdrant.tech/icons/outline/cloud-connections-blue.svg)
Techniques for working with custom datasets
![Chart bar](https://qdrant.tech/icons/outline/chart-bar-blue.svg)
Essential metrics to monitor during testing
[Download the Guide](https://qdrant.tech/rag/rag-evaluation-guide/#form)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/rag/rag-evaluation-guide/)
                    ## 📄 `https-qdrant-tech-rag.md`
                    ```md
                    # https://qdrant.tech/rag/
# Retrieval Augmented Generation (RAG)
Unlock the full potential of your AI with RAG powered by Qdrant. Dive into a new era of intelligent applications that understand and interact with unprecedented accuracy and depth.
[Contact Us](https://qdrant.tech/contact-us/)
![Retrieval Augmented Generation](https://qdrant.tech/img/vectors/vector-2.svg)
### RAG with Qdrant
RAG, powered by Qdrant's efficient data retrieval, elevates AI's capacity to generate rich, context-aware content across text, code, and multimedia, enhancing relevance and precision on a scalable platform. Discover why Qdrant is the perfect choice for your RAG project.
![Speedometer](https://qdrant.tech/icons/outline/speedometer-blue.svg)
###### Highest RPS
Qdrant leads with top requests-per-second, outperforming alternative vector databases in various datasets by up to 4x.
![Time](https://qdrant.tech/icons/outline/time-blue.svg)
###### Fast Retrieval
Qdrant achieves the lowest latency, ensuring quicker response times in data retrieval: 3ms response for 1M Open AI embeddings.
![Vectors](https://qdrant.tech/icons/outline/vectors-blue.svg)
###### Multi-Vector Support
Integrate the strengths of multiple vectors per document, such as title and body, to create search experiences your customers admire.
![Compression](https://qdrant.tech/icons/outline/compression-blue.svg)
###### Built-in Compression
Significantly reduce memory usage, improve search performance and save up to 30x cost for high-dimensional vectors with Quantization.
#### Qdrant integrates with all leading LLM providers and frameworks
![Cohere logo](https://qdrant.tech/img/integrations/integration-cohere.svg)
###### AWS Bedrock
Utilize AWS Bedrock's embedding models with Qdrant seamlessly.
![LangChain logo](https://qdrant.tech/img/integrations/integration-lang-chain.svg)
###### LlamaIndex
Qdrant integrates with LlamaIndex for efficient data indexing in LLMs.
### RAG Evaluation
Retrieval Augmented Generation (RAG) harnesses large language models to enhance content generation by effectively leveraging existing information. By amalgamating specific details from various sources, RAG facilitates accurate and relevant query results, making it invaluable across domains such as medical, finance, and academia for content creation, Q&A applications, and information synthesis.
However, evaluating RAG systems is essential to refine and optimize their performance, ensuring alignment with user expectations and validating their functionality.
![Graphic](https://qdrant.tech/img/retrieval-augmented-generation-evaluation/become-a-partner-graphic.svg)
###### We work with the best in the industry on RAG evaluation:
![Arize logo](https://qdrant.tech/img/retrieval-augmented-generation-evaluation/arize-logo.svg) ![Ragas logo](https://qdrant.tech/img/retrieval-augmented-generation-evaluation/ragas-logo.svg) ![Quotient logo](https://qdrant.tech/img/retrieval-augmented-generation-evaluation/quotient-logo.svg)
### Learn how to get started with Qdrant for your RAG use case
![Music recommendation](https://qdrant.tech/img/retrieval-augmented-generation-use-cases/case1.svg) ![Music recommendation](https://qdrant.tech/img/retrieval-augmented-generation-use-cases/case1-mobile.svg)
###### Question and Answer System with LlamaIndex
Combine Qdrant and LlamaIndex to create a self-updating Q&A system.
![Food discovery](https://qdrant.tech/img/retrieval-augmented-generation-use-cases/case2.svg) ![Food discovery](https://qdrant.tech/img/retrieval-augmented-generation-use-cases/case2-mobile.svg)
###### Retrieval Augmented Generation with OpenAI and Qdrant
Basic RAG pipeline with Qdrant and OpenAI SDKs.
[Learn More](https://qdrant.tech/articles/food-discovery-demo/)
“Qdrant powers our demanding recommendation and RAG applications. We chose it for its ease of deployment and high performance at scale, and have been consistently impressed with its results. The platform’s continuous feature enhancements and overall performance gains, coupled with their responsiveness, make Qdrant a reliable solution for our AI infrastructure.”
![Srubin Sethu Madhavan Avatar](https://qdrant.tech/img/customers/srubin-sethu-madhavan.svg)
Srubin Sethu Madhavan
Technical Lead II at Hubspot
![Logo](https://qdrant.tech/img/brands/hubspot.svg)
![Logo](https://qdrant.tech/img/retrieval-augmented-generation-use-cases/customer-logo.svg)
##### See how Dust is using Qdrant for RAG
Dust provides companies with the core platform to execute on their GenAI bet for their teams by deploying LLMs across the organization and providing context aware AI assistants through RAG.
[Read Case Study](https://qdrant.tech/blog/dust-and-qdrant/)
![Preview](https://qdrant.tech/img/retrieval-augmented-generation-use-cases/case-study.png)
![Guidebook](https://qdrant.tech/icons/outline/guidebook-blue.svg)
A comprehensive guide
## Best Practices in RAG Evaluation
Learn how to assess, calibrate, and optimize your RAG applications for long-term success.
[Get the Guide](https://qdrant.tech/rag/rag-evaluation-guide/)
![RAG guide](https://qdrant.tech/img/retrieval-augmented-generation-evaluation/guide-graphic.svg)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/rag/)
                    ## 📄 `https-qdrant-tech-recommendations.md`
                    ```md
                    # https://qdrant.tech/recommendations/
# Recommendation Systems
Step into the next generation of recommendation engines powered by Qdrant. Experience a new level of intelligence in application interactions, offering unprecedented accuracy and depth in user personalization.
[Contact Us](https://qdrant.tech/contact-us/)
![Recommendation systems](https://qdrant.tech/img/vectors/vector-1.svg)
### Recommendations with Qdrant
Recommendation systems, powered by Qdrant's efficient data retrieval, boost the ability to deliver highly personalized content recommendations across various media, enhancing user engagement and accuracy on a scalable platform. Explore why Qdrant is the optimal solution for your recommendation system projects.
![Chart bar](https://qdrant.tech/icons/outline/chart-bar-blue.svg)
###### Efficient Data Handling
Qdrant excels in managing high-dimensional vectors, enabling streamlined storage and retrieval for complex recommendation systems.
![Search text](https://qdrant.tech/icons/outline/search-text-blue.svg)
###### Advanced Indexing Method
Leveraging HNSW indexing, Qdrant ensures rapid, accurate searches crucial for effective recommendation engines.
![Headphones](https://qdrant.tech/icons/outline/headphones-blue.svg)
###### Flexible Query Options
With support for payloads and filters, Qdrant offers personalized recommendation capabilities through detailed metadata handling.
### Qdrant Recommendation API
The Qdrant Recommendation API enhances recommendation systems with advanced flexibility, supporting both ID and vector-based queries, and search strategies for precise, personalized content suggestions.
[Learn More](https://qdrant.tech/documentation/concepts/explore/)
![Recommendation api](https://qdrant.tech/img/recommendation-api.svg)
### Learn how to get started with Qdrant for your recommendation system use case
![Music recommendation](https://qdrant.tech/img/recommendations-use-cases/music-recommendation.svg) ![Music recommendation](https://qdrant.tech/img/recommendations-use-cases/music-recommendation-mobile.svg)
###### Music Recommendation with Qdrant
Build a song recommendation engine based on music genres and other metadata.
[View Tutorial](https://qdrant.tech/blog/human-language-ai-models/)
![Food discovery](https://qdrant.tech/img/recommendations-use-cases/food-discovery.svg) ![Food discovery](https://qdrant.tech/img/recommendations-use-cases/food-discovery-mobile.svg)
###### Food Discovery with Qdrant
Interactive demo recommends meals based on likes/dislikes and local restaurant options.
[View Demo](https://food-discovery.qdrant.tech/)
![Logo](https://qdrant.tech/img/recommendations-use-cases/customer-logo.svg)
##### Recommendation Engine with Qdrant Vector Database
Dailymotion's Journey to Crafting the Ultimate Content-Driven Video Recommendation Engine with Qdrant Vector Database.
[Read Case Study](https://qdrant.tech/blog/case-study-dailymotion/)
![Preview](https://qdrant.tech/img/recommendations-use-cases/case-study.png)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/recommendations/)
                    ## 📄 `https-qdrant-tech-security-bug-bounty-program.md`
                    ```md
                    # https://qdrant.tech/security/bug-bounty-program/
# Bug Bounty Program Overview
We prioritize user trust and adhere to the highest privacy and security standards. This is why we actively invite security experts to identify vulnerabilities and commit to collaborating with them to resolve issues swiftly and effectively. Qdrant values the security research community and supports the responsible disclosure of vulnerabilities in our products and services. Through our bug bounty program, we reward researchers who help enhance the security of our platform.
## Responsible Disclosure Program Rules
  * Include detailed, reproducible steps in your reports. We will not reward issues you cannot reproduce.
  * Submit one vulnerability per report unless you need to chain multiple vulnerabilities to demonstrate impact.
  * In cases of duplicate reports, we will reward only the first reproducible report.
  * We will consider vulnerabilities stemming from the same root cause as a single issue and award only one bounty.
  * We strictly prohibit social engineering attacks (e.g., phishing, vishing, smishing).
  * Interact only with accounts you own or have explicit permission to access. Do not test using Qdrant employee accounts or internal tools.
  * Before you run automated scanners, please check with us first.
### In Scope
The Bug Bounty program covers the following areas:
  * *.cloud.qdrant.io Qdrant Cloud Application
  * [qdrant.tech](http://qdrant.tech/) Website
In most cases, we will only reward the following types of vulnerabilities:
  * Arbitrary code execution and OS Command Injection
  * Stored Cross-Site Scripting (Stored XSS)
  * SQL injection
  * File Upload
  * Authentication bypass and privilege escalation (authentication / authorization circumvention)
  * Significant Sensitive Data Exposure
  * Server-Side Request Forgery (SSRF)
  * Critical Business Logic Flaws
### Out of Scope
We always exclude the following areas:
  * Findings related to intended functionality or accepted business risks
  * Qdrant support system on 
  * Third-party applications or websites
  * Staging or test environments
  * Social engineering attacks
  * DoS/DDoS attacks
  * User/email enumeration
  * Brute-force attacks
  * Physical security issues
  * Reports from automated tools or scanners
  * Generic information disclosure, such as the `Server` or `X-Powered-By` headers
  * Email security: DMARC, DKIM, SPF, etc.
  * Spamming that rate limiting techniques can prevent
  * Missing DNSSEC
  * CSRF for Login, Logout and Signup pages
  * Cross-site scripting that requires full control of a http header, such as Referer, Host etc.
  * Clickjacking and Tabnabbing
## Severity Levels and Rewards
  * We assess reported bugs based on their risk and other relevant factors; our response may take some time.
  * We tend to award higher rewards for submissions that include detailed remediation steps or recommendations.
  * We determine bounty amounts based on multiple factors, including the vulnerability’s impact, the ease of exploitation, and the quality of the report. Please note that we may not award a bounty for very low-risk issues.
  * We use the CVSS v4 framework to evaluate the criticality of issues and ensure a consistent risk assessment.
  * We aim to reward similar vulnerabilities with comparable compensation; however, we also consider factors such as the time and effort required to discover the issue. Keep in mind that we may not match previous compensations for future reports.
## Disclosure Policy
Contact us at 
Follow these guidelines when disclosing vulnerabilities to us:
  * Report any potential security vulnerabilities immediately upon discovery, as we commit to resolving issues swiftly.
  * Maintain strict confidentiality regarding discovered vulnerabilities. Obtain explicit authorization from the Qdrant security team before publicly disclosing any vulnerabilities.
  * Exercise caution to prevent data loss, privacy breaches, or service disruptions while conducting security research.
  * Limit testing to your own accounts or those for which you have received explicit permission. Report any accidental access to unauthorized data immediately.
  * **Safe Harbor:** We support ethical security research and promise not to initiate legal action against researchers who report vulnerabilities in good faith and comply with this disclosure policy. Ensure that your testing remains non-disruptive and respects the outlined guidelines so you qualify for Safe Harbor protections.
### Contact
For questions about the program or to report security issues, contact:
  * Email: 
  * PGP Key Fingerprint: [07E3 6646 E0D0 A3BF 0AFC B302 26C5 016B 97EB 804B](https://qdrant.tech/misc/qdrant-security-public-key.asc)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/security/bug-bounty-program/)
                    ## 📄 `https-qdrant-tech-solutions.md`
                    ```md
                    # https://qdrant.tech/solutions/
## Qdrant Vector Database Use Cases
Explore the vast applications of the Qdrant vector database. From retrieval augmented generation to anomaly detection, advanced search, and recommendation systems, our solutions unlock new dimensions of data and performance.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/solutions/)
                    ## 📄 `https-qdrant-tech-stars.md`
                    ```md
                    # https://qdrant.tech/stars/
# You are already a star in our community!
The Qdrant Stars program is here to take that one step further.
![Stars](https://qdrant.tech/img/stars-hero.svg)
### About Qdrant Stars
Qdrant Stars is an exclusive program to the top contributors and evangelists inside the Qdrant community.
These are the experts responsible for leading community discussions, creating high-quality content, and participating in Qdrant’s events and meetups.
![Stars program](https://qdrant.tech/img/stars-about.png)
#### Everything you need to extend your current reach to be the voice of the developer community and represent Qdrant
![Training](https://qdrant.tech/icons/outline/training-blue.svg)
###### Training
You will be equipped with the assets and knowledge to organize and execute successful talks and events. Get access to our content library with slide decks, templates, and more.
![Award](https://qdrant.tech/icons/outline/award-blue.svg)
###### Recognition
Win a certificate and be featured on our website page. Plus, enjoy the distinction of receiving exclusive Qdrant swag.
![Travel](https://qdrant.tech/icons/outline/travel-blue.svg)
###### Travel
Benefit from a dedicated travel fund for speaking engagements at developer conferences.
![Star ticket](https://qdrant.tech/icons/outline/star-ticket-blue.svg)
###### Beta-tests
Get a front-row seat to the future of Qdrant with opportunities to beta-test new releases and access our detailed product roadmap.
## Meet our Stars
Distinguished Ambassador ![Sparks](https://qdrant.tech/icons/fill/sparks-purple.svg)
###### M K Pavan Kumar
Data Scientist and Lead GenAI
Kameshwara Pavan Kumar Mantha is a seasoned technology expert with 14 years of extensive experience in full stack development, cloud solutions, and artificial intelligence.  
Specializing in Generative AI and Large Language Models, Pavan has established himself as a leader in these cutting-edge domains.
![M K Pavan Kumar Photo](https://qdrant.tech/img/stars/m-k-pavan-kumar.jpg)
![Robert Caulk Photo](https://qdrant.tech/img/stars/robert-caulk.jpg)
###### Robert Caulk
Founder of Emergent Methods
Robert is working with a team on AskNews.app to adaptively enrich, index, and report on over 1 million news articles per day
![Joshua Mo Photo](https://qdrant.tech/img/stars/joshua-mo.jpg)
###### Joshua Mo
DevRel at Shuttle.rs
Hey there! I primarily use Rust and am looking forward to contributing to the Qdrant community!
![Nick Khami Photo](https://qdrant.tech/img/stars/nick-khami.jpg)
###### Nick Khami
Founder & Product Engineer
Founder and product engineer at Trieve and has been using Qdrant since late 2022
![Owen Colegrove Photo](https://qdrant.tech/img/stars/owen-colegrove.jpg)
###### Owen Colegrove
Founder of SciPhi
Physics PhD, Quant @ Citadel and Founder at SciPhi
![Niranjan Akella Photo](https://qdrant.tech/img/stars/niranjan-akella.jpg)
###### Niranjan Akella
Scientist by Heart & AI Engineer
I build & deploy AI models like LLMs, Diffusion Models & Vision Models at scale
![Bojan Jakimovski Photo](https://qdrant.tech/img/stars/bojan-jakimovski.jpg)
###### Bojan Jakimovski
Machine Learning Engineer
I'm really excited to show the power of the Qdrant as vector database
![Haydar KULEKCI Photo](https://qdrant.tech/img/stars/haydar-kulekci.jpg)
###### Haydar KULEKCI
Senior Software Engineer
I am a senior software engineer and consultant with over 10 years of experience in data management, processing, and software development.
![Nicola Procopio Photo](https://qdrant.tech/img/stars/nicola-procopio.jpg)
###### Nicola Procopio
Senior Data Scientist | Machine Learning & A.I. Expert @ ACSoftware
I am a data scientist and open-source enthusiast since 2009, I used Qdrant since 2023. I contribute to FastEmbed integration for Haystack, Haystack core and vector search for Cheshire Cat A.I., and I like to share my expertise through articles, tutorials, and talks.
![Eduardo Vasquez Photo](https://qdrant.tech/img/stars/eduardo-vasquez.jpg)
###### Eduardo Vasquez
Data Scientist and MLOps Engineer
I am a Data Scientist and MLOps Engineer exploring generative AI and LLMs, creating YouTube content on RAG workflows and fine-tuning LLMs. I hold an MSc in Statistics and Data Science.
![Benito Martin Photo](https://qdrant.tech/img/stars/benito-martin.jpg)
###### Benito Martin
Independent Consultant | Data Science, ML and AI Project Implementation | Teacher and Course Content Developer
Over the past year, Benito developed MLOps and LLM projects. Based in Switzerland, Benito continues to advance his skills.
![Nirant Kasliwal Photo](https://qdrant.tech/img/stars/nirant-kasliwal.jpg)
###### Nirant Kasliwal
FastEmbed Creator
I'm a Machine Learning consultant specializing in NLP and Vision systems for early-stage products. I've authored an NLP book recommended by Dr. Andrew Ng to Stanford's CS230 students and maintain FastEmbed at Qdrant for speed.
![Denzell Ford Photo](https://qdrant.tech/img/stars/denzell-ford.jpg)
###### Denzell Ford
Founder at Trieve, has been using Qdrant since late 2022.
Denzell Ford, the founder of Trieve, has been using Qdrant since late 2022. He's passionate about helping people in the community.
![Pavan Nagula Photo](https://qdrant.tech/img/stars/pavan-nagula.jpg)
###### Pavan Nagula
Data Scientist | Machine Learning and Generative AI
I'm Pavan, a data scientist specializing in AI, ML, and big data analytics. I love experimenting with new technologies in the AI and ML space, and Qdrant is a place where I've seen such innovative implementations recently.
![Guohao Li Photo](https://qdrant.tech/img/stars/guohao-li.jpg)
###### Guohao Li
Founder of Eigent.AI
Guohao Li the founder of Eigent.AI, an artificial intelligence researcher and an open-source contributor working on building intelligent agents that can perceive, learn, communicate, reason, and act. He is the core lead of the open source projects CAMEL-AI.org.
![Şahin Utar Photo](https://qdrant.tech/img/stars/sahin-utar.jpg)
###### Şahin Utar
Software Builder, Entrepreneur
Şahin, a dedicated RAG evangelist since 2022, leverages vector databases in his startups as an early GenAI adopter. A former CTO, now an entrepreneur, he focuses on Dart and Python, using GenAI, RAG, and domain ontologies to simplify complex consumer challenges.
![Astra Clelia Bertelli Photo](https://qdrant.tech/img/stars/astra-clelia-bertelli.jpg)
###### Astra Clelia Bertelli
Foundation Engineer, Bioinformatics researcher
Foundation Engineer @ Criad LTD, Bioinformatics researcher @ Natural History Museum Vienna
![Turja Narayan Chaudhuri Photo](https://qdrant.tech/img/stars/turja-narayan-chaudhuri.jpg)
###### Turja Narayan Chaudhuri
Global Platform Presales Leader
Global Platform Presales Leader, EY. 13+ years of experience in the IT Industry across Samsung, PwC, EY, and Accenture.
#### Join our growing community
![Github icon](https://qdrant.tech/img/stars-marketplaces/github.svg)
###### 23.0k Stars
Join our GitHub community and contribute to the future of vector databases.
![Discord icon](https://qdrant.tech/img/stars-marketplaces/discord.svg)
###### 7.8k Members
Discover and chat on a vibrant community of developers working on the future of AI.
![Twitter icon](https://qdrant.tech/img/stars-marketplaces/twitter.svg)
###### 7.5k Followers
Join us on X, participate and find out about our updates and releases before anyone else.
### Are you contributing to our code, content, or community?
![](https://qdrant.tech/img/stars.svg)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/stars/)
                    ## 📄 `https-qdrant-tech-subscribe.md`
                    ```md
                    # https://qdrant.tech/subscribe/
##### Sign up for Qdrant Updates
Stay up to date on product news, technical articles, and upcoming educational webinars.
![Astronaut](https://qdrant.tech/img/subscribe.png) ![Astronaut](https://qdrant.tech/img/mobile/subscribe.png)
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy ](https://qdrant.tech/legal/privacy-policy/)[Impressum](https://qdrant.tech/legal/impressum/)
                    ## 📄 `https-qdrant-tech.md`
                    ```md
                    # https://qdrant.tech
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech)
                    ## 📄 `https-try-qdrant-tech-5-minute-rag-hslang-en.md`
                    ```md
                    # https://try.qdrant.tech/5-minute-rag?hsLang=en
![laptop icon with a play button](https://try.qdrant.tech/hubfs/training.svg)
On-demand webinar
# 5 Minute RAG: Learn How to Build GenAI at Warp Speed
Tuesday, October 29, 2024
8:00 AM PT/ 11:00 AM ET/ 4:00 PM CET
## What You'll Learn:
  * **Why RAG?:** What are the pros and cons of building a RAG app and why is everyone talking about it? Why is this different from every other chat app?
  * **Quick RAG App Development** : Discover the fastest way to build a functional RAG application.
  * **Evaluation Techniques** : Learn how to assess and improve your RAG model's performance.
  * **Testing Strategies** : Master the art of thorough testing for robust RAG applications.
  * **Essential Packages** : Learn about the key tools and libraries that streamline RAG development.
## Who Should Watch:
  * AI and machine learning enthusiasts
  * Software developers interested in NLP
  * Data scientists looking to enhance their skillset
  * Anyone curious about rapid AI application development
## What You'll Need:
  * Basic understanding of Python
  * Enthusiasm for AI and natural language processing
  * Familiarity with machine learning concepts is helpful, but not required
[ Watch the recording ](https://try.qdrant.tech/5-minute-rag?hsLang=en#form)
### Watch now
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=93ea8069-a8f9-4e5e-9dbf-61e2e5f00bb9&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=a2d38636-fd03-4d31-aaa8-1b4779598ef1&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2F5-minute-rag&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=93ea8069-a8f9-4e5e-9dbf-61e2e5f00bb9&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=a2d38636-fd03-4d31-aaa8-1b4779598ef1&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2F5-minute-rag&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=e5d44dad-1da4-47ef-9d68-369a3b6c5511&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=a2d38636-fd03-4d31-aaa8-1b4779598ef1&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2F5-minute-rag&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=e5d44dad-1da4-47ef-9d68-369a3b6c5511&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=a2d38636-fd03-4d31-aaa8-1b4779598ef1&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2F5-minute-rag&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-agentic-rag-crewai-hslang-en.md`
                    ```md
                    # https://try.qdrant.tech/agentic-rag-crewai?hsLang=en
![Tag](https://try.qdrant.tech/hubfs/raw_assets/public/New%20Qdrant%20LP%20Designs/images/icons/webinar-tag.svg)
# Building Intelligent Agentic RAG with CrewAI and Qdrant
Kacper Łukawski, Senior Developer Advocate at Qdrant
Tony Kipkemboi, Senior Developer Advocate at CrewAI
# About: 
Do you want to build an advanced agentic RAG system?
Are you interested in boosting your productivity, and automating certain tasks of your daily routines? 
We'll demonstrate how to build an intelligent personal assistant that semi-automates email management and knowledge organization using CrewAI and Qdrant.
You'll learn how to create a system where AI agents connect directly to your email inbox and personal knowledge base, analyzing incoming communications and existing knowledge to prepare contextually relevant response suggestions. The system will maintain human oversight by allowing you to review and modify these responses before sending.
We'll show you how to build a unified knowledge base in Qdrant that seamlessly integrates both email communications and Obsidian notes, enabling your AI agents to provide more informed and contextual assistance. Beyond email management, you'll learn how to implement agents that automatically generate and maintain to-do lists, organize your notes for clarity, and create structured summaries of your knowledge base. This automated approach to personal knowledge management can help you reclaim hours of your week while maintaining full control over your communications.
# Learning outcomes: 
  * Build an advanced agentic RAG system that combines automated email processing with Obsidian notes management
  * Learn practical agent orchestration patterns using CrewAI and Qdrant for personal data
  * Implement human-in-the-loop workflows for responsible AI automation
# Who should watch:
  * AI/ML Engineers
  * Solutions Architects  
  * Software Developers  
  * Technical Product Managers
# Pre-requisites: 
  * Basic understanding of vector databases and embeddings  
  * Familiarity with Python 
  * General knowledge of LLMs and their applications
  * No specific CrewAI or Qdrant experience required  
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=0990c2e9-f1d8-4725-87e6-0ed49484838a&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1062e527-e040-4558-ae16-b861acdf42f7&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fagentic-rag-crewai&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=0990c2e9-f1d8-4725-87e6-0ed49484838a&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1062e527-e040-4558-ae16-b861acdf42f7&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fagentic-rag-crewai&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=488a467b-9985-4cd5-ae33-85ad7781d128&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1062e527-e040-4558-ae16-b861acdf42f7&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fagentic-rag-crewai&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=488a467b-9985-4cd5-ae33-85ad7781d128&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1062e527-e040-4558-ae16-b861acdf42f7&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fagentic-rag-crewai&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-ai-agents-webinar-hslang-en.md`
                    ```md
                    # https://try.qdrant.tech/ai-agents-webinar?hsLang=en
#  Build production-ready AI Agents with Qdrant and n8n
### Learn how to design and deploy advanced AI agents with n8n’s low-code self-hosted AI starter kit and Qdrant’s vector database
Why? Because looking beyond RAG, AI agents are the next step in intelligent systems, in which LLMs serve as “brains of operation,” orchestrating tools and storing their “knowledge” in vector databases.
Vector databases "under the hood" of AI agents can be much more than a similarity search engine—they also can be used for diversity search, anomaly detection, and classification, especially useful for limited-label scenarios or expanding class structures over time.
It isn't easy to bring these impactful AI agents from ideation to production. You want:
  * to make the LLM produce consistent output in the required format
  * to seamlessly integrate tools with AI agents
  * debug and manage agentic pipelines
all of which can be difficult. 
### Watch this video to: 
Learn how to deploy advanced AI agents using Qdrant’s vector database power beyond similarity search and n8n’s low-code AI starter kit.
We’ll demonstrate how AI agents detect anomalies in satellite images (scaling search to the entire Earth) and moderate spam, showing how versatile they can be and how to overcome the challenge of making them production-ready.
### Speakers
![Screenshot 2024-11-13 at 7.38.46 AM](https://try.qdrant.tech/hs-fs/hubfs/Screenshot%202024-11-13%20at%207.38.46%20AM.png?width=500&height=436&name=Screenshot%202024-11-13%20at%207.38.46%20AM.png)
Max Tkacz 
Senior Developer Advocate, n8n 
![T027ADPGJUB-U07BZCSUM7H-70b6368e98ff-512](https://try.qdrant.tech/hs-fs/hubfs/Imported%20sitepage%20images/T027ADPGJUB-U07BZCSUM7H-70b6368e98ff-512.jpg?width=512&height=512&name=T027ADPGJUB-U07BZCSUM7H-70b6368e98ff-512.jpg)
Jenny Sukhodolskaya
Developer Advocate, Qdrant 
[ Watch now ](https://try.qdrant.tech/ai-agents-webinar?hsLang=en)
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=14aed9bc-811d-4051-862e-df98a99e305a&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=2efe3d48-60ae-4307-95c8-430b4ea647fa&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fai-agents-webinar&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=14aed9bc-811d-4051-862e-df98a99e305a&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=2efe3d48-60ae-4307-95c8-430b4ea647fa&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fai-agents-webinar&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=9d1bab86-3b0f-4e60-9997-ae8b9e1c5006&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=2efe3d48-60ae-4307-95c8-430b4ea647fa&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fai-agents-webinar&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=9d1bab86-3b0f-4e60-9997-ae8b9e1c5006&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=2efe3d48-60ae-4307-95c8-430b4ea647fa&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fai-agents-webinar&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-build-advanced-agents-with-llamaindex-and-qdrant-hslang-en.md`
                    ```md
                    # https://try.qdrant.tech/build-advanced-agents-with-llamaindex-and-qdrant?hsLang=en
![laptop icon with a play button](https://try.qdrant.tech/hubfs/training.svg)
On-demand Webinar
# Beyond the Tutorial: Building Agents with LlamaIndex & Qdrant
Are you ready to move beyond the basics and build advanced agents that can manage complex, real-world queries?
Watch this webinar recording on how to harness the power of LlamaIndex and Qdrant to create next-generation intelligent systems.
**Learning objectives:**
  * **Implement a RAG-enabled agent** using LlamaIndex and Qdrant, expanding beyond traditional RAG applications by building an intelligent system capable of handling complex queries across multiple data modalities.
  * **Learn how to integrate LlamaIndex with Qdrant** to leverage its vector database capabilities for enhanced search and retrieval performance in a RAG system.
### Speakers
![IMG_2960-removebg-preview-2](https://try.qdrant.tech/hs-fs/hubfs/IMG_2960-removebg-preview-2.png?width=204&height=222&name=IMG_2960-removebg-preview-2.png)
Thierry Damiba
Developer Advocate at Qdrant
![llama](https://try.qdrant.tech/hs-fs/hubfs/llama.jpeg?width=400&height=400&name=llama.jpeg)
Sourabh Desai
Founding Engineer at LlamaIndex
This webinar is ideal for data scientists, AI engineers, software developers, and tech enthusiasts who are looking to deepen their understanding of AI-driven agent systems and improve their implementation skills.
**LlamaIndex** is a powerful tool for managing and querying large datasets, offering an intuitive interface for integrating machine learning models. It simplifies the process of building retrieval-augmented generation (RAG) systems, enabling developers to create more sophisticated and responsive agents.
**Qdrant** is a high-performance vector database designed for handling large-scale, multidimensional data. With its ability to perform efficient similarity searches, Qdrant enhances the capabilities of RAG systems by optimizing search and retrieval processes, making it an indispensable component in your AI toolkit.
[ Watch Now ](https://try.qdrant.tech/build-advanced-agents-with-llamaindex-and-qdrant?hsLang=en#form)
### Watch now
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=d30dd01c-2815-4376-90a0-c922c3ff3388&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=e4931397-d0bc-4c25-9255-6f9198961e64&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fbuild-advanced-agents-with-llamaindex-and-qdrant&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=d30dd01c-2815-4376-90a0-c922c3ff3388&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=e4931397-d0bc-4c25-9255-6f9198961e64&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fbuild-advanced-agents-with-llamaindex-and-qdrant&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=14ef0320-d295-4858-b18c-2b2b00382e7f&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=e4931397-d0bc-4c25-9255-6f9198961e64&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fbuild-advanced-agents-with-llamaindex-and-qdrant&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=14ef0320-d295-4858-b18c-2b2b00382e7f&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=e4931397-d0bc-4c25-9255-6f9198961e64&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fbuild-advanced-agents-with-llamaindex-and-qdrant&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-colpali-webinar-hslang-en.md`
                    ```md
                    # https://try.qdrant.tech/colpali-webinar?hsLang=en
# Using ColPali and Binary Quantization for Efficient Multimodal Retrieval  
In this webinar, we explored the technical details of ColPali, an advanced multimodal retrieval approach that uses Vision Language Models (VLMs) to handle visually complex documents.
Learn how ColPali uses **multivectors** to represent document images, capturing both local and global context.
##### Key topics:
  * **Multivectors** : Representing documents as multiple embeddings to capture both local and global context, enhancing search accuracy.
  * **Late Interaction** : Performing token-level comparisons between queries and document patches for precise relevance scoring.
  * **MaxSim Pooling** : Aggregating the highest similarity scores from these comparisons to identify the most relevant document sections.
  * **Binary Quantization** : Compressing vector data to optimize memory usage and accelerate search with minimal accuracy loss.
Learn how these techniques can be applied for efficient multimodal retrieval for complex, visually-rich documents.
### Qdrant Speakers
Atita Arora, Solutions Architect
Atita Arora is a solution architect with 17+ years in information retrieval, driving AI innovation at Qdrant. She specializes in vector and hybrid search, focusing on Retrieval-Augmented Generation (RAG) and LLMs. An avid open-source contributor, Atita also champions diversity in tech as co-leader of Women in Search.
Sabrina Aquino, Developer Relations
Jenny Sukhodolskaya, Developer Advocate
Jenny Sukhodolskaya has 7 years of IT experience across software engineering, machine learning, and technical management, and 3 years in Developer Relations. She holds a Master’s in Machine Learning, Data Analytics, and Data Engineering, and is passionate about NLP, data-centric AI, and the role of vector databases in advancing AI technologies.
[ Watch the video ](https://try.qdrant.tech/colpali-webinar?hsLang=en#form)
### Watch the video
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=6c665b90-a288-4e23-b08e-5799633ae398&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=dcdef2b9-950c-44d9-82ce-f71bc4984e48&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fcolpali-webinar&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=6c665b90-a288-4e23-b08e-5799633ae398&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=dcdef2b9-950c-44d9-82ce-f71bc4984e48&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fcolpali-webinar&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=f635eb16-af84-4ee4-8be2-15153c26b5a1&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=dcdef2b9-950c-44d9-82ce-f71bc4984e48&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fcolpali-webinar&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=f635eb16-af84-4ee4-8be2-15153c26b5a1&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=dcdef2b9-950c-44d9-82ce-f71bc4984e48&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fcolpali-webinar&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-deepseek-hslang-en.md`
                    ```md
                    # https://try.qdrant.tech/deepseek?hsLang=en
# Building Open-Source Agentic RAG with DeepSeek
Thierry Damiba, Developer Advocate
Bastian Hofmann, Director, Enterprise Solutions
Fill out the form to watch the replay.
## What we'll cover:
Watch for an in-depth look at how to deploy DeepSeek for agentic retrieval-augmented generation, purely open-source and in your own environment.
We’ll walk through orchestrating your agentic AI application, and ensuring secure, high-performance, privacy-first vector search with Qdrant — all while maintaining full control over your data.
[ Watch now ](https://try.qdrant.tech/deepseek?hsLang=en#hero)
## Learning outcomes:
  * Build privacy-first AI Agents
  * Deploy DeepSeek models locally
  * Secure vector search data with Qdrant
  * Learn the benefits of optimized vector search
  * Understand the cost and benefit of open-source infrastructure
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=7f4e1a20-9891-4f4c-8ce9-c4d8d9409c08&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=30e317f6-733f-494d-b3e9-c06d2e5e30d3&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeepseek&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=7f4e1a20-9891-4f4c-8ce9-c4d8d9409c08&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=30e317f6-733f-494d-b3e9-c06d2e5e30d3&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeepseek&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=9cffd099-2eb4-4a59-9020-a79a80a3fd97&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=30e317f6-733f-494d-b3e9-c06d2e5e30d3&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeepseek&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=9cffd099-2eb4-4a59-9020-a79a80a3fd97&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=30e317f6-733f-494d-b3e9-c06d2e5e30d3&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeepseek&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-deutsche-telekom-talk-hslang-en.md`
                    ```md
                    # https://try.qdrant.tech/deutsche-telekom-talk?hsLang=en
![laptop icon with a play button](https://try.qdrant.tech/hubfs/training.svg)
Livestream
# How Deutsche Telekom Scaled an Enterprise Multi-Agent Platform with Qdrant, Powering 2M+ Conversations
Deutsche Telekom’s AI Competence Center (AICC) had a critical challenge: how do you efficiently and scalably deploy AI-powered assistants across a vast enterprise ecosystem?  
The goal was to deploy GenAI for customer sales and service operations to resolve customer queries faster across the 10 countries where Deutsche Telekom operates in Europe.  
In this Vector Space talk, Thierry from Qdrant and Arun from Deutsche Telekom talk about the key requirements for scaling enterprise AI agents, key AI stack considerations, and how the team built a Platform as a Service (PaaS) - LMOS (Language Models Operating System) — a multi-agent PaaS designed for high scalability and modular AI agent deployment.
### Hear from:
![Arun-Telekom](https://try.qdrant.tech/hs-fs/hubfs/Arun-Telekom.jpeg?width=800&height=800&name=Arun-Telekom.jpeg)
Arun Joseph
Engineering & Architecture Lead  
AI Competence Center  
Deutsche Telekom
![IMG_2960-removebg-preview-2](https://try.qdrant.tech/hs-fs/hubfs/IMG_2960-removebg-preview-2.png?width=204&height=222&name=IMG_2960-removebg-preview-2.png)
Thierry Damiba
Developer Advocate  
Qdrant
Learn how Telekom's LMOS with Qdrant processes over 2 million conversations across three countries, and decreased the time required to develop a new agent from 15 days to just 2. 
[ Watch now ](https://try.qdrant.tech/deutsche-telekom-talk?hsLang=en#form)
![Deutsche-Telekom-Case-Study-A-cropped](https://try.qdrant.tech/hs-fs/hubfs/Deutsche-Telekom-Case-Study-A-cropped.jpg?width=2000&height=1241&name=Deutsche-Telekom-Case-Study-A-cropped.jpg)
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=50db269c-4582-46fe-bfb5-959596a59cee&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=51b5441a-fc9e-43cb-ba7d-c6ae31b76d93&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeutsche-telekom-talk&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=50db269c-4582-46fe-bfb5-959596a59cee&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=51b5441a-fc9e-43cb-ba7d-c6ae31b76d93&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeutsche-telekom-talk&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=47d83fa0-8acf-4d0f-99db-4c8e82499180&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=51b5441a-fc9e-43cb-ba7d-c6ae31b76d93&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeutsche-telekom-talk&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=47d83fa0-8acf-4d0f-99db-4c8e82499180&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=51b5441a-fc9e-43cb-ba7d-c6ae31b76d93&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeutsche-telekom-talk&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-events.md`
                    ```md
                    # https://try.qdrant.tech/events
# Qdrant Technical Events
Meet us at upcoming hackathons, meetups, webinars and conferences.
![Data-Graphic](https://try.qdrant.tech/hs-fs/hubfs/Data-Graphic.png?width=882&height=440&name=Data-Graphic.png)
![AI-Agents-Light](https://try.qdrant.tech/hs-fs/hubfs/AI-Agents-Light.png?width=411&height=300&name=AI-Agents-Light.png)
### Using MCP to Orchestrate AI Agents with OpenAI SDK, AugmentCode, and Qdrant 
Virtual | April 29
[ Register now ](https://try.qdrant.tech/mcp-agent-interoperability?hsLang=en)
## Agents & GenAI Infrastructure and Tooling Summit
📍April 15 | Virtual
Kacper Lukawksi, Developer Advocate, will present a talk "All the Flavors of AI-Powered Search" at 
## PyCon DE
📍April 23-25 | Germany
Kacper Lukawksi, Developer Advocate, will present a talk about semantic search in Django at 
# Missed a live-stream or webinar? Access on demand. 
![Telekom-Hubspot landing page](https://try.qdrant.tech/hs-fs/hubfs/Telekom-Hubspot%20landing%20page.jpg?width=2000&height=1044&name=Telekom-Hubspot%20landing%20page.jpg)
### Agents for the Enterprise
Hear directly from Telekom's Arun Joseph about scaling enterprise agents across multiple countries. 
[ Watch now ](https://try.qdrant.tech/deutsche-telekom-talk?hsLang=en)
![Deepseek-agentic-rag](https://try.qdrant.tech/hs-fs/hubfs/Deepseek-agentic-rag.jpg?width=2000&height=1044&name=Deepseek-agentic-rag.jpg)
## DeepSeek
Learn how to deploy DeepSeek for agentic retrieval-augmented generation, purely open-source and in your own environment.
[ Watch now ](https://try.qdrant.tech/deepseek?hsLang=en)
![YouTube cover_2](https://try.qdrant.tech/hs-fs/hubfs/YouTube%20cover_2.jpg?width=2000&height=1044&name=YouTube%20cover_2.jpg)
## LLMs Coding RAG
Evaluating Cursor, Aider, Claude Code, and GitHub Copilot. Learn how to build a RAG app without writing any code.
[ Watch now ](https://try.qdrant.tech/llm-rag?hsLang=en)
![Colpali-binary-quan](https://try.qdrant.tech/hs-fs/hubfs/Colpali-binary-quan.jpg?width=2000&height=1044&name=Colpali-binary-quan.jpg)
### Multimodal Retrieval 
We'll explore how ColPali, an advanced multimodal retrieval approach, uses multivectors to represent document images, capturing both local and global context. [Watch now](https://try.qdrant.tech/colpali-webinar?hsLang=en).
![5-minute-RAG](https://try.qdrant.tech/hs-fs/hubfs/5-minute-RAG.jpg?width=2000&height=1044&name=5-minute-RAG.jpg)
### Build RAG in 5 Minutes 
Learn how to create a RAG application in just 5 minutes. We will also show you how quickly you can build an app using Bootstrap RAG. [Watch now.](https://try.qdrant.tech/5-minute-rag?hsLang=en)
![agents-with-n8n](https://try.qdrant.tech/hs-fs/hubfs/agents-with-n8n.jpg?width=2000&height=1044&name=agents-with-n8n.jpg)
### n8n + Qdrant = <3 
See how easy it can be to deploy advanced AI agents using Qdrant’s vector database power beyond similarity search and n8n’s low-code AI starter kit. [Watch now](https://try.qdrant.tech/ai-agents-webinar?hsLang=en).
![Crewai-agentic-rag](https://try.qdrant.tech/hs-fs/hubfs/Crewai-agentic-rag.jpg?width=2000&height=1044&name=Crewai-agentic-rag.jpg)
## CrewAI + Qdrant for Agents
Build an advanced agentic RAG system that combines automated email processing with Obsidian notes management.
[ Watch now ](https://try.qdrant.tech/agentic-rag-crewai?hsLang=en)
## Implement a RAG-enabled agent using LlamaIndex and Qdrant
Build advanced agents that can manage complex, real-world queries.
[ Watch now ](https://try.qdrant.tech/build-advanced-agents-with-llamaindex-and-qdrant?hsLang=en)
![Lllamaindex-agents-light](https://try.qdrant.tech/hs-fs/hubfs/Lllamaindex-agents-light.jpg?width=2000&height=1044&name=Lllamaindex-agents-light.jpg)
# Photos from past events (yes, to incite FOMO):
![event-crewai](https://try.qdrant.tech/hs-fs/hubfs/event-crewai.jpeg?width=2000&height=1500&name=event-crewai.jpeg)
###### Qdrant + CrewAI + n8n
![event-recap](https://try.qdrant.tech/hs-fs/hubfs/event-recap.jpg?width=2000&height=1500&name=event-recap.jpg)
###### Agents taking over SF
![thierry-deeplearning](https://try.qdrant.tech/hs-fs/hubfs/thierry-deeplearning.jpeg?width=1271&height=1075&name=thierry-deeplearning.jpeg)
###### DeepLearning AI
### 
Build with Qdrant
Turn embeddings or neural network encoders into full-fledged applications for matching, searching, recommending, and more. You can start prototyping with your forever-free first cluster. 
[ Try now ](https://qdrant.tech/)
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=d0b008c9-30ef-414d-ae4d-ae7b0905af60&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=7ba862fc-bddb-4346-8f7d-50708b475974&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fevents&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=d0b008c9-30ef-414d-ae4d-ae7b0905af60&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=7ba862fc-bddb-4346-8f7d-50708b475974&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fevents&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=ff6b84d7-6022-4859-b78e-8f8e8aca9613&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=7ba862fc-bddb-4346-8f7d-50708b475974&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fevents&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=ff6b84d7-6022-4859-b78e-8f8e8aca9613&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=7ba862fc-bddb-4346-8f7d-50708b475974&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fevents&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-llm-rag-hslang-en.md`
                    ```md
                    # https://try.qdrant.tech/llm-rag?hsLang=en
# Letting LLMs Write RAG Applications
Kacper Łukawski, Senior Developer Advocate
Learn how to build a RAG app without writing any code 
## What we'll cover:
"The hottest new programming language is English," as Andrej Karpathy famously said. But does that hold true for writing end-to-end RAG applications with Qdrant? We put it to the test.
In this livestream, we'll demonstrate how to build a complete RAG application by avoiding writing code ourselves at all costs. We'll explore how far we can push AI systems to generate both frontend and backend code through natural language prompts and instructions, creating a fully functional RAG application powered by Qdrant's vector search capabilities.
We've evaluated different AI coding assistants, including Cursor, Aider, Claude Code, and GitHub Copilot. While Claude 3.5 and 3.7 have earned recognition for producing amazing frontend code, we'll assess its capabilities for full-stack development and discuss which frameworks deliver the most consistent and high-quality results.
  * Understand the process of building a RAG application using AI-powered tools.
  * Explore how AI can be leveraged to generate both frontend and backend code with natural language prompts.
  * Gain insights into vector search capabilities through Qdrant in the context of a RAG application.
  * Learn about different AI coding assistants (Cursor, Aider, Claude Code, GitHub Copilot) and their strengths for full-stack development.
  * Evaluate which frameworks and approaches deliver the most consistent and high-quality results for AI-driven development.
## Who should attend:
  * Developers interested in AI-assisted programming and no-code/low-code solutions.
  * Engineers looking to explore the potential of natural language for end-to-end application development.
  * Anyone curious about using AI tools for full-stack development, including building RAG applications.
  * Professionals interested in understanding the latest trends in AI coding assistants and vector search technology.
## Pre-req's:
  * Basic understanding of software development, particularly in frontend and backend frameworks.
  * Familiarity with the concepts of RAG and vector search.
  * Some experience with general programming concepts will be helpful.
  * No prior knowledge of specific coding assistants like Cursor, Aider, or Claude required.
[ Watch now ](https://try.qdrant.tech/llm-rag?hsLang=en#hero)
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=ad6f5e8e-01a1-4243-9900-6ec69554d20f&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1595c2b1-4e79-4f47-9546-7c16d007e970&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fllm-rag&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=ad6f5e8e-01a1-4243-9900-6ec69554d20f&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1595c2b1-4e79-4f47-9546-7c16d007e970&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fllm-rag&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=0fc00e21-c6f7-490c-96a3-7d28776e6763&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1595c2b1-4e79-4f47-9546-7c16d007e970&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fllm-rag&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=0fc00e21-c6f7-490c-96a3-7d28776e6763&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1595c2b1-4e79-4f47-9546-7c16d007e970&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fllm-rag&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-mcp-agent-interoperability-hslang-en.md`
                    ```md
                    # https://try.qdrant.tech/mcp-agent-interoperability?hsLang=en
![laptop icon with a play button](https://try.qdrant.tech/hubfs/training.svg)
Webinar
# Using MCP to Orchestrate AI Agents with OpenAI SDK, AugmentCode, and Qdrant
Monday, April 29, 2024
8:00 AM PT/ 11:00 AM ET/ 5:00 PM CEST
Multi-client protocols (MCP) are gaining momentum (with recent adoption by OpenAI and Google) as a new standard for agent interoperability.
We’ll show you how to harness the power of MCP to connect AI coding tools like AugmentCode with OpenAI’s new Agents SDK, all backed by Qdrant for fast vector search.
### Speakers
![Avatar](https://try.qdrant.tech/hs-fs/hubfs/Avatar.png?width=64&height=64&name=Avatar.png)
Kacper Łukawski
Developer Advocate
You’ll learn:
  * What MCP is and why it's suddenly everywhere
  * The fundamentals of MCP: how it enables agent communication via a shared event bus
  * Setting up an MCP server and connecting multiple clients (OpenAI Agents, AugmentCode, custom tools)
  * Using Qdrant as a vector backend for memory, code context, and retrieval-augmented workflows
  * Where Qdrant fits in as the vector search layer for agent memory and tool use  
  * Real-time agent orchestration inside your IDE, with multi-agent collaboration on tasks like code generation, refactoring, and debugging
  * Real-world demos of coding agents collaborating in an IDE
  * How to extend these tools for your own AI developer workflows
Whether you're experimenting with AI-supported coding or building your own developer agents, this session will give you practical, future-ready insights into using MCP with real tools.
### Register Now
Qdrant needs the contact information you provide to us to contact you about our products and services. You may unsubscribe from these communications at any time. For information on how to unsubscribe, as well as our privacy practices and commitment to protecting your privacy, please review our Privacy Policy.
By registering, you agree to our [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) and allow Qdrant to store and process the information submitted above to provide you with the webinar information requested.  
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=44e57178-0670-478e-aa5d-b1c0020c01cd&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=b1db5c60-8f0a-4603-acc6-407644c406d0&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fmcp-agent-interoperability&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=44e57178-0670-478e-aa5d-b1c0020c01cd&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=b1db5c60-8f0a-4603-acc6-407644c406d0&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fmcp-agent-interoperability&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=640fc627-194e-45ac-a94e-e4a577b9cfe4&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=b1db5c60-8f0a-4603-acc6-407644c406d0&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fmcp-agent-interoperability&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=640fc627-194e-45ac-a94e-e4a577b9cfe4&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=b1db5c60-8f0a-4603-acc6-407644c406d0&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fmcp-agent-interoperability&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ```
                    ```
                    ## 📄 `http-qdrant-tech.md`
  * [Qdrant Vector Database](https://qdrant.tech/qdrant-vector-database/)
  * [Qdrant Cloud](https://qdrant.tech/cloud/)
  * [Qdrant Hybrid Cloud](https://qdrant.tech/hybrid-cloud/)
  * [Qdrant Enterprise Solutions](https://qdrant.tech/enterprise-solutions/)
Use Cases
  * [Advanced Search](https://qdrant.tech/advanced-search/)
  * [Recommendation Systems](https://qdrant.tech/recommendations/)
  * [Retrieval Augmented Generation](https://qdrant.tech/rag/)
  * [Data Analysis & Anomaly Detection](https://qdrant.tech/data-analysis-anomaly-detection/)
  * [AI Agents](https://qdrant.tech/ai-agents/)
Developers
  * [Documentation](https://qdrant.tech/documentation/)
  * [Community](https://qdrant.tech/community/)
Resources
  * [Blog](https://qdrant.tech/blog/)
  * [Benchmarks](https://qdrant.tech/benchmarks/)
  * [Articles](https://qdrant.tech/articles/)
  * [Events](https://try.qdrant.tech/events)
  * [Startup Program](https://qdrant.tech/qdrant-for-startups/)
  * [Demos](https://qdrant.tech/demo/)
  * [Bug Bounty](https://qdrant.tech/security/bug-bounty-program/)
Company
  * [About Us](https://qdrant.tech/about-us/)
  * [Customers](https://qdrant.tech/customers/)
  * [Partners](https://qdrant.tech/partners/)
  * [Contact Us](https://qdrant.tech/contact-us/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](http://qdrant.tech/legal/privacy-policy/)[I accept](http://qdrant.tech/)
### Qdrant Code Search Unleashing Semantic Power
Qdrant Code Explorer: Empowering Semantic Searching in Qdrant Repository with Advanced Code Analysis
                    ## 📄 `https-demo-qdrant-tech.md`
# Startup Semantic search with Qdrant
This demo uses short descriptions of startups to perform a semantic search.
Neural
Text
Search
Try this:
Qdrant
Wooden furniture
Milk Company
![No results found.](https://demo.qdrant.tech/home.gif)
Enter a query to start searching.
                    ## 📄 `https-food-discovery-qdrant-tech.md`
## What are you looking for?
CancelSearch
                    ## 📄 `https-qdrant-tech-about-us.md`
##### Want to build the technology for the next generation of AI applications with us?
Take a look at our open roles. We’re excited to hear from you.
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/about-us/)
                    ## 📄 `https-qdrant-tech-advanced-search.md`
###### Create a Hybrid Search Service with FastEmbed
This tutorial guides you through building and deploying your own hybrid search service using FastEmbed.
[View Tutorial](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/advanced-search/)
                    ## 📄 `https-qdrant-tech-ai-agents-ai-agents.md`
### Building AI agents?
Apply for the Qdrant for Startups program to access a 20% discount to Qdrant Cloud, our managed cloud service, perks from Hugging Face, LlamaIndex, and Airbyte, and much more.
[Apply Now](https://qdrant.tech/qdrant-for-startups/)
![](https://qdrant.tech/img/ai-agent.svg)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/ai-agents/)
                    ## 📄 `https-qdrant-tech-ai-agents.md`
  * [Articles](https://qdrant.tech/articles/)
  * What is Agentic RAG? Building Agents with Qdrant
[](https://qdrant.tech/articles/rag-and-genai/)
  * **Querying a vector database** - the most common tool used in agentic RAG systems. It allows the agent to retrieve relevant documents based on the query.
  * **Query expansion** - a tool that can be used to improve the query. It can be used to add synonyms, correct typos, or even to generate new queries based on the original one. ![Query expansion example](https://qdrant.tech/articles_data/agentic-rag/query-expansion.png)
  * **Extracting filters** - vector search alone is sometimes not enough. In many cases, you might want to narrow down the results based on specific parameters. This extraction process can automatically identify relevant conditions from the query. Otherwise, your users would have to manually define these search constraints. ![Extracting filters](https://qdrant.tech/articles_data/agentic-rag/extracting-filters.png)
  * **Quality judgement** - knowing the quality of the results for given query can be used to decide whether they are good enough to answer, or if the agent should take another step to improve them somehow. Alternatively it can also admit the failure to provide good response. ![Quality judgement](https://qdrant.tech/articles_data/agentic-rag/quality-judgement.png)
These are just some of the examples, but the list is not exhaustive. For example, your LLM could possibly play with Qdrant search parameters or choose different methods to query it. An example? If your users are searching using some specific keywords, you may prefer sparse vectors to dense vectors, as they are more efficient in such cases. In that case you have to arm your agent with tools to decide when to use sparse vectors and when to use dense vectors. Agent aware of the collection structure can make such decisions easily.
Each of these tools might be a separate agent on its own, and multi-agent systems are not uncommon. In such cases, agents can communicate with each other, and one agent can decide to use another agent to solve a particular problem. Pretty useful component of an agentic RAG is also a human in the loop, which can be used to correct the agent’s decisions, or steer it in the right direction.
  * **Persistence** - the state of the workflow graph is stored as a checkpoint. That happens at each so-called super-step (which is a single sequential node of a graph). It enables replying certain steps of the workflow, fault-tolerance, and including human-in-the-loop interactions. This mechanism also acts as a **short-term memory** , accessible in a context of a particular workflow execution.
  * **Long-term memory** - LangGraph also has a concept of memories that are shared between different workflow runs. However, this mechanism has to explicitly handled by our nodes. **Qdrant with its semantic search capabilities is often used as a long-term memory layer**.
  * **Multi-agent support** - while there is no separate concept of multi-agent systems in LangGraph, it’s possible to create such an architecture by building a graph that includes multiple agents and some kind of supervisor that makes a decision which agent to use in a given situation. If a node might be anything, then it might be another agent as well.
Some other interesting features of LangGraph include the ability to visualize the graph, automate the retries of failed steps, and include human-in-the-loop interactions.
A minimal example of an agentic RAG could improve the user query, e.g. by fixing typos, expanding it with synonyms, or even generating a new query based on the original one. The agent could then retrieve documents from a vector database based on the improved query, and generate a response. The LangGraph app implementing this approach could look like this:
  * **Agent** - a unit that has a specific role and goal, controlled by an LLM. It can optionally use some external tools to communicate with the outside world, but generally steered by prompt we provide to the LLM.
  * **Process** - currently either sequential or hierarchical. It defines how the task will be executed by the agents. In a sequential process, agents are executed one after another, while in a hierarchical process, agent is selected by the manager agent, which is responsible for making decisions about which agent to use in a given situation.
  * **Roles and goals** - each agent has a certain role within the crew, and the goal it should aim to achieve. These are set when we define an agent and are used to make decisions about which agent to use in a given situation.
  * **Memory** - an extensive memory system consists of short-term memory, long-term memory, entity memory, and contextual memory that combines the other three. There is also user memory for preferences and personalization. **This is where Qdrant comes into play, as it might be used as a long-term memory layer.**
CrewAI provides a rich set of tools integrated into the framework. That may be a huge advantage for those who want to combine RAG with e.g. code execution, or image generation. The ecosystem is rich, however brining your own tools is not a big deal, as CrewAI is designed to be extensible.
A simple agentic RAG application implemented in CrewAI could look like this:
  * **Tools/functions** - external components that can be used by agents to communicate with the outside world. They are defined as Python callables, and can be used for any external interaction we want to allow the agent to do. Type annotations are used to define the input and output of the tools, and Pydantic models are supported for more complex type schema. AutoGen supports only OpenAI-compatible tool call API for the time being.
  * **Code executors** - built-in code executors include local command, Docker command, and Jupyter. An agent can write and launch code, so theoretically the agents can do anything that can be done in Python. None of the other frameworks made code generation and execution that prominent. Code execution being the first-class citizen in AutoGen is an interesting concept.
Each AutoGen agent uses at least one of the components: human-in-the-loop, code executor, tool executor, or LLM. A simple agentic RAG, based on the conversation of two agents which can retrieve documents from a vector database, or improve the query, could look like this:
  * **Human-in-the-loop** - even though we aim to build autonomous agents, it’s often important to include the feedback from the human, so our agents cannot perform malicious actions.
  * **Observability** - how easy it is to debug the system, and how easy it is to understand what’s happening inside. Especially important, since we are dealing with lots of LLM prompts.
Still, choosing the right toolkit depends on the state of your project, and the specific requirements you have. If you want to integrate your agent with number of external tools, CrewAI might be the best choice, as the set of out-of-the-box integrations is the biggest. However, LangGraph integrates well with LangChain, so if you are familiar with that ecosystem, it may suit you better.
All the frameworks have different approaches to building agents, so it’s worth experimenting with all of them to see which one fits your needs the best. LangGraph and CrewAI are more mature and have more features, while AutoGen and OpenAI Swarm are more lightweight and more experimental. However, **none of the existing frameworks solves all the mentioned Information Retrieval problems** , so you still have to build your own tools to fill the gaps.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/agentic-rag/)
                    ## 📄 `https-qdrant-tech-articles-batch-vector-search-with-qdrant.md`
  * [Articles](https://qdrant.tech/articles/)
  * Mastering Batch Search for Vector Optimization
[](https://qdrant.tech/articles/vector-search-manuals/)
  1. Querying the database sequentially.
  2. Using many threads/processes with individual requests.
  3. Utilizing the batch search of Qdrant in a single request.
  4. Combining parallel processing and batch search.
In order to do that, we’ll create a richer collection of points, with vectors from the  _glove-25-angular_ dataset, quite a common choice for ANN comparison. If you’re interested in seeing some more details of how we benchmarked Qdrant, let’s take a 
  1. Sequential search: 225.9 seconds
  2. Batch search: 208.0 seconds
  3. Multiprocessing search (8 processes): 194.2 seconds
  4. Multiprocessing batch search (8 processes, batch size 10): 148.9 seconds
The results you may achieve on a specific setup may vary depending on the hardware, however, at the first glance, it seems that batch searching may save you quite a lot of time.
Additional improvements could be achieved in the case of distributed deployment, as Qdrant won’t need to make extensive inter-cluster requests. Moreover, if your requests share the same filtering condition, the query optimizer would be able to reuse it among batch requests.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/batch-vector-search-with-qdrant/)
                    ## 📄 `https-qdrant-tech-articles-binary-quantization-openai.md`
  * [Articles](https://qdrant.tech/articles/)
  * Optimizing OpenAI Embeddings: Enhance Efficiency with Qdrant's Binary Quantization
[](https://qdrant.tech/articles/practicle-examples/)
  * The significance of OpenAI embeddings and real-world challenges.
  * Qdrant’s Binary Quantization, and how it can improve the performance of OpenAI embeddings
  * Results of an experiment that highlights improvements in search efficiency and accuracy
  * Implications of these findings for real-world applications
  * Best practices for leveraging Binary Quantization to enhance OpenAI embeddings
If you’re new to Binary Quantization, consider reading our article which walks you through the concept and [how to use it with Qdrant](https://qdrant.tech/articles/binary-quantization/)
You can also try out these techniques as described in 
  * **Oversampling** : By oversampling, we can limit the loss of information inherent in quantization. This also helps to preserve the semantic richness of your OpenAI embeddings. We experimented with different oversampling factors, and identified the impact on the accuracy and efficiency of search. Spoiler: higher oversampling factors tend to improve the accuracy of searches. However, they usually require more computational resources.
  * **Rescoring** : Rescoring refines the first results of an initial binary search. This process leverages the original high-dimensional vectors to refine the search results, **always** improving accuracy. We toggled rescoring on and off to measure effectiveness, when combined with Binary Quantization. We also measured the impact on search performance.
  * **Search Limits** : We specify the number of results from the search process. We experimented with various search limits to measure their impact the accuracy and efficiency. We explored the trade-offs between search depth and performance. The results provide insight for applications with different precision and speed requirements.
Through this detailed setup, our experiment sought to shed light on the nuanced interplay between Binary Quantization and the high-quality embeddings produced by OpenAI’s models. By meticulously adjusting and observing the outcomes under different conditions, we aimed to uncover actionable insights that could empower users to harness the full potential of Qdrant in combination with OpenAI’s embeddings, regardless of their specific application needs.
     * For the `text-embedding-3-large` model with 3072 dimensions, rescoring boosts the accuracy from an average of about 76-77% without rescoring to 97-99% with rescoring, depending on the search limit and oversampling rate.
     * The accuracy improvement with increased oversampling is more pronounced when rescoring is enabled, indicating a better utilization of the additional binary codes in refining search results.
     * With the `text-embedding-3-small` model at 512 dimensions, accuracy increases from around 53-55% without rescoring to 71-91% with rescoring, highlighting the significant impact of rescoring, especially at lower dimensions.
In contrast, for lower dimension models (such as text-embedding-3-small with 512 dimensions), the incremental accuracy gains from increased oversampling levels are less significant, even with rescoring enabled. This suggests a diminishing return on accuracy improvement with higher oversampling in lower dimension spaces.
     * The performance gain from rescoring seems to be relatively stable across different search limits, suggesting that rescoring consistently enhances accuracy regardless of the number of top results considered.
In summary, enabling rescoring dramatically improves search accuracy across all tested configurations. It is crucial feature for applications where precision is paramount. The consistent performance boost provided by rescoring underscores its value in refining search results, particularly when working with complex, high-dimensional data like OpenAI embeddings. This enhancement is critical for applications that demand high accuracy, such as semantic search, content discovery, and recommendation systems, where the quality of search results directly impacts user experience and satisfaction.
  1. **Model Name** : Signifying the specific text embedding model variant, such as “text-embedding-3-large” or “text-embedding-3-small”. This distinction correlates with the model’s capacity, with “large” models offering more detailed embeddings at the cost of increased computational resources.
  2. **Dimensions** : This refers to the size of the vector embeddings produced by the model. Options range from 512 to 3072 dimensions. Higher dimensions could lead to more precise embeddings but might also increase the search time and memory usage in Qdrant.
Optimizing these parameters is a balancing act between search accuracy and resource efficiency. Testing across these combinations allows users to identify the configuration that best meets their specific needs, considering the trade-offs between computational resources and the quality of search results.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/binary-quantization-openai/)
                    ## 📄 `https-qdrant-tech-articles-binary-quantization.md`
  * [Articles](https://qdrant.tech/articles/)
  * Binary Quantization - Vector Search, 40x Faster
[](https://qdrant.tech/articles/qdrant-internals/)
  1. We store all the “full” vectors on disk.
  2. Then we set the binary embeddings to be in RAM.
By default, both the full vectors and BQ get stored in RAM. We move the full vectors to disk because this saves us memory and allows us to store more vectors in RAM. By doing this, we explicitly move the binary vectors to memory by setting `always_ram=True`.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/binary-quantization/)
                    ## 📄 `https-qdrant-tech-articles-cross-encoder-integration-gsoc.md`
  * [Articles](https://qdrant.tech/articles/)
  * Qdrant Summer of Code 2024 - ONNX Cross Encoders in Python
[](https://qdrant.tech/articles/machine-learning/)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/cross-encoder-integration-gsoc/)
                    ## 📄 `https-qdrant-tech-articles-data-exploration.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/data-exploration/)
                    ## 📄 `https-qdrant-tech-articles-data-privacy.md`
  1. **Admin or Owner:** with full access, and can generate API keys.
  2. **Editor:** with read-write access levels to specific collections.
  3. **Viewer:** with read-only access to specific collections.
  4. **Data Scientist or Analyst:** with read-only access to specific collections.
  5. **Developer:** with read-write access to development- or testing-specific collections, but limited access to production data.
  6. **Guest:** with limited read-only access to publicly available collections.
In addition, you can create access levels within sections of a collection. In a multi-tenant application, where you have used payload-based partitioning, you can create read-only access for specific user roles for a subset of the collection that belongs to that user.
Your application requirements will eventually help you decide the roles and access levels you should create. For example, in an application managing customer data, you could create additional roles such as:
**Customer Support Representative** : read-write access to customer service-related data but no access to billing information.
**Billing Department** : read-only access to billing data and read-write access to payment records.
**Marketing Analyst** : read-only access to anonymized customer data for analytics.
Each role can be assigned a JWT with claims that specify expiration times, read/write permissions for collections, and validating conditions.
In such an application, an example JWT payload for a customer support representative role could be:
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/data-privacy/)
                    ## 📄 `https-qdrant-tech-articles-dedicated-vector-search.md`
  * [**GPU-Accelerated Indexing**](https://qdrant.tech/blog/qdrant-1.13.x/#gpu-accelerated-indexing)  
By offloading index construction tasks to the GPU, Qdrant can significantly speed up the process of data indexing while keeping costs low. This becomes especially valuable when working with large datasets in hot data scenarios.
GPU acceleration in Qdrant is a custom solution developed by an enthusiast from our core team. It’s vendor-free and natively supports all Qdrant’s unique architectural features, from FIlterable HNSW to multivectors.
  * [**Multivectors**](https://qdrant.tech/documentation/concepts/vectors/?q=multivectors#multivectors)  
Some modern embedding models produce an entire matrix (a list of vectors) as output rather than a single vector. Qdrant supports multivectors natively.
This feature is critical when using state-of-the-art retrieval models such as [**ColBERT**](https://qdrant.tech/documentation/fastembed/fastembed-colbert/), ColPali, or ColQwen. For instance, ColPali and ColQwen produce multivector outputs, and supporting them natively is crucial for [**state-of-the-art (SOTA) PDF-retrieval**](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/).
In addition to that, we continuously look for improvements in:
**Memory Efficiency & Compression** | Techniques such as [**quantization**](https://qdrant.tech/articles/dedicated-vector-search/documentation/guides/quantization/) and [**HNSW compression**](https://qdrant.tech/blog/qdrant-1.13.x/#hnsw-graph-compression) to reduce storage requirements  
---|---  
**Retrieval Algorithms** | Support for the latest retrieval algorithms, including [**sparse neural retrieval**](https://qdrant.tech/articles/modern-sparse-neural-retrieval/), [**hybrid search**](https://qdrant.tech/documentation/concepts/hybrid-queries/) methods, and [**re-rankers**](https://qdrant.tech/documentation/fastembed/fastembed-rerankers/).  
**Vector Data Analysis & Visualization** | Tools like the [**distance matrix API**](https://qdrant.tech/blog/qdrant-1.12.x/#distance-matrix-api-for-data-insights) provide insights into vectorized data, and a [**Web UI**](https://qdrant.tech/blog/qdrant-1.11.x/#web-ui-search-quality-tool) allows for intuitive exploration of data.  
**Search Speed & Scalability** | Includes optimizations for [**multi-tenant environments**](https://qdrant.tech/articles/multitenancy/) to ensure efficient and scalable search.  
**These advancements are not just incremental improvements — they define the difference between a system optimized for vector search and one that accommodates it.**
Staying at the cutting edge of vector search is not just about performance — it’s also about keeping pace with an evolving AI landscape.
  * **High-Volume, Real-Time Search** : Ideal for applications with many simultaneous users who require fast, continuous access to search results—think search engines, e-commerce recommendations, social media, or media streaming services.
  * **Dynamic, Unstructured Data** : Perfect for scenarios where data is continuously evolving and where the goal is to discover insights from data patterns.
  * **Innovative Applications** : If you’re looking to implement advanced use cases such as recommendation engines, hybrid search solutions, or exploratory data analysis where traditional exact or token-based searches hold short.
Investing in a dedicated vector search engine will deliver the performance and flexibility necessary for success if your application relies on vector search at scale, keeps up with trends, or requires more than just a simple small-scale similarity search.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/dedicated-vector-search/)
                    ## 📄 `https-qdrant-tech-articles-detecting-coffee-anomalies.md`
  * Data-hungry - requiring quite a number of labeled data;
  * Expensive - data labeling is an expensive task itself;
  * Time-consuming - you would try to obtain what is necessarily scarce;
  * Hard to maintain - you would need to re-train the model repeatedly in response to changes in the data distribution.
These are not desirable features if you want to put your model into production in a rapidly-changing environment. And, despite all the mentioned difficulties, they do not necessarily offer superior performance compared to the alternatives. In this post, we will detail the lessons learned from such a use case.
  * We can benefit from unlabeled data, considering labeling is time-consuming and expensive.
  * The relevant metric, e.g., precision or recall, can be tuned according to changing requirements during the inference without re-training.
  * Queries labeled with a high score can be added to the KNN classifier on the fly as new data points.
To apply metric learning, we need to have a neural encoder, a model capable of transforming an image into a vector.
Training such an encoder from scratch may require a significant amount of data we might not have. Therefore, we will divide the training into two steps:
  * The first step is to train the autoencoder, with which we will prepare a model capable of representing the target domain.
  * The second step is finetuning. Its purpose is to train the model to distinguish the required types of anomalies.
![Model training architecture](https://qdrant.tech/articles_data/detecting-coffee-anomalies/anomaly_detection_training.png)
Model training architecture
  * Collect more unlabeled data and pretrain a larger autoencoder.
  * Obtain high-quality labels for a small number of images instead of tens of thousands for finetuning.
  * Use hyperparameter optimization and possibly gradual unfreezing in the finetuning step.
  * Use 
We are actively looking into these, and we will continue to publish our findings in this challenge and other use cases of metric learning.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/detecting-coffee-anomalies/)
                    ## 📄 `https-qdrant-tech-articles-dimension-reduction-qsoc.md`
  * [Articles](https://qdrant.tech/articles/)
  * Qdrant Summer of Code 2024 - WASM based Dimension Reduction
[](https://qdrant.tech/articles/ecosystem/)
  1. **Computing Pairwise Similarity:** This step involves calculating the similarity between each pair of data points in the original high-dimensional space.
  2. **Iterative Optimization:** The second step is iterative, where the embedding is refined using gradient descent. Here, the similarity matrix from the first step plays a crucial role.
At the outset, Andrey tasked me with rewriting the existing JavaScript implementation of t-SNE in Rust, introducing multi-threading along the way. Setting up WASM with Vite for multi-threaded execution was no small feat, but the effort paid off. The resulting Rust implementation outperformed the single-threaded JavaScript version, although it still struggled with large datasets.
Next came the challenge of optimizing the algorithm further. A key aspect of t-SNE’s first step is finding the nearest neighbors for each data point, which requires an efficient data structure. I opted for a 
To illustrate, imagine dividing a 2D space into quadrants, each containing multiple points. Every quadrant is again subdivided into four quadrants. This is done until every point belongs to a single cell.
![Calculating the resultant force on red point using Barnes-Hut approximation](https://qdrant.tech/articles_data/dimension-reduction-qsoc/barnes_hut.png)
Barnes-Hut Approximation
We then calculate the center of mass for each cell represented by a blue circle as shown in the figure. Now let’s say we want to find all the forces, represented by dotted lines, on the red point. Barnes Hut’s approximation states that for points that are sufficiently distant, instead of computing the force for each individual point, we use the center of mass as a proxy, significantly reducing the computational load. This is represented by the blue dotted line in the figure.
These optimizations made a remarkable difference — Barnes-Hut t-SNE was eight times faster than the exact t-SNE for 10,000 vectors.
![Image of visualizing 10,000 vectors using exact t-SNE which took 884.728s](https://qdrant.tech/articles_data/dimension-reduction-qsoc/rust_rewrite.jpg)
Exact t-SNE - Total time: 884.728s
![Image of visualizing 10,000 vectors using Barnes-Hut t-SNE which took 110.728s](https://qdrant.tech/articles_data/dimension-reduction-qsoc/rust_bhtsne.jpg)
Barnes-Hut t-SNE - Total time: 104.191s
Despite these improvements, the first step of the algorithm was still a bottleneck, leading to noticeable delays and blank screens. I experimented with approximate nearest neighbor algorithms, but the performance gains were minimal. After consulting with my mentor, we decided to compute the nearest neighbors on the server side, passing the distance matrix directly to the visualization process instead of the raw vectors.
While waiting for the distance-matrix API to be ready, I explored further optimizations. I observed that the worker thread sent results to the main thread for rendering at specific intervals, causing unnecessary delays due to serialization and deserialization.
![Image showing serialization and deserialization overhead due to message passing between threads](https://qdrant.tech/articles_data/dimension-reduction-qsoc/channels.png)
Serialization and Deserialization Overhead
To address this, I implemented a `SharedArrayBuffer`, allowing the main thread to access changes made by the worker thread instantly. This change led to noticeable improvements.
Additionally, the previous architecture resulted in choppy animations due to the fixed intervals at which the worker thread sent results.
![Image showing the previous architecture of the frontend with fixed intervals for sending results](https://qdrant.tech/articles_data/dimension-reduction-qsoc/prev_arch.png)
Previous architecture with fixed intervals
I introduced a “rendering-on-demand” approach, where the main thread would signal the worker thread when it was ready to render the next result. This created smoother, more responsive animations.
![Image showing the current architecture of the frontend with rendering-on-demand approach](https://qdrant.tech/articles_data/dimension-reduction-qsoc/curr_arch.png)
Current architecture with rendering-on-demand
With these optimizations in place, the final step was wrapping up the project by creating a Node.js 
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/dimension-reduction-qsoc/)
                    ## 📄 `https-qdrant-tech-articles-discovery-search.md`
  * [Articles](https://qdrant.tech/articles/)
  * Discovery needs context
[](https://qdrant.tech/articles/data-exploration/)
  * **target** : the main point of interest
  * **context** : the pairs of positive and negative points we just defined.
However, it is not the only way to use it. Alternatively, you can **only** provide a context, which invokes a [**Context Search**](https://qdrant.tech/articles/discovery-search/#context-search). This is useful when you want to explore the space defined by the context, but don’t have a specific target in mind. But hold your horses, we’ll get to that [later ↪](https://qdrant.tech/articles/discovery-search/#context-search).
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/discovery-search/)
                    ## 📄 `https-qdrant-tech-articles-distance-based-exploration.md`
  1. _Randomly generate points in 2D space_ : Assign a random 2D point to each high-dimensional point.
  2. _Compute distance matrix for high-dimensional points_ : Calculate distances between all pairs of points.
  3. _Compute distance matrix for 2D points_ : Perform similarly to step 2.
  4. _Match both distance matrices_ : Adjust 2D points to minimize differences.
![UMAP](https://qdrant.tech/articles_data/distance-based-exploration/umap.png)
Canonical example of UMAP results, 
UMAP preserves the relative distances between high-dimensional points; the actual coordinates are not essential. If we already have the distance matrix, step 2 can be skipped entirely.
Let’s use Qdrant to calculate the distance matrix and apply UMAP. We will use one of the default datasets perfect for experimenting in Qdrant–
Use this command to download and import the dataset into Qdrant:
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/distance-based-exploration/)
                    ## 📄 `https-qdrant-tech-articles-ecosystem.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/ecosystem/)
                    ## 📄 `https-qdrant-tech-articles-fastembed.md`
  1. 50% faster than PyTorch Transformers
  2. Better performance than Sentence Transformers and OpenAI Ada-002
  3. Cosine similarity of quantized and original model vectors is 0.92
We use `BAAI/bge-small-en-v1.5` as our DefaultEmbedding, hence we’ve chosen that for comparison:
![](https://qdrant.tech/articles_data/fastembed/throughput.png)
>   * onnx: Version ^1.11 – We’ll try to drop this also in the future if we can!
>   * onnxruntime: Version ^1.15
>   * tqdm: Version ^4.65 – used only at Download
>   * requests: Version ^2.31 – used only at Download
>   * tokenizers: Version ^0.13
> 
This minimized list serves two purposes. First, it significantly reduces the installation time, allowing for quicker deployments. Second, it limits the amount of disk space required, making it a viable option even for environments with storage limitations.
Notably absent from the dependency list are bulky libraries like PyTorch, and there’s no requirement for CUDA drivers. This is intentional. FastEmbed is engineered to deliver optimal performance right on your CPU, eliminating the need for specialized hardware or complex setups.
**ONNXRuntime** : The ONNXRuntime gives us the ability to support multiple providers. The quantization we do is limited for CPU (Intel), but we intend to support GPU versions of the same in the future as well. This allows for greater customization and optimization, further aligning with your specific performance and computational requirements.
  1. **Cloud** : Get started with a free plan on the 
  2. **Docker Container** : If you’re the DIY type, you can set everything up on your own machine. Here’s a quick guide to help you out: [Quick Start with Docker](https://qdrant.tech/documentation/quick-start/?utm_source=qdrant&utm_medium=website&utm_campaign=fastembed&utm_content=article).
So, go ahead, take it for a test drive. We’re excited to hear what you think!
Lastly, If you find FastEmbed useful and want to keep up with what we’re doing, giving our GitHub repo a star would mean a lot to us. Here’s the link to 
If you ever have questions about FastEmbed, please ask them on the Qdrant Discord: 
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/fastembed/)
                    ## 📄 `https-qdrant-tech-articles-filtrable-hnsw.md`
  * Categorical filtering
    * Select only points in a specific category
    * Select points which belong to a specific subset of categories
    * Select points with a specific set of labels
  * Numerical range
  * Selection within some geographical region
In the first case, we can guarantee that the HNSW graph will be connected simply by creating additional edges inside each category separately, using the same graph construction algorithm, and then combining them into the original graph. In this case, the total number of edges will increase by no more than 2 times, regardless of the number of categories.
Second case is a little harder. A connection may be lost between two categories if they lie in different clusters.
![category clusters](https://qdrant.tech/articles_data/filtrable-hnsw/hnsw_graph_category.png)
The idea here is to build same navigation graph but not between nodes, but between categories. Distance between two categories might be defined as distance between category entry points (or, for precision, as the average distance between a random sample). Now we can estimate expected graph connectivity by number of excluded categories, not nodes. It still does not guarantee that two random categories will be connected, but allows us to switch to multiple searches in each category if connectivity threshold passed. In some cases, multiple searches can be even faster if you take advantage of parallel processing.
![Dependency of connectivity to the random categories included in search](https://qdrant.tech/articles_data/filtrable-hnsw/exp_random_groups.png)
Dependency of connectivity to the random categories included in search
Third case might be resolved in a same way it is resolved in classical databases. Depending on labeled subsets size ration we can go for one of the following scenarios:
  * if at least one subset is small: perform search over the label containing smallest subset and then filter points consequently.
  * if large subsets give large intersection: perform regular search with constraints expecting that intersection size fits connectivity threshold.
  * if large subsets give small intersection: perform linear search over intersection expecting that it is small enough to fit a time frame.
Numerical range case can be reduces to the previous one if we split numerical range into a buckets containing equal amount of points. Next we also connect neighboring buckets to achieve graph connectivity. We still need to filter some results which presence in border buckets but do not fulfill actual constraints, but their amount might be regulated by the size of buckets.
Geographical case is a lot like a numerical one. Usual geographical search involves 
![Geohash example](https://qdrant.tech/articles_data/filtrable-hnsw/geohash.png)
We can use this identifiers as categories and additionally make connections between neighboring geohashes. It will ensure that any selected geographical region will also contain connected HNSW graph.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/filtrable-hnsw/)
                    ## 📄 `https-qdrant-tech-articles-food-discovery-demo.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/food-discovery-demo/)
                    ## 📄 `https-qdrant-tech-articles-gridstore-key-value-storage.md`
  * **How Gridstore works** – a deep dive into its architecture and mechanics.
  * **Why we built it this way** – the key design decisions that shaped it.
  * **Rigorous testing** – how we ensured the new storage is production-ready.
  * **Performance benchmarks** – official metrics that demonstrate its efficiency.
**Our first challenge?** Figuring out the best way to handle sequential keys and variable-sized data.
  * **The Data Layer** holds the data and associates each key with its location in storage, including page ID, block offset, and the size of its value.
  * **The Mask Layer** keeps track of which blocks are occupied and which are free.
  * **The Gaps Layer** provides an indexed view of free blocks for efficient space allocation.
Every time a new value is inserted or an existing value is updated, all these components need to be modified in a coordinated way.
  1. Initialize a Gridstore instance and an empty hash map.
  2. Run random operations (put, delete, update) on both.
  3. Verify that results match after each operation.
  4. Compare all keys and values to ensure consistency.
This approach provides high test coverage, exposing issues like incorrect persistence or faulty deletions. Running large-scale model tests ensures Gridstore remains reliable in real-world use.
Here is a naive way to generate operations in Rust.
  * Missing data (points, vectors, or payloads)
  * Corrupt payload values
This aggressive yet simple approach has uncovered real-world issues when run for extended periods. While we also use chaos testing for distributed setups, Crasher excels at fast, repeatable failure testing in a local environment.
  * A medium to large payload
  * A tiny dense vector (dense vectors use a different storage type)
  * A sparse vector
* * *
  * Gridstore: 2333MB
  * RocksDB: 2319MB
Strictly speaking, RocksDB is slightly smaller, but the difference is negligible compared to the 2x faster ingestion and more stable throughput. A small trade-off for a big performance gain!
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/gridstore-key-value-storage/)
                    ## 📄 `https-qdrant-tech-articles-hybrid-search.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/hybrid-search/)
                    ## 📄 `https-qdrant-tech-articles-immutable-data-structures.md`
  * making the number of buckets bigger so the probability of collision is lower
  * using a linked list or a tree to store multiple elements with the same hash
However, these strategies have overheads, which become more significant if we consider using high-latency storage like disk.
Indeed, every read operation from disk is several orders of magnitude slower than reading from RAM, so we want to know the correct location of the data from the first attempt.
In order to achieve this, we can use a so-called minimal perfect hash function (MPHF). This special type of hash function is constructed specifically for a given set of keys, and it guarantees no collisions while using minimal amount of buckets.
In Qdrant, we decided to use _fingerprint-based minimal perfect hash function_ implemented in the 
Volume | `ph::Function` | `std::hash::Hash` | `HashMap::get`  
---|---|---|---  
1000 | 60ns | ~20ns | 34ns  
100k | 90ns | ~20ns | 220ns  
10M | 238ns | ~20ns | 500ns  
Even thought the absolute time for hashing is higher, the time for the whole operation is lower, because PHF guarantees no collisions. The difference is even more significant when we consider disk read time, which might up to several milliseconds (10^6 ns).
PHF RAM size scales linearly for `ph::Function`: 3.46 kB for 10k elements, 119MB for 350M elements. The construction time required to build the hash function is surprisingly low, and we only need to do it once:
Volume |  `ph::Function` (construct) | PHF size | Size of int64 keys (for reference)  
---|---|---|---  
1M | 52ms | 0.34Mb | 7.62Mb  
100M | 7.4s | 33.7Mb | 762.9Mb  
The usage of PHF in Qdrant lets us minimize the latency of cold reads, which is especially important for large-scale multi-tenant systems. With PHF, it is enough to read a single page from a disk to get the exact location of the data.
  * **Higher update costs:** Immutable structures are less efficient for updates. The amortized time complexity might be the same as mutable structures, but the constant factor is higher.
  * **Rebuilding overhead:** In some cases, we may need to rebuild indices or structures for the same data more than once.
  * **Read-heavy workloads:** Immutability assumes a search-heavy workload, which is typical for search engines but not for all applications.
In Qdrant, we mitigate these downsides by allowing the user to adapt the system to their specific workload. For example, changing the default size of the segment might help to reduce the overhead of rebuilding indices.
In extreme cases, multi-segment storage can act as a single segment, falling back to the mutable data structure when needed.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/immutable-data-structures/)
                    ## 📄 `https-qdrant-tech-articles-indexing-optimization.md`
  * **Disable HNSW indexing**
To reduce memory and CPU pressure during bulk ingestion, you can **disable HNSW indexing entirely** by setting `"m": 0`. For dense vectors, the `m` parameter defines how many edges each node in the HNSW graph can have. This way, no dense vector index will be built, preventing unnecessary CPU usage during ingestion.
**Figure 1:** A description of three key HNSW parameters.
![](https://qdrant.tech/articles_data/indexing-optimization/hnsw-parameters.png)
  * **Disabling optimizations completely**
The `indexing_threshold` tells Qdrant how many unindexed dense vectors can accumulate in a segment before building the HNSW graph. Setting `"indexing_threshold"=0` defers indexing entirely, keeping **ingestion speed at maximum**. However, this means uploaded vectors are not moved to disk while uploading, which can lead to **high RAM usage**.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/indexing-optimization/)
                    ## 📄 `https-qdrant-tech-articles-io-uring.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/io_uring/)
                    ## 📄 `https-qdrant-tech-articles-machine-learning.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/machine-learning/)
                    ## 📄 `https-qdrant-tech-articles-memory-consumption.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/memory-consumption/)
                    ## 📄 `https-qdrant-tech-articles-modern-sparse-neural-retrieval.md`
  * The SPARTA model is not sparse enough by construction, so authors of the SPLADE family of models introduced explicit **sparsity regularisation** , preventing the model from producing too many non-zero values.
  * The SPARTA model mostly uses the BERT model as-is, without any additional neural network to capture the specifity of Information Retrieval problem, so SPLADE models introduce a trainable neural network on top of BERT with a specific architecture choice to make it perfectly fit the task.
  * SPLADE family of models, finally, uses **knowledge distillation** , which is learning from a bigger (and therefore much slower, not-so-fit for production tasks) model how to predict good representations.
One of the last versions of the SPLADE family of models is   
SPLADE++, opposed to SPARTA model, expands not only documents but also queries at inference time. We’ll demonstrate this in the next section.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/modern-sparse-neural-retrieval/)
                    ## 📄 `https-qdrant-tech-articles-multitenancy.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/multitenancy/)
                    ## 📄 `https-qdrant-tech-articles-neural-search-tutorial.md`
### Step 3: Upload data to Qdrant
Now once we have the vectors prepared and the search engine running, we can start uploading the data. To interact with Qdrant from python, I recommend using an out-of-the-box client library.
To install it, use the following command
At this point, we should have startup records in file `startups.json`, encoded vectors in file `startup_vectors.npy`, and running Qdrant on a local machine. Let’s write a script to upload all startup data and vectors into the search engine.
First, let’s create a client object for Qdrant.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/neural-search-tutorial/)
                    ## 📄 `https-qdrant-tech-articles-practicle-examples.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/practicle-examples/)
                    ## 📄 `https-qdrant-tech-articles-product-quantization-clustering.md`
  * Deployment in a low-RAM environment where the limiting factor is the number of disk reads rather than the vector comparison itself
  * Situations where the dimensionality of the original vectors is sufficiently high
  * Cases where indexing speed is not a critical factor
In circumstances that do not align with the above, Scalar Quantization should be the preferred choice.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/product-quantization/)
                    ## 📄 `https-qdrant-tech-articles-product-quantization-cutting-the-vector-into-pieces.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/qdrant-internals/)
                    ## 📄 `https-qdrant-tech-articles-rag-and-genai.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/rag-and-genai/)
                    ## 📄 `https-qdrant-tech-articles-rapid-rag-optimization-with-qdrant-and-quotient.md`
  1. **Irrelevance and Hallucinations** : When the documents retrieved are irrelevant, evidenced by low scores in both Chunk Relevance and Context Relevance, the model is prone to generating inaccurate or fabricated information.
  2. **Optimizing Document Retrieval** : By retrieving a greater number of documents and reducing the chunk size, we observed improved outcomes in the model’s performance.
  3. **Adaptive Retrieval Needs** : Certain queries may benefit from accessing more documents. Implementing a dynamic retrieval strategy that adjusts based on the query could enhance accuracy.
  4. **Influence of Model and Prompt Variations** : Alterations in language models or the prompts used can significantly impact the quality of the generated responses, suggesting that fine-tuning these elements could optimize performance.
Let us walk you through how we arrived at these findings!
  * **Chunk size**
  * **Chunk overlap**
  * **Embedding model**
  * **Number of documents retrieved (retrieval window)**
Following the ingestion of data in Qdrant, we proceed to retrieve pertinent documents corresponding to each query. These documents are then seamlessly integrated into our evaluation dataset, enriching the contextual information within the designated **`context`**column to fulfil the evaluation aspect.
Next we define methods to take care of logistics with respect to adding documents to Qdrant
  * **Embedding Model:`bge-small-en`**
  * **Chunk size:`512`**
  * **Chunk overlap:`64`**
  * **Number of docs retrieved (Retireval Window):`3`**
  * **LLM:`Mistral-7B-Instruct`**
We’ll process our documents based on configuration above and ingest them into Qdrant using `add_documents` method introduced earlier
  * **Embedding Model :`bge-small-en`**
  * **Chunk size:`1024`**
  * **Chunk overlap:`128`**
  * **Number of docs retrieved (Retireval Window):`3`**
  * **LLM:`Mistral-7B-Instruct`**
We will reprocess the data with the updated parameters above:
  * **Embedding Model :`bge-small-en`**
  * **Chunk size:`512`**
  * **Chunk overlap:`64`**
  * **Number of docs retrieved (Retrieval Window):`5`**
  * **LLM: :`Mistral-7B-Instruct`**
We can use the collection from Experiment 1 and run evaluation with modified `num_docs` parameter as :
  * **Embedding Model :`MiniLM-L6-v2`**
  * **Chunk size:`512`**
  * **Chunk overlap:`64`**
  * **Number of docs retrieved (Retrieval Window):`5`**
  * **LLM: :`Mistral-7B-Instruct`**
We will have to create another collection for this experiment :
  * **Embedding Model :`bge-small-en`**
  * **Chunk size:`512`**
  * **Chunk overlap:`64`**
  * **Number of docs retrieved (Retrieval Window):`5`**
  * **LLM: :`GPT-3.5-turbo`**
For this we can repurpose our collection from Experiment 3 while the evaluations to use a new recipe with **GPT-3.5-turbo** model.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/rapid-rag-optimization-with-qdrant-and-quotient/)
                    ## 📄 `https-qdrant-tech-articles-scalar-quantization-accessing-best-practices.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/scalar-quantization/)
                    ## 📄 `https-qdrant-tech-articles-scalar-quantization-benchmarks.md`
#### Distance calculation
We do not store the vectors in the collections represented by `int8` instead of `float32` just for the sake of compressing the memory. But the coordinates are being used while we calculate the distance between the vectors. Both dot product and cosine distance requires multiplying the corresponding coordinates of two vectors, so that’s the operation we perform quite often on `float32`. Here is how it would look like if we perform the conversion to `int8`:
f32×f32′= =(α×i8+offset)×(α×i8′+offset)= =α2×i8×i8′+offset×α×i8′+offset×α×i8+offset2⏟pre-compute
The first term, $ \alpha^{2} \times i8 \times i8’ $ has to be calculated when we measure the distance as it depends on both vectors. However, both the second and the third term ($ offset \times \alpha \times i8’ $ and $ offset \times \alpha \times i8 $ respectively), depend only on a single vector and those might be precomputed and kept for each vector. The last term, $ offset^{2} $ does not depend on any of the values, so it might be even computed once and reused.
If we had to calculate all the terms to measure the distance, the performance could have been even worse than without the conversion. But thanks for the fact we can precompute the majority of the terms, things are getting simpler. And in turns out the scalar quantization has a positive impact not only on the memory usage, but also on the performance. As usual, we performed some benchmarks to support this statement!
                    ## 📄 `https-qdrant-tech-articles-scalar-quantization-scalar-quantization.md`
  1. Text matches in titles
  2. Text matches in body (paragraphs or lists)
  3. Semantic matches in titles
  4. Any Semantic matches
Those are put together by taking them in the above order, deduplicating as necessary.
![merge workflow](https://qdrant.tech/articles_data/search-as-you-type/sayt_merge.png)
Instead of sending a `search` or `recommend` request, one can also send a `search/batch` or `recommend/batch` request, respectively. Each of those contain a `"searches"` property with any number of search/recommend JSON requests:
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/search-as-you-type/)
                    ## 📄 `https-qdrant-tech-articles-search-feedback-loop.md`
  1. How accurately can the automated judge determine relevance (or irrelevance)?
  2. How cost-efficient is it? After all, you can’t expect GPT-4o to re-rank thousands of documents for every user query — unless you’re filthy rich.
Nevertheless, automated re-scored feedback could be a scalable way to improve search when explicit binary feedback is not accessible.
  1. Query
  2. Documents
  3. Similarity scoring between them.
![Research Field Taxonomy Overview](https://qdrant.tech/articles_data/search-feedback-loop/taxonomy-overview.png)
Research Field Taxonomy Overview
Query formulation is a subjective process – it can be done in infinite configurations, making the relevance of a document unpredictable until the query is formulated and submitted to the system.
So, adapting documents (or the search index) to relevance feedback would require per-request dynamic changes, which is impractical, considering that modern retrieval systems store billions of documents.
Thus, approaches for incorporating relevance feedback in search fall into two categories: **refining a query** and **refining the similarity scoring function** between the query and documents.
  1. Either extract the **most frequent** terms from (pseudo-)relevant documents;
  2. Or the **most specific** ones (for example, according to IDF);
  3. Or the **most probable** ones (most likely to be in query according to a relevance set).
Well-known methods of those times come from the family of 
The most famous one, `RM3` – interpolation of expansion terms probability with their probability in a query – is still appearing in papers of the last few years as a (noticeably decent) baseline in term-based retrieval, usually as part of 
![Simplified Query Expansion](https://qdrant.tech/articles_data/search-feedback-loop/relevance-models.png)
Simplified Query Expansion
With the time approaching the modern machine learning era, 
Started with simple classifiers based on hand-crafted features, this trend naturally led to use the famous `BERT-QE` (Query Expansion) authors came up with this schema:
  1. Get pseudo-relevance feedback from the finetuned BERT reranker (~10 documents);
  2. Chunk these pseudo-relevant documents (~100 words) and score query-chunk relevance with the same reranker;
  3. Expand the query with the most relevant chunks;
  4. Rerank 1000 documents with the reranker using the expanded query.
This approach significantly outperformed BM25 + RM3 baseline in experiments (+11% NDCG@20). However, it required **11.01x** more computation than just using BERT for reranking, and reranking 1000 documents with BERT would take around 9 seconds alone.
Query term expansion can _hypothetically_ work for neural retrieval as well. New terms might shift the query vector closer to that of the desired document. However, 
It definitely works if **query refining is done by a model operating in the same vector space** , which typically requires offline training of a retriever. The goal is to extend the query encoder input to also include feedback documents, producing an adjusted query embedding. Examples include 
![Generating a new relevance-aware query vector](https://qdrant.tech/articles_data/search-feedback-loop/updated-encoder.png)
Generating a new relevance-aware query vector
The reason why you’re most probably not familiar with these models – their absence in the industry – is that their **training** itself is a **high upfront cost** , and even though it was “paid”, these models 
Alternatively, one could skip a step — and work directly with vectors.
  1. **Training rerankers offline** to ingest relevance feedback as an additional input at inference time, 
  2. **Finetuning rerankers** on relevance feedback from the first retrieval stage, 
The biggest limitation here is that these reranker-based methods cannot retrieve relevant documents beyond those returned in the initial search, and using rerankers on thousands of documents in production is a no-go – it’s too expensive. Ideally, to avoid that, a similarity scoring function updated with relevance feedback should be used directly in the second retrieval iteration. However, in every research paper we’ve come across, retrieval systems are **treated as black boxes** — ingesting queries, returning results, and offering no built-in mechanism to modify scoring.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/search-feedback-loop/)
                    ## 📄 `https-qdrant-tech-articles-semantic-cache-ai-data-retrieval.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/semantic-cache-ai-data-retrieval/)
                    ## 📄 `https-qdrant-tech-articles-serverless.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/serverless/)
                    ## 📄 `https-qdrant-tech-articles-sparse-vectors.md`
  1. Contextually relevant: Terms that represent a document well should be given more weight.
  2. Discriminative across documents: Terms that a document has, and other documents don’t, should be given more weight.
The token-level distributions that you’d expect in a standard transformer model are now transformed into token-level importance scores in SPLADE. These scores reflect the significance of each term in the context of the document or query, guiding the model to allocate more weight to terms that are likely to be more meaningful for retrieval purposes.
The resulting sparse vectors are not only memory-efficient but also tailored for precise matching in the high-dimensional space of a search engine like Qdrant.
  1. Problem Motivation: 
  2. Late Interaction - 
**Why just read when you can try it out?**
We’ve packed an easy-to-use Colab for you on how to make a Sparse Vector: 
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/sparse-vectors/)
                    ## 📄 `https-qdrant-tech-articles-storing-multiple-vectors-per-object-in-qdrant.md`
  * Qdrant 0.10 introduces efficient vector storage optimization, allowing seamless management of multiple vectors per object within a single collection.
  * This update streamlines semantic search capabilities by eliminating the need for separate collections for each vector type, enhancing search accuracy and performance.
  * With Qdrant’s new features, users can easily configure vector parameters, including size and distance functions, for each vector type, optimizing search results and user experience.
If you’d like to check out some other examples, please check out our 
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/storing-multiple-vectors-per-object-in-qdrant/)
                    ## 📄 `https-qdrant-tech-articles-vector-search-filtering.md`
  1. With filtering in Qdrant, you can **dramatically increase search precision**. More on this in the next section.  
  2. Filtering helps control resources and **reduce compute use**. More on this in [**Payload Indexing**](https://qdrant.tech/articles/vector-search-filtering/#filtering-with-the-payload-index).
  * the “t-rex” matches food=meat on `diet[1].food` and likes=true on `diet[1].likes`
  * the “diplodocus” matches food=meat on `diet[1].food` and likes=true on `diet[0].likes`
To retrieve only the points where the conditions apply to a specific element within an array (such as the point with id 1 in this example), you need to use a nested object filter.
Nested object filters enable querying arrays of objects independently, ensuring conditions are checked within individual array elements.
This is done by using the `nested` condition type, which consists of a payload key that targets an array and a filter to apply. The key should reference an array of objects and can be written with or without bracket notation (e.g., “data” or “data[]”).
httppythontypescriptrustjavacsharp
  * The planner estimates the cardinality of a filtered result before selecting a strategy.
  * Qdrant retrieves points using the **payload index** if cardinality is below threshold.
  * Qdrant uses the **filterable vector index** if the cardinality is above a threshold
Our default full scan threshold is 10 kilobytes.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/vector-search-filtering/)
                    ## 📄 `https-qdrant-tech-articles-vector-search-manuals.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/vector-search-manuals/)
                    ## 📄 `https-qdrant-tech-articles-vector-search-resource-optimization.md`
  * **Logical Isolation** : Ensures each tenant’s data remains separate while residing in the same collection.
  * **Minimized Overhead** : Reduces resource consumption compared to maintaining separate collections for each user.
  * **Scalability** : Handles high user volumes without compromising performance.
Here’s how you can implement multitenancy efficiently in Qdrant:
  1. **Shard Key** :
The shard key determines how data points are distributed across shards. For example, using a key like `tenant_id` allows you to control how Qdrant partitions the data. Each data point added to the collection will be assigned to a shard based on the value of this key, ensuring logical isolation of data.
  2. **Shard Number** :
This defines the total number of physical shards for each shard key, influencing resource allocation and query performance.
Here’s how you can add a data point to a collection with user-defined sharding:
  * **How it works** : Instead of loading all data into memory, memmap storage maps data files directly to a virtual address space on disk. The system’s page cache handles data access, making it highly efficient.
  * **When to use it** : Perfect for storing large collections that exceed your available RAM while still maintaining near in-memory performance when enough RAM is available.
  * **Advantages** : Balances performance and memory usage, allowing you to work with datasets larger than your physical RAM.
  * **Limitations** : Slightly slower than pure in-memory storage but significantly more scalable.
To enable memmap vector storage in Qdrant, you can set the **on_disk** parameter to `true` when creating or updating a collection.
  * **Prometheus** : An open-source monitoring and alerting toolkit, Prometheus collects and stores metrics in a time-series database. It scrapes metrics from predefined endpoints and supports powerful querying and visualization capabilities.
  * **Grafana** : Often paired with Prometheus, Grafana provides an intuitive interface for visualizing metrics and creating interactive dashboards.
Qdrant exposes metrics in the **Prometheus/OpenMetrics** format through the /metrics endpoint. Prometheus can scrape this endpoint to monitor various aspects of the Qdrant system.
For a local Qdrant instance, the metrics endpoint is typically available at:
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/vector-search-resource-optimization/)
                    ## 📄 `https-qdrant-tech-articles-vector-similarity-beyond-search.md`
  * **Full-text search** when you need to find documents that contain a particular word or phrase.
  * **[Vector search](https://qdrant.tech/documentation/overview/vector-search/)** when you need to find documents that are semantically similar to a given query.
Sometimes people mix those two approaches, so it might look like the vector similarity is just an extension of full-text search. However, in this article, we will explore some promising new techniques that can be used to expand the use-case of unstructured data and demonstrate that vector similarity creates its own stack of data exploration tools.
  * Choose a specific full-text search variant.
  * Either sacrifice API consistency or limit vector similarity functionality to only basic kNN search.
  * Introduce additional complexity to the system.
Qdrant, on the contrary, puts vector similarity in the center of its API and architecture, such that it allows us to move towards a new stack of vector-native operations. We believe that this is the future of vector databases, and we are excited to see what new use-cases will be unlocked by these techniques.
  * Vector similarity offers advanced data exploration tools beyond traditional full-text search, including dissimilarity search, diversity sampling, and recommendation systems.
  * Practical applications of vector similarity include improving data quality through mislabeling detection and anomaly identification.
  * Enhanced user experiences are achieved by leveraging advanced search techniques, providing users with intuitive data exploration, and improving decision-making processes.
Ready to unlock the full potential of your data? [Try a free demo](https://qdrant.tech/contact-us/) to explore how vector similarity can revolutionize your data insights and drive smarter decision-making.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/vector-similarity-beyond-search/)
                    ## 📄 `https-qdrant-tech-articles-web-ui-gsoc.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/web-ui-gsoc/)
                    ## 📄 `https-qdrant-tech-articles-what-are-embeddings.md`
  * “your answer is right”
  * “turn right at the corner”
  * “everyone has the right to freedom of speech”
Each of these sentences use the word ‘right’, with different meanings.
More advanced models like **surroundings** , and then creates different embeddings for each.
![How the BERT model creates the embeddings for a word](https://qdrant.tech/articles_data/what-are-embeddings/BERT-model.jpg)
But how does this process of understanding and interpreting work in practice? Think of the term: “biophilic design”, for example. To generate its embedding, the transformer architecture can use the following contexts:
  * “Biophilic design incorporates natural elements into architectural planning.”
  * “Offices with biophilic design elements report higher employee well-being.”
  * “…plant life, natural light, and water features are key aspects of biophilic design.”
And then it compares contexts to known architectural and design principles:
  * “Sustainable designs prioritize environmental harmony.”
  * “Ergonomic spaces enhance user comfort and health.”
The model creates a vector embedding for “biophilic design” that encapsulates the concept of integrating natural elements into man-made environments. Augmented with attributes that highlight the correlation between this integration and its positive impact on health, well-being, and environmental sustainability.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/what-are-embeddings/)
                    ## 📄 `https-qdrant-tech-articles-what-is-a-vector-database.md`
  * **Euclidean Distance:** The straight-line path. It’s like measuring the physical distance between two points in space. Pick this one when the actual distance (like spatial data) matters.
  * **Cosine Similarity:** This one is about the angle, not the length. It measures how two vectors point in the same direction, so it works well for text or documents when you care more about meaning than magnitude. For example, if two things are _similar_ , _opposite_ , or _unrelated_ :
![Cosine Similarity Example](https://qdrant.tech/articles_data/what-is-a-vector-database/cosine-similarity.png)
  * **Dot Product:** This looks at how much two vectors align. It’s popular in recommendation systems where you’re interested in how much two things “agree” with each other.
  1. **Automatic Sharding:** Points (vectors) are automatically distributed across shards using consistent hashing. Each shard contains non-overlapping subsets of the data.
  2. **User-defined Sharding:** Specify how points are distributed, enabling more control over your data organization, especially for use cases like **multitenancy** , where each tenant (a user, client, or organization) has their own isolated data.
Each shard is divided into **segments**. They are a smaller storage unit within a shard, storing a subset of vectors and their associated payloads (metadata). When a query is executed, it targets the only relevant segments, processing them in parallel.
![Segments act as smaller storage units within a shard](https://qdrant.tech/articles_data/what-is-a-vector-database/segments.png)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/what-is-a-vector-database/)
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-1-initial-quantized-search.md`
  * Values greater than zero are converted to 1.
  * Values less than or equal to zero are converted to 0.
Let’s consider our initial example of a 1536-dimensional vector that requires **6 KB** of memory (4 bytes for each `float32` value).
After Binary Quantization, each dimension is reduced to 1 bit (1/8 byte), so the memory required is:
1536 dimensions8 bits per byte=192 bytes
This leads to a **32x** memory reduction.
![Binary Quantization example](https://qdrant.tech/articles_data/what-is-vector-quantization/binary-quant.png)
Qdrant automates the Binary Quantization process during indexing. As vectors are added to your collection, each 32-bit floating-point component is converted into a binary value according to the configuration you define.
Here’s how you can set it up:
httppython
  * **OpenAI text-embedding-ada-002** (1536 dimensions)
  * **Cohere AI embed-english-v2.0** (4096 dimensions)
These models demonstrate minimal accuracy loss while still benefiting from substantial speed and memory gains.
Even though Binary Quantization is incredibly fast and memory-efficient, the trade-offs are in **precision** and **model compatibility** , so you may need to ensure search quality using techniques like oversampling and rescoring.
If you’re interested in exploring Binary Quantization in more detail—including implementation examples, benchmark results, and usage recommendations—check out our dedicated article on [Binary Quantization - Vector Search, 40x Faster](https://qdrant.tech/articles/binary-quantization/).
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/what-is-vector-quantization/)
                    ## 📄 `https-qdrant-tech-articles-what-is-vector-quantization-1-what-is-scalar-quantization.md`
  * [Articles](https://qdrant.tech/articles/)
  * Why Rust?
[](https://qdrant.tech/articles/)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/why-rust/)
                    ## 📄 `https-qdrant-tech-articles.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/articles/)
                    ## 📄 `https-qdrant-tech-benchmarks-are-we-biased.md`
  * We do comparative benchmarks, which means we focus on **relative numbers** rather than absolute numbers.
  * We use affordable hardware, so that you can reproduce the results easily.
  * We run benchmarks on the same exact machines to avoid any possible hardware bias.
  * All the benchmarks are 
Scenarios we tested
  1. Upload & Search benchmark on single node [Benchmark](https://qdrant.tech/benchmarks/single-node-speed-benchmark/)
  2. Filtered search benchmark - [Benchmark](https://qdrant.tech/benchmarks/#filtered-search-benchmark)
  3. Memory consumption benchmark - Coming soon
  4. Cluster mode benchmark - Coming soon
Some of our experiment design decisions are described in the [F.A.Q Section](https://qdrant.tech/benchmarks/#benchmarks-faq). Reach out to us on our 
##  [](https://qdrant.tech/benchmarks/#single-node-benchmarks)Single node benchmarks
We benchmarked several vector databases using various configurations of them on different datasets to check how the results may vary. Those datasets may have different vector dimensionality but also vary in terms of the distance function being used. We also tried to capture the difference we can expect while using some different configuration parameters, for both the engine itself and the search operation separately.  
**Updated: January/June 2024**
Dataset: dbpedia-openai-1M-1536-angular deep-image-96-angular gist-960-euclidean glove-100-angular
Search threads: 100 1
Plot values:
RPS  Latency  p95 latency  Index time
Engine | Setup | Dataset | Upload Time(m) | Upload + Index Time(m) | Latency(ms) | P95(ms) | P99(ms) | RPS | Precision  
---|---|---|---|---|---|---|---|---|---  
qdrant | _qdrant-sq-rps-m-64-ef-512_ | dbpedia-openai-1M-1536-angular | 3.51 | 24.43 | 3.54 | 4.95 | 8.62 | 1238.0016 | 0.99  
weaviate | _latest-weaviate-m32_ | dbpedia-openai-1M-1536-angular | 13.94 | 13.94 | 4.99 | 7.16 | 11.33 | 1142.13 | 0.97  
elasticsearch | _elasticsearch-m-32-ef-128_ | dbpedia-openai-1M-1536-angular | 19.18 | 83.72 | 22.10 | 72.53 | 135.68 | 716.80 | 0.98  
redis | _redis-m-32-ef-256_ | dbpedia-openai-1M-1536-angular | 92.49 | 92.49 | 140.65 | 160.85 | 167.35 | 625.27 | 0.97  
milvus | _milvus-m-16-ef-128_ | dbpedia-openai-1M-1536-angular | 0.27 | 1.16 | 393.31 | 441.32 | 576.65 | 219.11 | 0.99  
_Download raw data:[here](https://qdrant.tech/benchmarks/results-1-100-thread-2024-06-15.json)_
  * This was our setup for this experiment:
    * Client: 8 vcpus, 16 GiB memory, 64GiB storage (`Standard D8ls v5` on Azure Cloud)
    * Server: 8 vcpus, 32 GiB memory, 64GiB storage (`Standard D8s v3` on Azure Cloud)
  * The Python client uploads data to the server, waits for all required indexes to be constructed, and then performs searches with configured number of threads. We repeat this process with different configurations for each engine, and then select the best one for a given precision.
  * We ran all the engines in docker and limited their memory to 25GB. This was used to ensure fairness by avoiding the case of some engine configs being too greedy with RAM usage. This 25 GB limit is completely fair because even to serve the largest `dbpedia-openai-1M-1536-angular` dataset, one hardly needs `1M * 1536 * 4bytes * 1.5 = 8.6GB` of RAM (including vectors + index). Hence, we decided to provide all the engines with ~3x the requirement.
Please note that some of the configs of some engines crashed on some datasets because of the 25 GB memory limit. That’s why you might see fewer points for some engines on choosing higher precision thresholds.
  * Some use **post-filtering** , which applies filters after ANN search. It doesn’t scale well as it either loses results or requires many candidates on the first stage.
  * Others use **pre-filtering** , which requires a binary mask of the whole dataset to be passed into the ANN algorithm. It is also not scalable, as the mask size grows linearly with the dataset size.
On top of it, there is also a problem with search accuracy. It appears if too many vectors are filtered out, so the HNSW graph becomes disconnected.
Qdrant uses a different approach, not requiring pre- or post-filtering while addressing the accuracy problem. Read more about the Qdrant approach in our [Filtrable HNSW](https://qdrant.tech/articles/filtrable-hnsw/) article.
  * **Speed boost** - for some engines/queries, the filtered search is faster than the unfiltered one. It might happen if the filter is restrictive enough, to completely avoid the usage of the vector index.
  * **Speed downturn** - some engines struggle to keep high RPS, it might be related to the requirement of building a filtering mask for the dataset, as described above.
  * **Accuracy collapse** - some engines are loosing accuracy dramatically under some filters. It is related to the fact that the HNSW graph becomes disconnected, and the search becomes unreliable.
Qdrant avoids all these problems and also benefits from the speed boost, as it implements an advanced [query planning strategy](https://qdrant.tech/documentation/search/#query-planning).
The Filtering Benchmark is all about changes in performance between filter and un-filtered queries. Please refer to the search benchmark for absolute speed comparison.
  1. While generating embeddings you’re most likely going to use Python and python based ML frameworks.
  2. Based on GitHub stars, python clients are one of the most popular clients across all the engines.
From the user’s perspective, the crucial thing is the latency perceived while using a specific library - in most cases a Python client. Nobody can and even should redefine the whole technology stack, just because of using a specific search tool. That’s why we decided to focus primarily on official Python libraries, provided by the database authors. Those may use some different protocols under the hood, but at the end of the day, we do not care how the data is transferred, as long as it ends up in the target location.
##  [](https://qdrant.tech/benchmarks/#how-to-contribute)How to contribute?
We made the benchmark Open Source because we believe that it has to be transparent. We could have misconfigured one of the engines or just done it inefficiently. If you feel like you could help us out, check out our 
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/benchmarks/)
                    ## 📄 `https-qdrant-tech-benchmarks-benchmarking-vector-databases.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Benchmarks](https://qdrant.tech/benchmarks/)
  * /
  * Single node benchmarks (2022)
Dataset: deep-image-96-angular gist-960-euclidean glove-100-angular
Search threads: 100 8 4 2 1
Plot values:
RPS  Latency  p95 latency  Index time
Engine | Setup | Dataset | Upload Time(m) | Upload + Index Time(m) | Latency(ms) | P95(ms) | P99(ms) | RPS | Precision  
---|---|---|---|---|---|---|---|---|---  
qdrant | _qdrant-rps-m-64-ef-512_ | deep-image-96-angular | 14.096 | 149.32 | 24.73 | 55.75 | 63.73 | 1541.86 | 0.96  
weaviate | _weaviate-m-16-ef-128_ | deep-image-96-angular | 148.70 | 148.70 | 190.94 | 351.75 | 414.16 | 507.33 | 0.94  
milvus | _milvus-m-16-ef-128_ | deep-image-96-angular | 6.074 | 35.28 | 171.50 | 220.26 | 236.97 | 339.44 | 0.97  
elastic | _elastic-m-16-ef-128_ | deep-image-96-angular | 87.54 | 101.16 | 923.031 | 1116.83 | 1671.31 | 95.90 | 0.97  
_Download raw data:[here](https://qdrant.tech/benchmarks/result-2022-08-10.json)_
This is an archived version of Single node benchmarks. Please refer to the new version [here](https://qdrant.tech/benchmarks/single-node-speed-benchmark/).
Share this article
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/benchmarks/single-node-speed-benchmark-2022/)
                    ## 📄 `https-qdrant-tech-benchmarks-single-node-speed-benchmark.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Benchmarks](https://qdrant.tech/benchmarks/)
  * /
  * Single node benchmarks
Dataset: dbpedia-openai-1M-1536-angular deep-image-96-angular gist-960-euclidean glove-100-angular
Search threads: 100 1
Plot values:
RPS  Latency  p95 latency  Index time
Engine | Setup | Dataset | Upload Time(m) | Upload + Index Time(m) | Latency(ms) | P95(ms) | P99(ms) | RPS | Precision  
---|---|---|---|---|---|---|---|---|---  
qdrant | _qdrant-sq-rps-m-64-ef-512_ | dbpedia-openai-1M-1536-angular | 3.51 | 24.43 | 3.54 | 4.95 | 8.62 | 1238.0016 | 0.99  
weaviate | _latest-weaviate-m32_ | dbpedia-openai-1M-1536-angular | 13.94 | 13.94 | 4.99 | 7.16 | 11.33 | 1142.13 | 0.97  
elasticsearch | _elasticsearch-m-32-ef-128_ | dbpedia-openai-1M-1536-angular | 19.18 | 83.72 | 22.10 | 72.53 | 135.68 | 716.80 | 0.98  
redis | _redis-m-32-ef-256_ | dbpedia-openai-1M-1536-angular | 92.49 | 92.49 | 140.65 | 160.85 | 167.35 | 625.27 | 0.97  
milvus | _milvus-m-16-ef-128_ | dbpedia-openai-1M-1536-angular | 0.27 | 1.16 | 393.31 | 441.32 | 576.65 | 219.11 | 0.99  
_Download raw data:[here](https://qdrant.tech/benchmarks/results-1-100-thread-2024-06-15.json)_
###  [](https://qdrant.tech/benchmarks/single-node-speed-benchmark/#setup)Setup
![Benchmarks configuration](https://qdrant.tech/benchmarks/client-server.png)
Benchmarks configuration
Please note that some of the configs of some engines crashed on some datasets because of the 25 GB memory limit. That’s why you might see fewer points for some engines on choosing higher precision thresholds.
Share this article
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/benchmarks/single-node-speed-benchmark/)
                    ## 📄 `https-qdrant-tech-benchmarks-tested-datasets.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Dailymotion's Journey to Crafting the Ultimate Content-Driven Video Recommendation Engine with Qdrant Vector Database
On this page:
  *     * [Dailymotion’s Journey to Crafting the Ultimate Content-Driven Video Recommendation Engine with Qdrant Vector Database](https://qdrant.tech/blog/case-study-dailymotion/#dailymotions-journey-to-crafting-the-ultimate-content-driven-video-recommendation-engine-with-qdrant-vector-database)
      * [Scale](https://qdrant.tech/blog/case-study-dailymotion/#scale)
      * [Challenge](https://qdrant.tech/blog/case-study-dailymotion/#challenge)
      * [Background / Journey](https://qdrant.tech/blog/case-study-dailymotion/#background--journey)
      * [Solution at glance](https://qdrant.tech/blog/case-study-dailymotion/#solution-at-glance)
      * [Why Qdrant?](https://qdrant.tech/blog/case-study-dailymotion/#why-qdrant)
      * [Data Processing pipeline](https://qdrant.tech/blog/case-study-dailymotion/#data-processing-pipeline)
      * [Results](https://qdrant.tech/blog/case-study-dailymotion/#results)
      * [Outlook / Future plans](https://qdrant.tech/blog/case-study-dailymotion/#outlook--future-plans)
      * [References](https://qdrant.tech/blog/case-study-dailymotion/#references)
  1. Subpar video recommendations due to long processing time ~ 5 hours
  2. Collaborative recommender tended to recommend and focused on high signal / popular videos
  3. Metadata based recommender focussed only on a very small scope of trusted video sources
  4. The recommendations did not take contents of the video into consideration
![after-qdrant-results](https://qdrant.tech/case-studies/dailymotion/after-qdrant.png)
The new recommender system implementation leveraging Qdrant along with the collaborative recommender offered various advantages :
  1. The processing time for the new video content reduced significantly to a few minutes which enabled the fresh videos to be part of recommendations.
  2. The performant & scalable scope of video recommendation currently processes 22 Million videos and can provide recommendation for videos with fewer interactions too.
  3. The overall huge performance gain on the low signal videos has contributed to more than 3 times increase on the interaction and CTR ( number of clicks) on the recommended videos.
  4. Seamlessly solved the initial cold start and low performance problems with the fresh content.
### Get Started with Qdrant Free
![](https://qdrant.tech/img/rocket.svg)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-dailymotion/)
                    ## 📄 `https-qdrant-tech-blog-case-study-deutsche-telekom.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * How Deutsche Telekom Built a Multi-Agent Enterprise Platform Leveraging Qdrant
  *     *       * [Key Requirements for Scaling Enterprise AI Agents](https://qdrant.tech/blog/case-study-deutsche-telekom/#key-requirements-for-scaling-enterprise-ai-agents)
      * [Why Deutsche Telekom Had to Rethink Its AI Stack from the Ground Up](https://qdrant.tech/blog/case-study-deutsche-telekom/#why-deutsche-telekom-had-to-rethink-its-ai-stack-from-the-ground-up)
      * [LMOS: Deutsche Telekom’s Open-Source Multi-Agent AI PaaS for Enterprise AI](https://qdrant.tech/blog/case-study-deutsche-telekom/#lmos-deutsche-telekoms-open-source-multi-agent-ai-paas-for-enterprise-ai)
      * [Why Qdrant? Finding the Right Vector Database for LMOS](https://qdrant.tech/blog/case-study-deutsche-telekom/#why-qdrant-finding-the-right-vector-database-for-lmos)
      * [Scaling AI at Deutsche Telekom & The Future of LMOS](https://qdrant.tech/blog/case-study-deutsche-telekom/#scaling-ai-at-deutsche-telekom--the-future-of-lmos)
      * [Watch livestream with Arun](https://qdrant.tech/blog/case-study-deutsche-telekom/#watch-livestream-with-arun)
**How Deutsche Telekom Built a Scalable, Multi-Agent Enterprise Platform Leveraging Qdrant—Powering Over 2 Million Conversations Across Europe**
![Deutsche Telekom’s AI Competence Center team leading the LMOS platform development](https://qdrant.tech/blog/case-study-deutsche-telekom/dtag-team.jpg)
To achieve this, Telekom developed _(Eng: Ask Magenta)_ , a platform that includes chatbots and voice bots, built as a Platform as a Service (PaaS) to ensure scalability across Deutsche Telekom’s ten European subsidiaries.
“We knew from the start that we couldn’t just deploy RAG, tool calling, and workflows at scale without a platform-first approach,” Arun explains. “When I looked at the challenge, it looked a lot like a distributed systems and engineering challenge, not just an AI problem.”
  1. **Handling Tenancy & Memory Management:** AI workloads spanning 10 different countries require strict data segregation and compliance.
  2. **Horizontal Scaling & Context Sharing**: AI agents require real-time processing while maintaining historical context, so efficiently storing, retrieving, and processing AI-generated context at scale is critical.
  3. **Non-Deterministic Agent Collaboration:** AI agents often exhibit unpredictable behavior, making seamless inter-agent communication and workflow orchestration complex.
“From our experience, these challenges are fundamentally distributed systems problems, not just AI problems,” Arun explains. “We need feedback loops, state management, lifecycle orchestration, and intelligent routing for staggered rollouts. Microservices alone aren’t enough — we need a domain-driven approach to AI agent design.”
This insight led to the formation of 
  * Memory spikes and operational instability due to the sheer number of components used in the previous provide
  * Complex maintenance requirements, with frequent dependency issues, high operational overhead due to missing memory optimizations, and streamlined deployment.
Despite efforts to improve annotations and tuning, it became evident that this approach wouldn’t scale for Deutsche Telekom.
Additionally, there was a strong need to leverage existing engineering assets, as most developers and systems were already equipped with SDKs and familiar tooling. Rather than building an entirely new stack from scratch, the focus shifted to enabling developers to build AI agents within the tools and frameworks they were already comfortable with. This approach allowed domain experts who understood the APIs and enterprise systems to quickly develop AI agents without disrupting existing workflows.
Recognizing this, the team made a bold decision: to build a **fully-fledged PaaS platform for AI agents** , streamlining development and accelerating deployment of AI Agents.
  * **Choosing Kotlin and JVM** to ensure engineers familiar with existing Deutsche Telekom systems could easily integrate with LMOS.
  * **Moving away from pre-built frameworks** in favor of a ground-up, highly optimized solution tailored to Deutsche Telekom’s specific needs.
  * **Providing a Heroku-like experience** where engineers don’t need to worry about classifiers, agent lifecycles, deployment models, monitoring, and horizontal scaling.
  * **Enterprise Grade while being flexible:** LMOS was built with enterprise-grade scalability, versioning, and multi-tenancy in mind, while also offering the flexibility to integrate agents from other frameworks — not just JVM-based solutions — ensuring interoperability across diverse AI ecosystems.
“Our engineers already knew their APIs — billing, shopping, user profiles. Why should we introduce new abstractions that only complicate the stack?” Arun notes, “also, I envisioned us building the foundations of what I call **agentic computing** , playing a role in shaping the application stacks of the future on top of LLMs.”
![LMOS architecture diagram showing AI agent collaboration and lifecycle management](https://qdrant.tech/blog/case-study-deutsche-telekom/lmos-architecture.png)
LMOS architecture powering AI agent collaboration and lifecycle management in a cloud-native environment.
  1. **Qualitative metrics** : developer experience, ease of use, memory efficiency features.
  2. **Operational simplicity** : how well it fit into their PaaS-first approach and [multitenancy requirements](https://qdrant.tech/documentation/guides/multiple-partitions/).
Deutsche Telekom’s engineers also cited several standout features that made Qdrant the right fit:
  1. **Simplicity in operations** —Qdrant is lightweight and doesn’t require an excessive component stack.
  2. **Developer experience** —libraries, multi-language clients, and cross-framework support make integrations seamless.
  3. **WebUI & Collection Visualization**—engineers found Qdrant’s [built-in collection visualization](https://qdrant.tech/documentation/web-ui/) tools highly useful.
As part of their evaluation, Deutsche Telekom engineers compared multiple solutions, weighing operational simplicity and reliability.
One engineer summarized their findings: “Qdrant has way fewer components, compared to the another that required required Kafka, Zookeeper, and only had a hot standby for its index and query nodes. If you rescale it, you get downtime. Qdrant stays up.”
###  [](https://qdrant.tech/blog/case-study-deutsche-telekom/#watch-livestream-with-arun)Watch livestream with Arun
In this Vector Space talk, Thierry from Qdrant and Arun from Deutsche Telekom talk about the key requirements for scaling enterprise AI agents, key AI stack considerations, and how the team built a Platform as a Service (PaaS) - LMOS (Language Models Operating System) — a multi-agent PaaS designed for high scalability and modular AI agent deployment.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-deutsche-telekom/)
                    ## 📄 `https-qdrant-tech-blog-case-study-hubspot.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * HubSpot & Qdrant: Scaling an Intelligent AI Assistant
  *     * [**Challenges Scaling an Intelligent AI**](https://qdrant.tech/blog/case-study-hubspot/#challenges-scaling-an-intelligent-ai)
    * [**Why HubSpot Chose Qdrant**](https://qdrant.tech/blog/case-study-hubspot/#why-hubspot-chose-qdrant)
    * [**Faster, More Accurate Search Improves Customer Satisfaction and Engagement**](https://qdrant.tech/blog/case-study-hubspot/#faster-more-accurate-search-improves-customer-satisfaction-and-engagement)
HubSpot, a global leader in CRM solutions, continuously enhances its product suite with powerful AI-driven features. To optimize Breeze AI, its flagship intelligent assistant, HubSpot chose Qdrant as its vector database.
  * Delivering highly personalized, context-aware responses required a robust vector search solution that could retrieve data quickly while maintaining accuracy.
  * With increasing user interactions, HubSpot needed a scalable system capable of handling rapid data growth without performance degradation.
  * Integration with HubSpot’s existing AI infrastructure had to be swift and easy to support fast-paced development cycles.
  * HubSpot sought a future-proof vector search solution that could adapt to emerging AI advancements while maintaining high availability.
These challenges made it essential to find a high-performance, developer-friendly vector database that could power Breeze AI efficiently.
* * *
_“Qdrant powers our demanding recommendation and RAG applications. We chose it for its ease of deployment and high performance at scale, and we have been consistently impressed with its results. The platform’s continuous feature enhancements and overall performance gains, coupled with their responsiveness, make Qdrant a reliable solution for our AI infrastructure.”_
**– Srubin Sethu Madhavan, Technical Lead, HubSpot**
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-hubspot/)
                    ## 📄 `https-qdrant-tech-blog-case-study-kairoswealth.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Kairoswealth & Qdrant: Transforming Wealth Management with AI-Driven Insights and Scalable Vector Search
  *     * [**About Kairoswealth**](https://qdrant.tech/blog/case-study-kairoswealth/#about-kairoswealth)
    * [**Motivations for Adopting a Vector Database**](https://qdrant.tech/blog/case-study-kairoswealth/#motivations-for-adopting-a-vector-database)
    * [**Challenges with Previous Solutions**](https://qdrant.tech/blog/case-study-kairoswealth/#challenges-with-previous-solutions)
    * [**Qdrant Use Cases at Kairoswealth**](https://qdrant.tech/blog/case-study-kairoswealth/#qdrant-use-cases-at-kairoswealth)
    * [**Why Kairoswealth Chose Qdrant**](https://qdrant.tech/blog/case-study-kairoswealth/#why-kairoswealth-chose-qdrant)
    * [**Conclusion**](https://qdrant.tech/blog/case-study-kairoswealth/#conclusion)
    * [**Future Roadmap for Kairoswealth**](https://qdrant.tech/blog/case-study-kairoswealth/#future-roadmap-for-kairoswealth)
![Kairoswealth overview](https://qdrant.tech/blog/case-study-kairoswealth/image2.png)
  * **Internal Data RAG:** Efficiently handling internal RAG use cases.
  * **Financial Regulatory Reports RAG:** Managing and generating financial reports.
  * **Recommendations:** Enhancing the accuracy and efficiency of recommendations with the Kairoswealth platform.
![Stock recommendation](https://qdrant.tech/blog/case-study-kairoswealth/image1.png)
##  [](https://qdrant.tech/blog/case-study-kairoswealth/#future-roadmap-for-kairoswealth)**Future Roadmap for Kairoswealth**
Kairoswealth is seizing the opportunity to disrupt the wealth management sector, which has traditionally been underserved by technology. For example, they are developing the Kairos Terminal, a natural language interface that translates user queries into OpenBB commands (a set of tools for financial analysis and data visualization within the OpenBB Terminal). With regards to the future of the wealth management sector, Teyssier notes that “the integration of Generative AI will automate back-office tasks such as data collation, data reconciliation, and market research. This technology will also enable wealth managers to scale their services to broader segments, including affluent clients, by automating relationship management and interactions.”
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-kairoswealth/)
                    ## 📄 `https-qdrant-tech-blog-case-study-kern.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Kern AI & Qdrant: Precision AI Solutions for Finance and Insurance
  *     * [About Kern AI](https://qdrant.tech/blog/case-study-kern/#about-kern-ai)
    * [The Challenge](https://qdrant.tech/blog/case-study-kern/#the-challenge)
    * [The Solution](https://qdrant.tech/blog/case-study-kern/#the-solution)
    * [The Results](https://qdrant.tech/blog/case-study-kern/#the-results)
    * [Outlook](https://qdrant.tech/blog/case-study-kern/#outlook)
![kern-case-study](https://qdrant.tech/blog/case-study-kern/kern-case-study.png)
  * **Multi-vector Storage** : This feature was crucial as it allowed the team to store and manage different search indexes. Given that no single embedding fits all use cases, this capability brought essential diversity to their embeddings, enabling more flexible and robust data handling.
  * **Easy Setup** : Qdrant’s straightforward setup process enabled Kern AI to quickly integrate and start utilizing the database without extensive overhead, which was critical for maintaining development momentum.
  * **Open Source** : The open-source nature of Qdrant aligned with Kern AI’s own product development philosophy. This allowed for greater customization and integration into their existing open-source projects.
  * **Rapid Progress** : Qdrant’s swift advancements and frequent updates ensured that Kern AI could rely on continuous improvements and cutting-edge features to keep their solutions competitive.
  * **Multi-vector Search** : Allowed Kern AI to perform complex queries across different embeddings simultaneously, enhancing the depth and accuracy of their search results.
  * **Hybrid Search/Filters** : Enabled the combination of traditional keyword searches with vector searches, allowing for more nuanced and precise data retrieval.
Kern AI uses Qdrant’s open-source, on-premise solution for both their open-source project and their commercial end-to-end framework. This framework, focused on the financial and insurance markets, is similar to LangChain or LlamaIndex but tailored to the industry-specific needs.
![kern-data-retrieval](https://qdrant.tech/blog/case-study-kern/kern-data-retrieval.png)
_Configuring data retrieval in Kern AI: Fine-tuning search inputs and metadata for optimized information extraction._
  * **< 1% Hallucination Rate**: Ensures the highest level of accuracy and reliability in their chatbot solutions for the financial and insurance sector.
  * **Reduced Customer Service Response Times** : Using Kern AI’s solution, Markel Insurance SE reduced response times from five minutes to under 30 seconds, significantly improving customer experience and operational efficiency.
By utilizing Qdrant, Kern AI effectively supports various use cases in financial services, such as:
  * **Claims Management** : Streamlining the claims process by quickly identifying relevant data points.
  * **Similarity Search** : Enhancing incident handling by finding similar cases to improve decision-making quality.
##  [](https://qdrant.tech/blog/case-study-kern/#outlook)Outlook
Kern AI plans to expand its use of Qdrant to support both brownfield and greenfield use cases across the financial and insurance industry.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-kern/)
                    ## 📄 `https-qdrant-tech-blog-case-study-mixpeek.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * How Mixpeek Uses Qdrant for Efficient Multimodal Feature Stores
  * [How Mixpeek Uses Qdrant for Efficient Multimodal Feature Stores](https://qdrant.tech/blog/case-study-mixpeek/#how-mixpeek-uses-qdrant-for-efficient-multimodal-feature-stores)
    * [About Mixpeek](https://qdrant.tech/blog/case-study-mixpeek/#about-mixpeek)
    * [The Challenge: Optimizing Feature Stores for Complex Retrievers](https://qdrant.tech/blog/case-study-mixpeek/#the-challenge-optimizing-feature-stores-for-complex-retrievers)
    * [Why Mixpeek Chose Qdrant for Feature Stores](https://qdrant.tech/blog/case-study-mixpeek/#why-mixpeek-chose-qdrant-for-feature-stores)
      * [Simplifying Hybrid Retrievers](https://qdrant.tech/blog/case-study-mixpeek/#simplifying-hybrid-retrievers)
      * [40% Faster Query Times with Parallel Retrieval](https://qdrant.tech/blog/case-study-mixpeek/#40-faster-query-times-with-parallel-retrieval)
      * [Optimizing SageMaker Feature Extraction Workflows](https://qdrant.tech/blog/case-study-mixpeek/#optimizing-sagemaker-feature-extraction-workflows)
    * [Supporting Mixpeek’s Taxonomy and Clustering Architecture](https://qdrant.tech/blog/case-study-mixpeek/#supporting-mixpeeks-taxonomy-and-clustering-architecture)
      * [Taxonomies (JOIN Analogue)](https://qdrant.tech/blog/case-study-mixpeek/#taxonomies-join-analogue)
      * [Clustering (GROUP BY Analogue)](https://qdrant.tech/blog/case-study-mixpeek/#clustering-group-by-analogue)
    * [Measurable Improvements After Feature Store Migration](https://qdrant.tech/blog/case-study-mixpeek/#measurable-improvements-after-feature-store-migration)
    * [Future Direction: Supporting Diverse Multimodal Use Cases](https://qdrant.tech/blog/case-study-mixpeek/#future-direction-supporting-diverse-multimodal-use-cases)
    * [Conclusion: Specialized Feature Stores for Multimodal Data Warehousing](https://qdrant.tech/blog/case-study-mixpeek/#conclusion-specialized-feature-stores-for-multimodal-data-warehousing)
##  [](https://qdrant.tech/blog/case-study-mixpeek/#conclusion-specialized-feature-stores-for-multimodal-data-warehousing)Conclusion: Specialized Feature Stores for Multimodal Data Warehousing
Mixpeek’s journey highlights the importance of specialized feature stores in a multimodal data warehouse architecture. Qdrant’s focus on vector search efficiency made it the ideal choice for powering Mixpeek’s feature stores, enabling more efficient retrievers and ingestion pipelines.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-mixpeek/)
                    ## 📄 `https-qdrant-tech-blog-case-study-nyris.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Nyris & Qdrant: How Vectors are the Future of Visual Search
  *     * [About Nyris](https://qdrant.tech/blog/case-study-nyris/#about-nyris)
    * [Overcoming Limitations in Visual Product Search](https://qdrant.tech/blog/case-study-nyris/#overcoming-limitations-in-visual-product-search)
    * [The Path to Vector-Based Visual Search](https://qdrant.tech/blog/case-study-nyris/#the-path-to-vector-based-visual-search)
      * [The Selection Process](https://qdrant.tech/blog/case-study-nyris/#the-selection-process)
    * [Key Benefits of Qdrant in Production](https://qdrant.tech/blog/case-study-nyris/#key-benefits-of-qdrant-in-production)
    * [Why Pure-Vector Search is the Future for Product Search](https://qdrant.tech/blog/case-study-nyris/#why-pure-vector-search-is-the-future-for-product-search)
![nyris-case-study](https://qdrant.tech/blog/case-study-nyris/nyris-case-study.png)
  * **Enhanced Security with JWT** : [JSON Web Tokens](https://qdrant.tech/documentation/guides/security/#granular-access-control-with-jwt) provide enhanced security and performance, critical for safeguarding their data.
  * **Seamless Scalability** : Qdrant’s ability to [scale effortlessly across nodes](https://qdrant.tech/documentation/guides/distributed_deployment/) ensures consistent high performance, even as Nyris’s data volume grows.
  * **Flexible Search Options** : The availability of both graph-based and brute-force search methods offers Nyris the flexibility to tailor the search approach to specific use case requirements.
  * **Versatile Data Handling** : Qdrant imposes almost no restrictions on data types and vector sizes, allowing Nyris to manage diverse and complex datasets effectively.
  * **Built with Rust** : The use of [Rust](https://qdrant.tech/articles/why-rust/) ensures superior performance and future-proofing, while its open-source nature allows Nyris to inspect and customize the code as necessary.
  * **Cost-Effective High Performance Search** : Qdrant’s efficient search capabilities ensure that Nyris can maintain high performance at a reasonable cost. With Qdrant, Nyris can search through extensive datasets efficiently, making it a crucial part of their technology stack.
By hosting Qdrant on Google Cloud within their Kubernetes Cluster, Nyris benefits from the scalability and reliability essential for their demanding operations, ensuring a robust and efficient visual search solution.
##  [](https://qdrant.tech/blog/case-study-nyris/#why-pure-vector-search-is-the-future-for-product-search)Why Pure-Vector Search is the Future for Product Search
Nyris’s vision is to identify every single product and spare part within milliseconds, and Qdrant plays an integral role in this. When envisioning the future of product search, Lukasson is convinced that vector representations will be the key to advancing search capabilities. Unlike keyword searches, vector search can seamlessly integrate various modalities, such as text, images, as well as depth or audio. This holistic approach will transform product and spare part searches, allowing for a single vector representation that encompasses a product’s text, visual and geometric descriptions.
“While traditional algorithms like BM25 are fast and cheap and still have a place in the search stack, vectors will replace them in the coming years,” says Lukasson. “Today, we have separate spaces for text search, visual search, and other modalities, but we envision a future with a unified vector representation that encompasses all relevant item data. No matter what input you use for your query, the search results will be accurate. The days of scrolling through thousands of results or encountering ’no results’ pages will soon be over. Every search request will deliver the right product or spare part in milliseconds.”
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-nyris/)
                    ## 📄 `https-qdrant-tech-blog-case-study-qatech.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Empowering QA.tech’s Testing Agents with Real-Time Precision and Scale
  *     * [What prompted QA.tech to use a vector database?](https://qdrant.tech/blog/case-study-qatech/#what-prompted-qatech-to-use-a-vector-database)
    * [Why QA.tech chose Qdrant for its AI Agent platform](https://qdrant.tech/blog/case-study-qatech/#why-qatech-chose-qdrant-for-its-ai-agent-platform)
    * [How QA.tech Overcame Key Challenges in AI Agent Development](https://qdrant.tech/blog/case-study-qatech/#how-qatech-overcame-key-challenges-in-ai-agent-development)
![qdrant-qatech-1](https://qdrant.tech/blog/case-study-qatech/qdrant-qatech-1.png)
**fully testing web applications, especially end-to-end, can be complex and time-consuming**. Unlike unit tests, end-to-end tests reveal what’s actually happening in the browser, often uncovering issues that other methods miss.
Traditional solutions like hard-coded tests are not only labor-intensive to set up but also challenging to maintain over time. Alternatively, hiring QA testers can be a solution, but for startups, it quickly becomes a bottleneck. With every release, more testers are needed, and if testing is outsourced, managing timelines and ensuring quality becomes even harder.
To address this, QA.tech has developed **testing agents** that perform tasks on the browser just like a user would - for example, purchasing a ticket on a travel app. These agents navigate the entire booking process, from searching for flights to completing the purchase, all while assessing their success. **They document errors, record the process, and flag issues for developers to review.** With access to console logs and network calls, developers can easily analyze each step, quickly understanding and debugging any issues that arise.
![qdrant-qatech-2](https://qdrant.tech/blog/case-study-qatech/qdrant-qatech-2.png)
_Output from a QA.tech AI agent_
> “The more steps you ask an agent to take, the harder it becomes to ensure consistent performance,” Vilhelm von Ehrenheim, Co-Founder of QA.tech.
Each additional action adds layers of interdependent variables, creating pathways that can easily lead to errors if not managed carefully.
Von Ehrenheim also points out the limitations of current large language models (LLMs), noting that _“LLMs are getting more powerful, but they still struggle with multi-step reasoning and for example handling subtle visual changes like dark mode or adaptive UIs.”_ These challenges make it essential for agents to have precise planning capabilities and context awareness, which QA.tech has addressed by implementing custom embeddings and multimodal models.
_“This is where scalable, adaptable infrastructure becomes crucial,”_ von Ehrenheim adds. Qdrant has been instrumental for QA.tech, providing stable, high-performance vector search to support the demanding workflows. **“With Qdrant, we’re able to handle these complex, high-velocity tasks without compromising on reliability.”**
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-qatech/)
                    ## 📄 `https-qdrant-tech-blog-case-study-sprinklr.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * How Sprinklr Leverages Qdrant to Enhance AI-Driven Customer Experience Solutions
  *     * [The Need for a Vector Database](https://qdrant.tech/blog/case-study-sprinklr/#the-need-for-a-vector-database)
      * [Why Qdrant?](https://qdrant.tech/blog/case-study-sprinklr/#why-qdrant)
    * [Implementation and Qdrant’s Performance](https://qdrant.tech/blog/case-study-sprinklr/#implementation-and-qdrants-performance)
      * [Key Outcomes with Qdrant](https://qdrant.tech/blog/case-study-sprinklr/#key-outcomes-with-qdrant)
    * [Outlook](https://qdrant.tech/blog/case-study-sprinklr/#outlook)
    * [Benchmarking Conclusion](https://qdrant.tech/blog/case-study-sprinklr/#benchmarking-conclusion)
![case-study-sprinklr-1](https://qdrant.tech/blog/case-study-sprinklr/image1.png)
Raghav Sonavane, Associate Director of Machine Learning Engineering at Sprinklr, leads the Applied AI team, focusing on Generative AI (GenAI) and Retrieval-Augmented Generation (RAG). His team is responsible for training and fine-tuning in-house models and deploying advanced retrieval and generation systems for customer-facing applications like FAQ bots and other 
![case-study-sprinklr-2](https://qdrant.tech/blog/case-study-sprinklr/image2.png)
_Figure:_ Sprinklr’s RAG architecture
Sprinklr’s platform is composed of four key product suites - Sprinklr Service, Sprinklr Marketing, Sprinklr Social, and Sprinklr Insights. Each suite is embedded with AI-first features such as assist agents, post-call analysis, and real-time analytics, which are crucial for managing large-scale contact center operations. “These AI-driven capabilities, supported by Qdrant’s advanced vector search, enhance Sprinklr’s customer-facing tools such as FAQ bots, transactional bots, conversational services, and product recommendation engines,” says Sonavane.
These self-serve applications rely heavily on advanced vector search to analyze and optimize community content and refine knowledge bases, ensuring efficient and relevant responses. For customers requiring further assistance, Sprinklr equips support agents with powerful search capabilities, enabling them to quickly access similar cases and draw from past interactions, enhancing the quality and speed of customer support.
  * **30% Cost Reduction** : Internal benchmarking showed Qdrant reduced Sprinklr’s retrieval infrastructure costs by 30%.
  * **Improved Developer Efficiency** : Qdrant’s user-friendly environment made it easier to maintain instances, enhancing overall efficiency.
The Sprinklr team conducted a thorough internal benchmark on applications requiring vector search across 10k to over 1M vectors with varying dimensions of vectors depending on the use case. The key results from these benchmarks include:
  * **Superior Write Performance** : Qdrant’s write performance excelled in Sprinklr’s benchmark tests, with incremental indexing time for 100k to 1M vectors being less than 10% of Elasticsearch’s, making it highly efficient for handling updates and append queries in high-ingestion use cases.
  * **Low Latency for Real-Time Applications:** In Sprinklr’s benchmark, Qdrant delivered a P99 latency of 20ms for searches on 1 million vectors, making it ideal for real-time use cases like live chat, where Elasticsearch and Milvus both exceeded 100ms.
  * **High Throughput for Heavy Query Loads** : In Sprinklr’s benchmark, Qdrant handled up to 250 requests per second (RPS) under similar configurations, significantly outperforming Elasticsearch’s 100 RPS, making it ideal for environments with heavy query loads.
“Qdrant is a very fast and high quality retrieval system,” Sonavane points out.
![case-study-sprinklr-3](https://qdrant.tech/blog/case-study-sprinklr/image3.png)
_Figure: P95 Query Time vs Mean Average Precision Benchmark Across Varying Index Sizes_
  * We benchmarked applications requiring search on different sizes ranging from 10k to 1M+ vectors, with varying dimensions of vectors depending on the usage. Our infrastructure mainly consisted of Elasticsearch and in-memory Faiss vector search.
Key Observations:
  2. **Low Latency** : Tail latencies are very critical for real-time applications such as live chat, requiring low P95 and P99 latencies. For a workload requiring search on 1 million vectors, qdrant provided inference latency of 20ms P99 whereas ES and Milvus were more than 100ms.
  3. **High Throughput** : Qdrant handles a high number of requests per second, making it ideal for environments with heavy query loads. For similar configurations, Qdrant provided a throughput of 250 RPS whereas ES was around 100 RPS.
![case-study-sprinklr-5](https://qdrant.tech/blog/case-study-sprinklr/image3.png)
![case-study-sprinklr-6](https://qdrant.tech/blog/case-study-sprinklr/image6.png)
![case-study-sprinklr-7](https://qdrant.tech/blog/case-study-sprinklr/image7.png)
![case-study-sprinklr-8](https://qdrant.tech/blog/case-study-sprinklr/image8.png)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-sprinklr/)
                    ## 📄 `https-qdrant-tech-blog-case-study-visua.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Visua and Qdrant: Vector Search in Computer Vision
  *     * [The Challenge](https://qdrant.tech/blog/case-study-visua/#the-challenge)
    * [The Solution](https://qdrant.tech/blog/case-study-visua/#the-solution)
    * [The Selection Process](https://qdrant.tech/blog/case-study-visua/#the-selection-process)
    * [Implementing Qdrant](https://qdrant.tech/blog/case-study-visua/#implementing-qdrant)
    * [The Results](https://qdrant.tech/blog/case-study-visua/#the-results)
![visua/image1.png](https://qdrant.tech/blog/case-study-visua/image1.png)
For over a decade, **Brandwatch** , cybersecurity like **Mimecast** , trademark protection like **Ebay** and several sports agencies like **Vision Insights** for sponsorship evaluation.
![visua/image3.png](https://qdrant.tech/blog/case-study-visua/image3.png)
  * **Hybrid Query Capability:** Qdrant enables the execution of hybrid queries that combine payload fields and vector data, allowing for comprehensive and nuanced searches. This functionality leverages the strengths of both payload attributes and vector similarities for detailed data analysis. Prest noted the importance of Qdrant’s hybrid approach, saying, “When talking with the founders of Qdrant, we realized that they put a lot of effort into this hybrid approach, which really resonated with us.”
  * **Performance Superiority** : Qdrant distinguished itself as the fastest engine for VISUA’s specific needs, significantly outpacing alternatives with query speeds up to 40 times faster for certain VISUA use cases. Alessandro Prest highlighted, “Qdrant was the fastest engine by a large margin for our use case,” underscoring its significant efficiency and scalability advantages.
  * **API Documentation** : The clarity, comprehensiveness, and user-friendliness of Qdrant’s API documentation and reference guides further solidified VISUA’s decision.
This strategic selection enabled VISUA to achieve a notable increase in operational efficiency and scalability in its quality control processes.
####  [](https://qdrant.tech/blog/case-study-visua/#expanding-qdrants-use-beyond-anomaly-detection)Expanding Qdrant’s Use Beyond Anomaly Detection
While the primary application of Qdrant is focused on quality control, VISUA’s team is actively exploring additional use cases with Qdrant. VISUA’s use of Qdrant has inspired new opportunities, notably in content moderation. “The moment we started to experiment with Qdrant, opened up a lot of ideas within the team for new applications,” said Prest on the potential unlocked by Qdrant. For example, this has led them to actively explore the Qdrant [Discovery API](https://qdrant.tech/documentation/concepts/explore/?q=discovery#discovery-api), with an eye on enhancing content moderation processes.
Beyond content moderation, VISUA is set for significant growth by broadening its copyright infringement detection services. As the demand for detecting a wider range of infringements, like unauthorized use of popular characters on merchandise, increases, VISUA plans to expand its technology capabilities. Qdrant will be pivotal in this expansion, enabling VISUA to meet the complex and growing challenges of moderating copyrighted content effectively and ensuring comprehensive protection for brands and creators.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-visua/)
                    ## 📄 `https-qdrant-tech-blog-case-study-voiceflow.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Voiceflow & Qdrant: Powering No-Code AI Agent Creation with Scalable Vector Search
  *     * [Evaluation Criteria](https://qdrant.tech/blog/case-study-voiceflow/#evaluation-criteria)
    * [Migration and Onboarding](https://qdrant.tech/blog/case-study-voiceflow/#migration-and-onboarding)
    * [RAG Pipeline Setup](https://qdrant.tech/blog/case-study-voiceflow/#rag-pipeline-setup)
    * [How Voiceflow Uses Qdrant](https://qdrant.tech/blog/case-study-voiceflow/#how-voiceflow-uses-qdrant)
    * [The Outcome](https://qdrant.tech/blog/case-study-voiceflow/#the-outcome)
    * [What’s Next](https://qdrant.tech/blog/case-study-voiceflow/#whats-next)
![voiceflow/image2.png](https://qdrant.tech/blog/case-study-voiceflow/image1.png)
  * **Performance** : The ability to [handle the scale](https://qdrant.tech/documentation/guides/distributed_deployment/) required by Voiceflow, supporting hundreds of thousands of projects efficiently.
  * **Metadata** : The capability to tag data and chunks and retrieve based on those values, essential for organizing and accessing specific information swiftly.
  * **Managed Solution** : The availability of a [managed service](https://qdrant.tech/documentation/cloud/) with automated maintenance, scaling, and security, freeing the team from infrastructure concerns.
_“We started with Pinecone but eventually switched to Qdrant,”_ Linkov noted. The reasons for the switch included:
  * **Scaling Capabilities** : Qdrant offers a robust multi-node setup with [horizontal scaling](https://qdrant.tech/documentation/cloud/cluster-scaling/), allowing clusters to grow by adding more nodes and distributing data and load among them. This ensures high performance and resilience, which is crucial for handling large-scale projects.
  * **Infrastructure** : “Qdrant provides robust infrastructure support, allowing integration with virtual private clouds on AWS using AWS Private Links and ensuring encryption with AWS KMS. This setup ensures high security and reliability,” says Portillo Edo.
  * **Responsive Qdrant Team** : “The Qdrant team is very responsive, ships features quickly and is a great partner to build with,” Linkov added.
  * **Data Upload** : Customers can upload data via API from sources such as URLs, PDFs, Word documents, and plain text formats. Integration with platforms like Zendesk is supported, and users can choose between single uploads or refresh-based uploads.
  * **Data Ingestion** : Once data is ingested, Voiceflow offers preset strategies for data checking. Users can utilize these strategies or opt for more customization through the API to tailor the ingestion process as needed.
  * **Metadata Tagging** : Metadata tags can be applied during the ingestion process, which helps organize and facilitate efficient data retrieval later on.
  * **Data Retrieval** : At retrieval time, Voiceflow provides prompts that can modify user questions by adding context, variables, or other modifications. This customization includes adding personas or structuring responses as markdown. Depending on the type of interaction (e.g., button, carousel with an image for image retrieval), these prompts are displayed to users in a structured format.
This comprehensive setup ensures that Voiceflow users can efficiently manage and customize their data workflows, providing a robust solution for building AI-driven applications.
  * **Quantization** : This feature helps Voiceflow to perform efficient data processing by reducing the size of vectors, making searches faster. The team uses [Product Quantization](https://qdrant.tech/articles/product-quantization/) in particular.
  * **Chunking Search** : Voiceflow uses chunking search to improve search efficiency by breaking down large datasets into manageable chunks, which allows for faster and more efficient data retrieval.
  * **Sparse Vector Search** : Although not yet implemented, this feature is being explored for more precise keyword searches. “This is an encouraging direction the Qdrant team is taking here as many users seek more exact keyword search,” said Linkov.
_Architecture:_
  * **Node Pool** : A large node pool is used for public cloud users, ensuring scalability, while several smaller, isolated instances cater to private cloud users, providing enhanced security.
_Infrastructure:_
  * **Private Link** : The ability to use Private Link connections across different instances is a significant advantage, requiring robust infrastructure support from Qdrant. “This setup was crucial for SOC2 compliance, and Qdrant’s support team made the process seamless by ensuring feasibility and aiding in the implementation,” Linkov explained.
By utilizing these features, Voiceflow ensures that its platform is scalable, secure, and efficient, meeting the diverse needs of its users.
  * **Enhanced Metadata Tagging** : Implemented robust metadata tagging, allowing for custom fields and tags that facilitate efficient search filtering.
  * **Optimized Performance** : Resolved concerns about retrieval times with a high number of tags by optimizing indexing strategies, achieving efficient performance.
  * **Minimal Operational Overhead** : Experienced minimal overhead, streamlining their operational processes.
  * **Future-Ready** : Anticipates further innovation in hybrid search with multi-token attention.
  * **Multitenancy Support** : Utilized Qdrant’s efficient and [isolated data management](https://qdrant.tech/documentation/guides/multiple-partitions/) to support diverse user needs.
Overall, Qdrant’s features and infrastructure provided Voiceflow with a stable, scalable, and efficient solution for their data processing and retrieval needs.
##  [](https://qdrant.tech/blog/case-study-voiceflow/#whats-next)What’s Next
Voiceflow plans to enhance its platform with more filtering and customization options, allowing developers to host and customize chatbot interfaces without building their own [RAG](https://qdrant.tech/rag/) pipeline.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/case-study-voiceflow/)
                    ## 📄 `https-qdrant-tech-blog-colpali-qdrant-optimization.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Optimizing ColPali for Retrieval at Scale, 13x Faster Results
  *     * [The Scaling Dilemma](https://qdrant.tech/blog/colpali-qdrant-optimization/#the-scaling-dilemma)
    * [Two-Stage Retrieval Process](https://qdrant.tech/blog/colpali-qdrant-optimization/#two-stage-retrieval-process)
      * [Pooling](https://qdrant.tech/blog/colpali-qdrant-optimization/#pooling)
      * [The “ColPali as a Reranker” Experiment](https://qdrant.tech/blog/colpali-qdrant-optimization/#the-colpali-as-a-reranker-experiment)
      * [Implementation](https://qdrant.tech/blog/colpali-qdrant-optimization/#implementation)
      * [Experiment Setup](https://qdrant.tech/blog/colpali-qdrant-optimization/#experiment-setup)
    * [Results](https://qdrant.tech/blog/colpali-qdrant-optimization/#results)
      * [Metrics](https://qdrant.tech/blog/colpali-qdrant-optimization/#metrics)
    * [What’s Next?](https://qdrant.tech/blog/colpali-qdrant-optimization/#whats-next)
      * [Try It Yourself](https://qdrant.tech/blog/colpali-qdrant-optimization/#try-it-yourself)
ColPali is a fascinating leap in document retrieval. Its precision in handling visually rich PDFs is phenomenal, but scaling it to handle real-world datasets comes with its share of computational challenges.
Here’s how we solved these challenges to make ColPali 13x faster without sacrificing the precision it’s known for.
  * **Dataset Size:** 20,000 PDF pages.
  * **Number of Vectors:** Each page generates ~1,000 vectors of 128 dimensions.
The total number of comparisons is calculated as:
1,000⋅1,000⋅20,000⋅128=2.56×1012 comparisons!
That’s trillions of comparisons needed to build the index. Even advanced indexing algorithms like **HNSW** struggle with this scale, as computational costs grow quadratically with amount of multivectors per page.
We turned to a hybrid optimization strategy combining **pooling** (to reduce computational overhead) and **reranking** (to preserve accuracy).
Before we go any deeper, watch our 
For those eager to explore, the 
  * **Mean Pooling:** Averages values across rows.
  * **Max Pooling:** Selects the maximum value for each feature.
32 vectors represent the pooled rows, while 6 vectors encode contextual information derived from ColPali’s special tokens (e.g., for the beginning of the sequence, and task-specific instructions like “Describe the image”).
For our experiments, we chose to preserve these 6 additional vectors.
  * **ViDoRe Benchmark:** Designed for PDF documents retrieval evaluation.
  * **UFO Dataset:** Visually rich documents paired with synthetic queries 
  * **DocVQA Dataset:** A large set of document-derived Q&A pairs.
Each document was processed into 32x32 grids, generating both full-resolution and pooled embeddings. **Full-resolution** embeddings consisted of 1,030 vectors per page, while **pooled embeddings** included mean and max pooling variants.
All embeddings were were stored and kept in RAM to avoid caching effects during retrieval speed experiments.
  * **Demo Notebook:**
  * **Webinar Walkthrough:**
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/colpali-qdrant-optimization/)
                    ## 📄 `https-qdrant-tech-blog-dust-and-qdrant.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Dust and Qdrant: Using AI to Unlock Company Knowledge and Drive Employee Productivity
  *     * [Challenge](https://qdrant.tech/blog/dust-and-qdrant/#challenge)
    * [Solution](https://qdrant.tech/blog/dust-and-qdrant/#solution)
    * [Results](https://qdrant.tech/blog/dust-and-qdrant/#results)
    * [Outlook](https://qdrant.tech/blog/dust-and-qdrant/#outlook)
One of the major promises of artificial intelligence is its potential to accelerate efficiency and productivity within businesses, empowering employees and teams in their daily tasks. The French company 
##  [](https://qdrant.tech/blog/dust-and-qdrant/#outlook)Outlook
Dust will continue to build out their platform, aiming to be the platform of choice for companies to execute on their internal GenAI strategy, unlocking company knowledge and driving team productivity. Over the coming months, Dust will add more connections, such as Intercom, Jira, or Salesforce. Additionally, Dust will expand on its structured data capabilities.
To learn more about how Dust uses Qdrant to help employees in their day to day tasks, check out our 
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/dust-and-qdrant/)
                    ## 📄 `https-qdrant-tech-blog-enterprise-vector-search.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Introducing Qdrant Cloud’s New Enterprise-Ready Vector Search
  *     * [Securely Scale Your AI Workloads](https://qdrant.tech/blog/enterprise-vector-search/#securely-scale-your-ai-workloads)
    * [Our New Qdrant Cloud Capabilities:](https://qdrant.tech/blog/enterprise-vector-search/#our-new-qdrant-cloud-capabilities)
    * [Ok, now for the good part…](https://qdrant.tech/blog/enterprise-vector-search/#ok-now-for-the-good-part)
      * [Cloud API for Simplified Management](https://qdrant.tech/blog/enterprise-vector-search/#cloud-api-for-simplified-management)
      * [Secure Access & Authentication - Control the Who and What](https://qdrant.tech/blog/enterprise-vector-search/#secure-access--authentication---control-the-who-and-what)
      * [Advanced Monitoring and Observability for Full Performance Insights](https://qdrant.tech/blog/enterprise-vector-search/#advanced-monitoring-and-observability-for-full-performance-insights)
    * [Simply put, Qdrant is Enterprise-Ready](https://qdrant.tech/blog/enterprise-vector-search/#simply-put-qdrant-is-enterprise-ready)
    * [Come Build with Us!](https://qdrant.tech/blog/enterprise-vector-search/#come-build-with-us)
At Qdrant, we enable developers to power AI workloads - not only securely, but at any scale. That’s why we are excited to introduce Qdrant Cloud’s new suite of enterprise-grade features. With **our Cloud API, Cloud RBAC** , **Single Sign-On (SSO)** , granular **Database API Keys** , and **Advanced Monitoring & Observability**, you now have the control and visibility needed to operate at scale.
##  [](https://qdrant.tech/blog/enterprise-vector-search/#come-build-with-us)Come Build with Us!
[Contact Sales](https://qdrant.tech/contact-us/) to enable enterprise features for your team, or 
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/enterprise-vector-search/)
                    ## 📄 `https-qdrant-tech-blog-human-language-ai-models.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * When music just doesn't match our vibe, can AI help? - Filip Makraduli | Vector Space Talks
  *     * [**Top Takeaways:**](https://qdrant.tech/blog/human-language-ai-models/#top-takeaways)
    * [Show Notes:](https://qdrant.tech/blog/human-language-ai-models/#show-notes)
    * [More Quotes from Filip:](https://qdrant.tech/blog/human-language-ai-models/#more-quotes-from-filip)
    * [Transcript:](https://qdrant.tech/blog/human-language-ai-models/#transcript)
##  [](https://qdrant.tech/blog/human-language-ai-models/#transcript)Transcript:
Demetrios: So for those who do not know, you are going to be talking to us about when the music we listen to does not match our vibe. And can we get AI to help us on that? And you’re currently working as a data scientist at Marks and Spencer. I know you got some slides to share, right? So I’ll let you share your screen. We can kick off the slides and then we’ll have a little presentation and I’ll be back on to answer some questions. And if Neil’s is still around at the end, which I don’t think he will be able to hang around, but we’ll see, we can pull him back on and have a little discussion at the end of the.
Filip Makraduli: That’s. That’s great. All right, cool. I’ll share my screen.
Demetrios: Right on.
Filip Makraduli: Yeah.
Demetrios: There we go.
Filip Makraduli: Yeah. So I had to use this slide because it was really well done as an introductory slide. Thank you. Yeah. Thank you also for making it so. Yeah, the idea was, and kind of the inspiration with music, we all listen to it. It’s part of our lives in many ways. Sometimes it’s like the gym.
Filip Makraduli: We’re ready to go, we’re all hyped up, ready to do a workout, and then we click play. But the music and the playlist we get, it’s just not what exactly we’re looking for at that point. Or if we try to work for a few hours and try to get concentrated and try to code for hours, we can do the same and then we click play, but it’s not what we’re looking for again. So my inspiration was here. Was it possible to somehow maybe find a way to transfer this feeling that we have this vibe and get the help of AI to understand what exactly we need at that moment in terms of songs. So the obvious first question is how do we even capture a vibe and feel of a song? So initially, one approach that’s popular and that works quite well is basically using a data set that has a lot of features. So Spotify has one data set like this and there are many others open source ones which include different features like loudness, key tempo, different kind of details related to the acoustics, the melody and so on. And this would work.
Filip Makraduli: And this is kind of a way that a lot of song recommendation systems are built. However, what I wanted to do was maybe try a different approach in a way. Try to have a more unconventional recommender system, let’s say. So what I did here was I tried to concentrate just on language. So my idea was, okay, is it possible to use human language to transfer this experience, this feeling that we have, and just use that and try to maybe encapsulate these features of songs. And instead of having a data set, just have descriptions of songs or sentences that explain different aspects of a song. So, as I said, this is a bit of a less traditional approach, and it’s more of kind of testing the waters, but it worked to a decent extent. So what I did was, first I created a data set where I queried a large language model.
Filip Makraduli: So I tried with llama and chat GPT, both. And the idea was to ask targeted questions, for example, like, what movie character does this song make you feel like? Or what’s the tempo like? So, different questions that would help us understand maybe in what situation we would listen to this song, how will it make us feel like? And so on. And the idea was, as I said, again, to only use song names as queries for this large language model. So not have the full data sets with multiple features, but just song name, and kind of use this pretrained ability of all these LLMs to get this info that I was looking for. So an example of the generated data was this. So this song called Deep Sea Creature. And we have, like, a small description of the song. So it says a heavy, dark, mysterious vibe.
Filip Makraduli: It will make you feel like you’re descending into the unknown and so on. So a bit of a darker choice here, but that’s the general idea. So trying to maybe do a bit of prompt engineering in a way to get the right features of a song, but through human language. So that was the first step. So the next step was how to encode this text. So all of this kind of querying reminds me of sentences. And this led me to sentence transformers and sentence Bird. And the usual issue with kind of doing this sentence similarity in the past was this, what I have highlighted here.
Filip Makraduli: So this is actually a quote from a paper that Nils published a few years ago. So, basically, the way that this similarity was done was using cross encoders in the past, and that worked well, but it was really slow and unscalable. So Nils and his colleague created this kind of model, which helped scale this and make this a lot quicker, but also keep a lot of the accuracy. So Bert and Roberta were used, but they were not, as I said, quite scalable or useful for larger applications. So that’s how sentence Bert was created. So the idea here was that there would be, like, a Siamese network that would train the model so that there could be, like, two bird models, and then the training would be done using this like zero, one and two tags, where kind of the sentences would be compared, whether there is entailment, neutrality or contradiction. So how similar these sentences are to each other. And by training a model like this and doing mean pooling, in the end, the model performed quite well and was able to kind of encapsulate this language intricacies of sentences.
Filip Makraduli: So I decided to use and try out sentence transformers for my use case, and that was the encoding bit. So we have the model, we encode the text, and we have the embedding. So now the question is, how do we actually generate the recommendations? How is the similarity performed? So the similarity was done using vector spaces and cosine similarity search here. There were multiple ways of doing this. First, I tried things with a flat index and I tried Qdrant and I tried FIS. So I’ve worked with both. And with the flat index, it was good. It works well.
Filip Makraduli: It’s quick for small number of examples, small number of songs, but there is an issue when scaling. So once the vector indices get bigger, there might be a problem. So one popular kind of index architecture is this one here on the left. So hierarchical, navigable, small world graphs. So the idea here is that you wouldn’t have to kind of go through all of the examples, but search through the examples in different layers, so that the search for similarities quicker. And this is a really popular approach. And Qdrant have done a really good customizable version of this, which is quite useful, I think, for very larger scales of application. And this graph here illustrates kind of well what the idea is.
Filip Makraduli: So there is the sentence in this example. It’s like a stripped striped blue shirt made from cotton, and then there is the network or the encoder. So in my case, this sentence is the song description, the neural network is the sentence transformer in my case. And then this embeddings are generated, which are then mapped into this vector space, and then this vector space is queryed and the cosine similarity is found, and the recommendations are generated in this way, so that once the user writes a query and the query mentions, like some kind of a mood, for example, I feel happy and it’s a sunny day and so on, you would get the similarity to the song that has this kind of language explanations and language intricacies in its description. And there are a lot of ways of doing this, as Nils mentioned, especially with different embedding models and doing context related search. So this is an interesting area for improvement, even in my use case. And the quick screenshot looks like this. So for example, the mood that the user wrote, it’s a bit rainy, but I feel like I need a long walk in London.
Filip Makraduli: And these are the top five suggested songs. This is also available on Streamlit. In the end I’ll share links of everything and also after that you can click create a Spotify playlist and this playlist will be saved in your Spotify account. As you can see here, it says playlist generated earlier today. So yeah, I tried this, it worked. I will try live demo bit later. Hopefully it works again. But this is in beta currently so you won’t be able to try it at home because Spotify needs to approve my app first and go through that process so that then I can do this part fully.
Filip Makraduli: And the front end bit, as I mentioned, was done in Streamlit. So why Streamlit? I like the caching bit. So of course this general part where it’s really easy and quick to do a lot of data dashboarding and data applications to test out models, that’s quite nice. But this caching options that they have help a lot with like loading models from hugging face or if you’re loading models from somewhere, or if you’re loading different databases. So if you’re combining models and data. In my case I had a binary file of the index and also the model. So it was quite useful and quick to do these things and to be able to try things out quickly. So this is kind of the step by step outline of everything I’ve mentioned and the whole project.
Filip Makraduli: So the first step is encoding this descriptions into embeddings. Then this vector embeddings are mapped into a vector space. Examples here with how I’ve used Qdrant for this, which was quite nice. I feel like the developer experience is really good for scalable purposes. It’s really useful. So if the number of songs keep increasing it’s quite good. And the query and more similar embeddings. The front is done with Streamlit and the Spotify API to save the playlists on the Spotify account.
Filip Makraduli: All of these steps can be improved and tweaked in certain ways and I will talk a bit about that too. So a lot more to be done. So now there are 2000 songs, but as I’ve mentioned, in this vector space, the more songs that are there, the more representative this recommendations would be. So this is something I’m currently exploring and doing, generating, filtering and user specific personalization. So once maybe you log in with Spotify, you could get recommendations related to your taste on Spotify or on whatever app you listen your music on. And referring to the talk that Niels had a lot of potential for better models and embeddings and embedding models. So also the contrastive learning bits or the contents aware querying, that could be useful too. And a vector database because currently I’m using a binary file.
Filip Makraduli: But I’ve explored Qdrant and as I said with Spotify web API there are a lot of things to be done with this specific user created recommendations. So with Qdrant, the Python client is quite good. The getting started helps a lot. So I wrote a bit of code. I think for production use cases it’s really great. So for my use case here, as you can see on the right, I just read the text from a column and then I encode with the model. So the sentence transformer is the model that I encode with. And there is this collections that they’re so called in Qdrant that are kind of like this vector spaces that you can create and you can also do different things with them, which I think one of the more helpful ones is the payload one and the batch one.
Filip Makraduli: So you can batch things in terms of how many vectors will go to the server per single request. And also the payload helps if you want to add extra context. So maybe I want to filter by genres. I can add useful information to the vector embedding. So this is quite a cool feature that I’m planning on using. And another potential way of doing this and kind of combining things is using audio waves too, lyrics and descriptions and combining all of this as embeddings and then going through the similar process. So that’s something that I’m looking to do also. And yeah, you also might have noticed that I’m a data scientist at Marks and Spencer and I just wanted to say that there are a lot of interesting ML and data related stuff going on there.
Filip Makraduli: So a lot of teams that work on very interesting use cases, like in recommender systems, personalization of offers different stuff about forecasting. There is a lot going on with causal ML and yeah, the digital and tech department is quite well developed and I think it’s a fun place to explore if you’re interested in retail data science use cases. So yeah, thank you for your attention. I’ll try the demo. So this is the QR code with the repo and all the useful links. You can contact me on LinkedIn. This is the screenshot of the repo and you have the link in the QR code. The name of the repo is song Vibe.
Filip Makraduli: A friend of mine said that that wasn’t a great name of a repo. Maybe he was right. But yeah, here we are. I’ll just try to do the demo quickly and then we can step back to the.
Demetrios: I love dude, I got to say, when you said you can just automatically create the Spotify playlist, that made me.
Filip Makraduli: Go like, oh, yes, let’s see if it works locally. Do you have any suggestion what mood are you in?
Demetrios: I was hoping you would ask me, man. I am in a bit of an esoteric mood and I want female kind of like Gaelic voices, but not Gaelic music, just Gaelic voices and lots of harmonies, heavy harmonies.
Filip Makraduli: Also.
Demetrios: You didn’t realize you’re asking a musician. Let’s see what we got.
Filip Makraduli: Let’s see if this works in 2000 songs. Okay, so these are the results. Okay, yeah, you’d have to playlist. Let’s see.
Demetrios: Yeah, can you make the playlist public and then I’ll just go find it right now. Here we go.
Filip Makraduli: Let’s see. Okay, yeah, open in. Spotify playlist created now. Okay, cool. I can also rename it. What do you want to name the playlist?
Demetrios: Esoteric Gaelic Harmonies. That’s what I think we got to go with AI. Well, I mean, maybe we could just put maybe in parenthes.
Filip Makraduli: Yeah. So I’ll share this later with you. Excellent. But yeah, basically that was it.
Demetrios: It worked. Ten out of ten for it. Working. That is also very cool.
Filip Makraduli: Live demo working. That’s good. So now doing the infinite screen, which I have stopped now.
Demetrios: Yeah, classic, dude. Well, I’ve got some questions coming through and the chat has been active too. So I’ll ask a few of the questions in the chat for a minute. But before I ask those questions in the chat, one thing that I was thinking about when you were talking about how to, like, the next step is getting better embeddings. And so was there a reason that you just went with the song title and then did you check, you said there was 2000 songs or how many songs? So did you do anything to check the output of the descriptions of these songs?
Filip Makraduli: Yeah, so I didn’t do like a systematic testing in terms of like, oh, yeah, the output is structured in this way. But yeah, I checked it roughly went through a few songs and they seemed like, I mean, of course you could add more info, but they seemed okay. So I was like, okay, let me try kind of whether this works. And, yeah, the descriptions were nice.
Demetrios: Awesome. Yeah. So that kind of goes into one of the questions that mornie’s asking. Let me see. Are you going to team this up with other methods, like collaborative filtering, content embeddings and stuff like that.
Filip Makraduli: Yeah, I was thinking about this different kind of styles, but I feel like I want to first try different things related to embeddings and language just because I feel like with the other things, with the other ways of doing these recommendations, other companies and other solutions have done a really great job there. So I wanted to try something different to see whether that could work as well or maybe to a similar degree. So that’s why I went towards this approach rather than collaborative filtering.
Demetrios: Yeah, it kind of felt like you wanted to test the boundaries and see if something like this, which seems a little far fetched, is actually possible. And it seems like I would give it a yes.
Filip Makraduli: It wasn’t that far fetched, actually, once you see it working.
Demetrios: Yeah, totally. Another question is coming through is asking, is it possible to merge the current mood so the vibe that you’re looking for with your musical preferences?
Filip Makraduli: Yeah. So I was thinking of that when we’re doing this, the playlist creation that I did for you, there is a way to get your top ten songs or your other playlists and so on from Spotify. So my idea of kind of capturing this added element was through Spotify like that. But of course it could be that you could enter that in your own profile in the app or so on. So one idea would be how would you capture that preferences of the user once you have the user there. So you’d need some data of the preferences of the user. So that’s the problem. But of course it is possible.
Demetrios: You know what I’d lOve? Like in your example, you put that, I feel like going for a walk or it’s raining, but I still feel like going through for a long walk in London. Right. You could probably just get that information from me, like what is the weather around me, where am I located? All that kind of stuff. So I don’t have to give you that context. You just add those kind of contextual things, especially weather. And I get the feeling that that would be another unlock too. Unless you’re like, you are the exact opposite of a sunny day on a sunny day. And it’s like, why does it keep playing this happy music? I told you I was sad.
Filip Makraduli: Yeah. You’re predicting not just the songs, but the mood also.
Demetrios: Yeah, totally.
Filip Makraduli: You don’t have to type anything, just open the website and you get everything.
Demetrios: Exactly. Yeah. Give me a few predictions just right off the bat and then maybe later we can figure it out. The other thing that I was thinking, could be a nice add on. I mean, the infinite feature request, I don’t think you realized you were going to get so many feature requests from me, but let it be known that if you come on here and I like your app, you’ll probably get some feature requests from me. So I was thinking about how it would be great if I could just talk to it instead of typing it in, right? And I could just explain my mood or explain my feeling and even top that off with a few melodies that are going on in my head, or a few singers or songwriters or songs that I really want, something like this, but not this song, and then also add that kind of thing, do the.
Filip Makraduli: Humming sound a bit and you play your melody and then you get.
Demetrios: Except I hum out of tune, so I don’t think that would work very well. I get a lot of random songs, that’s for sure. It would probably be just about as accurate as your recommendation engine is right now. Yeah. Well, this is awesome, man. I really appreciate you coming on here. I’m just going to make sure that there’s no other questions that came through the chat. No, looks like we’re good.
Demetrios: And for everyone out there that is listening, if you want to come on and talk about anything cool that you have built with Qdrant, or how you’re using Qdrant, or different ways that you would like Qdrant to be better, or things that you enjoy, whatever it may be, we’d love to have you on here. And I think that is it. We’re going to call it a day for the vector space talks, number two. We’ll see you all later. Philip, thanks so much for coming on. It’s.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/human-language-ai-models/)
                    ## 📄 `https-qdrant-tech-blog-iris-agent-qdrant.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * IrisAgent and Qdrant: Redefining Customer Support with AI
  *     * [The Challenge](https://qdrant.tech/blog/iris-agent-qdrant/#the-challenge)
    * [The Solution](https://qdrant.tech/blog/iris-agent-qdrant/#the-solution)
    * [Optimizing IrisAgent’s AI Pipeline: The Evaluation and Integration of Qdrant](https://qdrant.tech/blog/iris-agent-qdrant/#optimizing-irisagents-ai-pipeline-the-evaluation-and-integration-of-qdrant)
    * [Future of IrisAgent](https://qdrant.tech/blog/iris-agent-qdrant/#future-of-irisagent)
Artificial intelligence is evolving customer support, offering unprecedented capabilities for automating interactions, understanding user needs, and enhancing the overall customer experience. 
Bhatia describes IrisAgent as “the system of intelligence which sits on top of existing systems of records like support tickets, engineering bugs, sales data, or product data,” with the main objective of leveraging AI and generative AI, to automatically detect the intent and tags behind customer support tickets, reply to a large number of support tickets chats improve the time to resolution and increase the deflection rate of support teams. Ultimately, IrisAgent enables support teams to more with less and be more effective in helping customers.
##  [](https://qdrant.tech/blog/iris-agent-qdrant/#future-of-irisagent)Future of IrisAgent
Looking ahead, IrisAgent is committed to pushing the boundaries of AI in customer support, with ambitious plans to evolve their product further. The cornerstone of this vision is a feature that will allow support teams to leverage historical support data more effectively, by automating the generation of knowledge base content to redefine how FAQs and product documentation are created. This strategic initiative aims not just to reduce manual effort but also to enrich the self-service capabilities of users. As IrisAgent continues to refine its AI algorithms and expand its training datasets, the goal is to significantly elevate the support experience, making it more seamless and intuitive for end-users.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/iris-agent-qdrant/)
                    ## 📄 `https-qdrant-tech-blog-metadata-deasy-labs.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Metadata automation and optimization - Reece Griffiths | Vector Space Talks
  *     * [**Top takeaways:**](https://qdrant.tech/blog/metadata-deasy-labs/#top-takeaways)
    * [**Show notes:**](https://qdrant.tech/blog/metadata-deasy-labs/#show-notes)
    * [**More Quotes from Reece:**](https://qdrant.tech/blog/metadata-deasy-labs/#more-quotes-from-reece)
      * [**Try Deasy Labs 🚀**](https://qdrant.tech/blog/metadata-deasy-labs/#try-deasy-labs-)
###  [](https://qdrant.tech/blog/metadata-deasy-labs/#try-deasy-labs-)**Try Deasy Labs 🚀**
Want to enhance your vector search performance with **automated metadata workflows**?
**Start now at**
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/metadata-deasy-labs/)
                    ## 📄 `https-qdrant-tech-blog-page-10.md`
###### Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/10/)
                    ## 📄 `https-qdrant-tech-blog-page-2.md`
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Building a Facial Recognition System with Qdrant](https://qdrant.tech/blog/facial-recognition/preview/preview.jpg) Building a Facial Recognition System with Qdrant Build an AI app that uses facial recognition embeddings & vector search to match users with their celebrity look-alikes. David Myriel December 03, 2024 ](https://qdrant.tech/blog/facial-recognition/)[![Best Practices in RAG Evaluation: A Comprehensive Guide](https://qdrant.tech/blog/rag-evaluation-guide/preview/preview.jpg) Best Practices in RAG Evaluation: A Comprehensive Guide Explore best practices for evaluating Retrieval-Augmented Generation (RAG) systems. David Myriel November 24, 2024 ](https://qdrant.tech/blog/rag-evaluation-guide/)[![Empowering QA.tech’s Testing Agents with Real-Time Precision and Scale](https://qdrant.tech/blog/case-study-qatech/preview/preview.jpg) Empowering QA.tech’s Testing Agents with Real-Time Precision and Scale QA.tech uses Qdrant to power AI agents, enabling scalable, real-time web testing with custom embeddings and batch efficiency. Qdrant November 21, 2024 ](https://qdrant.tech/blog/case-study-qatech/)[![How Sprinklr Leverages Qdrant to Enhance AI-Driven Customer Experience Solutions](https://qdrant.tech/blog/case-study-sprinklr/preview/preview.jpg) How Sprinklr Leverages Qdrant to Enhance AI-Driven Customer Experience Solutions Learn how Sprinklr uses vector search to power AI tools for customer engagement. Qdrant October 17, 2024 ](https://qdrant.tech/blog/case-study-sprinklr/)[![New DeepLearning.AI Course on Retrieval Optimization: From Tokenization to Vector Quantization](https://qdrant.tech/blog/qdrant-deeplearning-ai-course/preview/preview.jpg) New DeepLearning.AI Course on Retrieval Optimization: From Tokenization to Vector Quantization Join Qdrant and DeepLearning.AI’s free, beginner-friendly course to learn retrieval optimization and boost search performance in machine learning. Qdrant October 06, 2024 ](https://qdrant.tech/blog/qdrant-deeplearning-ai-course/)[![Introducing Qdrant for Startups](https://qdrant.tech/blog/qdrant-for-startups-launch/preview/preview.jpg) Introducing Qdrant for Startups Enjoy special discounts from Qdrant, HuggingFace, LlamaIndex, and Airbyte, as well as expert support & tooling perks, and be the first to try new features. Qdrant October 02, 2024 ](https://qdrant.tech/blog/qdrant-for-startups-launch/)[![Qdrant and Shakudo: Secure & Performant Vector Search in VPC Environments](https://qdrant.tech/blog/case-study-shakudo/preview/preview.jpg) Qdrant and Shakudo: Secure & Performant Vector Search in VPC Environments Implementing vector search for enterprise AI via Qdrant's Hybrid Cloud integration into Shakudo’s virtual private cloud. Qdrant September 23, 2024 ](https://qdrant.tech/blog/case-study-shakudo/)[![Data-Driven RAG Evaluation: Testing Qdrant Apps with Relari AI](https://qdrant.tech/blog/qdrant-relari/preview/preview.jpg) Data-Driven RAG Evaluation: Testing Qdrant Apps with Relari AI Learn how Qdrant and Relari enhance RAG systems with vector search and data-driven RAG evaluation. Thierry Damiba, David Myriel & Yi Zhang September 16, 2024 ](https://qdrant.tech/blog/qdrant-relari/)[![Nyris & Qdrant: How Vectors are the Future of Visual Search](https://qdrant.tech/blog/case-study-nyris/preview/preview.jpg) Nyris & Qdrant: How Vectors are the Future of Visual Search Revolutionizing customer service in finance and insurance by leveraging vector search for faster responses and improved operational efficiency. Qdrant September 10, 2024 ](https://qdrant.tech/blog/case-study-nyris/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/2/)
                    ## 📄 `https-qdrant-tech-blog-page-3.md`
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Kern AI & Qdrant: Precision AI Solutions for Finance and Insurance](https://qdrant.tech/blog/case-study-kern/preview/preview.jpg) Kern AI & Qdrant: Precision AI Solutions for Finance and Insurance Revolutionizing customer service in finance and insurance by leveraging vector search for faster responses and improved operational efficiency. Qdrant August 28, 2024 ](https://qdrant.tech/blog/case-study-kern/)[![Kairoswealth & Qdrant: Transforming Wealth Management with AI-Driven Insights and Scalable Vector Search](https://qdrant.tech/blog/case-study-kairoswealth/preview/preview.jpg) Kairoswealth & Qdrant: Transforming Wealth Management with AI-Driven Insights and Scalable Vector Search Enhancing wealth management using AI-driven insights and efficient vector search for improved recommendations and scalability. Qdrant July 10, 2024 ](https://qdrant.tech/blog/case-study-kairoswealth/)[![Qdrant 1.10 - Universal Query, Built-in IDF & ColBERT Support](https://qdrant.tech/blog/qdrant-1.10.x/preview/preview.jpg) Qdrant 1.10 - Universal Query, Built-in IDF & ColBERT Support Consolidated search API, built-in IDF, and native multivector support. David Myriel July 01, 2024 ](https://qdrant.tech/blog/qdrant-1.10.x/)[![Community Highlights #1](https://qdrant.tech/blog/community-highlights-1/preview/preview.jpg) Community Highlights #1 Celebrating top contributions and achievements in vector search, featuring standout projects, articles, and the Creator of the Month, Pavan Kumar! Sabrina Aquino June 20, 2024 ](https://qdrant.tech/blog/community-highlights-1/)[![Response to CVE-2024-3829: Arbitrary file upload vulnerability](https://qdrant.tech/blog/cve-2024-3829-response/preview/preview.jpg) Response to CVE-2024-3829: Arbitrary file upload vulnerability Upgrade your deployments to at least v1.9.0. Cloud deployments not materially affected. Mac Chaffee June 10, 2024 ](https://qdrant.tech/blog/cve-2024-3829-response/)[![Qdrant Attains SOC 2 Type II Audit Report](https://qdrant.tech/blog/qdrant-soc2-type2-audit/preview/preview.jpg) Qdrant Attains SOC 2 Type II Audit Report We're proud to announce achieving SOC 2 Type II compliance for Security, Availability, and Confidentiality. Sabrina Aquino May 23, 2024 ](https://qdrant.tech/blog/qdrant-soc2-type2-audit/)[![Introducing Qdrant Stars: Join Our Ambassador Program!](https://qdrant.tech/blog/qdrant-stars-announcement/preview/preview.jpg) Introducing Qdrant Stars: Join Our Ambassador Program! Say hello to the first Qdrant Stars and learn more about our new ambassador program! Sabrina Aquino May 19, 2024 ](https://qdrant.tech/blog/qdrant-stars-announcement/)[![Intel’s New CPU Powers Faster Vector Search](https://qdrant.tech/blog/qdrant-cpu-intel-benchmark/preview/preview.jpg) Intel’s New CPU Powers Faster Vector Search Intel’s 5th gen Xeon processor is made for enterprise-scale operations in vector space. David Myriel, Kumar Shivendu May 10, 2024 ](https://qdrant.tech/blog/qdrant-cpu-intel-benchmark/)[![QSoC 2024: Announcing Our Interns!](https://qdrant.tech/blog/qsoc24-interns-announcement/preview/preview.jpg) QSoC 2024: Announcing Our Interns! We are pleased to announce the selection of interns for the inaugural Qdrant Summer of Code (QSoC) program. Sabrina Aquino May 08, 2024 ](https://qdrant.tech/blog/qsoc24-interns-announcement/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/3/)
                    ## 📄 `https-qdrant-tech-blog-page-4.md`
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Are You Vendor Locked?](https://qdrant.tech/blog/are-you-vendor-locked/preview/preview.jpg) Are You Vendor Locked? Redefining freedom in the age of Generative AI. We believe that vendor-dependency comes from hardware, not software. David Myriel May 05, 2024 ](https://qdrant.tech/blog/are-you-vendor-locked/)[![Visua and Qdrant: Vector Search in Computer Vision](https://qdrant.tech/blog/case-study-visua/preview/preview.jpg) Visua and Qdrant: Vector Search in Computer Vision How Visua uses Qdrant as a vector search engine for quality control and anomaly detection in their computer vision platform. Manuel Meyer May 01, 2024 ](https://qdrant.tech/blog/case-study-visua/)[![Qdrant 1.9.0 - Heighten Your Security With Role-Based Access Control Support](https://qdrant.tech/blog/qdrant-1.9.x/preview/preview.jpg) Qdrant 1.9.0 - Heighten Your Security With Role-Based Access Control Support New access control options for RBAC, a much faster shard transfer procedure, and direct support for byte embeddings. David Myriel April 24, 2024 ](https://qdrant.tech/blog/qdrant-1.9.x/)[![Qdrant's Trusted Partners for Hybrid Cloud Deployment](https://qdrant.tech/blog/hybrid-cloud-launch-partners/preview/preview.jpg) Qdrant's Trusted Partners for Hybrid Cloud Deployment With the launch of Qdrant Hybrid Cloud we provide developers the ability to deploy Qdrant as a managed vector database in any desired environment. Manuel Meyer April 15, 2024 ](https://qdrant.tech/blog/hybrid-cloud-launch-partners/)[![Developing Advanced RAG Systems with Qdrant Hybrid Cloud and LangChain ](https://qdrant.tech/blog/hybrid-cloud-langchain/preview/preview.jpg) Developing Advanced RAG Systems with Qdrant Hybrid Cloud and LangChain Empowering engineers and scientists globally to easily and securely develop and scale their GenAI applications. Qdrant April 14, 2024 ](https://qdrant.tech/blog/hybrid-cloud-langchain/)[![Advancements and Challenges in RAG Systems - Syed Asad | Vector Space Talks](https://qdrant.tech/blog/rag-advancements-challenges/preview/preview.jpg) Advancements and Challenges in RAG Systems - Syed Asad | Vector Space Talks Syed Asad unfolds the challenges of developing multimodal RAG systems at Kiwi Tech, detailing the balance between accuracy and cost-efficiency, and exploring various tools and approaches like GPT 4 and Mixtral to enhance family tree apps and financial chatbots while navigating the hurdles of data privacy and infrastructure demands. Demetrios Brinkmann April 11, 2024 ](https://qdrant.tech/blog/rag-advancements-challenges/)[![Building Search/RAG for an OpenAPI spec - Nick Khami | Vector Space Talks](https://qdrant.tech/blog/building-search-rag-open-api/preview/preview.jpg) Building Search/RAG for an OpenAPI spec - Nick Khami | Vector Space Talks Nick Khami discuss Trieve's work with Qdrant's Open API spec for creating powerful and simplified search and recommendation systems, touching on real-world applications, technical specifics, and the potential for improved user experiences. Demetrios Brinkmann April 11, 2024 ](https://qdrant.tech/blog/building-search-rag-open-api/)[![Iveta Lohovska on Gen AI and Vector Search | Qdrant](https://qdrant.tech/blog/gen-ai-and-vector-search/preview/preview.jpg) Iveta Lohovska on Gen AI and Vector Search | Qdrant Discover valuable insights on generative AI, vector search, and ethical AI implementation from Iveta Lohovska, Chief Technologist at HPE. Demetrios Brinkmann April 11, 2024 ](https://qdrant.tech/blog/gen-ai-and-vector-search/)[![Red Hat OpenShift and Qdrant Hybrid Cloud Offer Seamless and Scalable AI](https://qdrant.tech/blog/hybrid-cloud-red-hat-openshift/preview/preview.jpg) Red Hat OpenShift and Qdrant Hybrid Cloud Offer Seamless and Scalable AI Qdrant brings managed vector databases to Red Hat OpenShift for large-scale GenAI. Qdrant April 11, 2024 ](https://qdrant.tech/blog/hybrid-cloud-red-hat-openshift/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/4/)
                    ## 📄 `https-qdrant-tech-blog-page-5.md`
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Qdrant Hybrid Cloud and DigitalOcean for Scalable and Secure AI Solutions](https://qdrant.tech/blog/hybrid-cloud-digitalocean/preview/preview.jpg) Qdrant Hybrid Cloud and DigitalOcean for Scalable and Secure AI Solutions Enabling developers to deploy a managed vector database in their DigitalOcean Environment. Qdrant April 11, 2024 ](https://qdrant.tech/blog/hybrid-cloud-digitalocean/)[![Enhance AI Data Sovereignty with Aleph Alpha and Qdrant Hybrid Cloud](https://qdrant.tech/blog/hybrid-cloud-aleph-alpha/preview/preview.jpg) Enhance AI Data Sovereignty with Aleph Alpha and Qdrant Hybrid Cloud Empowering the world’s best companies in their AI journey. Qdrant April 11, 2024 ](https://qdrant.tech/blog/hybrid-cloud-aleph-alpha/)[![Vultr and Qdrant Hybrid Cloud Support Next-Gen AI Projects](https://qdrant.tech/blog/hybrid-cloud-vultr/preview/preview.jpg) Vultr and Qdrant Hybrid Cloud Support Next-Gen AI Projects Providing a flexible platform for high-performance vector search in next-gen AI workloads. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-vultr/)[![STACKIT and Qdrant Hybrid Cloud for Best Data Privacy](https://qdrant.tech/blog/hybrid-cloud-stackit/preview/preview.jpg) STACKIT and Qdrant Hybrid Cloud for Best Data Privacy Empowering German AI development with a data privacy-first platform. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-stackit/)[![Qdrant Hybrid Cloud and Scaleway Empower GenAI](https://qdrant.tech/blog/hybrid-cloud-scaleway/preview/preview.jpg) Qdrant Hybrid Cloud and Scaleway Empower GenAI Supporting innovation in AI with the launch of a revolutionary managed database for startups and enterprises. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-scaleway/)[![Qdrant and OVHcloud Bring Vector Search to All Enterprises](https://qdrant.tech/blog/hybrid-cloud-ovhcloud/preview/preview.jpg) Qdrant and OVHcloud Bring Vector Search to All Enterprises Collaborating to support startups and enterprises in Europe with a strong focus on data control and privacy. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-ovhcloud/)[![New RAG Horizons with Qdrant Hybrid Cloud and LlamaIndex](https://qdrant.tech/blog/hybrid-cloud-llamaindex/preview/preview.jpg) New RAG Horizons with Qdrant Hybrid Cloud and LlamaIndex Unlock the most advanced RAG opportunities with Qdrant Hybrid Cloud and LlamaIndex. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-llamaindex/)[![Cutting-Edge GenAI with Jina AI and Qdrant Hybrid Cloud](https://qdrant.tech/blog/hybrid-cloud-jinaai/preview/preview.jpg) Cutting-Edge GenAI with Jina AI and Qdrant Hybrid Cloud Build your most successful app with Jina AI embeddings and on Qdrant Hybrid Cloud. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-jinaai/)[![Qdrant Hybrid Cloud and Haystack for Enterprise RAG](https://qdrant.tech/blog/hybrid-cloud-haystack/preview/preview.jpg) Qdrant Hybrid Cloud and Haystack for Enterprise RAG A winning combination for enterprise-scale RAG consists of a strong framework and a scalable database. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-haystack/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/5/)
                    ## 📄 `https-qdrant-tech-blog-page-6.md`
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Elevate Your Data With Airbyte and Qdrant Hybrid Cloud](https://qdrant.tech/blog/hybrid-cloud-airbyte/preview/preview.jpg) Elevate Your Data With Airbyte and Qdrant Hybrid Cloud Leverage Airbyte and Qdrant Hybrid Cloud for best-in-class data performance. Qdrant April 10, 2024 ](https://qdrant.tech/blog/hybrid-cloud-airbyte/)[![Teaching Vector Databases at Scale - Alfredo Deza | Vector Space Talks](https://qdrant.tech/blog/teaching-vector-db-at-scale/preview/preview.jpg) Teaching Vector Databases at Scale - Alfredo Deza | Vector Space Talks Alfredo Deza discusses the practicality of machine learning operations, highlighting how personal interest in topics like wine datasets enhances engagement, while reflecting on the synergies between his professional sportsman discipline and the persistent, straightforward approach required for effectively educating on vector databases and large language models. Demetrios Brinkmann April 09, 2024 ](https://qdrant.tech/blog/teaching-vector-db-at-scale/)[![How to meow on the long tail with Cheshire Cat AI? - Piero and Nicola | Vector Space Talks](https://qdrant.tech/blog/meow-with-cheshire-cat/preview/preview.jpg) How to meow on the long tail with Cheshire Cat AI? - Piero and Nicola | Vector Space Talks Cheshire Cat AI's Piero Savastano and Nicola Procopio discusses the framework's vector space complexities, community growth, and future cloud-based expansions. Demetrios Brinkmann April 09, 2024 ](https://qdrant.tech/blog/meow-with-cheshire-cat/)[![Response to CVE-2024-2221: Arbitrary file upload vulnerability](https://qdrant.tech/blog/cve-2024-2221-response/preview/preview.jpg) Response to CVE-2024-2221: Arbitrary file upload vulnerability Upgrade your deployments to at least v1.9.0. Cloud deployments not materially affected. Mike Jang April 05, 2024 ](https://qdrant.tech/blog/cve-2024-2221-response/)[![Introducing FastLLM: Qdrant’s Revolutionary LLM](https://qdrant.tech/blog/fastllm-announcement/preview/preview.jpg) Introducing FastLLM: Qdrant’s Revolutionary LLM Lightweight and open-source. Custom made for RAG and completely integrated with Qdrant. David Myriel April 01, 2024 ](https://qdrant.tech/blog/fastllm-announcement/)[![VirtualBrain: Best RAG to unleash the real power of AI - Guillaume Marquis | Vector Space Talks](https://qdrant.tech/blog/virtualbrain-best-rag/preview/preview.jpg) VirtualBrain: Best RAG to unleash the real power of AI - Guillaume Marquis | Vector Space Talks Guillaume Marquis, CTO & Co-Founder at VirtualBrain, reveals the mechanics of advanced document retrieval with RAG technology, discussing the challenges of scalability, up-to-date information, and navigating user feedback to enhance the productivity of knowledge workers. Demetrios Brinkmann March 27, 2024 ](https://qdrant.tech/blog/virtualbrain-best-rag/)[![Talk with YouTube without paying a cent - Francesco Saverio Zuppichini | Vector Space Talks](https://qdrant.tech/blog/youtube-without-paying-cent/preview/preview.jpg) Talk with YouTube without paying a cent - Francesco Saverio Zuppichini | Vector Space Talks Francesco Zuppichini outlines the process of converting YouTube video subtitles into searchable vector databases, leveraging tools like YouTube DL and Hugging Face, and addressing the challenges of coding without conventional frameworks in machine learning engineering. Demetrios Brinkmann March 27, 2024 ](https://qdrant.tech/blog/youtube-without-paying-cent/)[![Qdrant is Now Available on Azure Marketplace!](https://qdrant.tech/blog/azure-marketplace/preview/preview.jpg) Qdrant is Now Available on Azure Marketplace! Discover the power of Qdrant on Azure Marketplace! Get started today and streamline your operations with ease. David Myriel March 26, 2024 ](https://qdrant.tech/blog/azure-marketplace/)[![Production-scale RAG for Real-Time News Distillation - Robert Caulk | Vector Space Talks](https://qdrant.tech/blog/real-time-news-distillation-rag/preview/preview.jpg) Production-scale RAG for Real-Time News Distillation - Robert Caulk | Vector Space Talks Robert Caulk, founder of Emergent Methods, discusses the complexities of context engineering, the power of Newscatcher API for broader news access, and the sophisticated use of tools like Qdrant for improved recommendation systems, all while emphasizing the importance of efficiency and modularity in technology stacks for real-time data management. Demetrios Brinkmann March 25, 2024 ](https://qdrant.tech/blog/real-time-news-distillation-rag/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/6/)
                    ## 📄 `https-qdrant-tech-blog-page-7.md`
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Insight Generation Platform for LifeScience Corporation - Hooman Sedghamiz | Vector Space Talks](https://qdrant.tech/blog/insight-generation-platform/preview/preview.jpg) Insight Generation Platform for LifeScience Corporation - Hooman Sedghamiz | Vector Space Talks Hooman Sedghamiz discloses the potential of AI in life sciences, from custom knowledge applications to improving crop yield predictions, while tearing apart the nuances of in-house AI deployment for multi-faceted enterprise efficiency. Demetrios Brinkmann March 25, 2024 ](https://qdrant.tech/blog/insight-generation-platform/)[![The challenges in using LLM-as-a-Judge - Sourabh Agrawal | Vector Space Talks](https://qdrant.tech/blog/llm-as-a-judge/preview/preview.jpg) The challenges in using LLM-as-a-Judge - Sourabh Agrawal | Vector Space Talks Everything you need to know about chatbots, Sourabh Agrawal goes in to detail on evaluating their performance, from real-time to post-feedback assessments, and introduces uptrendAI—an open-source tool for enhancing chatbot interactions through customized and logical evaluations. Demetrios Brinkmann March 19, 2024 ](https://qdrant.tech/blog/llm-as-a-judge/)[![Vector Search for Content-Based Video Recommendation - Gladys and Samuel from Dailymotion](https://qdrant.tech/blog/vector-search-vector-recommendation/preview/preview.jpg) Vector Search for Content-Based Video Recommendation - Gladys and Samuel from Dailymotion Gladys Roch and Samuel Leonardo Gracio from Dailymotion, discussed optimizing video recommendations using Qdrant's vector search alongside challenges and solutions in content-based recommender systems. Demetrios Brinkmann March 19, 2024 ](https://qdrant.tech/blog/vector-search-vector-recommendation/)[![IrisAgent and Qdrant: Redefining Customer Support with AI](https://qdrant.tech/blog/iris-agent-qdrant/preview/preview.jpg) IrisAgent and Qdrant: Redefining Customer Support with AI Learn how IrisAgent leverages Qdrant for RAG to automate support, and improve resolution times, transforming customer service Manuel Meyer March 06, 2024 ](https://qdrant.tech/blog/iris-agent-qdrant/)[![Dailymotion's Journey to Crafting the Ultimate Content-Driven Video Recommendation Engine with Qdrant Vector Database](https://qdrant.tech/blog/case-study-dailymotion/preview/preview.jpg) Dailymotion's Journey to Crafting the Ultimate Content-Driven Video Recommendation Engine with Qdrant Vector Database Dailymotion's Journey to Crafting the Ultimate Content-Driven Video Recommendation Engine with Qdrant Vector Database Atita Arora February 27, 2024 ](https://qdrant.tech/blog/case-study-dailymotion/)[![Qdrant vs Pinecone: Vector Databases for AI Apps](https://qdrant.tech/blog/comparing-qdrant-vs-pinecone-vector-databases/preview/preview.jpg) Qdrant vs Pinecone: Vector Databases for AI Apps In this detailed Qdrant vs Pinecone comparison, we share the top features to determine the best vector database for your AI applications. Qdrant Team February 25, 2024 ](https://qdrant.tech/blog/comparing-qdrant-vs-pinecone-vector-databases/)[![What is Vector Similarity? Understanding its Role in AI Applications.](https://qdrant.tech/blog/what-is-vector-similarity/preview/preview.jpg) What is Vector Similarity? Understanding its Role in AI Applications. Discover the significance of vector similarity in AI applications and how our vector database revolutionizes similarity search technology for enhanced performance and accuracy. Qdrant Team February 24, 2024 ](https://qdrant.tech/blog/what-is-vector-similarity/)[![DSPy vs LangChain: A Comprehensive Framework Comparison](https://qdrant.tech/blog/dspy-vs-langchain/preview/preview.jpg) DSPy vs LangChain: A Comprehensive Framework Comparison We dive deep into the capabilities of DSPy and LangChain and discuss scenarios where each of these frameworks shine. Qdrant Team February 23, 2024 ](https://qdrant.tech/blog/dspy-vs-langchain/)[![Qdrant Summer of Code 24](https://qdrant.tech/blog/qdrant-summer-of-code-24/preview/preview.jpg) Qdrant Summer of Code 24 Introducing Qdrant Summer of Code 2024 program. GSoC alternative. Andre Zayarni February 21, 2024 ](https://qdrant.tech/blog/qdrant-summer-of-code-24/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/7/)
                    ## 📄 `https-qdrant-tech-blog-page-8.md`
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Dust and Qdrant: Using AI to Unlock Company Knowledge and Drive Employee Productivity](https://qdrant.tech/blog/dust-and-qdrant/preview/preview.jpg) Dust and Qdrant: Using AI to Unlock Company Knowledge and Drive Employee Productivity Using AI to Unlock Company Knowledge and Drive Employee Productivity Manuel Meyer February 06, 2024 ](https://qdrant.tech/blog/dust-and-qdrant/)[![The Bitter Lesson of Retrieval in Generative Language Model Workflows - Mikko Lehtimäki | Vector Space Talks](https://qdrant.tech/blog/bitter-lesson-generative-language-model/preview/preview.jpg) The Bitter Lesson of Retrieval in Generative Language Model Workflows - Mikko Lehtimäki | Vector Space Talks Mikko Lehtimäki delves into the intricate world of retrieval-augmented generation, discussing how Yokot AI manages vast diverse data inputs and how focusing on re-ranking can massively improve LLM workflows and output quality. Demetrios Brinkmann January 29, 2024 ](https://qdrant.tech/blog/bitter-lesson-generative-language-model/)[![Indexify Unveiled - Diptanu Gon Choudhury | Vector Space Talks](https://qdrant.tech/blog/indexify-content-extraction-engine/preview/preview.jpg) Indexify Unveiled - Diptanu Gon Choudhury | Vector Space Talks Diptanu Gon Choudhury shares insights on re-imaging Spark and data infrastructure while discussing his work on Indexify to enhance AI-driven workflows and knowledge bases. Demetrios Brinkmann January 26, 2024 ](https://qdrant.tech/blog/indexify-content-extraction-engine/)[![Unlocking AI Potential: Insights from Stanislas Polu](https://qdrant.tech/blog/qdrant-x-dust-vector-search/preview/preview.jpg) Unlocking AI Potential: Insights from Stanislas Polu Explore the dynamic discussion with Stanislas Polu on AI, ML, entrepreneurship, and product development. Gain valuable insights into AI's transformative power. Demetrios Brinkmann January 26, 2024 ](https://qdrant.tech/blog/qdrant-x-dust-vector-search/)[![Announcing Qdrant's $28M Series A Funding Round](https://qdrant.tech/blog/series-A-funding-round/preview/preview.jpg) Announcing Qdrant's $28M Series A Funding Round Andre Zayarni, CEO & Co-Founder January 23, 2024 ](https://qdrant.tech/blog/series-a-funding-round/)[![Introducing Qdrant Cloud on Microsoft Azure](https://qdrant.tech/blog/qdrant-cloud-on-microsoft-azure/preview/preview.jpg) Introducing Qdrant Cloud on Microsoft Azure Learn the benefits of Qdrant Cloud on Azure. Manuel Meyer January 17, 2024 ](https://qdrant.tech/blog/qdrant-cloud-on-microsoft-azure/)[![Qdrant Updated Benchmarks 2024](https://qdrant.tech/blog/qdrant-benchmarks-2024/preview/preview.jpg) Qdrant Updated Benchmarks 2024 We've compared how Qdrant performs against the other vector search engines to give you a thorough performance analysis Sabrina Aquino January 15, 2024 ](https://qdrant.tech/blog/qdrant-benchmarks-2024/)[![Navigating challenges and innovations in search technologies](https://qdrant.tech/blog/navigating-challenges-innovations/preview/preview.jpg) Navigating challenges and innovations in search technologies Podcast on search and LLM with Datatalk.club Atita Arora January 12, 2024 ](https://qdrant.tech/blog/navigating-challenges-innovations/)[![Optimizing an Open Source Vector Database with Andrey Vasnetsov](https://qdrant.tech/blog/open-source-vector-search-engine-vector-database/preview/preview.jpg) Optimizing an Open Source Vector Database with Andrey Vasnetsov Learn key strategies for optimizing vector search from Andrey Vasnetsov, CTO at Qdrant. Dive into techniques like efficient indexing for improved performance. Demetrios Brinkmann January 10, 2024 ](https://qdrant.tech/blog/open-source-vector-search-engine-vector-database/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/8/)
                    ## 📄 `https-qdrant-tech-blog-page-9.md`
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Vector Search Complexities: Insights from Projects in Image Search and RAG - Noé Achache | Vector Space Talks](https://qdrant.tech/blog/vector-image-search-rag/preview/preview.jpg) Vector Search Complexities: Insights from Projects in Image Search and RAG - Noé Achache | Vector Space Talks Noé Achache shares insights on vector search complexities, discussing projects on image matching, document retrieval, and handling sensitive medical data with practical solutions and industry challenges. Demetrios Brinkmann January 09, 2024 ](https://qdrant.tech/blog/vector-image-search-rag/)[![How to Superpower Your Semantic Search Using a Vector Database Vector Space Talks](https://qdrant.tech/blog/semantic-search-vector-database/preview/preview.jpg) How to Superpower Your Semantic Search Using a Vector Database Vector Space Talks Unlock the secrets of supercharging semantic search with Nicolas Mauti's insights on leveraging vector databases. Discover advanced strategies. Demetrios Brinkmann January 09, 2024 ](https://qdrant.tech/blog/semantic-search-vector-database/)[![Building LLM Powered Applications in Production - Hamza Farooq | Vector Space Talks](https://qdrant.tech/blog/llm-complex-search-copilot/preview/preview.jpg) Building LLM Powered Applications in Production - Hamza Farooq | Vector Space Talks Hamza Farooq presents the future of large language models, complex search, and copilot, discussing real-world applications and the challenges of implementing these technologies in production. Demetrios Brinkmann January 09, 2024 ](https://qdrant.tech/blog/llm-complex-search-copilot/)[![Building a High-Performance Entity Matching Solution with Qdrant - Rishabh Bhardwaj | Vector Space Talks](https://qdrant.tech/blog/entity-matching-qdrant/preview/preview.jpg) Building a High-Performance Entity Matching Solution with Qdrant - Rishabh Bhardwaj | Vector Space Talks Rishabh Bhardwaj, a Data Engineer at HRS Group, discusses building a high-performance hotel matching solution with Qdrant, addressing data inconsistency, duplication, and real-time processing challenges. Demetrios Brinkmann January 09, 2024 ](https://qdrant.tech/blog/entity-matching-qdrant/)[![FastEmbed: Fast & Lightweight Embedding Generation - Nirant Kasliwal | Vector Space Talks](https://qdrant.tech/blog/fast-embed-models/preview/preview.jpg) FastEmbed: Fast & Lightweight Embedding Generation - Nirant Kasliwal | Vector Space Talks Nirant Kasliwal discusses the efficiency and optimization techniques of FastEmbed, a Python library designed for speedy, lightweight embedding generation in machine learning applications. Demetrios Brinkmann January 09, 2024 ](https://qdrant.tech/blog/fast-embed-models/)[![When music just doesn't match our vibe, can AI help? - Filip Makraduli | Vector Space Talks](https://qdrant.tech/blog/human-language-ai-models/preview/preview.jpg) When music just doesn't match our vibe, can AI help? - Filip Makraduli | Vector Space Talks Filip Makraduli discusses using human language and AI to capture music vibes, encoding text with sentence transformers, generating recommendations through vector spaces, integrating Streamlit and Spotify API, and future improvements for AI-powered music recommendations. Demetrios Brinkmann January 09, 2024 ](https://qdrant.tech/blog/human-language-ai-models/)[![Binary Quantization - Andrey Vasnetsov | Vector Space Talks](https://qdrant.tech/blog/binary-quantization/preview/preview.jpg) Binary Quantization - Andrey Vasnetsov | Vector Space Talks Andrey Vasnetsov, CTO of Qdrant, discusses the concept of binary quantization and its benefits in vector indexing, including the challenges and potential future developments of this technique. Demetrios Brinkmann January 09, 2024 ](https://qdrant.tech/blog/binary-quantization/)[![Loading Unstructured.io Data into Qdrant from the Terminal](https://qdrant.tech/blog/qdrant-unstructured/preview/preview.jpg) Loading Unstructured.io Data into Qdrant from the Terminal Learn how to simplify the process of loading unstructured data into Qdrant using the Qdrant Unstructured destination. Anush Shetty January 09, 2024 ](https://qdrant.tech/blog/qdrant-unstructured/)[![Chat with a codebase using Qdrant and N8N](https://qdrant.tech/blog/qdrant-n8n/preview/preview.jpg) Chat with a codebase using Qdrant and N8N Building a RAG-based chatbot using Qdrant and N8N to chat with a codebase on GitHub Anush Shetty January 06, 2024 ](https://qdrant.tech/blog/qdrant-n8n/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/page/9/)
                    ## 📄 `https-qdrant-tech-blog-qdrant-1-13-x.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine
  *     * [GPU Accelerated Indexing](https://qdrant.tech/blog/qdrant-1.13.x/#gpu-accelerated-indexing)
      * [Benchmarks on Common GPUs](https://qdrant.tech/blog/qdrant-1.13.x/#benchmarks-on-common-gpus)
      * [](https://qdrant.tech/blog/qdrant-1.13.x/#instructions--documentationdocumentationguidesrunning-with-gpu)[Instructions & Documentation](https://qdrant.tech/documentation/guides/running-with-gpu/)
    * [Strict Mode for Operational Control](https://qdrant.tech/blog/qdrant-1.13.x/#strict-mode-for-operational-control)
      * [Enable Strict Mode](https://qdrant.tech/blog/qdrant-1.13.x/#enable-strict-mode)
    * [HNSW Graph Compression](https://qdrant.tech/blog/qdrant-1.13.x/#hnsw-graph-compression)
    * [Filter by Named Vectors](https://qdrant.tech/blog/qdrant-1.13.x/#filter-by-named-vectors)
      * [Create a Collection with Named Vectors](https://qdrant.tech/blog/qdrant-1.13.x/#create-a-collection-with-named-vectors)
      * [Sample Request](https://qdrant.tech/blog/qdrant-1.13.x/#sample-request)
    * [Custom Storage Engine](https://qdrant.tech/blog/qdrant-1.13.x/#custom-storage-engine)
      * [Our New Storage Architecture](https://qdrant.tech/blog/qdrant-1.13.x/#our-new-storage-architecture)
    * [Get Started with Qdrant](https://qdrant.tech/blog/qdrant-1.13.x/#get-started-with-qdrant)
**GPU Accelerated Indexing:** Fast HNSW indexing with architecture-free GPU support.  
**Strict Mode:** Enforce operation restrictions on collections for enhanced control.  
**HNSW Graph Compression:** Reduce storage use via HNSW Delta Encoding.  
**Named Vector Filtering:** New `has_vector` filtering condition for named vectors.  
**Custom Storage:** For constant-time reads/writes of payloads and sparse vectors.  
##  [](https://qdrant.tech/blog/qdrant-1.13.x/#get-started-with-qdrant)Get Started with Qdrant
![get-started](https://qdrant.tech/blog/qdrant-1.13.x/image_1.png)
The easiest way to reach that **Hello World** moment is to [**try vector search in a live cluster**](https://qdrant.tech/documentation/quickstart-cloud/). Our **interactive tutorial** will show you how to create a cluster, add data and try some filtering clauses.
**New features, like named vector filtering, can be tested in the Qdrant Dashboard:**
![qdrant-filtering-tutorial](https://qdrant.tech/articles_data/vector-search-filtering/qdrant-filtering-tutorial.png)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/qdrant-1.13.x/)
                    ## 📄 `https-qdrant-tech-blog-qdrant-n8n-beyond-simple-similarity-search.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Automating Business Processes with Qdrant and n8n: Use Cases Beyond Simple Similarity Search
  *     * [Setting Up Qdrant in n8n](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#setting-up-qdrant-in-n8n)
      * [Qdrant Cloud](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#qdrant-cloud)
      * [Local Mode](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#local-mode)
    * [Beyond Simple Similarity Search](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#beyond-simple-similarity-search)
      * [Recommendations](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#recommendations)
      * [Big Data Analysis](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#big-data-analysis)
    * [What’s Next?](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/#whats-next)
Low-code automation tools make it easy to turn ideas into reality quickly. As AI becomes central to modern business, having low-code platforms with built-in AI capabilities is no longer optional—it’s essential. 
Vector search has become a key building block in modern AI systems. While it’s often used as memory or a knowledge base for generative AI, its potential goes much further.
In this blog, we explore combining a dedicated vector search engine like Qdrant with an AI automation platform like n8n, moving beyond basic Retrieval-Augmented Generation (RAG) use cases. We’ll show you how to use vector search for recommendations and big data analysis using ready-to-use n8n workflows.
  1. Open the 
  2. From the **Cluster Details** , copy the `Endpoint` address—this will be used as the `Qdrant URL` in n8n.
  3. Navigate to the **API Keys** tab and copy your API key—this will be the `API Key` in n8n.
For a walkthrough, see this 
  1. Follow the instructions in the repository to install the AI Starter Kit.
  2. Use the values from the `docker-compose.yml` file to fill in the connection details.
Remember to update to the latest Qdrant Docker image using `docker-compose pull`.
The default Qdrant configuration in AI Starter Kit’s `docker-compose.yml` looks like this:
  1. **Dataset** : We use movie descriptions from the 
  2. **Embedding Model** : We’ll use OpenAI `text-embedding-3-small`, but you can opt for any other suitable embedding model.
**Workflow:**
A 
  1. **Movie Data Uploader** : Embeds movie descriptions and uploads them to Qdrant using the 
  2. **AI Agent** : Uses the 
  3. **Recommendations Tool** : A `text-embedding-3-small` and uses the Qdrant Recommendation API to get movie recommendations, which are passed back to the agent.
To use Qdrant's functionality beyond [Qdrant API reference](https://api.qdrant.tech/api-reference) to n8n's 
Set it up, run a chat and ask for “ _something about wizards but not Harry Potter_.” What results do you get?
  1. Store vectorized images.
  2. Identify a “center” (representative) for each crop cluster.
  3. Define the borders of each cluster.
  4. Check if new images fall within these boundaries. If an image does not fit within any cluster, it is flagged as anomalous. Alternatively, you can check if an image is anomalous to a specific cluster.
![anomaly-detection](https://qdrant.tech/blog/qdrant-n8n-2/anomaly-detection.png)
**Setup:**
  1. **Dataset** : We use the 
  2. **Embedding Model** : The 
**1. Uploading Images to Qdrant**
Since the 
**Workflow:**
_There are three workflows: (1) Uploading images to Qdrant (2) Setting up cluster centers and thresholds (3) Anomaly detection tool itself._
An 
  1. **Check Collection** : Verifies if a collection with the specified name exists in Qdrant. If not, it creates one.
  2. **Payload Index** : Adds a [payload index](https://qdrant.tech/documentation/concepts/indexing/#payload-index) on the `crop_name` payload (metadata) field. This field stores crop class labels, and indexing it improves the speed of filterable searches in Qdrant. It changes the way a vector index is constructed, adapting it for fast vector search under filtering constraints. For more details, refer to this [guide on filtering in Qdrant](https://qdrant.tech/articles/vector-search-filtering/).
  3. **Fetch Images** : Fetches images from Google Cloud Storage using the 
  4. **Generate IDs** : Assigns UUIDs to each data point.
  5. **Embed Images** : Embeds the images using the Voyage API.
  6. **Batch Upload** : Uploads the embeddings to Qdrant in batches.
**2. Defining a Cluster Representative**
We used two approaches (it’s not an exhaustive list) to defining a cluster representative, depending on the availability of labeled data:
Method | Description  
---|---  
**Medoids** | A point within the cluster that has the smallest total distance to all other cluster points. This approach needs labeled data for each cluster.  
**Perfect Representative** | A representative defined by a textual description of the ideal cluster member—the multimodality of Voyage AI embeddings allows for this trick. For example, for cherries: _“Small, glossy red fruits on a medium-sized tree with slender branches and serrated leaves.”_ The closest image to this description in the vector space is selected as the representative. This method requires experimentation to align descriptions with real data.  
![cluster-representative](https://qdrant.tech/blog/qdrant-n8n-2/cluster-representative.png)
**Workflow:**
Both methods are demonstrated in the 
**Method** | **Steps**  
---|---  
**Medoids** | 1. Sample labeled cluster points from Qdrant.  
2. Compute a **pairwise distance matrix** for the cluster using Qdrant’s [Distance Matrix API](https://qdrant.tech/documentation/concepts/explore/?q=distance+#distance-matrix). This API helps with scalable cluster analysis and data points relationship exploration. Learn more in [this article](https://qdrant.tech/articles/distance-based-exploration/).  
3. For each point, calculate the sum of its distances to all other points. The point with the smallest total distance (or highest similarity for COSINE distance metric) is the medoid.  
4. Mark this point as the cluster representative.  
**Perfect Representative** | 1. Define textual descriptions for each cluster (e.g., AI-generated).  
2. Embed these descriptions using Voyage.  
3. Find the image embedding closest to the description one.  
4. Mark this image as the cluster representative.  
**3. Defining the Cluster Border**
**Workflow:**
The approach demonstrated in 
  1. Within a cluster, identify the furthest data point from the cluster representative (it can also be the 2nd or Xth furthest point; the best way to define it is through experimentation—for us, the 5th furthest point worked well). Since we use COSINE similarity, this is equivalent to the most similar point to the 
  2. Save the distance between the representative and respective furthest point as the cluster border (threshold).
**4. Anomaly Detection Tool**
**Workflow:**
With the preparatory steps complete, you can set up the anomaly detection tool, demonstrated in the 
Steps:
  1. Choose the method of the cluster representative definition.
  2. Fetch all the clusters to compare the candidate image against.
  3. Using Voyage AI, embed the candidate image in the same vector space.
  4. Calculate the candidate’s similarity to each cluster representative. The image is flagged as anomalous if the similarity is below the threshold for all clusters (outside the cluster borders). Alternatively, you can check if it’s anomalous to a particular cluster, for example, the cherries one.
* * *
Anomaly detection in image data has diverse applications, including:
  * Moderation of advertisements.
  * Anomaly detection in vertical farming.
  * Quality control in the food industry, such as [detecting anomalies in coffee beans](https://qdrant.tech/articles/detecting-coffee-anomalies/).
  * Identifying anomalies in map tiles for tasks like automated map updates or ecological monitoring.
This tool is adaptable to these use cases and, when combined with n8n integrations, has the potential to become a production-level business solution.
  1. **Dataset** : We’ll use the 
  2. **Embedding Model** : As for anomaly detection, we’ll use the 
Additionally, it’s good to have test and validation data to determine the optimal value of K for your dataset.
**Workflow:**
Uploading images to Qdrant can be done using the same workflow—
The 
  1. **Embed Image** : Embeds the candidate for classification using Voyage.
  2. **Fetch neighbors** : Retrieves the K closest labeled neighbors from Qdrant.
  3. **Majority Voting** : Determines the prevailing class in the neighborhood by simple majority voting.
  4. **Optional: Ties Resolving** : In case of ties, expands the neighborhood radius.
Of course, this is a simple solution, and there exist more advanced approaches with higher precision & no need for labeled data—for example, you could try [metric learning with Qdrant](https://qdrant.tech/articles/metric-learning-tips/).
Though classification seems like a task that was solved in machine learning decades ago, it’s not so trivial to deal with in production. Issues like data drift, shifting class definitions, mislabeled data, and fuzzy differences between classes create unexpected problems, which require continuous adjustments of classifiers. Vector Search can be an unusual but effective solution, interesting due to its scalability.
  * **Deduplication**
  * **Dissimilarity search**
  * **Diverse sampling**
With Qdrant and n8n, there’s plenty of room to create something unique!
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/)
                    ## 📄 `https-qdrant-tech-blog-qdrant-soc2-type2-audit.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Qdrant Attains SOC 2 Type II Audit Report
  *     * [SOC 2 Type II: What Is It?](https://qdrant.tech/blog/qdrant-soc2-type2-audit/#soc-2-type-ii-what-is-it)
    * [Key Audit Findings](https://qdrant.tech/blog/qdrant-soc2-type2-audit/#key-audit-findings)
    * [Future Compliance](https://qdrant.tech/blog/qdrant-soc2-type2-audit/#future-compliance)
    * [About Qdrant](https://qdrant.tech/blog/qdrant-soc2-type2-audit/#about-qdrant)
At Qdrant, we are happy to announce the successful completion our the SOC 2 Type II Audit. This achievement underscores our unwavering commitment to upholding the highest standards of security, availability, and confidentiality for our services and our customers’ data.
  * Security
  * Confidentiality
  * Availability
These certifications are available today and automatically apply to your existing workloads. The full SOC 2 Type II report is available to customers and stakeholders upon request through the 
##  [](https://qdrant.tech/blog/qdrant-soc2-type2-audit/#about-qdrant)About Qdrant
Qdrant is a vector database designed to handle large-scale, high-dimensional data efficiently. It allows for fast and accurate similarity searches in complex datasets. Qdrant strives to achieve seamless and scalable vector search capabilities for various applications.
For more information about Qdrant and our security practices, please visit our [website](http://qdrant.tech) or [reach out to our team directly](https://qdrant.tech/contact-us/).
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/qdrant-soc2-type2-audit/)
                    ## 📄 `https-qdrant-tech-blog-satellite-vector-broadcasting.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Satellite Vector Broadcasting: Near-Zero Latency Retrieval from Space
  *     * [📡 Qdrant Launches Satellite Vector Broadcasting for Near-Zero Latency Retrieval](https://qdrant.tech/blog/satellite-vector-broadcasting/#-qdrant-launches-satellite-vector-broadcasting-for-near-zero-latency-retrieval)
      * [📊 Benchmark Results](https://qdrant.tech/blog/satellite-vector-broadcasting/#-benchmark-results)
      * [🛰 Key Features](https://qdrant.tech/blog/satellite-vector-broadcasting/#-key-features)
      * [💬 Field Reports](https://qdrant.tech/blog/satellite-vector-broadcasting/#-field-reports)
      * [🛸 Coming Soon](https://qdrant.tech/blog/satellite-vector-broadcasting/#-coming-soon)
      * [📡 Availability](https://qdrant.tech/blog/satellite-vector-broadcasting/#-availability)
###  [](https://qdrant.tech/blog/satellite-vector-broadcasting/#-availability)📡 Availability
Satellite Vector Broadcasting is now available in limited orbit. Each query costs **one launch credit** (or barter in moon rocks). Commercial adoption expected Q3 2025, pending space traffic regulations.
Learn more at: [**Qdrant Vector Database**](https://qdrant.tech/qdrant-vector-database/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/satellite-vector-broadcasting/)
                    ## 📄 `https-qdrant-tech-blog-static-embeddings.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Static Embeddings: should you pay attention?
  *     * [What makes static embeddings different?](https://qdrant.tech/blog/static-embeddings/#what-makes-static-embeddings-different)
    * [Static embeddings in Qdrant](https://qdrant.tech/blog/static-embeddings/#static-embeddings-in-qdrant)
    * [Quantization of the static embeddings](https://qdrant.tech/blog/static-embeddings/#quantization-of-the-static-embeddings)
    * [Who should use static embeddings?](https://qdrant.tech/blog/static-embeddings/#who-should-use-static-embeddings)
      * [Customization of the static embeddings](https://qdrant.tech/blog/static-embeddings/#customization-of-the-static-embeddings)
In the world of resource-constrained computing, a quiet revolution is taking place. While transformers dominate leaderboards with their impressive capabilities, static embeddings are making an unexpected comeback, offering remarkable speed improvements with surprisingly small quality trade-offs. **We evaluated how Qdrant users can benefit from this renaissance, and the results are promising**.
  * **Mobile applications** - although many smartphones have powerful CPUs or even GPUs, the battery life is still a concern, and the static embeddings might be a good compromise between the quality and the power consumption. Moreover, the static embeddings can be used in the applications that require offline mode.
  * **Web browser extensions** - running a transformer-based model in a web browser is usually not quite an option, but static embeddings might be a good choice, as they have fewer parameters and are faster to encode.
  * **Embedded systems** - the static embeddings might be a good choice for the devices with limited computational power, such as IoT devices or microcontrollers.
If you are one of the above, then you should definitely give static embeddings a try. **However, if the search quality is not the top of your priorities, then you might consider using static embeddings even in the high-performance environments**. The speedup in the encoding process might be a game-changer for you.
###  [](https://qdrant.tech/blog/static-embeddings/#customization-of-the-static-embeddings)Customization of the static embeddings
Last, but not least. The training pipeline published by **you can adjust it the specifics of your data easily**. This training process will also be way faster than for a transformer-based model, so you can even retrain it more often. Recomputing the embeddings is a bottleneck of the semantic search systems, and the static embeddings might be a good solution to this problem. Whether a custom static embedding model can beat a general pre-trained model remains an open question, but it’s definitely worth trying.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/static-embeddings/)
                    ## 📄 `https-qdrant-tech-blog-webinar-crewai-qdrant-obsidian.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * How to Build Intelligent Agentic RAG with CrewAI and Qdrant
  *     * [Background agents](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#background-agents)
      * [The basic concepts of CrewAI](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#the-basic-concepts-of-crewai)
      * [Email automation with CrewAI, Qdrant, and Obsidian notes](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#email-automation-with-crewai-qdrant-and-obsidian-notes)
    * [Implementing the system](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#implementing-the-system)
      * [CrewAI <> Qdrant integration](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#crewai--qdrant-integration)
      * [Loading the Obsidian notes to Qdrant](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#loading-the-obsidian-notes-to-qdrant)
      * [Drafting emails in Gmail Inbox](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#drafting-emails-in-gmail-inbox)
      * [Working system](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#working-system)
    * [Results](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#results)
    * [Materials](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#materials)
In a recent live session, we teamed up with 
In this article, we’ll guide you through the process of setting up an AI-powered system that connects directly to your email inbox and knowledge base, enabling it to analyze incoming messages and existing content to generate contextually relevant response suggestions.
##  [](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/#materials)Materials
As usual, we prepared a video recording of the webinar, so you can watch it at your convenience:
The source code of the demo is available on 
Are you building agentic RAG applications using CrewAI and Qdrant? Please join 
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/)
                    ## 📄 `https-qdrant-tech-blog-webinar-vibe-coding-rag.md`
  * [Home](https://qdrant.tech/)
  * /
  * [Blog](https://qdrant.tech/blog/)
  * /
  * Vibe Coding RAG with our MCP server
  *     * [Vibe coding](https://qdrant.tech/blog/webinar-vibe-coding-rag/#vibe-coding)
    * [Understanding the Model Context Protocol (MCP)](https://qdrant.tech/blog/webinar-vibe-coding-rag/#understanding-the-model-context-protocol-mcp)
    * [AI coding assistants](https://qdrant.tech/blog/webinar-vibe-coding-rag/#ai-coding-assistants)
    * [Building the project](https://qdrant.tech/blog/webinar-vibe-coding-rag/#building-the-project)
      * [Setting up the MCP server](https://qdrant.tech/blog/webinar-vibe-coding-rag/#setting-up-the-mcp-server)
      * [Building the knowledge base of the DaisyUI components](https://qdrant.tech/blog/webinar-vibe-coding-rag/#building-the-knowledge-base-of-the-daisyui-components)
      * [Scoping the project: YouTube In-Video Search](https://qdrant.tech/blog/webinar-vibe-coding-rag/#scoping-the-project-youtube-in-video-search)
    * [The vibe coding session](https://qdrant.tech/blog/webinar-vibe-coding-rag/#the-vibe-coding-session)
Another month means another webinar! This time 
  1. Store and retrieve memories (code snippets, documentation, etc.)
  2. Perform semantic searches across your codebase
  3. Find the most relevant context for generating new code
The server provides two primary tools:
  * `qdrant-store`: Stores information with optional metadata in the Qdrant database
  * `qdrant-find`: Retrieves relevant information using semantic search
This architecture enables AI coding agents to maintain context awareness throughout your development process.
  * Store code snippets, documentation, and implementation details using the `qdrant-store` tool
  * Retrieve the most relevant information based on natural language queries with the `qdrant-find` tool
For our live coding session, we configured Claude Code to work with this MCP server. When Claude needs to generate code, it can automatically search for relevant examples in our codebase and create new code based on the extracted examples. Moreover, when the assistant is done with generating the code, it can also store it in Qdrant for further reference. And if configured correctly, it will only do that when we accept the change.
The latest version of the `mcp-server-qdrant` allows to specify the instructions for the AI agent, so it can understand when to use which of the tools. This way, the MCP server can not only be used for coding but virtually to any semantic search task, where the context is crucial. This is how we did that during the webinar:
##  [](https://qdrant.tech/blog/webinar-vibe-coding-rag/#the-vibe-coding-session)The vibe coding session
If you are interested to see how well Claude Code performed in action, you can watch the full webinar recording below:
No matter if you build an MVP, or want to build a more complex application with the help of AI, it’s key to give your agent a reliable source of information. That’s why we’ve built our MCP server, so you can easily connect your documentation and codebase to Claude Code, Cursor, Windsurf or any other AI agent that supports the Model Context Protocol.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
Up!
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/webinar-vibe-coding-rag/)
                    ## 📄 `https-qdrant-tech-blog.md`
###### [HubSpot & Qdrant: Scaling an Intelligent AI Assistant Andre Zayarni March 24, 2025 ](https://qdrant.tech/blog/case-study-hubspot/)###### [Qdrant 1.13 - GPU Indexing, Strict Mode & New Storage Engine David Myriel January 23, 2025 ](https://qdrant.tech/blog/qdrant-1.13.x/)###### [Optimizing ColPali for Retrieval at Scale, 13x Faster Results Evgeniya Sukhodolskaya, Sabrina Aquino November 27, 2024 ](https://qdrant.tech/blog/colpali-qdrant-optimization/)
[![Automating Business Processes with Qdrant and n8n: Use Cases Beyond Simple Similarity Search](https://qdrant.tech/blog/qdrant-n8n-2/preview/preview.jpg) Automating Business Processes with Qdrant and n8n: Use Cases Beyond Simple Similarity Search Build powerful agentic workflows for recommendations and large-scale data analysis with the combined capabilities of Qdrant and n8n. Evgeniya Sukhodolskaya April 04, 2025 ](https://qdrant.tech/blog/qdrant-n8n-beyond-simple-similarity-search/)[![Satellite Vector Broadcasting: Near-Zero Latency Retrieval from Space](https://qdrant.tech/blog/satellite-vector-broadcasting/preview/preview.jpg) Satellite Vector Broadcasting: Near-Zero Latency Retrieval from Space The future of vector search, featuring a constellation of CubeSats for ultra-low-latency vector retrieval. Complete with benchmark results and field reports from our beta testers. Qdrant Team April 01, 2025 ](https://qdrant.tech/blog/satellite-vector-broadcasting/)[![Vibe Coding RAG with our MCP server](https://qdrant.tech/blog/webinar-vibe-coding-rag/preview/preview.jpg) Vibe Coding RAG with our MCP server Check out how the MCP server can give you more control over the quality of vibe coding with AI agents like Cursor, and Claude Code! Kacper Łukawski March 21, 2025 ](https://qdrant.tech/blog/webinar-vibe-coding-rag/)[![How Deutsche Telekom Built a Multi-Agent Enterprise Platform Leveraging Qdrant](https://qdrant.tech/blog/case-study-deutsche-telekom/preview/preview.jpg) How Deutsche Telekom Built a Multi-Agent Enterprise Platform Leveraging Qdrant Learn about Deutsche Telekom's requirements for scaling enterprise AI agents, key AI stack considerations, and how the team built a Platform as a Service (PaaS) - LMOS (Language Models Operating System) — a multi-agent PaaS designed for high scalability and modular AI agent deployment. Manuel Meyer March 07, 2025 ](https://qdrant.tech/blog/case-study-deutsche-telekom/)[![Introducing Qdrant Cloud’s New Enterprise-Ready Vector Search](https://qdrant.tech/blog/enterprise-vector-search/preview/preview.jpg) Introducing Qdrant Cloud’s New Enterprise-Ready Vector Search Discover Qdrant Cloud's enterprise features: RBAC, SSO, granular API keys, advanced monitoring/observability. Daniel Azoulai March 04, 2025 ](https://qdrant.tech/blog/enterprise-vector-search/)[![Metadata automation and optimization - Reece Griffiths | Vector Space Talks](https://qdrant.tech/blog/metadata-deasy-labs/preview/preview.jpg) Metadata automation and optimization - Reece Griffiths | Vector Space Talks Metadata plays a critical role in vector search accuracy, yet it’s often overlooked. In this episode of Vector Space Talks, Reece Griffiths, CEO of Deasy Labs, explains why metadata automation is essential for scalable AI systems. He walks us through how Deasy Labs orchestrates metadata extraction, classification, and enrichment to boost retrieval efficiency. Sabrina Aquino February 24, 2025 ](https://qdrant.tech/blog/metadata-deasy-labs/)[![How to Build Intelligent Agentic RAG with CrewAI and Qdrant](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/preview/preview.jpg) How to Build Intelligent Agentic RAG with CrewAI and Qdrant Learn how to build an agentic RAG system to semi-automate email communication with CrewAI, Qdrant, and Obsidian. Kacper Łukawski January 24, 2025 ](https://qdrant.tech/blog/webinar-crewai-qdrant-obsidian/)[![Static Embeddings: should you pay attention?](https://qdrant.tech/blog/static-embeddings/preview/preview.jpg) Static Embeddings: should you pay attention? Static embeddings are a thing back! Is the encoding speedup worth a try? We checked that! Kacper Łukawski January 17, 2025 ](https://qdrant.tech/blog/static-embeddings/)[![Voiceflow & Qdrant: Powering No-Code AI Agent Creation with Scalable Vector Search](https://qdrant.tech/blog/case-study-voiceflow/preview/preview.jpg) Voiceflow & Qdrant: Powering No-Code AI Agent Creation with Scalable Vector Search Learn how Voiceflow builds scalable, customizable, no-code AI agent solutions for enterprises. Qdrant December 10, 2024 ](https://qdrant.tech/blog/case-study-voiceflow/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/blog/)
                    ## 📄 `https-qdrant-tech-cloud.md`
###### Pricing
Visit our pricing page for more details on Qdrant’s free tier, managed cloud, and enterprise plans.
[Learn More ](https://qdrant.tech/pricing/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/cloud/)
                    ## 📄 `https-qdrant-tech-community.md`
### Launch a new cluster today
![](https://qdrant.tech/img/database.svg)
Do you have further questions? We are happy to assist you.
[Contact us ](https://qdrant.tech/contact-us/)[Contact us](https://qdrant.tech/contact-us/)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/community/)
                    ## 📄 `https-qdrant-tech-contact-us.md`
###### Talk to our Team
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/contact-us/)
                    ## 📄 `https-qdrant-tech-customers.md`
## Vector Space Wall
![Avatar](https://qdrant.tech/img/customers/jonathan-eisenzopf.svg)
Jonathan Eisenzopf
Chief Strategy and Research Officer at Talkmap
“With Qdrant, we found the missing piece to develop our own provider independent multimodal generative AI platform on enterprise scale.”
![Avatar](https://qdrant.tech/img/customers/angel-luis-almaraz-sanchez.svg)
Angel Luis Almaraz Sánchez
Full Stack | DevOps
Thank you, great work, Qdrant is my favorite option for similarity search.
![Avatar](https://qdrant.tech/img/customers/shubham-krishna.svg)
Shubham Krishna
ML Engineer @ ML6
Go ahead and checkout Qdrant. I plan to build a movie retrieval search where you can ask anything regarding a movie based on the vector embeddings generated by a LLM. It can also be used for getting recommendations.
![Avatar](https://qdrant.tech/img/customers/kwok-hing-leon.svg)
Kwok Hing LEON
Data Science
Check out qdrant for improving searches. Bye to non-semantic KM engines.
![Avatar](https://qdrant.tech/img/customers/ankur-s.svg)
Ankur S
Building
Quadrant is a great vector database. There is a real sense of thought behind the api!
![Avatar](https://qdrant.tech/img/customers/yasin-salimibeni-view-yasin-salimibeni.svg)
Yasin Salimibeni View Yasin Salimibeni’s profile
AI Evangelist | Generative AI Product Designer | Entrepreneur | Mentor
Great work. I just started testing Qdrant Azure and I was impressed by the efficiency and speed. Being deploy-ready on large cloud providers is a great plus. Way to go!
![Avatar](https://qdrant.tech/img/customers/marcel-coetzee.svg)
Marcel Coetzee
Data and AI Plumber
Using Qdrant as a blazing fact vector store for a stealth project of mine. It offers fantasic functionality for semantic search ✨
![Avatar](https://qdrant.tech/img/customers/andrew-rove.svg)
Andrew Rove
Principal Software Engineer
We have been using Qdrant in production now for over 6 months to store vectors for cosine similarity search and it is way more stable and faster than our old ElasticSearch vector index.  
No merging segments, no red indexes at random times. It just works and was super easy to deploy via docker to our cluster.  
It’s faster, cheaper to host, and more stable, and open source to boot!
![Avatar](https://qdrant.tech/img/customers/josh-lloyd.svg)
Josh Lloyd
ML Engineer
I'm using Qdrant to search through thousands of documents to find similar text phrases for question answering. Qdrant's awesome filtering allows me to slice along metadata while I'm at it! 🚀 and it's fast ⏩🔥
![Avatar](https://qdrant.tech/img/customers/leonard-puttmann.svg)
Leonard Püttmann
data scientist
Amidst the hype around vector databases, Qdrant is by far my favorite one. It's super fast (written in Rust) and open-source! At Kern AI we use Qdrant for fast document retrieval and to do quick similarity search for text data.
![Avatar](https://qdrant.tech/img/customers/stanislas-polu.svg)
Stanislas Polu
Software Engineer & Co-Founder, Dust
Qdrant's the best. By. Far.
![Avatar](https://qdrant.tech/img/customers/sivesh-sukumar.svg)
Sivesh Sukumar
Investor at Balderton
We're using Qdrant to help segment and source Europe's next wave of extraordinary companies!
![Avatar](https://qdrant.tech/img/customers/saksham-gupta.svg)
Saksham Gupta
AI Governance Machine Learning Engineer
Looking forward to using Qdrant vector similarity search in the clinical trial space! OpenAI Embeddings + Qdrant = Match made in heaven!
![Avatar](https://qdrant.tech/img/customers/rishav-dash.svg)
Rishav Dash
Data Scientist
awesome stuff 🔥
### Get started for free
Turn embeddings or neural network encoders into full-fledged applications for matching, searching, recommending, and more.
Do you have further questions? We are happy to assist you.
[Contact us ](https://qdrant.tech/contact-us/)[Contact us](https://qdrant.tech/contact-us/)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/customers/)
                    ## 📄 `https-qdrant-tech-data-analysis-anomaly-detection.md`
##### Metric Learning for Anomaly Detection
Detecting Coffee Anomalies with Qdrant: Discover how Qdrant can be used for anomaly detection in green coffee quality control, transforming the industry's approach to sorting and classification.
[Read Case Study](https://qdrant.tech/articles/detecting-coffee-anomalies/)
![Preview](https://qdrant.tech/img/data-analysis-anomaly-detection/case-study.png)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/data-analysis-anomaly-detection/)
                    ## 📄 `https-qdrant-tech-demo.md`
### Interactive Tutorials
Dive into the capabilities of Qdrant with our hands-on tutorials. Discover various methods to integrate vector search into your applications, enhancing functionality and user experience.
[View All Tutorials](https://qdrant.tech/documentation/tutorials/)
`...  
"hnsw_config": {  
"m": 64,  
"ef_construct": 512,  
"on_disk": true  
}  
...  
`
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/demo/)
                    ## 📄 `https-qdrant-tech-documentation-advanced-tutorials-code-search.md`
  * [Understanding Vector Search in Qdrant](https://qdrant.tech/documentation/overview/vector-search/)
[Local Quickstart](https://qdrant.tech/documentation/quickstart/)
[API & SDKs](https://qdrant.tech/documentation/interfaces/)
[Qdrant Web UI](https://qdrant.tech/documentation/web-ui/)
  * [Collections](https://qdrant.tech/documentation/concepts/collections/)
  * [Points](https://qdrant.tech/documentation/concepts/points/)
  * [Vectors](https://qdrant.tech/documentation/concepts/vectors/)
  * [Payload](https://qdrant.tech/documentation/concepts/payload/)
  * [Search](https://qdrant.tech/documentation/concepts/search/)
  * [Explore](https://qdrant.tech/documentation/concepts/explore/)
  * [Hybrid Queries](https://qdrant.tech/documentation/concepts/hybrid-queries/)
  * [Filtering](https://qdrant.tech/documentation/concepts/filtering/)
  * [Optimizer](https://qdrant.tech/documentation/concepts/optimizer/)
  * [Storage](https://qdrant.tech/documentation/concepts/storage/)
  * [Indexing](https://qdrant.tech/documentation/concepts/indexing/)
  * [Snapshots](https://qdrant.tech/documentation/concepts/snapshots/)
[Guides](https://qdrant.tech/documentation/guides/installation/)
  * [Installation](https://qdrant.tech/documentation/guides/installation/)
  * [Administration](https://qdrant.tech/documentation/guides/administration/)
  * [Running with GPU](https://qdrant.tech/documentation/guides/running-with-gpu/)
  * [Capacity Planning](https://qdrant.tech/documentation/guides/capacity-planning/)
  * [Optimize Performance](https://qdrant.tech/documentation/guides/optimize/)
  * [Multitenancy](https://qdrant.tech/documentation/guides/multiple-partitions/)
  * [Distributed Deployment](https://qdrant.tech/documentation/guides/distributed_deployment/)
  * [Quantization](https://qdrant.tech/documentation/guides/quantization/)
  * [Monitoring & Telemetry](https://qdrant.tech/documentation/guides/monitoring/)
  * [Configuration](https://qdrant.tech/documentation/guides/configuration/)
  * [Security](https://qdrant.tech/documentation/guides/security/)
  * [Usage Statistics](https://qdrant.tech/documentation/guides/usage-statistics/)
  * [Troubleshooting](https://qdrant.tech/documentation/guides/common-errors/)
  * [Semantic Search 101](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)
  * [Build a Neural Search Service](https://qdrant.tech/documentation/beginner-tutorials/neural-search/)
  * [Setup Hybrid Search with FastEmbed](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)
  * [Measure Search Quality](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)
[Advanced Retrieval](https://qdrant.tech/documentation/advanced-tutorials/)
  * [Search Through Your Codebase](https://qdrant.tech/documentation/advanced-tutorials/code-search/)
  * [Build a Recommendation System with Collaborative Filtering](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/)
  * [Scaling PDF Retrieval with Qdrant](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)
[Using the Database](https://qdrant.tech/documentation/database-tutorials/)
  * [Bulk Upload Vectors](https://qdrant.tech/documentation/database-tutorials/bulk-upload/)
  * [Create & Restore Snapshots](https://qdrant.tech/documentation/database-tutorials/create-snapshot/)
  * [Large Scale Search](https://qdrant.tech/documentation/database-tutorials/large-scale-search/)
  * [Load a HuggingFace Dataset](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/)
  * [Build With Async API](https://qdrant.tech/documentation/database-tutorials/async-api/)
  * [Automate filtering with LLMs](https://qdrant.tech/documentation/database-tutorials/automate-filtering-with-llms/)
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/advanced-tutorials/code-search/)
                    ## 📄 `https-qdrant-tech-documentation-advanced-tutorials-collaborative-filtering.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/advanced-tutorials/collaborative-filtering/)
                    ## 📄 `https-qdrant-tech-documentation-advanced-tutorials-pdf-retrieval-at-scale.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/advanced-tutorials/pdf-retrieval-at-scale/)
                    ## 📄 `https-qdrant-tech-documentation-advanced-tutorials.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/advanced-tutorials/)
                    ## 📄 `https-qdrant-tech-documentation-agentic-rag-crewai-zoom.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/agentic-rag-crewai-zoom/)
                    ## 📄 `https-qdrant-tech-documentation-beginner-tutorials-hybrid-search-fastembed.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/beginner-tutorials/hybrid-search-fastembed/)
                    ## 📄 `https-qdrant-tech-documentation-beginner-tutorials-neural-search.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/beginner-tutorials/neural-search/)
                    ## 📄 `https-qdrant-tech-documentation-beginner-tutorials-retrieval-quality.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/beginner-tutorials/retrieval-quality/)
                    ## 📄 `https-qdrant-tech-documentation-beginner-tutorials-search-beginners.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/beginner-tutorials/search-beginners/)
                    ## 📄 `https-qdrant-tech-documentation-beginner-tutorials.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/beginner-tutorials/)
                    ## 📄 `https-qdrant-tech-documentation-cloud-authentication.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/cloud/authentication/)
                    ## 📄 `https-qdrant-tech-documentation-cloud-backups.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/cloud/backups/)
                    ## 📄 `https-qdrant-tech-documentation-cloud-cluster-scaling.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/cloud/cluster-scaling/)
                    ## 📄 `https-qdrant-tech-documentation-cloud-qdrant-cloud-setup-enterprise-single-sign-on-sso.md`
  * [Getting Started](https://qdrant.tech/documentation/cloud/getting-started/)
  * [Account Setup](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/)
  * [Create a Cluster](https://qdrant.tech/documentation/cloud/create-cluster/)
  * [Authentication](https://qdrant.tech/documentation/cloud/authentication/)
  * [Cluster Access](https://qdrant.tech/documentation/cloud/cluster-access/)
  * [Scale Clusters](https://qdrant.tech/documentation/cloud/cluster-scaling/)
  * [Monitor Clusters](https://qdrant.tech/documentation/cloud/cluster-monitoring/)
  * [Upgrade Clusters](https://qdrant.tech/documentation/cloud/cluster-upgrades/)
  * [Backup Clusters](https://qdrant.tech/documentation/cloud/backups/)
  * [Billing & Payments](https://qdrant.tech/documentation/cloud/pricing-payments/)
  * [Premium Tier](https://qdrant.tech/documentation/cloud/premium/)
[Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/)
  * [Setup Hybrid Cloud](https://qdrant.tech/documentation/hybrid-cloud/hybrid-cloud-setup/)
  * [Create a Cluster](https://qdrant.tech/documentation/hybrid-cloud/hybrid-cloud-cluster-creation/)
  * [Configure the Qdrant Operator](https://qdrant.tech/documentation/hybrid-cloud/operator-configuration/)
  * [Networking, Logging & Monitoring](https://qdrant.tech/documentation/hybrid-cloud/networking-logging-monitoring/)
  * [Deployment Platforms](https://qdrant.tech/documentation/hybrid-cloud/platform-deployment-options/)
[Private Cloud](https://qdrant.tech/documentation/private-cloud/)
  * [Setup Private Cloud](https://qdrant.tech/documentation/private-cloud/private-cloud-setup/)
  * [Configuration](https://qdrant.tech/documentation/private-cloud/configuration/)
  * [Managing a Cluster](https://qdrant.tech/documentation/private-cloud/qdrant-cluster-management/)
  * [Backups](https://qdrant.tech/documentation/private-cloud/backups/)
  * [Logging & Monitoring](https://qdrant.tech/documentation/private-cloud/logging-monitoring/)
  * [API Reference](https://qdrant.tech/documentation/private-cloud/api-reference/)
  * [Changelog](https://qdrant.tech/documentation/private-cloud/changelog/)
[Cloud RBAC](https://qdrant.tech/documentation/cloud-rbac/)
  * [Role Management](https://qdrant.tech/documentation/cloud-rbac/role-management/)
  * [User Management](https://qdrant.tech/documentation/cloud-rbac/user-management/)
  * [Permission Reference](https://qdrant.tech/documentation/cloud-rbac/permission-reference/)
  * [Early Access FAQ](https://qdrant.tech/documentation/cloud-rbac/early-access-faq/)
  * With an email address and passwordless login via email
  * With a Google account
  * With a GitHub account
  * By connection an enterprise SSO solution
Every account is tied to an email address. You can invite additional users to your account and manage their permissions.
  * Active Directory/LDAP
  * ADFS
  * Azure Active Directory Native
  * Google Workspace
  * OpenID Connect
  * Okta
  * PingFederate
  * SAML
  * Azure Active Directory
Enterprise Sign-On is available as an add-on for [Premium Tier](https://qdrant.tech/documentation/cloud/premium/) customers. If you are interested in using SSO, please [contact us](https://qdrant.tech/contact-us/).
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/cloud/qdrant-cloud-setup/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-collections.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/collections/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-explore.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/explore/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-filtering-full-text-match.md`
###  [](https://qdrant.tech/documentation/concepts/filtering/#nested-object-filter)Nested object filter
_Available as of v1.2.0_
By default, the conditions are taking into account the entire payload of a point.
For instance, given two points with the following payload:
The following query would match both points:
httppythontypescriptrustjavacsharpgo
  * `gt` - greater than
  * `gte` - greater than or equal
  * `lt` - less than
  * `lte` - less than or equal
Can be applied to [float](https://qdrant.tech/documentation/concepts/payload/#float) and [integer](https://qdrant.tech/documentation/concepts/payload/#integer) payloads.
###  [](https://qdrant.tech/documentation/concepts/filtering/#has-vector)Has vector
_Available as of v1.13.0_
This condition enables filtering by the presence of a given named vector on a point.
For example, if we have two named vector in our collection.
Some points in the collection might have all vectors, some might have only a subset of them.
If your collection does not have named vectors, use an empty (`""`) name.
This is how you can search for points which have the dense `image` vector defined:
httppythontypescriptrustjavacsharpgo
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/filtering/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-filtering-geo-bounding-box.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/hybrid-queries/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-indexing-filtrable-index.md`
  * `keyword` - for [keyword](https://qdrant.tech/documentation/concepts/payload/#keyword) payload, affects [Match](https://qdrant.tech/documentation/concepts/filtering/#match) filtering conditions.
  * `integer` - for [integer](https://qdrant.tech/documentation/concepts/payload/#integer) payload, affects [Match](https://qdrant.tech/documentation/concepts/filtering/#match) and [Range](https://qdrant.tech/documentation/concepts/filtering/#range) filtering conditions.
  * `float` - for [float](https://qdrant.tech/documentation/concepts/payload/#float) payload, affects [Range](https://qdrant.tech/documentation/concepts/filtering/#range) filtering conditions.
  * `bool` - for [bool](https://qdrant.tech/documentation/concepts/payload/#bool) payload, affects [Match](https://qdrant.tech/documentation/concepts/filtering/#match) filtering conditions (available as of v1.4.0).
  * `geo` - for [geo](https://qdrant.tech/documentation/concepts/payload/#geo) payload, affects [Geo Bounding Box](https://qdrant.tech/documentation/concepts/filtering/#geo-bounding-box) and [Geo Radius](https://qdrant.tech/documentation/concepts/filtering/#geo-radius) filtering conditions.
  * `datetime` - for [datetime](https://qdrant.tech/documentation/concepts/payload/#datetime) payload, affects [Range](https://qdrant.tech/documentation/concepts/filtering/#range) filtering conditions (available as of v1.8.0).
  * `text` - a special kind of index, available for [keyword](https://qdrant.tech/documentation/concepts/payload/#keyword) / string payloads, affects [Full Text search](https://qdrant.tech/documentation/concepts/filtering/#full-text-match) filtering conditions.
  * `uuid` - a special type of index, similar to `keyword`, but optimized for [UUID values](https://qdrant.tech/documentation/concepts/payload/#uuid). Affects [Match](https://qdrant.tech/documentation/concepts/filtering/#match) filtering conditions. (available as of v1.11.0)
Payload index may occupy some additional memory, so it is recommended to only use index for those fields that are used in filtering conditions. If you need to filter by many fields and the memory limits does not allow to index all of them, it is recommended to choose the field that limits the search result the most. As a rule, the more different values a payload value has, the more efficiently the index will be used.
  * `word` - splits the string into words, separated by spaces, punctuation marks, and special characters.
  * `whitespace` - splits the string into words, separated by spaces.
  * `prefix` - splits the string into words, separated by spaces, punctuation marks, and special characters, and then creates a prefix index for each word. For example: `hello` will be indexed as `h`, `he`, `hel`, `hell`, `hello`.
  * `multilingual` - special type of tokenizer based on `--features multiling-chinese,multiling-japanese,multiling-korean` flags.
See [Full Text match](https://qdrant.tech/documentation/concepts/filtering/#full-text-match) for examples of querying with full-text index.
  * `lookup`: enables support for direct lookup using [Match](https://qdrant.tech/documentation/concepts/filtering/#match) filters.
  * `range`: enables support for [Range](https://qdrant.tech/documentation/concepts/filtering/#range) filters.
The regular `integer` index assumes both `lookup` and `range` are `true`. In contrast, to configure a parameterized index, you would set only one of these filters to `true`:
`lookup` | `range` | Result  
---|---|---  
`true` | `true` | Regular integer index  
`true` | `false` | Parameterized integer index  
`false` | `true` | Parameterized integer index  
`false` | `false` | No integer index  
The parameterized index can enhance performance in collections with millions of points. We encourage you to try it out. If it does not enhance performance in your use case, you can always restore the regular `integer` index.
Note: If you set `"lookup": true` with a range filter, that may lead to significant performance issues.
For example, the following code sets up a parameterized integer index which supports only range filters:
httppythontypescriptrustjavacsharpgo
  * `keyword`
  * `integer`
  * `float`
  * `datetime`
  * `uuid`
  * `text`
  * `geo`
The list will be extended in future versions.
  * A sparse vector index in Qdrant is exact, meaning it does not use any approximation algorithms.
  * All sparse vectors added to the collection are immediately indexed in the mutable version of a sparse index.
With Qdrant, you can benefit from a more compact and efficient immutable sparse index, which is constructed during the same optimization process as the dense vector index.
This approach is particularly useful for collections storing both dense and sparse vectors.
To configure a sparse vector index, create a collection with the following parameters:
httppythontypescriptrustjavacsharpgo
  * `on_disk: true` - The index is stored on disk, which lets you save memory. This may slow down search performance.
  * `on_disk: false` - The index is still persisted on disk, but it is also loaded into memory for faster search.
Unlike a dense vector index, a sparse vector index does not require a pre-defined vector size. It automatically adjusts to the size of the vectors added to the collection.
**Note:** A sparse vector index only supports dot-product similarity searches. It does not support other distance metrics.
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/indexing/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-indexing-full-text-index.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/optimizer/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-payload-bool.md`
  * `"2023-02-08T10:49:00Z"` (
  * `"2023-02-08T11:49:00+01:00"` (
  * `"2023-02-08T10:49:00"` (without timezone, UTC is assumed)
  * `"2023-02-08T10:49"` (without timezone and seconds)
  * `"2023-02-08"` (only date, midnight is assumed)
Notes about the format:
  * `T` can be replaced with a space.
  * The `T` and `Z` symbols are case-insensitive.
  * UTC is always assumed when the timezone is not specified.
  * Timezone can have the following formats: `±HH:MM`, `±HHMM`, `±HH`, or `Z`.
  * Seconds can have up to 6 decimals, so the finest granularity for `datetime` is microseconds.
##  [](https://qdrant.tech/documentation/concepts/payload/#payload-indexing)Payload indexing
To search more efficiently with filters, Qdrant allows you to create indexes for payload fields by specifying the name and type of field it is intended to be.
The indexed fields also affect the vector index. See [Indexing](https://qdrant.tech/documentation/concepts/indexing/) for details.
In practice, we recommend creating an index on those fields that could potentially constrain the results the most. For example, using an index for the object ID will be much more efficient, being unique for each record, than an index by its color, which has only a few possible values.
In compound queries involving multiple fields, Qdrant will attempt to use the most restrictive index first.
To create index for the field, you can use the following:
REST API ([Schema](https://api.qdrant.tech/api-reference/indexes/create-field-index))
httppythontypescriptrustjavacsharpgo
The index usage flag is displayed in the payload schema with the [collection info API](https://api.qdrant.tech/api-reference/collections/get-collection).
Payload schema example:
  * Know which unique values exist for a payload key.
  * Know the number of points that contain each unique value.
  * Know how restrictive a filter would become by matching a specific value.
Specifically, it is a counting aggregation for the values in a field, akin to a `GROUP BY` with `COUNT(*)` commands in SQL.
These results for a specific field is called a “facet”. For example, when you look at an e-commerce search results page, you might see a list of brands on the sidebar, showing the number of products for each brand. This would be a facet for a `"brand"` field.
In Qdrant you can facet on a field **only** if you have created a field index that supports `MatchValue` conditions for it, like a `keyword` index.
To get the facet counts for a field, you can use the following:
By default, the number of `hits` returned is limited to 10. To change this, use the `limit` parameter. Keep this in mind when checking the number of unique values a payload field contains.
REST API ([Facet](https://api.qdrant.tech/v-1-13-x/api-reference/points/facet))
httppythontypescriptrustjavacsharpgo
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/payload/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-payload-datetime.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/points/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-search-query-planning.md`
  * Dot product: `Dot` - 
  * Cosine similarity: `Cosine` - 
  * Euclidean distance: `Euclid` - 
  * Manhattan distance: `Manhattan`*- _*Available as of v1.7_
The most typical metric used in similarity learning models is the cosine metric.
![Embeddings](https://qdrant.tech/docs/cos.png)
Qdrant counts this metric in 2 steps, due to which a higher search speed is achieved. The first step is to normalize the vector when adding it to the collection. It happens only once for each vector.
The second step is the comparison of vectors. In this case, it becomes equivalent to dot production - a very fast operation due to SIMD.
Depending on the query configuration, Qdrant might prefer different strategies for the search. Read more about it in the [query planning](https://qdrant.tech/documentation/concepts/search/#query-planning) section.
  * `hnsw_ef` - value that specifies `ef` parameter of the HNSW algorithm.
  * `exact` - option to not use the approximate search (ANN). If set to true, the search may run for a long as it performs a full scan to retrieve exact results.
  * `indexed_only` - With this option you can disable the search in those segments where vector index is not built yet. This may be useful if you want to minimize the impact to the search performance whilst the collection is also being updated. Using this option may lead to a partial result if the collection is not fully indexed yet, consider using it only if eventual consistency is acceptable for your use case.
Since the `filter` parameter is specified, the search is performed only among those points that satisfy the filter condition. See details of possible filters and their work in the [filtering](https://qdrant.tech/documentation/concepts/filtering/) section.
Example result of this API would be
  * `payload.nested_field` - for a nested field
  * `payload.nested_array[].sub_field` - for projecting nested fields within an array
Accessing array elements by index is currently not supported.
##  [](https://qdrant.tech/documentation/concepts/search/#query-by-id)Query by ID
Whenever you need to use a vector as an input, you can always use a [point ID](https://qdrant.tech/documentation/concepts/points/#point-ids) instead.
httppythontypescriptrustjavacsharpgo
The above example will fetch the default vector from the point with this id, and use it as the query vector.
If the `using` parameter is also specified, Qdrant will use the vector with that name.
It is also possible to reference an ID from a different collection, by setting the `lookup_from` parameter.
httppythontypescriptrustjavacsharpgo
  * planning is performed for each segment independently (see [storage](https://qdrant.tech/documentation/concepts/storage/) for more information about segments)
  * prefer a full scan if the amount of points is below a threshold
  * estimate the cardinality of a filtered result before selecting a strategy
  * retrieve points using payload index (see [indexing](https://qdrant.tech/documentation/concepts/indexing/)) if cardinality is below threshold
  * use filterable vector index if the cardinality is above a threshold
You can adjust the threshold using a 
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/search/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-search.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/snapshots/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-storage.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/storage/)
                    ## 📄 `https-qdrant-tech-documentation-concepts-vectors.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/vectors/)
                    ## 📄 `https-qdrant-tech-documentation-concepts.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/concepts/)
                    ## 📄 `https-qdrant-tech-documentation-database-tutorials-async-api.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/database-tutorials/async-api/)
                    ## 📄 `https-qdrant-tech-documentation-database-tutorials-automate-filtering-with-llms.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/database-tutorials/automate-filtering-with-llms/)
                    ## 📄 `https-qdrant-tech-documentation-database-tutorials-bulk-upload.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/database-tutorials/bulk-upload/)
                    ## 📄 `https-qdrant-tech-documentation-database-tutorials-create-snapshot.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/database-tutorials/create-snapshot/)
                    ## 📄 `https-qdrant-tech-documentation-database-tutorials-huggingface-datasets.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/database-tutorials/huggingface-datasets/)
                    ## 📄 `https-qdrant-tech-documentation-database-tutorials-large-scale-search.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/database-tutorials/large-scale-search/)
                    ## 📄 `https-qdrant-tech-documentation-database-tutorials.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/database-tutorials/)
                    ## 📄 `https-qdrant-tech-documentation-embeddings.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/embeddings/)
                    ## 📄 `https-qdrant-tech-documentation-faq-database-optimization.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/faq/database-optimization/)
                    ## 📄 `https-qdrant-tech-documentation-faq-qdrant-fundamentals.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/faq/qdrant-fundamentals/)
                    ## 📄 `https-qdrant-tech-documentation-frameworks-autogen.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/frameworks/autogen/)
                    ## 📄 `https-qdrant-tech-documentation-frameworks-crewai.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/frameworks/crewai/)
                    ## 📄 `https-qdrant-tech-documentation-frameworks-langgraph.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/frameworks/langgraph/)
                    ## 📄 `https-qdrant-tech-documentation-frameworks-swarm.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/frameworks/swarm/)
                    ## 📄 `https-qdrant-tech-documentation-frameworks.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/frameworks/)
                    ## 📄 `https-qdrant-tech-documentation-guides-administration.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/administration/)
                    ## 📄 `https-qdrant-tech-documentation-guides-capacity-planning.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/capacity-planning/)
                    ## 📄 `https-qdrant-tech-documentation-guides-common-errors.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/common-errors/)
                    ## 📄 `https-qdrant-tech-documentation-guides-configuration.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/configuration/)
                    ## 📄 `https-qdrant-tech-documentation-guides-distributed-deployment.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/distributed_deployment/)
                    ## 📄 `https-qdrant-tech-documentation-guides-installation.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/installation/)
                    ## 📄 `https-qdrant-tech-documentation-guides-monitoring.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/monitoring/)
                    ## 📄 `https-qdrant-tech-documentation-guides-multiple-partitions.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/multiple-partitions/)
                    ## 📄 `https-qdrant-tech-documentation-guides-optimize.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/optimize/)
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-accuracy-tuning.md`
  * OpenAI `text-embedding-ada-002` - 1536d tested with 
  * Cohere AI `embed-english-v2.0` - 4096d tested on Wikipedia embeddings - 0.98 recall@50 with 2x oversampling
Models with a lower dimensionality or a different distribution of vector components may require additional experiments to find the optimal quantization parameters.
We recommend using binary quantization only with rescoring enabled, as it can significantly improve the search quality with just a minor performance impact. Additionally, oversampling can be used to tune the tradeoff between search speed and search quality in the query time.
  * **All in RAM** - all vector, original and quantized, are loaded and kept in RAM. This is the fastest mode, but requires a lot of RAM. Enabled by default.
  * **Original on Disk, quantized in RAM** - this is a hybrid mode, allows to obtain a good balance between speed and memory usage. Recommended scenario if you are aiming to shrink the memory footprint while keeping the search speed.
This mode is enabled by setting `always_ram` to `true` in the quantization config while using memmap storage:
httppythontypescriptrustjavacsharpgo
  * **All on Disk** - all vectors, original and quantized, are stored on disk. This mode allows to achieve the smallest memory footprint, but at the cost of the search speed.
It is recommended to use this mode if you have a large collection and fast storage (e.g. SSD or NVMe).
This mode is enabled by setting `always_ram` to `false` in the quantization config while using mmap storage:
httppythontypescriptrustjavacsharpgo
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/quantization/)
                    ## 📄 `https-qdrant-tech-documentation-guides-quantization-binary-quantization-as-hamming-distance.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/running-with-gpu/)
                    ## 📄 `https-qdrant-tech-documentation-guides-security.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/security/)
                    ## 📄 `https-qdrant-tech-documentation-guides-usage-statistics.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/usage-statistics/)
                    ## 📄 `https-qdrant-tech-documentation-guides.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/guides/)
                    ## 📄 `https-qdrant-tech-documentation-hybrid-cloud.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/hybrid-cloud/)
                    ## 📄 `https-qdrant-tech-documentation-interfaces-api-reference.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/interfaces/)
                    ## 📄 `https-qdrant-tech-documentation-interfaces.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/overview/vector-search/)
                    ## 📄 `https-qdrant-tech-documentation-overview.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/overview/)
                    ## 📄 `https-qdrant-tech-documentation-quantization-setting-up-quantization-in-qdrant.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/quantization/)
                    ## 📄 `https-qdrant-tech-documentation-quick-start.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/quick-start/)
                    ## 📄 `https-qdrant-tech-documentation-quickstart-cloud.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/quickstart-cloud/)
                    ## 📄 `https-qdrant-tech-documentation-quickstart.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/quickstart/)
                    ## 📄 `https-qdrant-tech-documentation-search-query-planning.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/search/)
                    ## 📄 `https-qdrant-tech-documentation-tutorials-multimodal-search-fastembed.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/tutorials/multimodal-search-fastembed/)
                    ## 📄 `https-qdrant-tech-documentation-tutorials.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/tutorials/)
                    ## 📄 `https-qdrant-tech-documentation-web-ui.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/web-ui/)
                    ## 📄 `https-qdrant-tech-documentation.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/documentation/)
                    ## 📄 `https-qdrant-tech-enterprise-solutions.md`
##### Manual Infrastructure Management Overhead
Enterprises often struggle to keep up with scaling demands. **Manual cluster provisioning and management** lead to slow deployments, human errors, and high operational costs.
Enterprises like Bosch use Qdrant for unparalleled performance and massive-scale vector search. “With Qdrant, we found the missing piece to develop our own provider independent multimodal generative AI platform at enterprise scale.”
![Jeremy Teichmann Avatar](https://qdrant.tech/img/customers/jeremy-t-daly-singh.svg)
Jeremy Teichmann & Daly Singh
Generative AI Expert & Product Owner
![Logo](https://qdrant.tech/img/brands/bosch.svg)
“Vector stores are definitely here to stay, the objects in the world around us from image, sound, video and text become easily universal and searchable thanks to the embedding models and vector stores. I personally recommend Qdrant. We have been using it for a while and couldn’t be happier.”
![Hooman Sedghamiz Avatar](https://qdrant.tech/img/customers/hooman-sedghamiz.svg)
Hooman Sedghamiz
Director AI/ML, Bayer
![Logo](https://qdrant.tech/img/brands/bayer.svg)
Do you have further questions? We are happy to assist you.
[Contact us ](https://qdrant.tech/contact-us/)[Contact us](https://qdrant.tech/contact-us/)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/enterprise-solutions/)
                    ## 📄 `https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-articles-product-quantization-md.md`
![Galaxy](https://qdrant.tech/img/404-galaxy.svg) ![Galaxy](https://qdrant.tech/img/404-galaxy-mobile.svg)
Oops! We can't find the page you were looking for.
[Go to Home ](https://qdrant.tech/)
                    ## 📄 `https-qdrant-tech-github-com-qdrant-landing-page-tree-master-qdrant-landing-content-articles-scalar-quantization-md.md`
#### Ready to get started with Qdrant?
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
×
[ Powered by ](https://qdrant.tech/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/guides/distributed_deployment/)
                    ## 📄 `https-qdrant-tech-hybrid-cloud.md`
### Get started today
Turn embeddings or neural network encoders into full-fledged applications for matching, searching, recommending, and more.
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/hybrid-cloud/)
                    ## 📄 `https-qdrant-tech-legal-impressum.md`
### Google Analytics
Diese Website benutzt Google Analytics, einen Webanalysedienst der Google Inc. (‘‘Google’’). Google Analytics verwendet sog. ‘‘Cookies’’, Textdateien, die auf Ihrem Computer gespeichert werden und die eine Analyse der Benutzung der Website durch Sie ermöglicht. Die durch den Cookie erzeugten Informationen über Ihre Benutzung dieser Website (einschließlich Ihrer IP-Adresse) wird an einen Server von Google in den USA übertragen und dort gespeichert. Google wird diese Informationen benutzen, um Ihre Nutzung der Website auszuwerten, um Reports über die Websiteaktivitäten für die Websitebetreiber zusammenzustellen und um weitere mit der Websitenutzung und der Internetnutzung verbundene Dienstleistungen zu erbringen. Auch wird Google diese Informationen gegebenenfalls an Dritte übertragen, sofern dies gesetzlich vorgeschrieben oder soweit Dritte diese Daten im Auftrag von Google verarbeiten. Google wird in keinem Fall Ihre IP-Adresse mit anderen Daten der Google in Verbindung bringen. Sie können die Installation der Cookies durch eine entsprechende Einstellung Ihrer Browser Software verhindern; wir weisen Sie jedoch darauf hin, dass Sie in diesem Fall gegebenenfalls nicht sämtliche Funktionen dieser Website voll umfänglich nutzen können. Durch die Nutzung dieser Website erklären Sie sich mit der Bearbeitung der über Sie erhobenen Daten durch Google in der zuvor beschriebenen Art und Weise und zu dem zuvor benannten Zweck einverstanden.
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/legal/impressum/)
                    ## 📄 `https-qdrant-tech-legal-privacy-policy.md`
  * Qdrant needs to perform a contract with you
  * You have given Qdrant permission to do so
  * Processing your personal information is in Qdrant legitimate interests
  * Qdrant needs to comply with the law
Qdrant will retain your personal information only for as long as is necessary for the purposes set out in this Privacy Policy. We will retain and use your information to the extent necessary to comply with our legal obligations, resolve disputes, and enforce our policies.
If you are a resident of the European Economic Area (EEA), you have certain data protection rights. If you wish to be informed what Personal Information we hold about you and if you want it to be removed from our systems, please contact us. In certain circumstances, you have the following data protection rights:
  * The right to access, update or to delete the information we have on you.
  * The right of rectification.
  * The right to object.
  * The right of restriction.
  * The right to data portability
  * The right to withdraw consent
## Consent
By using our website, you hereby consent to our Privacy Policy and agree to its terms.
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/legal/privacy-policy/)
                    ## 📄 `https-qdrant-tech-legal-terms-and-conditions.md`
### Contact Us
If you have any questions about these Terms and Conditions, You can contact us:
By email: 
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/legal/terms_and_conditions/)
                    ## 📄 `https-qdrant-tech-misc-qdrant-security-public-key-asc.md`
### Become a Certified Solutions Partner
We partner with industry leaders to deliver innovative solutions and an exceptional customer experience.
[Become a Partner](https://qdrant.tech/contact-us/)
![](https://qdrant.tech/img/partner-banner.svg)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/partners/)
                    ## 📄 `https-qdrant-tech-pricing.md`
### Deploy Qdrant locally with Docker
Get started with our [Quick Start Guide](https://qdrant.tech/documentation/quick-start/), or our main 
`1 docker pull qdrant/qdrant  
2 docker run -p 6333:6333 qdrant/qdrant  
`
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/pricing/)
                    ## 📄 `https-qdrant-tech-private-cloud.md`
###### Qdrant Private Cloud offers a dedicated, on-premise solution that guarantees supreme data privacy and sovereignty.
![Private cloud data privacy](https://qdrant.tech/img/private-cloud-data-privacy.svg)
Designed for enterprise-grade demands, it provides a seamless management experience for your vector database, ensuring optimal performance and security for vector search and AI applications.
To learn more about Qdrant Private Cloud, please contact our team.
[Contact us ](https://qdrant.tech/contact-us/)[Contact us](https://qdrant.tech/contact-us/)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/private-cloud/)
                    ## 📄 `https-qdrant-tech-qdrant-for-startups-form.md`
# Qdrant for Startups
Qdrant for Startups is committed to being the catalyst for the next generation of AI innovators.  
Our program is specifically designed to provide AI-focused startups with the right resources to scale. If AI is at the heart of your startup, you're in the right place.
[Apply Now](https://qdrant.tech/qdrant-for-startups/#form)
![Qdrant for Startups](https://qdrant.tech/img/startups-program.svg)
###### Who can I contact for more information about the program?
After reading these FAQs in full, if you need more details or assistance, please contact 
[Apply Now](https://qdrant.tech/qdrant-for-startups/#form)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/qdrant-for-startups/)
                    ## 📄 `https-qdrant-tech-qdrant-for-startups.md`
### Qdrant Cloud is the fastest way to get started with Qdrant.
![](https://qdrant.tech/img/rocket.svg)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/qdrant-vector-database/)
                    ## 📄 `https-qdrant-tech-rag-rag-evaluation-guide.md`
  * Search precision
  * Recall
  * Contextual relevance
  * Response accuracy.
![Search text](https://qdrant.tech/icons/outline/search-text-blue.svg)
### Read Qdrant’s Best Practices in RAG Evaluation guide for a deep dive into:
![Case study](https://qdrant.tech/icons/outline/case-study-blue.svg)
Why RAG evaluation is crucial for your AI's success
![Similarity](https://qdrant.tech/icons/outline/similarity-blue.svg)
Recommended frameworks for comprehensive assessment
![Bug](https://qdrant.tech/icons/outline/bug-blue.svg)
How to identify and solve common RAG performance issues
![Cloud connections](https://qdrant.tech/icons/outline/cloud-connections-blue.svg)
Techniques for working with custom datasets
![Chart bar](https://qdrant.tech/icons/outline/chart-bar-blue.svg)
Essential metrics to monitor during testing
[Download the Guide](https://qdrant.tech/rag/rag-evaluation-guide/#form)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/rag/rag-evaluation-guide/)
                    ## 📄 `https-qdrant-tech-rag.md`
## Best Practices in RAG Evaluation
Learn how to assess, calibrate, and optimize your RAG applications for long-term success.
[Get the Guide](https://qdrant.tech/rag/rag-evaluation-guide/)
![RAG guide](https://qdrant.tech/img/retrieval-augmented-generation-evaluation/guide-graphic.svg)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/rag/)
                    ## 📄 `https-qdrant-tech-recommendations.md`
##### Recommendation Engine with Qdrant Vector Database
Dailymotion's Journey to Crafting the Ultimate Content-Driven Video Recommendation Engine with Qdrant Vector Database.
[Read Case Study](https://qdrant.tech/blog/case-study-dailymotion/)
![Preview](https://qdrant.tech/img/recommendations-use-cases/case-study.png)
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/recommendations/)
                    ## 📄 `https-qdrant-tech-security-bug-bounty-program.md`
  * *.cloud.qdrant.io Qdrant Cloud Application
  * [qdrant.tech](http://qdrant.tech/) Website
In most cases, we will only reward the following types of vulnerabilities:
  * Arbitrary code execution and OS Command Injection
  * Stored Cross-Site Scripting (Stored XSS)
  * SQL injection
  * File Upload
  * Authentication bypass and privilege escalation (authentication / authorization circumvention)
  * Significant Sensitive Data Exposure
  * Server-Side Request Forgery (SSRF)
  * Critical Business Logic Flaws
  * Email: 
  * PGP Key Fingerprint: [07E3 6646 E0D0 A3BF 0AFC B302 26C5 016B 97EB 804B](https://qdrant.tech/misc/qdrant-security-public-key.asc)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/security/bug-bounty-program/)
                    ## 📄 `https-qdrant-tech-solutions.md`
## Qdrant Vector Database Use Cases
Explore the vast applications of the Qdrant vector database. From retrieval augmented generation to anomaly detection, advanced search, and recommendation systems, our solutions unlock new dimensions of data and performance.
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/solutions/)
                    ## 📄 `https-qdrant-tech-stars.md`
###### M K Pavan Kumar
Data Scientist and Lead GenAI
Kameshwara Pavan Kumar Mantha is a seasoned technology expert with 14 years of extensive experience in full stack development, cloud solutions, and artificial intelligence.  
Specializing in Generative AI and Large Language Models, Pavan has established himself as a leader in these cutting-edge domains.
![M K Pavan Kumar Photo](https://qdrant.tech/img/stars/m-k-pavan-kumar.jpg)
![Robert Caulk Photo](https://qdrant.tech/img/stars/robert-caulk.jpg)
### Are you contributing to our code, content, or community?
![](https://qdrant.tech/img/stars.svg)
[![Qdrant Logo](https://qdrant.tech/img/logo-white.png)](https://qdrant.tech/ "Go to Home Page")
Powering the next generation of AI applications with advanced, high-performant vector similarity search technology.
Products
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech/stars/)
                    ## 📄 `https-qdrant-tech-subscribe.md`
##### Sign up for Qdrant Updates
Stay up to date on product news, technical articles, and upcoming educational webinars.
![Astronaut](https://qdrant.tech/img/subscribe.png) ![Astronaut](https://qdrant.tech/img/mobile/subscribe.png)
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy ](https://qdrant.tech/legal/privacy-policy/)[Impressum](https://qdrant.tech/legal/impressum/)
                    ## 📄 `https-qdrant-tech.md`
[Pricing](https://qdrant.tech/pricing/)
Sign up for Qdrant updates
We'll occasionally send you best practices for using vector data and similarity search, as well as product news.
© 2025 Qdrant. All Rights Reserved
[Terms](https://qdrant.tech/legal/terms_and_conditions/) [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) [Impressum](https://qdrant.tech/legal/impressum/)
We use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.
[Learn more](https://qdrant.tech/legal/privacy-policy/)[I accept](https://qdrant.tech)
                    ## 📄 `https-try-qdrant-tech-5-minute-rag-hslang-en.md`
  * Basic understanding of Python
  * Enthusiasm for AI and natural language processing
  * Familiarity with machine learning concepts is helpful, but not required
[ Watch the recording ](https://try.qdrant.tech/5-minute-rag?hsLang=en#form)
### Watch now
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=93ea8069-a8f9-4e5e-9dbf-61e2e5f00bb9&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=a2d38636-fd03-4d31-aaa8-1b4779598ef1&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2F5-minute-rag&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=93ea8069-a8f9-4e5e-9dbf-61e2e5f00bb9&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=a2d38636-fd03-4d31-aaa8-1b4779598ef1&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2F5-minute-rag&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=e5d44dad-1da4-47ef-9d68-369a3b6c5511&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=a2d38636-fd03-4d31-aaa8-1b4779598ef1&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2F5-minute-rag&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=e5d44dad-1da4-47ef-9d68-369a3b6c5511&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=a2d38636-fd03-4d31-aaa8-1b4779598ef1&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2F5-minute-rag&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-agentic-rag-crewai-hslang-en.md`
  * AI/ML Engineers
  * Solutions Architects  
  * Software Developers  
  * Technical Product Managers
  * Basic understanding of vector databases and embeddings  
  * Familiarity with Python 
  * General knowledge of LLMs and their applications
  * No specific CrewAI or Qdrant experience required  
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=0990c2e9-f1d8-4725-87e6-0ed49484838a&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1062e527-e040-4558-ae16-b861acdf42f7&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fagentic-rag-crewai&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=0990c2e9-f1d8-4725-87e6-0ed49484838a&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1062e527-e040-4558-ae16-b861acdf42f7&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fagentic-rag-crewai&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=488a467b-9985-4cd5-ae33-85ad7781d128&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1062e527-e040-4558-ae16-b861acdf42f7&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fagentic-rag-crewai&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=488a467b-9985-4cd5-ae33-85ad7781d128&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1062e527-e040-4558-ae16-b861acdf42f7&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fagentic-rag-crewai&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-ai-agents-webinar-hslang-en.md`
  * to make the LLM produce consistent output in the required format
  * to seamlessly integrate tools with AI agents
  * debug and manage agentic pipelines
all of which can be difficult. 
### Speakers
![Screenshot 2024-11-13 at 7.38.46 AM](https://try.qdrant.tech/hs-fs/hubfs/Screenshot%202024-11-13%20at%207.38.46%20AM.png?width=500&height=436&name=Screenshot%202024-11-13%20at%207.38.46%20AM.png)
Max Tkacz 
Senior Developer Advocate, n8n 
![T027ADPGJUB-U07BZCSUM7H-70b6368e98ff-512](https://try.qdrant.tech/hs-fs/hubfs/Imported%20sitepage%20images/T027ADPGJUB-U07BZCSUM7H-70b6368e98ff-512.jpg?width=512&height=512&name=T027ADPGJUB-U07BZCSUM7H-70b6368e98ff-512.jpg)
Jenny Sukhodolskaya
Developer Advocate, Qdrant 
[ Watch now ](https://try.qdrant.tech/ai-agents-webinar?hsLang=en)
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=14aed9bc-811d-4051-862e-df98a99e305a&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=2efe3d48-60ae-4307-95c8-430b4ea647fa&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fai-agents-webinar&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=14aed9bc-811d-4051-862e-df98a99e305a&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=2efe3d48-60ae-4307-95c8-430b4ea647fa&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fai-agents-webinar&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=9d1bab86-3b0f-4e60-9997-ae8b9e1c5006&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=2efe3d48-60ae-4307-95c8-430b4ea647fa&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fai-agents-webinar&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=9d1bab86-3b0f-4e60-9997-ae8b9e1c5006&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=2efe3d48-60ae-4307-95c8-430b4ea647fa&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fai-agents-webinar&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-build-advanced-agents-with-llamaindex-and-qdrant-hslang-en.md`
### Watch now
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=d30dd01c-2815-4376-90a0-c922c3ff3388&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=e4931397-d0bc-4c25-9255-6f9198961e64&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fbuild-advanced-agents-with-llamaindex-and-qdrant&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=d30dd01c-2815-4376-90a0-c922c3ff3388&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=e4931397-d0bc-4c25-9255-6f9198961e64&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fbuild-advanced-agents-with-llamaindex-and-qdrant&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=14ef0320-d295-4858-b18c-2b2b00382e7f&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=e4931397-d0bc-4c25-9255-6f9198961e64&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fbuild-advanced-agents-with-llamaindex-and-qdrant&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=14ef0320-d295-4858-b18c-2b2b00382e7f&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=e4931397-d0bc-4c25-9255-6f9198961e64&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fbuild-advanced-agents-with-llamaindex-and-qdrant&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-colpali-webinar-hslang-en.md`
# Using ColPali and Binary Quantization for Efficient Multimodal Retrieval  
In this webinar, we explored the technical details of ColPali, an advanced multimodal retrieval approach that uses Vision Language Models (VLMs) to handle visually complex documents.
Learn how ColPali uses **multivectors** to represent document images, capturing both local and global context.
  * **Multivectors** : Representing documents as multiple embeddings to capture both local and global context, enhancing search accuracy.
  * **Late Interaction** : Performing token-level comparisons between queries and document patches for precise relevance scoring.
  * **MaxSim Pooling** : Aggregating the highest similarity scores from these comparisons to identify the most relevant document sections.
  * **Binary Quantization** : Compressing vector data to optimize memory usage and accelerate search with minimal accuracy loss.
Learn how these techniques can be applied for efficient multimodal retrieval for complex, visually-rich documents.
### Watch the video
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=6c665b90-a288-4e23-b08e-5799633ae398&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=dcdef2b9-950c-44d9-82ce-f71bc4984e48&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fcolpali-webinar&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=6c665b90-a288-4e23-b08e-5799633ae398&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=dcdef2b9-950c-44d9-82ce-f71bc4984e48&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fcolpali-webinar&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=f635eb16-af84-4ee4-8be2-15153c26b5a1&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=dcdef2b9-950c-44d9-82ce-f71bc4984e48&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fcolpali-webinar&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=f635eb16-af84-4ee4-8be2-15153c26b5a1&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=dcdef2b9-950c-44d9-82ce-f71bc4984e48&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fcolpali-webinar&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-deepseek-hslang-en.md`
  * Build privacy-first AI Agents
  * Deploy DeepSeek models locally
  * Secure vector search data with Qdrant
  * Learn the benefits of optimized vector search
  * Understand the cost and benefit of open-source infrastructure
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=7f4e1a20-9891-4f4c-8ce9-c4d8d9409c08&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=30e317f6-733f-494d-b3e9-c06d2e5e30d3&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeepseek&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=7f4e1a20-9891-4f4c-8ce9-c4d8d9409c08&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=30e317f6-733f-494d-b3e9-c06d2e5e30d3&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeepseek&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=9cffd099-2eb4-4a59-9020-a79a80a3fd97&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=30e317f6-733f-494d-b3e9-c06d2e5e30d3&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeepseek&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=9cffd099-2eb4-4a59-9020-a79a80a3fd97&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=30e317f6-733f-494d-b3e9-c06d2e5e30d3&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeepseek&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-deutsche-telekom-talk-hslang-en.md`
# How Deutsche Telekom Scaled an Enterprise Multi-Agent Platform with Qdrant, Powering 2M+ Conversations
Deutsche Telekom’s AI Competence Center (AICC) had a critical challenge: how do you efficiently and scalably deploy AI-powered assistants across a vast enterprise ecosystem?  
The goal was to deploy GenAI for customer sales and service operations to resolve customer queries faster across the 10 countries where Deutsche Telekom operates in Europe.  
In this Vector Space talk, Thierry from Qdrant and Arun from Deutsche Telekom talk about the key requirements for scaling enterprise AI agents, key AI stack considerations, and how the team built a Platform as a Service (PaaS) - LMOS (Language Models Operating System) — a multi-agent PaaS designed for high scalability and modular AI agent deployment.
### Hear from:
![Arun-Telekom](https://try.qdrant.tech/hs-fs/hubfs/Arun-Telekom.jpeg?width=800&height=800&name=Arun-Telekom.jpeg)
Arun Joseph
Engineering & Architecture Lead  
AI Competence Center  
Deutsche Telekom
![IMG_2960-removebg-preview-2](https://try.qdrant.tech/hs-fs/hubfs/IMG_2960-removebg-preview-2.png?width=204&height=222&name=IMG_2960-removebg-preview-2.png)
Thierry Damiba
Developer Advocate  
Qdrant
Learn how Telekom's LMOS with Qdrant processes over 2 million conversations across three countries, and decreased the time required to develop a new agent from 15 days to just 2. 
[ Watch now ](https://try.qdrant.tech/deutsche-telekom-talk?hsLang=en#form)
![Deutsche-Telekom-Case-Study-A-cropped](https://try.qdrant.tech/hs-fs/hubfs/Deutsche-Telekom-Case-Study-A-cropped.jpg?width=2000&height=1241&name=Deutsche-Telekom-Case-Study-A-cropped.jpg)
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=50db269c-4582-46fe-bfb5-959596a59cee&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=51b5441a-fc9e-43cb-ba7d-c6ae31b76d93&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeutsche-telekom-talk&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=50db269c-4582-46fe-bfb5-959596a59cee&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=51b5441a-fc9e-43cb-ba7d-c6ae31b76d93&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeutsche-telekom-talk&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=47d83fa0-8acf-4d0f-99db-4c8e82499180&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=51b5441a-fc9e-43cb-ba7d-c6ae31b76d93&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeutsche-telekom-talk&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=47d83fa0-8acf-4d0f-99db-4c8e82499180&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=51b5441a-fc9e-43cb-ba7d-c6ae31b76d93&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fdeutsche-telekom-talk&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-events.md`
### 
Build with Qdrant
Turn embeddings or neural network encoders into full-fledged applications for matching, searching, recommending, and more. You can start prototyping with your forever-free first cluster. 
[ Try now ](https://qdrant.tech/)
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=d0b008c9-30ef-414d-ae4d-ae7b0905af60&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=7ba862fc-bddb-4346-8f7d-50708b475974&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fevents&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=d0b008c9-30ef-414d-ae4d-ae7b0905af60&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=7ba862fc-bddb-4346-8f7d-50708b475974&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fevents&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=ff6b84d7-6022-4859-b78e-8f8e8aca9613&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=7ba862fc-bddb-4346-8f7d-50708b475974&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fevents&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=ff6b84d7-6022-4859-b78e-8f8e8aca9613&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=7ba862fc-bddb-4346-8f7d-50708b475974&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fevents&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-llm-rag-hslang-en.md`
  * Basic understanding of software development, particularly in frontend and backend frameworks.
  * Familiarity with the concepts of RAG and vector search.
  * Some experience with general programming concepts will be helpful.
  * No prior knowledge of specific coding assistants like Cursor, Aider, or Claude required.
[ Watch now ](https://try.qdrant.tech/llm-rag?hsLang=en#hero)
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=ad6f5e8e-01a1-4243-9900-6ec69554d20f&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1595c2b1-4e79-4f47-9546-7c16d007e970&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fllm-rag&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=ad6f5e8e-01a1-4243-9900-6ec69554d20f&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1595c2b1-4e79-4f47-9546-7c16d007e970&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fllm-rag&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=0fc00e21-c6f7-490c-96a3-7d28776e6763&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1595c2b1-4e79-4f47-9546-7c16d007e970&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fllm-rag&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=0fc00e21-c6f7-490c-96a3-7d28776e6763&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=1595c2b1-4e79-4f47-9546-7c16d007e970&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fllm-rag&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ## 📄 `https-try-qdrant-tech-mcp-agent-interoperability-hslang-en.md`
  * What MCP is and why it's suddenly everywhere
  * The fundamentals of MCP: how it enables agent communication via a shared event bus
  * Setting up an MCP server and connecting multiple clients (OpenAI Agents, AugmentCode, custom tools)
  * Using Qdrant as a vector backend for memory, code context, and retrieval-augmented workflows
  * Where Qdrant fits in as the vector search layer for agent memory and tool use  
  * Real-time agent orchestration inside your IDE, with multi-agent collaboration on tasks like code generation, refactoring, and debugging
  * Real-world demos of coding agents collaborating in an IDE
  * How to extend these tools for your own AI developer workflows
Whether you're experimenting with AI-supported coding or building your own developer agents, this session will give you practical, future-ready insights into using MCP with real tools.
### Register Now
Qdrant needs the contact information you provide to us to contact you about our products and services. You may unsubscribe from these communications at any time. For information on how to unsubscribe, as well as our privacy practices and commitment to protecting your privacy, please review our Privacy Policy.
By registering, you agree to our [Privacy Policy](https://qdrant.tech/legal/privacy-policy/) and allow Qdrant to store and process the information submitted above to provide you with the webinar information requested.  
All rights are reserved 
![](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=44e57178-0670-478e-aa5d-b1c0020c01cd&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=b1db5c60-8f0a-4603-acc6-407644c406d0&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fmcp-agent-interoperability&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=2&event_id=44e57178-0670-478e-aa5d-b1c0020c01cd&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=b1db5c60-8f0a-4603-acc6-407644c406d0&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fmcp-agent-interoperability&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o81g6&type=javascript&version=2.3.31) ![](https://t.co/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=640fc627-194e-45ac-a94e-e4a577b9cfe4&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=b1db5c60-8f0a-4603-acc6-407644c406d0&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fmcp-agent-interoperability&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)![](https://analytics.twitter.com/1/i/adsct?bci=5&dv=UTC%26en-US%2Cen%26Google%20Inc.%26Linux%20x86_64%26255%261080%26600%264%2624%261080%26600%260%26na&eci=3&event=%7B%7D&event_id=640fc627-194e-45ac-a94e-e4a577b9cfe4&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=b1db5c60-8f0a-4603-acc6-407644c406d0&tw_document_href=https%3A%2F%2Ftry.qdrant.tech%2Fmcp-agent-interoperability&tw_iframe_status=0&txn_id=o81g6&type=javascript&version=2.3.31)
                    ```